[{"categories":null,"content":"介绍怎么开启GC日志采集。\nJava  1-XX:+PrintGC 2-XX:+PrintGCTimeStamps 3-XX:+PrintGCDetails 4-Xloggc:/path/to/gc.log 5-XX:+UseGCLogFileRotation 6-XX:NumberOfGCLogFiles=5 前4个参数文档在Java 8文档 ，后两个参数的文档只能在Java 7文档 看到，不过Java 8也能用。\n如果你不想要日志滚动，可以这样：\n1-XX:+PrintGC 2-XX:+PrintGCTimeStamps 3-XX:+PrintGCDetails 4-Xloggc:/path/to/gc-%t.log 形成的文件会是YYYY-MM-DD_HH-MM-SS（程序启动的时间）这个形式（见这篇Blog ）。\nJava = 9 Java 9开始，使用Xlog（文档） 统一了所有日志的输出，所以参数要变化：\n1-Xlog:gc*:file=/path/to/gc.log:time,level,tags:filecount=5,filesize=5M 如果你不想要日志滚动，可以这样：\n1-Xlog:gc*:file=/path/to/gc-%t.log:time,level,tags:filecount=0 ","date":"2022-01-15","img":"","permalink":"/post/jvm/gc-log-options/","series":null,"tags":["jvm","gc"],"title":"JVM - GC日志参数"},{"categories":null,"content":"本文专注于从程序角度看如何使用Redis集群，以及相关的方案。\n概要 为何要做集群？主要原因就是为了做Sharding/Partitioning，所以Redis集群方案等价为Redis Sharding/Partitioning方案。\nPartitioning: how to split data among multiple Redis instances 对Redis做集群的利弊和考量做了详细说明。因此，在确定方案之前，要先确定你的Redis是用来做什么的？做Cache还是数据持久化，不同方案对此的支持程度是不同的。不言自明的是，如果Redis用途是Cache，整个集群方案会更简单。\n需要注意的是，无论采取何种方案，因为Sharding的存在，天然会导致有些命令在集群环境下是无法（正常）工作的，因此对于程序的改造是不可避免的。\nRedis集群的方案基本上由以下组件构成：\n Client Proxy Redis实例  集群管理组件和Redis Sentinel不在本文的探讨范围之内。\n而这些组件又可以做出以下细分：\n   组件 类型 说明     Redis simple 最简单的standalone Redis实例    cluster Redis Cluster    Proxy sharding 连接多个Redis Simple实例，内置Sharding逻辑    cluster 支持Redis Cluster    Client simple 傻瓜式客户端，只能连接单个Redis Simple实例    sharding 连接多个Redis Simple实例，内置Sharding逻辑    cluster 支持Redis Cluster     组件 具体讲讲集群的各个组件，以及可用的开源项目。\nProxy 不管何种Proxy，其目的都是伪装成一个Simple Redis实例，使得程序无需改造就能够利用Redis集群。\nsharding类型 这种类型的Proxy连接多个simple redis实例，根据自己的Sharding/LB算法，把请求分配到各个redis实例上。\n这类Proxy 需要配合 Dashboard（管理组件）才能够更新节点列表。更复杂的运维任务也需要Dashboard配合。\ncluster类型 这种类型的Proxy直接连接在Redis Cluster 上，集群的管理工作全部交给Redis Cluster ，Proxy能够感知到集群节点变化，并且路由命令到正确的Slot上，避免MOVED/ASK重定向，提升执行效率。\n开源项目    项目 sharding cluster 维护 说明     twemproxy  Y  不活跃    corvus  Y  停止 改进twemproxy ，饿了么   Codis  Y  停止 改进twemproxy ，自带Dashboard，豌豆荚   samaritan  ? Y 停止 corvus 的继任项目，sidecar形式的proxy，只支持Redis \u0026lt;= 5.0，配套Dashboard sash    Redis Cluster Proxy   Y 停止 官方搞的，处于alpha状态，不推荐生产使用   envoy  ? Y 活跃 sidecar形式的proxy, redis只是其中一项功能   camellia-redis-proxy  Y Y 活跃 网易   bilibili-overlord  Y Y 不活跃 B站    Client Client方案和Proxy方案类似，可以类比为把Proxy的基本功能以类库的形式集成到Client里。\nsimple （傻瓜式）client没什么好谈的，就是最简单的客户端，只能连接一个Redis实例。\n随着技术的发展，有些simple client也渐渐支持sharding和cluster特性。\n不过需要注意的是，某些Client的实现不是太好，不同模式的API形式不一致，这意味着一定的改造成本。\nsharding类型 这种类型的Client连接多个simple redis实例，根据自己的Sharding/LB算法，把请求分配到各个redis实例上。\n这类Client 需要配合 Dashboard（管理组件）才能够更新节点列表。更复杂的运维任务也需要Dashboard配合。\ncluster类型 这种类型的 Client 直接支持 Redis Cluster 协议，能够感知到集群中节点的变化。\n开源项目    项目 sharding cluster API一致 维护 说明     jedis  ShardedJedis   N     lettuce   Y Y 活跃    camellia-redis  Y Y Y 活跃 网易    结论 根据上面的信息，可以组合出以下几种方案（方案顺序最便利-\u0026gt;最麻烦）：\n   Client Proxy Redis 便利性     simple cluster cluster 无改动   simple sharding simple 无改动，另外需要Dashboard来管理集群   cluster \u0026ndash; cluster 可能有改动   sharding \u0026ndash; simple 可能有改动，无改动，另外需要Dashboard来管理集群    注意：这里的程序改动指的是建立连接或者API的改动，不包括Redis命令的改动，这部分改动是不可避免的。\n","date":"2022-01-13","img":"","permalink":"/post/redis/redis-cluster-solutions-compare/","series":null,"tags":["redis","分布式算法"],"title":"Redis集群方案对比"},{"categories":null,"content":"容器使用了 Linux Namespace 技术，通过Namespace技术可以做到网络、PID、用户等等信息的隔离，因此就产生了容器。\n但是这种隔离并非物理隔离，只是一种逻辑上的隔离，如果你是root用户，Host上可以看到一切信息。\n以PID Namespace来说，容器内进程的PID从1开始，但其在Host上的PID不仅可以看见，而且是另外一个值。\n以用户 Namespace来说，容器内的用户UID和用户组GID，是可以和Host上的现有用户、用户组冲突的，比如容器内有个用户foo UID=1000，Host上有个用户 bar UID=1000，完全没有任何问题。\n同时容器fs在Host的 /proc/\u0026lt;host pid\u0026gt;/root 目录下（参考这个 ），如果以 bar 用户 操作这个目录下需要foo 用户的文件/目录也是完全没有任何问题的，因为 bar的foo的UID相同。\n下面是一些脚本\n得到容器在Host上的PID：\n1docker inspect $container_id -f \u0026#39;{{.State.Pid}}\u0026#39; 探测容器用户、UID、用户组、GID：\n1# 先touch个一文件 2$ docker exec $container_id touch /tmp/.pod_jvm_tools 3# stat这个文件 4$ docker exec $container_id stat -c \u0026#39;%u %U %g %G\u0026#39; /tmp/.pod_jvm_tools) 51000 java-app 65535 nogroup 6[uid] [usr] [gid] [group] 检查当前系统有没有用户、用户组：\n1getent passwd [uid] 2getent group [gid] nsenter ，进入某个PID的Namesapce，然后执行某些命令:\n1nsenter -t \u0026lt;pid\u0026gt; -a -r runuser ，以某用户某group身份执行某些命令：\n1runuser -u \u0026lt;usr\u0026gt; -g \u0026lt;group\u0026gt; -m -- cat /proc/\u0026lt;pid\u0026gt;/root/path/to/file pgrep ，列出同属某进程Namespace的所有其他进程：\n1pgrep --ns \u0026lt;pid\u0026gt; -a lsns ，显示每个容器的根namesapce，但实际用下来没有搞明白（可以参考这个 和这个 ），没有nsenter好用：\n1lsns -t pid ","date":"2021-12-07","img":"","permalink":"/post/linux/namespace/","series":null,"tags":["linux","kernel","docker"],"title":"Linux命名空间一些笔记"},{"categories":null,"content":"本文介绍JDK 8的jps、jstat、jstack \u0026hellip; 的工作原理。\nJvmstat Performance Counters jps和jstat命令使用的是Jvmstat Performance Counters 。\njps 先说结论：\n jps命令扫描的是 $TMPDIR/hsperfdata_$usr 下的PID文件。比如在 Linux 系统下，/tmp/hsperfdata_foo/2121，这体现两个信息，JVM进程的PID是2121，启动这个进程的是foo用户。  源码脉络：\n Jps.java  MonitoredHost (javadoc ) 有三子类。 看local实现：MonitoredHostProvider.java  LocalVmManager.java  PerfDataFile.java 规定了PID文件的匹配模式，tmpDirName 属性是平台相关的 VMSupport.c -\u0026gt; jvm.h -\u0026gt; jvm.cpp 规定了 JVM_GetTemporaryDirectory的返回值  所以说，如果你把别的机器的/tmp/hsperfdata_\u0026lt;usr\u0026gt;/\u0026lt;pid\u0026gt; 复制到你本地，jps也是能够返回结果的。\n但是，前提是PID得在你的机器上存在，比如别的机器上PID是2121，那么你的机器上也必须有PID=2121的进程，无论这个进程是什么。否则jps会返回 -- process information unavailable 这样的信息。\n如果你这样执行jps（其实所有命令都可以这样执行），可以看到异常：\n1java -cp $JAVA_HOME/lib/tools.jar -Djps.debug=true -Djps.printStackTrace=true sun.tools.jps.Jps 2 3sun.jvmstat.monitor.MonitorException: 2121 not found 4 at sun.jvmstat.perfdata.monitor.protocol.local.PerfDataBuffer.\u0026lt;init\u0026gt;(PerfDataBuffer.java:84) 5 at sun.jvmstat.perfdata.monitor.protocol.local.LocalMonitoredVm.\u0026lt;init\u0026gt;(LocalMonitoredVm.java:68) 6 at sun.jvmstat.perfdata.monitor.protocol.local.MonitoredHostProvider.getMonitoredVm(MonitoredHostProvider.java:77) 7 at sun.tools.jps.Jps.main(Jps.java:92) 8Caused by: java.lang.IllegalArgumentException: Process not found 9 at sun.misc.Perf.attach(Native Method) 10 at sun.misc.Perf.attachImpl(Perf.java:270) 11 at sun.misc.Perf.attach(Perf.java:200) 12 at sun.jvmstat.perfdata.monitor.protocol.local.PerfDataBuffer.\u0026lt;init\u0026gt;(PerfDataBuffer.java:64) 13 ... 3 more 顺着这个错误分析PerfDataBuffer.java ，可以发现解决的办法就是创建一个/tmp/hsperfdata_\u0026lt;pid\u0026gt;的文件。\njstat 先说结论：\n jstat和jps一样，读取的是 $TMPDIR/hsperfdata_$usr 下的PID文件，这个文件准确来说应该是 perfdata。这里面有 jstat 所想要的一切。 JVM在运行过程中会更新 perfdata，perfdata 采用的是mmap机制（内存映射文件），详见JVM源码分析之jstat工具原理完全解读  顺带一提，mmap文件内容的修改是无法通过 inotify(7) 探测到的（见Limitations and caveats）。  源码脉络：\n Jstat.java ，你可以看到两个隐藏参数-list和-snap，这不是我们的主题，关键看logSamples() 方法 可以看到同样依赖于 MonitoredHost (javadoc ) 然后得到 MonitoredVm ，类层级结构是 BufferedMonitoredVm -\u0026gt; AbstractMonitoredVm -\u0026gt; LocalMonitoredVm  LocalMonitoredVm 用到了 PerfDataBuffer   Dynamic Attach Mechanism jstack和jmap命令使用的是Dynamic Attach Mechanism 。\njstack 先说结论：\n 和socket文件 /tmp/.java_pid$pid 通信 如果这个文件不存在，则 touch /proc/$pid/cwd/.attach_pid$pid文件 然后 kill -3 $pid，JVM就会创建socket文件 然后把attach_pid$pid文件可以删掉  源码脉络：\n Jstack.java 使用 VirtualMachine.attach()  VirtualMachine ，有一个子类HotSpotVirtualMachine  VirtualMachine.attach() 依赖 AttachProvider javadoc  AttachProvider 子类 HotSpotAttachProvider 子类 LinuxAttachProvider  然后用到了 LinuxVirtualMachine ，这里描述了上述逻辑。  jmap jmap的机制和jstack一摸一样，不做赘述。\n参考资料  Serviceability in the J2SE Repository  ","date":"2021-12-07","img":"","permalink":"/post/jvm-tools/","series":null,"tags":["jvm"],"title":"Jps Jstat Jstack...的工作原理"},{"categories":null,"content":"在现场发现后台频繁抛出异常：\n1org.springframework.dao.CannotAcquireLockException:2###Errorqueryingdatabase.Cause:com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException:Lockwaittimeoutexceeded;tryrestartingtransaction3###SQL:selectserialNumberfromFF_ACT_FROM_SERIALNUMBERwhereid=\u0026#39;1\u0026#39;forupdate;;4###Cause:com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException:Lockwaittimeoutexceeded;tryrestartingtransaction看上去是select serialNumber from FF_ACT_FROM_SERIALNUMBER where id = '1' for update条语句尝试获取行锁的时候超市导致的。\n分析 和开发人员要到了完整的SQL语句：\n1selectserialNumberfromFF_ACT_FROM_SERIALNUMBERwhereid=\u0026#39;1\u0026#39;forupdate2updateFF_ACT_FROM_SERIALNUMBERsetserialNumber=#{number}whereid=\u0026#39;1\u0026#39;以上两条SQL语句是在一个事务中执行的。对应的Java代码如下：\n1@Transactional(propagation = Propagation.REQUIRES_NEW) 2public int updateSerialNumber(String str) { 3 // 两条SQL 4} 而这个又是在一个大事务中执行的：\n1@Transactional 2public void someOperation() { 3 // 很多其他SQL 4 this.updateSerialNumber(...); 5 // 很多其他SQL 6} 这里有一个烟雾弹，虽然updateSerialNumber方法标记了REQUIRES_NEW，似乎会在调用的时候开启一个新事务，从而获取一个新的数据库连接，但实际上不会，这是因为Spring AOP在调用this自身方法的时候，是不会经过切面的，详情见Understanding AOP Proxies 。\n经过开发沟通，updateSerialNumber的意思是刷新一个序列号，序列号的前两位是年份。\n而产生lock wait timeout exceeded 是因为行锁的占用在一个事务里，而只有等事务结束才会释放行锁。在高并发业务下，事务执行时间很长，导致获取行锁的事务堆积，排在后面的事务自然就会等待超时了。\n解决办法 有几个解决办法：\n 去掉someOperation()的@Transactional，使其不要在一个事务中运行，和开发沟通后不能这么做，放弃。 把updateSerialNumber()方法尽量放到someOperation()的最后执行，即放到事务的最后，和开发沟通后不能这么做，放弃。 使用sequence代替FF_ACT_FROM_SERIALNUMBER表，和开发沟通后不能这么做，因为要保证序列号是年份前缀，放弃。  最后的解决办法是，预先新建10个年份的sequence，比如seq_2021、seq_2022，代码根据系统当前年份使用对应sequence。\n如果会开启新事务 当然如果会开启一个新事务那就是另一个故事了。假设有两个线程，同时数据库连接池大小为2，那么很容易出现死锁：\n    Thread A Thread B     T1 begin transaction;select 1 from dual;    T2  begin transaction;select 1 from dual;   T3 begin transaction;select \u0026hellip; for update;(Blocked)    T4  begin transaction;select \u0026hellip; for update;(Blocked)    每一次begin transaction都会获取一个数据库连接，在T2的时候，连接池的连接已经耗尽了，所以在T3时线程A就会被阻塞等待线程B释放连接，而在T4时线程B也在等待线程A释放连接，进入死锁。\n这种情况在连接池不够用的情况下（比如高并发）极易发生。\n当然实际项目中不会无限等待下去，因为连接池会有一个获取连接超时，不过超时后会导致所有线程A或者线程B的所有事务回滚。\n","date":"2021-10-11","img":"","permalink":"/post/mysql/opt-big-transaction-lock/","series":null,"tags":["mysql","性能调优"],"title":"SQL优化:大事务中的行锁获取超时"},{"categories":null,"content":"有一条SQL语句执行比较慢，在并发情况下存在瓶颈：\n1select2t.APP_ID,3t.API_VERSION_MANAGEMENTasAPI_ID,4max(t.QUERY_NUM)asDATA_COUNT5fromdata_statistics_logt6groupbyt.APP_ID,t.API_VERSION_MANAGEMENT这张表的数据量在60w左右，查看这张表的执行计划：\n   id select_type table partitions type possible_keys key key_len ref rows filtered Extra     1 SIMPLE t NULL ALL NULL NULL NULL NULL 608731 100 Using temporary    可以看到使用了全表扫描和临时表。\n根据MySQL GROUP BY优化 的要义，对此次查询的3个字段做联合索引：\n1altertabledata_statistics_logaddindexquery_max(APP_ID,API_VERSION_MANAGEMENT,QUERY_NUM);再看执行计划：\n   id select_type table partitions type possible_keys key key_len ref rows filtered Extra     1 SIMPLE t NULL range query_max query_max 497 NULL 5854 100 Using index for group-by    在Extra可以看到Using index for group-by，说明使用了优化。\n对比之前的查询速度有了显著提升 2秒244毫秒 -\u0026gt; 17毫秒。\n","date":"2021-10-11","img":"","permalink":"/post/mysql/opt-group-by/","series":null,"tags":["mysql","性能调优"],"title":"SQL优化:一个超大表的GROUP BY"},{"categories":null,"content":"间隙锁和next-key lock是为了解决幻读问题的，先回顾一下幻读的定义：\n A事务通过SELECT ... WHERE得到一些行，B事务插入新行或者更新已有的行使得这些行满足A事务的WHERE条件，A事务再次SELECT ... WHERE结果比上一次少了一些或者多了一些行。\n 幻读 MySQL默认隔离级别为Repeatable Read（可重复读）：\n1showvariableslike\u0026#39;%isolation%\u0026#39;;23+-----------------------+-----------------+ 4|Variable_name|Value|5+-----------------------+-----------------+ 6|transaction_isolation|REPEATABLE-READ|7+-----------------------+-----------------+ 在这个隔离级别下，下面所讲的间隙锁、next-key lock才会起作用。\n再接下去看间隙锁和next-key lock之前，先复习一下SELECT ... FOR SHARE和SELECT ... FOR UPDATE：\n SELECT ... FOR SHARE/LOCK IN SHARE MODE只会锁定扫描过程中使用的索引里的记录行，即如果你的查询正好使用了覆盖索引，那么只有这个索引里的记录行会被锁定，主键索引的记录行是不会被锁定的。\n  SELECT ... FOR UPDATE除了会锁定扫描过程中使用的索引里的记录行，相关的其他索引的记录行也会被锁定。换句话说就算你使用了覆盖索引，但是主键索引里的记录行也会被锁定。而又因为主键索引就已经包含了所有字段，那么就相当于锁定表的整行记录。\n详情见：Locking Reads  所以分析问题的时候：\n 一定要先明确扫描过程中用到了哪些索引（不仅仅是条件判断用到，还包括回表），如果是share mode那么就到此为止，如果是SELECT ... FOR UPDATE和UPDATE/DELETE，则还会用到主键索引。 然后再明确影响了哪些记录行。 最后再根据索引的类型和扫描到的行，分析间隙锁和next-key lock。  间隙锁(gap lock) 传统的行锁只能锁定表中已经存在的行，因此就算你把表中所有行都锁住，也无法阻止插入新行（幻读问题）。为了解决这个问题InnoDB引入gap lock （间隙锁）。\n表t就有7个间隙：\n1CREATETABLE`t`(2`id`int(11)NOTNULL,3`c`int(11)DEFAULTNULL,4`d`int(11)DEFAULTNULL,5PRIMARYKEY(`id`),6KEY`c`(`c`)7)ENGINE=InnoDB;89insertintotvalues(0,0,0),(5,5,5),10(10,10,10),(15,15,15),(20,20,20),(25,25,25);间隙锁就是把索引的间隙给锁住，防止往中间插入新行。\n所以下面语句在扫描全表的过程中，除了把6个已有行（主键索引）加了锁，也把主键索引的7个间隙加上锁：\n1select*fromtwhered=5forupdate和行锁有冲突的关系的是“另外一个行锁”，但是跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。所以下面的session B不会被阻塞：\n因为表 t 里并没有 c=7 这个记录，因此 session A 加的是间隙锁 (5,10)，而 session B 也是在这个间隙加的间隙锁，它们都是保护这个间隙，不允许插入值，他们之间不冲突。\n间隙锁造成的死锁 间隙锁的引入会使同样的语句锁住更大的范围，这其实是影响并发度的，有时候还会更容易造成死锁，看下面场景：\n分析一下：\n session A 执行 select … for update 语句，由于 id=9 这一行并不存在，因此会加上间隙锁 (5,10); session B 执行 select … for update 语句，由于 id=9 这一行并不存在，因此也会加上间隙锁 (5,10); session B 试图插入一行 (9,9,9)，被 session A 的间隙锁挡住了，只好进入等待 session A 试图插入一行 (9,9,9)，被 session B 的间隙锁挡住了  间隙锁和binlog MySQL在可重复读个里级别下（默认），才会启用间隙锁。你如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把 binlog 格式设置为 row。\nnext-key lock 行锁 + 该行之前的间隙锁 合称 next-key lock ，每个 next-key lock 是前开后闭区间。也就是说，我们的表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]（supremum只是为了保证开闭区间的一致性，可以理解为无穷大）。\nnext-key lock的加锁过程是先加间隙锁再加行锁，这不是一个原子性操作，因此会出现只加了间隙锁但加行锁被阻塞的情况，比如下面这个情况：\n分析一下过程：\n session A 启动事务后执行查询语句加 lock in share mode，在索引 c 上加了 next-key lock (5,10] 和间隙锁 (10,15)； session B 的 update 语句也要在索引 c 上加 next-key lock(5,10] ，但是只有间隙锁(5, 10) 加成功了，行锁[10]进入锁等待； 然后 session A 要再插入 (8,8,8) 这一行，被 session B 的间隙锁锁住。由于出现了死锁，InnoDB 让 session B 回滚。  间隙锁和next-key lock的加锁规则 两个原则：\n 加锁的基本单位是 next-key lock，next-key lock 是前开后闭区间。 查找过程中访问到的对象才会加锁。  两个优化：\n 索引上的等值查询，给唯一索引加锁的时候，如果满足条件，next-key lock 退化为行锁。 索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。   注意，非等值查询是不会优化的。  一个 bug：\n 唯一索引上的范围查询会访问到不满足条件的第一个值为止。（8.0.26 没有这个bug）  案例分析 案例分析见：\n 极客时间 - 为什么我只改一行的语句，锁这么多？  用动态的观点看加锁  ","date":"2021-10-09","img":"","permalink":"/post/mysql/gap-lock-next-key-lock/","series":null,"tags":["mysql"],"title":"MySQL - 幻读、间隙锁和next-Key Lock"},{"categories":null,"content":"等MDL锁 下面语句长时间不返回，被锁住了：\n1select*fromtwhereid=1;先用show processlist查看：\n可以看到Waiting for table metadata lock，但是没法看到另一个线程在干什么，值看到Command是Sleep。\nMySQL启动时设置performance_schema=on，相比于设置为 off 会有 10% 左右的性能损失，然后：\n1selectblocking_pidfromsys.schema_table_lock_waits;找到造成阻塞的process id，把这个连接用 kill 命令断开即可。\n等flush 下面语句长时间不返回：\n1select*fromtwhereid=1;用select * from information_schema.processlist where id=?;查看：\n看到状态是Waiting for table flush，表示的是现在有一个线程正要对表 t 做 flush 操作。MySQL 里面对表做 flush 操作的用法，一般有以下两个：\n1flushtablestwithreadlock;2flushtableswithreadlock;注意，这都是读锁，应该是不会阻塞我们的SQL的，除非它们也被别的线程堵住了。\n我们用show processlist查看：\nselect sleep(1) from t把表t打开，但是flush table ...需要把表t关闭，于是就这么阻塞了。\n等行锁 下列语句对某行记录添加了读锁：\n1select*fromtwhereid=1lockinsharemode;如果此时这行记录上已经持有了一个写锁，这条sql就会阻塞，比如：\n但是show processlist看不出来：\n所以要通过sys.innodb_lock_waits查询谁占着写锁：\n1select*fromsys.innodb_lock_waitswherelocked_table=\u0026#39;`test`.`t`\u0026#39;;得到结果：\n可以看到，4 号线程是造成堵塞的罪魁祸首，干掉它的方式 KILL QUERY 4 或 KILL 4。\n其实KILL QUERY 4是不对的，因为update语句已经执行完毕了，只是事务没有提交，这也是为什么blocking_query: NULL的原因。\n死锁 1showengineinnodbstatus看LATESTDETECTED DEADLOCK小节，就是记录的最后一次死锁信息：\n我们来看看这图中的几个关键信息：\n 这个结果分成三部分：  (1) TRANSACTION，是第一个事务的信息； (2) TRANSACTION，是第二个事务的信息； WE ROLL BACK TRANSACTION (1)，是最终的处理结果，表示回滚了第一个事务。   第一个事务的信息中：  WAITING FOR THIS LOCK TO BE GRANTED，表示的是这个事务在等待的锁信息； index c of table test.t，说明在等的是表 t 的索引 c 上面的锁； lock mode S waiting 表示这个语句要自己加一个读锁，当前的状态是等待中； Record lock 说明这是一个记录锁； n_fields 2 表示这个记录是两列，也就是字段 c 和主键字段 id； 0: len 4; hex 0000000a; asc ;; 是第一个字段，也就是 c。值是十六进制 a，也就是 10； 1: len 4; hex 0000000a; asc ;; 是第二个字段，也就是主键 id，值也是 10； 这两行里面的 asc 表示的是，接下来要打印出值里面的“可打印字符”，但 10 不是可打印字符，因此就显示空格。 第一个事务信息就只显示出了等锁的状态，在等待 (c=10,id=10) 这一行的锁。 当然你是知道的，既然出现死锁了，就表示这个事务也占有别的锁，但是没有显示出来。别着急，我们从第二个事务的信息中推导出来。   第二个事务显示的信息要多一些：  “ HOLDS THE LOCK(S)”用来显示这个事务持有哪些锁； index c of table test.t 表示锁是在表 t 的索引 c 上； hex 0000000a 和 hex 00000014 表示这个事务持有 c=10 和 c=20 这两个记录锁； WAITING FOR THIS LOCK TO BE GRANTED，表示在等 (c=5,id=5) 这个记录锁。    从上面这些信息中，我们就知道：\n “lock in share mode”的这条语句，持有 c=5 的记录锁，在等 c=10 的锁； “for update”这个语句，持有 c=20 和 c=10 的记录锁，在等 c=5 的记录锁。  因此导致了死锁。这里，我们可以得到两个结论：\n 由于锁是一个个加的，要避免死锁，对同一组资源，要按照尽量相同的顺序访问； 在发生死锁的时刻，for update 这条语句占有的资源更多，回滚成本更大，所以 InnoDB 选择了回滚成本更小的 lock in share mode 语句，来回滚。  快捷SQL 查慢SQL（慢于5秒）：\n1selectCOMMAND,TIME,STATE,substr(INFO,1,100),length(INFO)frominformation_schema.processlist2where3COMMAND\u0026lt;\u0026gt;\u0026#39;Sleep\u0026#39;4anddb=\u0026#39;\u0026lt;db\u0026gt;\u0026#39;5andTIME\u0026gt;=56orderbyTIMEdesclimit10;查行锁：\n1select*fromsys.innodb_lock_waitswherelocked_tablelike\u0026#39;`\u0026lt;db\u0026gt;`.%\u0026#39;;查行锁+Block Pid正在执行的SQL：\n1select2w.wait_started,w.wait_age_secs,w.locked_table,w.locked_index,w.locked_type,3w.waiting_pid,substr(wp.INFO,1,100)waiting_query,4w.blocking_pid,w.blocking_query,w.blocking_trx_started,w.blocking_trx_age,5substr(bp.INFO,1,100)blocking_query6fromsys.innodb_lock_waitsw7joininformation_schema.processlistbponbp.ID=w.blocking_pid8joininformation_schema.processlistwponwp.ID=w.waiting_pid9where10w.locked_tablelike\u0026#39;`\u0026lt;db\u0026gt;`.%\u0026#39;;","date":"2021-10-09","img":"","permalink":"/post/mysql/lock-cause/","series":null,"tags":["mysql"],"title":"MySQL - 诊断锁的方法"},{"categories":null,"content":"在上一篇文章 里我们对一条SQL语句做了新的优化，在项目上做了性能测试对比新优化的效果。\n压测 压测试方案：\n 测试三个版本：未优化版本，优化版本v1，优化版本v2 测试三种情况：无where clause，where clause 1，where clause 2  未优化SQL：\n1selectaccount.IDasid,2account.GENDER_IDasgenderId,3userGender.CODEasgenderCode,4userGender.NAMEasgenderName,5account.NATION_IDasnationId,6userNation.CODEasnationCode,7userNation.NAMEasnationName,8account.COUNTRY_IDascountryId,9userCountry.CODEascountryCode,10userCountry.NAMEascountryName,11account.ADDRESS_IDasaddressId,12userAddress.CODEasaddressCode,13userAddress.NAMEasaddressName,14account.USER_IDasuserId,15account.USER_NAMEasuserName,16account.USER_UIDasuserUid,17account.ACCOUNT_NAMEasaccountName,18account.IDENTITY_TYPE_IDasidentityTypeId,19accountIdentity.CODEasidentityTypeCode,20accountIdentity.NAMEasidentityTypeName,21account.ORGANIZATION_IDasorganizationId,22accountOrganization.CODEasorganizationCode,23accountOrganization.NAMEasorganizationName,24account.IS_DATA_CENTERasisDataCenter,25account.ACTIVATIONasactivation,26account.STATEasstate,27account.ACCOUNT_EXPIRY_DATEasaccountExpiryDate,28account.ACCOUNT_LOCKEDasaccountLocked,29account.PHONE_NUMBERasphoneNumber,30account.EMAILasemail,31user.IMAGE_URLasimageUrl32fromTB_B_ACCOUNTaccount33innerjoinTB_B_ORGANIZATIONaccountOrganization34onaccount.ORGANIZATION_ID=accountOrganization.IDANDaccountOrganization.DELETED=035innerjoinTB_B_IDENTITY_TYPEaccountIdentityonaccount.IDENTITY_TYPE_ID=accountIdentity.ID36innerjoinTB_B_DICTIONARYuserCertificateTypeonaccount.certificate_type_id=userCertificateType.ID37leftjoinTB_B_DICTIONARYuserGenderonaccount.GENDER_ID=userGender.ID38leftjoinTB_B_DICTIONARYuserNationonaccount.NATION_ID=userNation.ID39leftjoinTB_B_DICTIONARYuserCountryonaccount.COUNTRY_ID=userCountry.ID40leftjoinTB_B_DICTIONARYuserAddressonaccount.ADDRESS_ID=userAddress.ID41leftjoinTB_B_USERuseronaccount.USER_ID=user.ID42where1=143and\u0026lt;condition\u0026gt;44ORDERBYlength(account.ACCOUNT_NAME),account.ACCOUNT_NAME45limit20;优化版本v1 SQL，先查出ACCOUNT_NAME，然后再查出详细信息，可能会根据条件选择合适索引：\n1selectaccount.ACCOUNT_NAME2fromTB_B_ACCOUNTaccount3where1=14and\u0026lt;condition\u0026gt;5ORDERBYlength(account.ACCOUNT_NAME),account.ACCOUNT_NAME6LIMIT20;优化版本v2 SQL，先查出ACCOUNT_NAME，然后再查出详细信息，会使用ACCOUNT_NAME_PAD索引：\n1selectaccount.ACCOUNT_NAME2fromTB_B_ACCOUNTaccount3where1=14and\u0026lt;condition\u0026gt;5ORDERBYaccount.ACCOUNT_NAME_PAD6LIMIT20;压测命令：\n1wrk2 -c 100 -d 60 -R 2000 -B \u0026lt;url\u0026gt; 无where clause    未优化 v1 v2     0.83 QPS 145.18 QPS 1547.37 QPS    这个结果符合预期，v2版本的因为扫描时直接走了索引省去了排序动作，同时又没有JOIN，所以吞吐量特别高。\n这个可以从两者的执行计划看出来，v1执行计划：\n   id select_type table partitions type possible_keys key key_len ref rows filtered Extra     1 SIMPLE account NULL index NULL UQ_ACCOUNT_NAME 362 NULL 163505 100.00 Using index; Using filesort    v2执行计划：\n   id select_type table partitions type possible_keys key key_len ref rows filtered Extra     1 SIMPLE account NULL index NULL ACCOUNT_NAME_PAD 767 NULL 20 100.00 NULL    where clause 1压测结果 1(2account.ACCOUNT_NAMElike?3ORaccount.USER_NAMElike?4ORaccount.IDENTITY_TYPE_IDin(selectaccountIdentity.IDfromTB_B_IDENTITY_TYPEaccountIdentitywhereaccountIdentity.NAMElike?)5ORaccount.ORGANIZATION_IDin(selectaccountOrganization.IDFROMTB_B_ORGANIZATIONaccountOrganizationwhereaccountOrganization.NAMElike?)6)压测结果：\n   查询参数/吞吐量 未优化 v1 v2     LIKE 20% ，预估140,000行 0.83 QPS 60.59 QPS 64.76 QPS   LIKE 202% ，预估26,000行 2.39 QPS 58.36 QPS 7.11 QPS   LIKE 2021% ，预估12,000 行 3.18 QPS 55.59 QPS 6.37 QPS   LIKE 20211%，预估1,200行 2.31 QPS 57.38 QPS 8.03 QPS    为何v2性能的急剧下降？ 看到了异常现象，v2版本在 LIKE 20%时吞吐量64.76 QPS，LIKE 202%时吞吐量在7.11 QPS，下降了很多，两者的执行计划都是一样的，都是走了ACCOUNT_NAME_PAD索引：\n   id select_type table partitions type possible_keys key key_len ref rows filtered Extra     1 PRIMARY account NULL index UQ_ACCOUNT_NAME,IDX_ACCOUNT_USERNAME ACCOUNT_NAME_PAD 767 NULL 20 100.00 Using where   3 SUBQUERY accountOrganization NULL range PRIMARY,IDX_ORG_NAME IDX_ORG_NAME 602 NULL 1 100.00 Using where; Using index   2 SUBQUERY accountIdentity NULL range PRIMARY,IDX_ID_TYPE_NAME IDX_ID_TYPE_NAME 602 NULL 1 100.00 Using where; Using index    虽然扫描ACCOUNT_NAME_PAD索引避免了排序，但是对于where clause来说，还是一行行过滤的，LIKE 20%的扫描行数少，因为目标数据比较靠前，LIKE 202%的扫描行数多，因为目标数据比较靠后。\n通过EXPLAIN ANALYZE来分析LIKE 20%时的SQL执行情况，可以看到实际扫描26,566行：\n1-\u0026gt; Limit: 20 row(s) (actual time=2.201..479.425 rows=20 loops=1) 2 -\u0026gt; Filter: ((`account`.ACCOUNT_NAME like \u0026#39;20%\u0026#39;) or ...) (cost=0.33 rows=20) (actual time=2.199..479.417 rows=20 loops=1) 3 -\u0026gt; Index scan on account using ACCOUNT_NAME_PAD (cost=0.33 rows=20) (actual time=0.368..462.221 rows=26566 loops=1) 4 -\u0026gt; Select #2 (subquery in condition; run only once) 5 -\u0026gt; Filter: (accountIdentity.`NAME` like \u0026#39;20%\u0026#39;) (cost=1.21 rows=1) (actual time=0.026..0.026 rows=0 loops=1) 6 -\u0026gt; Index range scan on accountIdentity using IDX_ID_TYPE_NAME (cost=1.21 rows=1) (actual time=0.026..0.026 rows=0 loops=1) 7 -\u0026gt; Select #3 (subquery in condition; run only once) 8 -\u0026gt; Filter: (accountOrganization.`NAME` like \u0026#39;20%\u0026#39;) (cost=1.21 rows=1) (actual time=0.033..0.033 rows=0 loops=1) 9 -\u0026gt; Index range scan on accountOrganization using IDX_ORG_NAME (cost=1.21 rows=1) (actual time=0.032..0.032 rows=0 loops=1) 但是在LIKE 202%时，实际扫描14,1377行，已经接近于全表行数了（16.8w行）：\n1-\u0026gt; Limit: 20 row(s) (actual time=99.352..1137.270 rows=20 loops=1) 2 -\u0026gt; Filter: ((`account`.ACCOUNT_NAME like \u0026#39;202%\u0026#39;) or ...) (cost=0.33 rows=20) (actual time=99.351..1137.265 rows=20 loops=1) 3 -\u0026gt; Index scan on account using ACCOUNT_NAME_PAD (cost=0.33 rows=20) (actual time=0.779..1057.634 rows=141377 loops=1) 4 -\u0026gt; Select #2 (subquery in condition; run only once) 5 -\u0026gt; Filter: (accountIdentity.`NAME` like \u0026#39;202%\u0026#39;) (cost=1.21 rows=1) (actual time=0.016..0.016 rows=0 loops=1) 6 -\u0026gt; Index range scan on accountIdentity using IDX_ID_TYPE_NAME (cost=1.21 rows=1) (actual time=0.016..0.016 rows=0 loops=1) 7 -\u0026gt; Select #3 (subquery in condition; run only once) 8 -\u0026gt; Filter: (accountOrganization.`NAME` like \u0026#39;202%\u0026#39;) (cost=1.21 rows=1) (actual time=0.012..0.012 rows=0 loops=1) 9 -\u0026gt; Index range scan on accountOrganization using IDX_ORG_NAME (cost=1.21 rows=1) (actual time=0.012..0.012 rows=0 loops=1) 后面的情况其实也一样。\n为何v1比较稳定，而且还比v2快？ 从v1的执行计划上看，v1实际上对account的扫描行数和全表总行数相当，同时还有排序动作：\n   id select_type table partitions type possible_keys key key_len ref rows filtered Extra     1 PRIMARY account NULL ALL UQ_ACCOUNT_NAME,IDX_ACCOUNT_USERNAME NULL NULL NULL 163505 100.00 Using where; Using filesort   3 SUBQUERY accountOrganization NULL range PRIMARY,IDX_ORG_NAME IDX_ORG_NAME 602 NULL 1 100.00 Using where; Using index   2 SUBQUERY accountIdentity NULL range PRIMARY,IDX_ID_TYPE_NAME IDX_ID_TYPE_NAME 602 NULL 1 100.00 Using where; Using index    看EXPLAIN ANALYZE结果：\n1-\u0026gt; Limit: 20 row(s) (actual time=1542.761..1542.765 rows=20 loops=1) 2 -\u0026gt; Sort: \u0026lt;temporary\u0026gt;.tmp_field_0, \u0026lt;temporary\u0026gt;.ACCOUNT_NAME, limit input to 20 row(s) per chunk (actual time=1542.759..1542.763 rows=20 loops=1) 3 -\u0026gt; Stream results (actual time=2.586..1533.389 rows=26224 loops=1) 4 -\u0026gt; Nested loop inner join (cost=55023.35 rows=49960) (actual time=2.583..1528.278 rows=26224 loops=1) 5 -\u0026gt; Filter: (accountOrganization.DELETED = 0) (cost=67.50 rows=61) (actual time=0.161..1.679 rows=599 loops=1) 6 -\u0026gt; Table scan on accountOrganization (cost=67.50 rows=605) (actual time=0.160..1.441 rows=605 loops=1) 7 -\u0026gt; Filter: ((`account`.ACCOUNT_NAME like \u0026#39;202%\u0026#39;) or (`account`.USER_NAME like \u0026#39;202%\u0026#39;) or \u0026lt;in_optimizer\u0026gt;(`account`.IDENTITY_TYPE_ID,`account`.IDENTITY_TYPE_ID in (select #2)) or \u0026lt;in_optimizer\u0026gt;(`account`.ORGANIZATION_ID,`account`.ORGANIZATION_ID in (select #3))) (cost=827.15 rows=826) (actual time=0.319..2.545 rows=44 loops=599) 8 -\u0026gt; Index lookup on account using ORGANIZATION_ID (ORGANIZATION_ID=accountOrganization.ID) (cost=827.15 rows=826) (actual time=0.086..2.398 rows=281 loops=599) 9 -\u0026gt; Select #2 (subquery in condition; run only once) 10 -\u0026gt; Filter: (accountIdentity.`NAME` like \u0026#39;202%\u0026#39;) (cost=1.21 rows=1) (actual time=0.016..0.016 rows=0 loops=1) 11 -\u0026gt; Index range scan on accountIdentity using IDX_ID_TYPE_NAME (cost=1.21 rows=1) (actual time=0.015..0.015 rows=0 loops=1) 12 -\u0026gt; Select #3 (subquery in condition; run only once) 13 -\u0026gt; Filter: (accountOrganization.`NAME` like \u0026#39;202%\u0026#39;) (cost=1.21 rows=1) (actual time=0.012..0.012 rows=0 loops=1) 14 -\u0026gt; Index range scan on accountOrganization using IDX_ORG_NAME (cost=1.21 rows=1) (actual time=0.012..0.012 rows=0 loops=1) 也可以看到，SQL执行过程中，通过acccount.ORGANIZATION_ID索引查找account记录，总共查了599次，每次平均281行，总共16.8w行：\n1Index lookup on account using ORGANIZATION_ID (ORGANIZATION_ID=accountOrganization.ID) (cost=827.15 rows=826) (actual time=0.086..2.398 rows=281 loops=599) 那为何v1总是比较稳定，而且还比v2快呢？\n因为v1扫描的是主键索引，不需要回表，而v2扫描的是ACCOUNT_NAME_PAD索引，在判断条件的时候需要回表，时间复杂度是 14w * log2(14w)。\nwhere clause 2压测结果 1(2account.ACCOUNT_NAMElike?3ORaccount.USER_NAMElike?4)压测结果\n   查询参数/吞吐量 v1 v2     LIKE 20% ，预估140,000行 84.71 QPS 67.61 QPS   LIKE 202% ，预估26,000行 96.93 QPS 5.76 QPS   LIKE 2021% ，预估12,000 行 96.98 QPS 5.18 QPS   LIKE 20211%，预估1,200行 585.31 QPS 456.99 QPS    为何v2突然又行了？ v2的 LIKE 202%和LIKE 2021%比LIKE 20%吞吐量低这个在之前已经分析过了，但是为何v2的LIKE 20211%吞吐量突然提升6倍？\n看一下LIKE 20211%的执行计划：\n   id select_type table partitions type possible_keys key key_len ref rows filtered Extra     1 SIMPLE account NULL index_merge UQ_ACCOUNT_NAME,IDX_ACCOUNT_USERNAME UQ_ACCOUNT_NAME,IDX_ACCOUNT_USERNAME 362,767 NULL 1255 100.00 Using sort_union(UQ_ACCOUNT_NAME,IDX_ACCOUNT_USERNAME); Using where; Using filesort    也就是说，当条件的预期结果集很少的时候，就会优先使用索引，而且还使用了Index Merge 优化 。\n那么为何在where clause 1中没有启用Index Merge 优化？这是因为当查询语句复杂的时候，MySQL不会启用该优化。\n事实上你在优化版本v1也能看到同样的结果（Index Merge优化）。\n优化方向 经过一系列测试，发现OR查询条件是影响索引使用的罪魁祸首，尝试用UNION修改：\n1selectaccount.ACCOUNT_NAME2fromTB_B_ACCOUNTaccount3where1=14and(5account.ACCOUNT_NAMElike\u0026#39;20211%\u0026#39;6)7union8selectaccount.ACCOUNT_NAME9fromTB_B_ACCOUNTaccount10where1=111and(12account.USER_NAMElike\u0026#39;20211%\u0026#39;13)14union15selectaccount.ACCOUNT_NAME16fromTB_B_ACCOUNTaccount17where1=118and(19account.IDENTITY_TYPE_IDin(selectaccountIdentity.IDfromTB_B_IDENTITY_TYPEaccountIdentitywhereaccountIdentity.NAMElike\u0026#39;202%\u0026#39;)20)21union22selectaccount.ACCOUNT_NAME23fromTB_B_ACCOUNTaccount24where1=125and(26account.ORGANIZATION_IDin(selectaccountOrganization.IDFROMTB_B_ORGANIZATIONaccountOrganizationwhereaccountOrganization.NAMElike\u0026#39;202%\u0026#39;)27)28ORDERBYlength(ACCOUNT_NAME),ACCOUNT_NAME29LIMIT20执行计划：\n   id select_type table partitions type possible_keys key key_len ref rows filtered Extra     1 PRIMARY account NULL range UQ_ACCOUNT_NAME UQ_ACCOUNT_NAME 362 NULL 52208 100.00 Using where; Using index   2 UNION account NULL range IDX_ACCOUNT_USERNAME IDX_ACCOUNT_USERNAME 767 NULL 1 100.00 Using index condition   3 UNION accountIdentity NULL range PRIMARY,IDX_ID_TYPE_NAME IDX_ID_TYPE_NAME 602 NULL 1 100.00 Using where; Using index   3 UNION account NULL ref IDENTITY_TYPE_ID IDENTITY_TYPE_ID 194 user_test.accountIdentity.ID 14864 100.00 NULL   5 UNION accountOrganization NULL range PRIMARY,IDX_ORG_NAME IDX_ORG_NAME 602 NULL 1 100.00 Using where; Using index   5 UNION account NULL ref ORGANIZATION_ID ORGANIZATION_ID 194 user_test.accountOrganization.ID 825 100.00 NULL   NULL UNION RESULT \u0026lt;union1,2,3,5\u0026gt; NULL ALL NULL NULL NULL NULL NULL NULL Using temporary; Using filesort    可以看到所有的查询都用到了正确的索引。\n优化方案 所以针对不同的情况有三种形式：\n 无条件时，ORDER BY ACCOUNT_NAME_PAD，这样就会利用 ACCOUNT_NAME_PAD 索引：  1selectLTRIM(account.ACCOUNT_NAME_PAD)2fromTB_B_ACCOUNTaccount3ORDERBYaccount.ACCOUNT_NAME_PAD4LIMIT20 有条件时，ORDER BY length(ACCOUNT_NAME), ACCOUNT_NAME：  1selectaccount.ACCOUNT_NAME2fromTB_B_ACCOUNTaccount3where\u0026lt;condition\u0026gt;4ORDERBYlength(ACCOUNT_NAME),ACCOUNT_NAME5LIMIT20 有OR条件时，改成UNION形式：  1selectaccount.ACCOUNT_NAME2fromTB_B_ACCOUNTaccount3where\u0026lt;ORcondition-1\u0026gt;4and\u0026lt;othercondition\u0026gt;5union6selectaccount.ACCOUNT_NAME7fromTB_B_ACCOUNTaccount8where\u0026lt;ORcondition-2\u0026gt;9and\u0026lt;othercondition\u0026gt;10\u0026lt;otherunion\u0026gt;11ORDERBYlength(ACCOUNT_NAME),ACCOUNT_NAME12LIMIT20压测验证 命令：\n1wrk2-c100-d60-R2000-B...无条件 1selectaccount.ACCOUNT_NAME2fromTB_B_ACCOUNTaccount3ORDERBYaccount.ACCOUNT_NAME_PAD4LIMIT20结果：1636.14 QPS\n一个条件 1selectaccount.ACCOUNT_NAME2fromTB_B_ACCOUNTaccount3where1=14ANDACCOUNT_NAMELIKE?5ORDERBYlength(ACCOUNT_NAME),ACCOUNT_NAME6LIMIT20结果\n   查询参数/吞吐量 吞吐量     LIKE 20% ，预估140,000行 100 QPS   LIKE 202% ，预估26,000行 460.81 QPS   LIKE 2021% ，预估12,000 行 776.09 QPS   LIKE 20211%，预估1,200行 1451.60 QPS    两个UNION 1selectaccount.ACCOUNT_NAMEasaccountName2fromTB_B_ACCOUNTaccount3where1=14andaccount.ACCOUNT_NAMElike?5union6selectaccount.ACCOUNT_NAMEasaccountName7fromTB_B_ACCOUNTaccount8where1=19andaccount.USER_NAMElike?10ORDERBYlength(accountName),accountName11limit20结果\n   查询参数/吞吐量 吞吐量     LIKE 20% ，预估140,000行 20.65 QPS   LIKE 202% ，预估26,000行 97.70 QPS   LIKE 2021% ，预估12,000 行 221.69 QPS   LIKE 20211%，预估1,200行 1651.56 QPS    4个UNION 1selectaccount.ACCOUNT_NAMEasaccountName2fromTB_B_ACCOUNTaccount3where1=14andaccount.ACCOUNT_NAMElike?5union6selectaccount.ACCOUNT_NAMEasaccountName7fromTB_B_ACCOUNTaccount8where1=19andaccount.USER_NAMElike?10union11selectaccount.ACCOUNT_NAMEasaccountName12fromTB_B_ACCOUNTaccount13where1=114andaccount.IDENTITY_TYPE_IDIN15(selectaccountIdentity.IDfromTB_B_IDENTITY_TYPEaccountIdentitywhereaccountIdentity.NAMElike?)16union17selectaccount.ACCOUNT_NAMEasaccountName18fromTB_B_ACCOUNTaccount19where1=120andaccount.ORGANIZATION_IDIN21(selectaccountOrganization.IDFROMTB_B_ORGANIZATIONaccountOrganizationwhereaccountOrganization.NAMElike?)22ORDERBYlength(accountName),accountName23limit20结果：\n   查询参数/吞吐量 吞吐量     LIKE 20% ，预估140,000行 20.48 QPS   LIKE 202% ，预估26,000行 97.43 QPS   LIKE 2021% ，预估12,000 行 238.63 QPS   LIKE 20211%，预估1,200行 1638.49 QPS    参考资料  MySQL EXPLAIN解读  MySQL LIMIT 优化  MySQL ORDER BY 优化  MySQL filesort with small LIMIT optimization  MySQL 优化器跟踪  ","date":"2021-09-28","img":"","permalink":"/post/mysql/sql-opt-join-limit-order-by-3/","series":null,"tags":["mysql","性能调优"],"title":"SQL优化:一个含有JOIN+LIMIT+ORDER BY的SQL(下)"},{"categories":null,"content":"在上一篇文章 里我们对一条SQL语句做了优化，放到项目上实际压测后，在100个数据库连接，2000并发的情况下，性能得到比较大的提升，从原来的 0.8 QPS升到了 15.94 QPS，吞吐量是原来的19.924倍！但这还是太慢了所以进行了再一次的优化，先看上次优化后的结果。\n回顾并分析 上次优化后将SQL拆分成了2部分。\n1）先查询ACCOUNT_NAME\n1selectaccount.ACCOUNT_NAME2fromTB_B_ACCOUNTaccount3where1=14and(5account.ACCOUNT_NAMElike\u0026#39;user%\u0026#39;6ORaccount.USER_NAMElike\u0026#39;user%\u0026#39;7ORaccount.IDENTITY_TYPE_IDin(selectaccountIdentity.IDfromTB_B_IDENTITY_TYPEaccountIdentitywhereaccountIdentity.NAMElike\u0026#39;user%\u0026#39;)8ORaccount.ORGANIZATION_IDin(selectaccountOrganization.IDFROMTB_B_ORGANIZATIONaccountOrganizationwhereaccountOrganization.NAMElike\u0026#39;user%\u0026#39;)9)10andaccount.USER_NAMElike\u0026#39;user%\u0026#39;11andaccount.ACCOUNT_NAMElike\u0026#39;user%\u0026#39;12andaccount.ORGANIZATION_IDin13(selectaccountOrganization.IDFROMTB_B_ORGANIZATIONaccountOrganizationwhereDELETED=0)14ORDERBYlength(account.ACCOUNT_NAME),account.ACCOUNT_NAME15LIMIT20;2）再拿ACCOUNT_NAME去查询记录\n1selectaccount.IDasid,2account.GENDER_IDasgenderId,3userGender.CODEasgenderCode,4userGender.NAMEasgenderName,5account.NATION_IDasnationId,6userNation.CODEasnationCode,7userNation.NAMEasnationName,8account.COUNTRY_IDascountryId,9userCountry.CODEascountryCode,10userCountry.NAMEascountryName,11account.ADDRESS_IDasaddressId,12userAddress.CODEasaddressCode,13userAddress.NAMEasaddressName,14account.USER_IDasuserId,15account.USER_NAMEasuserName,16account.USER_UIDasuserUid,17account.ACCOUNT_NAMEasaccountName,18account.IDENTITY_TYPE_IDasidentityTypeId,19accountIdentity.CODEasidentityTypeCode,20accountIdentity.NAMEasidentityTypeName,21account.ORGANIZATION_IDasorganizationId,22accountOrganization.CODEasorganizationCode,23accountOrganization.NAMEasorganizationName,24account.IS_DATA_CENTERasisDataCenter,25account.ACTIVATIONasactivation,26account.STATEasstate,27account.ACCOUNT_EXPIRY_DATEasaccountExpiryDate,28account.ACCOUNT_LOCKEDasaccountLocked,29account.PHONE_NUMBERasphoneNumber,30account.EMAILasemail,31user.IMAGE_URLasimageUrl32fromTB_B_ACCOUNTaccount33innerjoinTB_B_ORGANIZATIONaccountOrganization34onaccount.ORGANIZATION_ID=accountOrganization.ID35innerjoinTB_B_IDENTITY_TYPEaccountIdentityonaccount.IDENTITY_TYPE_ID=accountIdentity.ID36innerjoinTB_B_DICTIONARYuserCertificateTypeonaccount.certificate_type_id=userCertificateType.ID37leftjoinTB_B_DICTIONARYuserGenderonaccount.GENDER_ID=userGender.ID38leftjoinTB_B_DICTIONARYuserNationonaccount.NATION_ID=userNation.ID39leftjoinTB_B_DICTIONARYuserCountryonaccount.COUNTRY_ID=userCountry.ID40leftjoinTB_B_DICTIONARYuserAddressonaccount.ADDRESS_ID=userAddress.ID41leftjoinTB_B_USERuseronaccount.USER_ID=user.ID42whereaccount.ACCOUNT_NAMEin(...);在压测期间得知，绝大部分时间消耗在第一条SQL上，回顾第一条SQL的EXPLAIN：\n   id select_type table partitions type possible_keys key key_len ref rows filtered Extra     1 PRIMARY accountOrganization NULL ALL PRIMARY NULL NULL NULL 84 10 Using where; Using temporary; Using filesort   1 PRIMARY account NULL ref UQ_ACCOUNT_NAME,ORGANIZATION_ID,UQ_ACCOUNT_USRNAME,IDX_ACCOUNT_USERNAME ORGANIZATION_ID 194 user_new.accountOrganization.ID 3629 25 Using where   3 SUBQUERY accountOrganization NULL range PRIMARY,IDX_ORG_NAME IDX_ORG_NAME 602 NULL 1 100 Using where; Using index   2 SUBQUERY accountIdentity NULL range PRIMARY,IDX_ID_TYPE_NAME IDX_ID_TYPE_NAME 602 NULL 1 100 Using where; Using index    可以看到：\n 第一行是 accountOrganization 表，它是JOIN驱动表，但是SQL语句里没有直接的用JOIN，但是MySQL把Where翻译成JOIN了。 第二行是 account 表，是被驱动表，这个表实际上会被全扫描，总数据量为14w左右。 不论是 accountOrganization表还是 account 表，都是全表扫描来过滤记录的，压根没有用到索引。  另外补充信息，在项目实际情况中：\n where里的条件除了 accountOrganization.DELETED=0之外，其他条件可以全部没有。 上一条情况比较普遍，因为业务上用户的第一次查询是程序发起的，几乎都是没有查询条件的。 accountOrganization.DELETED=1的记录很少，500条中只有1条。 accountOrganization，accountIdentity 表的记录比较稳定，几乎不会变。  所以我们的目标是：\n 让查询用到account上的索引  去掉JOIN 已经可以确定EXPLAIN结果中的JOIN是因为这个WHERE条件造成的：\n1andaccount.ORGANIZATION_IDin2(selectaccountOrganization.IDFROMTB_B_ORGANIZATIONaccountOrganizationwhereDELETED=0)根据项目现场的数据，accountOrganization.DELETED=1的记录很少，500条中只有1条，且数据基本稳定不怎么变动，所以我们可以做以下改动：\n 先做一个查询，把 accountOrganization.DELETED=1的数据查出来，并缓存结果。 修改 account.ORGANIZATION_ID not in (id, ...)  1selectaccount.ACCOUNT_NAME2fromTB_B_ACCOUNTaccount3where1=14and(5account.ACCOUNT_NAMElike\u0026#39;user%\u0026#39;6ORaccount.USER_NAMElike\u0026#39;user%\u0026#39;7ORaccount.IDENTITY_TYPE_IDin(selectaccountIdentity.IDfromTB_B_IDENTITY_TYPEaccountIdentitywhereaccountIdentity.NAMElike\u0026#39;user%\u0026#39;)8ORaccount.ORGANIZATION_IDin(selectaccountOrganization.IDFROMTB_B_ORGANIZATIONaccountOrganizationwhereaccountOrganization.NAMElike\u0026#39;user%\u0026#39;)9)10andaccount.USER_NAMElike\u0026#39;user%\u0026#39;11andaccount.ACCOUNT_NAMElike\u0026#39;user%\u0026#39;12andaccount.ORGANIZATION_IDnotin(\u0026#39;6394cd50297911ebe98bc1e17e87f048\u0026#39;)13ORDERBYlength(account.ACCOUNT_NAME),account.ACCOUNT_NAME14LIMIT20;然后我们还可以做进一步优化，从业务上分析，去掉ORGANIZATION.DELETED=0也是可以的。所以进一步变成：\n1selectaccount.ACCOUNT_NAME2fromTB_B_ACCOUNTaccount3where1=14and(5account.ACCOUNT_NAMElike\u0026#39;user%\u0026#39;6ORaccount.USER_NAMElike\u0026#39;user%\u0026#39;7ORaccount.IDENTITY_TYPE_IDin(selectaccountIdentity.IDfromTB_B_IDENTITY_TYPEaccountIdentitywhereaccountIdentity.NAMElike\u0026#39;user%\u0026#39;)8ORaccount.ORGANIZATION_IDin(selectaccountOrganization.IDFROMTB_B_ORGANIZATIONaccountOrganizationwhereaccountOrganization.NAMElike\u0026#39;user%\u0026#39;)9)10andaccount.USER_NAMElike\u0026#39;user%\u0026#39;11andaccount.ACCOUNT_NAMElike\u0026#39;user%\u0026#39;12ORDERBYlength(account.ACCOUNT_NAME),account.ACCOUNT_NAME13LIMIT20;EXPLAIN结果：\n   id select_type table partitions type possible_keys key key_len ref rows filtered Extra     1 PRIMARY account NULL ALL UQ_ACCOUNT_NAME,UQ_ACCOUNT_USRNAME,IDX_ACCOUNT_USERNAME NULL NULL NULL 130679 25 Using where; Using filesort   3 SUBQUERY accountOrganization NULL range PRIMARY,IDX_ORG_NAME IDX_ORG_NAME 602 NULL 1 100 Using where; Using index   2 SUBQUERY accountIdentity NULL range PRIMARY,IDX_ID_TYPE_NAME IDX_ID_TYPE_NAME 602 NULL 1 100 Using where; Using index    可以看到，JOIN没有了，但是对account表的还是全表扫描（Extra: Using where; Using filesort）。\n为什么会发生这个情况呢？因为查询条件LIKE 'user%'的查询结果几乎就是全表了，所以MySQL就说干脆全表不走索引了。如果条件换成LIKE '20%'实际结集是80行，就会走索引了，且使用了filesort：\n   id select_type table partitions type possible_keys key key_len ref rows filtered Extra     1 PRIMARY account NULL range UQ_ACCOUNT_NAME,UQ_ACCOUNT_USRNAME,IDX_ACCOUNT_USERNAME UQ_ACCOUNT_NAME 362 NULL 80 100 Using index condition; Using where; Using filesort   3 SUBQUERY accountOrganization NULL range PRIMARY,IDX_ORG_NAME IDX_ORG_NAME 602 NULL 1 100 Using where; Using index   2 SUBQUERY accountIdentity NULL range PRIMARY,IDX_ID_TYPE_NAME IDX_ID_TYPE_NAME 602 NULL 1 100 Using where; Using index    使用索引走全表扫描 原始ORDER BY条件的意思是先根据长度排序，即短的放前面长的放后面，再根据字典序：\n1...2ORDERBYlength(account.ACCOUNT_NAME),account.ACCOUNT_NAME3...我们可以对ACCOUNT_NAME的值做填充，使其长度一致，排序后又能得到同样的效果，比如：\n   原始 填充     3 __3   22 _22    上面的_实际为空格。\n于是添加一个字段用来存放ACCOUNT_NAME的填充数据，填充长度为max(length(ACCOUNT_NAME))，并且加上了索引，因为MySQL在走全表扫描的时候，可能会优先使用ORDER BY字段的索引：\n1altertableTB_B_ACCOUNTaddcolumnACCOUNT_NAME_PADVARCHAR(255)NOTNULLDEFAULT(LPAD(ACCOUNT_NAME,20,\u0026#39; \u0026#39;));2altertableTB_B_ACCOUNTaddindexACCOUNT_NAME_PAD(ACCOUNT_NAME_PAD);然后SQL改成：\n1selectaccount.ACCOUNT_NAME2fromTB_B_ACCOUNTaccount3where1=14and(5account.ACCOUNT_NAMElike\u0026#39;user%\u0026#39;6ORaccount.USER_NAMElike\u0026#39;user%\u0026#39;7ORaccount.IDENTITY_TYPE_IDin(selectaccountIdentity.IDfromTB_B_IDENTITY_TYPEaccountIdentitywhereaccountIdentity.NAMElike\u0026#39;user%\u0026#39;)8ORaccount.ORGANIZATION_IDin(selectaccountOrganization.IDFROMTB_B_ORGANIZATIONaccountOrganizationwhereaccountOrganization.NAMElike\u0026#39;user%\u0026#39;)9)10andaccount.USER_NAMElike\u0026#39;user%\u0026#39;11andaccount.ACCOUNT_NAMElike\u0026#39;user%\u0026#39;12ORDERBYaccount.ACCOUNT_NAME_PAD13LIMIT20;EXPLAIN：\n   id select_type table partitions type possible_keys key key_len ref rows filtered Extra     1 PRIMARY account NULL index UQ_ACCOUNT_NAME,UQ_ACCOUNT_USRNAME,IDX_ACCOUNT_USERNAME ACCOUNT_NAME_PAD 767 NULL 40 25 Using where   3 SUBQUERY accountOrganization NULL range PRIMARY,IDX_ORG_NAME IDX_ORG_NAME 602 NULL 1 100 Using where; Using index   2 SUBQUERY accountIdentity NULL range PRIMARY,IDX_ID_TYPE_NAME IDX_ID_TYPE_NAME 602 NULL 1 100 Using where; Using index    可以看到使用了ACCOUNT_NAME_PAD索引，并且取消了filesort。\n总结 总结一下两次优化的结论：\n WHERE用到的字段都加上索引。 LIKE改写成前缀匹配，这样可以利用索引。 尽一切可能去掉JOIN，这样可以让MySQL选择被查表上的索引。 预期结果集小的时候，MySQL会选择索引匹配查询条件，然后filesort。这个时候要确保sort_buffer_size足够，避免filesort排序时写磁盘，并且利用堆+LIMIT来优化排序。 预期结果集大的时候，MySQL会选择全表扫描，此时就要在排序字段上添加索引，这样就会用排序字段索引全表扫描，避免了filesort。 虽然取消了filesort，但是却走了全表扫描，这样会更快吗？请看下一篇文章分析 。  参考资料  MySQL EXPLAIN解读  MySQL LIMIT 优化  MySQL ORDER BY 优化  MySQL filesort with small LIMIT optimization  MySQL 优化器跟踪  ","date":"2021-09-28","img":"","permalink":"/post/mysql/sql-opt-join-limit-order-by-2/","series":null,"tags":["mysql","性能调优"],"title":"SQL优化:一个含有JOIN+LIMIT+ORDER BY的SQL(中)"},{"categories":null,"content":"有一条SQL语句执行比较慢，在并发情况下存在瓶颈：\n1selectaccount.IDasid,2account.GENDER_IDasgenderId,3userGender.CODEasgenderCode,4userGender.NAMEasgenderName,5account.NATION_IDasnationId,6userNation.CODEasnationCode,7userNation.NAMEasnationName,8account.COUNTRY_IDascountryId,9userCountry.CODEascountryCode,10userCountry.NAMEascountryName,11account.ADDRESS_IDasaddressId,12userAddress.CODEasaddressCode,13userAddress.NAMEasaddressName,14account.USER_IDasuserId,15account.USER_NAMEasuserName,16account.USER_UIDasuserUid,17account.ACCOUNT_NAMEasaccountName,18account.IDENTITY_TYPE_IDasidentityTypeId,19accountIdentity.CODEasidentityTypeCode,20accountIdentity.NAMEasidentityTypeName,21account.ORGANIZATION_IDasorganizationId,22accountOrganization.CODEasorganizationCode,23accountOrganization.NAMEasorganizationName,24account.IS_DATA_CENTERasisDataCenter,25account.ACTIVATIONasactivation,26account.STATEasstate,27account.ACCOUNT_EXPIRY_DATEasaccountExpiryDate,28account.ACCOUNT_LOCKEDasaccountLocked,29account.PHONE_NUMBERasphoneNumber,30account.EMAILasemail,31user.IMAGE_URLasimageUrl32fromTB_B_ACCOUNTaccount33innerjoinTB_B_ORGANIZATIONaccountOrganization34onaccount.ORGANIZATION_ID=accountOrganization.IDANDaccountOrganization.DELETED=035innerjoinTB_B_IDENTITY_TYPEaccountIdentityonaccount.IDENTITY_TYPE_ID=accountIdentity.ID36innerjoinTB_B_DICTIONARYuserCertificateTypeonaccount.certificate_type_id=userCertificateType.ID37leftjoinTB_B_DICTIONARYuserGenderonaccount.GENDER_ID=userGender.ID38leftjoinTB_B_DICTIONARYuserNationonaccount.NATION_ID=userNation.ID39leftjoinTB_B_DICTIONARYuserCountryonaccount.COUNTRY_ID=userCountry.ID40leftjoinTB_B_DICTIONARYuserAddressonaccount.ADDRESS_ID=userAddress.ID41leftjoinTB_B_USERuseronaccount.USER_ID=user.ID42where1=143and(44account.ACCOUNT_NAMElike\u0026#39;%user%\u0026#39;45ORaccount.USER_NAMElike\u0026#39;%user%\u0026#39;46ORaccountIdentity.NAMElike\u0026#39;%user%\u0026#39;47ORaccountOrganization.NAMElike\u0026#39;%user%\u0026#39;48)49andaccount.USER_NAMElike\u0026#39;%user%\u0026#39;50andaccount.ACCOUNT_NAMElike\u0026#39;%user%\u0026#39;51ORDERBYlength(account.ACCOUNT_NAME),account.ACCOUNT_NAME52limit20;在优化之前先刷新相关表的统计数据：\n1ANALYZETABLETB_B_ACCOUNT;2ANALYZETABLETB_B_ORGANIZATION;3ANALYZETABLETB_B_IDENTITY_TYPE;4ANALYZETABLETB_B_DICTIONARY;5ANALYZETABLETB_B_USER;1）排除ORDER BY和LIMIT 检查字段索引 检查查询条件中的相关字段，把相关字段的索引加上。\nEXPLAIN结果：\n   id select_type table partitions type possible_keys key key_len ref rows filtered Extra     1 SIMPLE accountOrganization NULL ALL PRIMARY NULL NULL NULL 84 10 Using where   1 SIMPLE account NULL ref ORGANIZATION_ID,IDENTITY_TYPE_ID,TB_B_ACCOUNT_fk3 ORGANIZATION_ID 194 user_new.accountOrganization.ID 3637 1.23 Using where   1 SIMPLE accountIdentity NULL eq_ref PRIMARY PRIMARY 194 user_new.account.IDENTITY_TYPE_ID 1 100 Using where   1 SIMPLE userCertificateType NULL eq_ref PRIMARY PRIMARY 194 user_new.account.CERTIFICATE_TYPE_ID 1 100 Using index   1 SIMPLE userGender NULL eq_ref PRIMARY PRIMARY 194 user_new.account.GENDER_ID 1 100 NULL   1 SIMPLE userNation NULL eq_ref PRIMARY PRIMARY 194 user_new.account.NATION_ID 1 100 NULL   1 SIMPLE userCountry NULL eq_ref PRIMARY PRIMARY 194 user_new.account.COUNTRY_ID 1 100 NULL   1 SIMPLE userAddress NULL eq_ref PRIMARY PRIMARY 194 user_new.account.ADDRESS_ID 1 100 NULL   1 SIMPLE user NULL eq_ref PRIMARY PRIMARY 194 user_new.account.USER_ID 1 100 NULL    去掉JOIN 根据业务逻辑，把查询分成两部分，第一步先查ACCOUNT_NAME，第二步查其他字段，第一步SQL：\n1selectaccount.ACCOUNT_NAME2fromTB_B_ACCOUNTaccount3where1=14and(5account.ACCOUNT_NAMElike\u0026#39;%user%\u0026#39;6ORaccount.USER_NAMElike\u0026#39;%user%\u0026#39;7ORaccount.IDENTITY_TYPE_IDin(selectaccountIdentity.IDfromTB_B_IDENTITY_TYPEaccountIdentitywhereaccountIdentity.NAMElike\u0026#39;%user%\u0026#39;)8ORaccount.ORGANIZATION_IDin(selectaccountOrganization.IDFROMTB_B_ORGANIZATIONaccountOrganizationwhereaccountOrganization.NAMElike\u0026#39;%user%\u0026#39;)9)10andaccount.USER_NAMElike\u0026#39;%user%\u0026#39;11andaccount.ACCOUNT_NAMElike\u0026#39;%user%\u0026#39;12andaccount.ORGANIZATION_IDin13(selectaccountOrganization.IDFROMTB_B_ORGANIZATIONaccountOrganizationwhereDELETED=0);EXPLAIN如下：\n   id select_type table partitions type possible_keys key key_len ref rows filtered Extra     1 PRIMARY accountOrganization NULL ALL PRIMARY NULL NULL NULL 84 10 Using where   1 PRIMARY account NULL ref ORGANIZATION_ID ORGANIZATION_ID 194 user_new.accountOrganization.ID 3637 1.23 Using where   3 SUBQUERY accountOrganization NULL index PRIMARY IDX_ORG_NAME 602 NULL 84 11.11 Using where; Using index   2 SUBQUERY accountIdentity NULL index PRIMARY IDX_ID_TYPE_NAME 602 NULL 49 11.11 Using where; Using index    优化LIKE 看到LIKE用的是中间匹配%...%，这种是无法利用索引的，遂改成前缀匹配，所以做出以下优化：\n1selectaccount.ACCOUNT_NAME2fromTB_B_ACCOUNTaccount3where1=14and(5account.ACCOUNT_NAMElike\u0026#39;user%\u0026#39;6ORaccount.USER_NAMElike\u0026#39;user%\u0026#39;7ORaccount.IDENTITY_TYPE_IDin(selectaccountIdentity.IDfromTB_B_IDENTITY_TYPEaccountIdentitywhereaccountIdentity.NAMElike\u0026#39;user%\u0026#39;)8ORaccount.ORGANIZATION_IDin(selectaccountOrganization.IDFROMTB_B_ORGANIZATIONaccountOrganizationwhereaccountOrganization.NAMElike\u0026#39;user%\u0026#39;)9)10andaccount.USER_NAMElike\u0026#39;user%\u0026#39;11andaccount.ACCOUNT_NAMElike\u0026#39;user%\u0026#39;12andaccount.ORGANIZATION_IDin13(selectaccountOrganization.IDFROMTB_B_ORGANIZATIONaccountOrganizationwhereDELETED=0);EXPLAIN结果：\n   id select_type table partitions type possible_keys key key_len ref rows filtered Extra     1 PRIMARY accountOrganization NULL ALL PRIMARY NULL NULL NULL 84 10 Using where   1 PRIMARY account NULL ref UQ_ACCOUNT_NAME,ORGANIZATION_ID,UQ_ACCOUNT_USRNAME,IDX_ACCOUNT_USERNAME ORGANIZATION_ID 194 user_new.accountOrganization.ID 3637 25 Using where   3 SUBQUERY accountOrganization NULL range PRIMARY,IDX_ORG_NAME IDX_ORG_NAME 602 NULL 1 100 Using where; Using index   2 SUBQUERY accountIdentity NULL range PRIMARY,IDX_ID_TYPE_NAME IDX_ID_TYPE_NAME 602 NULL 1 100 Using where; Using index    2）考虑ORDER BY优化 加上原先的ORDER BY之后，SQL如下：\n1selectaccount.ACCOUNT_NAME2fromTB_B_ACCOUNTaccount3where1=14and(5account.ACCOUNT_NAMElike\u0026#39;user%\u0026#39;6ORaccount.USER_NAMElike\u0026#39;user%\u0026#39;7ORaccount.IDENTITY_TYPE_IDin(selectaccountIdentity.IDfromTB_B_IDENTITY_TYPEaccountIdentitywhereaccountIdentity.NAMElike\u0026#39;user%\u0026#39;)8ORaccount.ORGANIZATION_IDin(selectaccountOrganization.IDFROMTB_B_ORGANIZATIONaccountOrganizationwhereaccountOrganization.NAMElike\u0026#39;user%\u0026#39;)9)10andaccount.USER_NAMElike\u0026#39;user%\u0026#39;11andaccount.ACCOUNT_NAMElike\u0026#39;user%\u0026#39;12andaccount.ORGANIZATION_IDin13(selectaccountOrganization.IDFROMTB_B_ORGANIZATIONaccountOrganizationwhereDELETED=0)14ORDERBYlength(account.ACCOUNT_NAME),account.ACCOUNT_NAME;EXPLAIN结果：\n   id select_type table partitions type possible_keys key key_len ref rows filtered Extra     1 PRIMARY accountOrganization NULL ALL PRIMARY NULL NULL NULL 84 10 Using where; Using temporary; Using filesort   1 PRIMARY account NULL ref UQ_ACCOUNT_NAME,ORGANIZATION_ID,UQ_ACCOUNT_USRNAME,IDX_ACCOUNT_USERNAME ORGANIZATION_ID 194 user_new.accountOrganization.ID 3637 25 Using where   3 SUBQUERY accountOrganization NULL range PRIMARY,IDX_ORG_NAME IDX_ORG_NAME 602 NULL 1 100 Using where; Using index   2 SUBQUERY accountIdentity NULL range PRIMARY,IDX_ID_TYPE_NAME IDX_ID_TYPE_NAME 602 NULL 1 100 Using where; Using index    第一行可以看到 Using temporary; Using filesort。\n Using temporary意思是为了排序，使用了临时表hold住结果。 Using filesort意思是无法使用索引直接得到排好序的数据，需要利用内存或者磁盘文件排序。  三种方案评估 那么对于这个SQL有三种做法，下面分析它们的复杂度。\n先汇总一下基本情况：\n  A表 accountOrganization表有N行\n  B表 account表有M行\n  JOIN条件A.ID = B.ORGANIZATION_ID\n  B.ORGANIZATION上有索引。\n  列出基本算法复杂度\n B+树查找复杂度 Log2(n) 排序复杂度是 n * Log2(n) 堆插入复杂度 Log2(n)  原方案 A做驱动表 N=500，B是被驱动表 M=14w，对结果做普通排序。\n算法复杂度分析：\n扫描A表 + A表每一行利用B表索引查找 + B表每条记录查找主键索引（回表） + B表记录的排序。\n1 N + N * Log2(M) + M * Log2(M) + M * Log2(M) 2= 500 + 500 * Log2(14w) + 14w * Log2(14w) + 14w * Log2(14w) 3= 4,372,745 优化方案一 A做驱动表 N=500，B是被驱动表 M=14w，利用filesort with small LIMIT optimization 优化，即利用一个尺寸20的堆（LIMIT 20）来取前20条数据，前提是数据能够在sort_buffer_size里放得下。\n算法复杂度分析：\n扫描A表 + A表每一行利用B表索引查找 + B表每行查找主键索引（回表） + B表每行过一遍堆。\n1 N + N * Log2(M) + M * Log2(M) + M * Log2(20) 2= 500 + 500 * Log2(14w) + 14w * Log2(14w) + 14w * Log2(20) 3= 2,612,945 优化方案二 B做驱动表 M=14w，A是被驱动表 N=500，在B表新建字段ACCOUNT_NAME_LEN，并建立索引ACCOUNT_NAME_LEN,ACCOUNT_NAME，查询时强制走ACCOUNT_LEN_NAME索引从而达避免排序。\n算法复杂度分析：\n扫描B表索引 + B表每一行利用A表主键查找。\n1 M + M * Log2(N) 2= 14w + 14w * Log2(500) 3= 1,394,400 方案抉择 虽然从分析结果看，方案二更好，但是方案二强制使用了某个索引。而方案一看上去不好，但是MySQL可能会根据查询条件使用合适的索引来过滤数据避免全表扫描，所以选择方案一。\n实现优化方案一 实现优化方案一的关键是让filesort在内存中发生，然后配合LIMIT，我们需要跟踪优化器来查看原始SQL执行情况：\n1SEToptimizer_trace=\u0026#34;enabled=on\u0026#34;;2SETOPTIMIZER_TRACE_MAX_MEM_SIZE=10485760;3SELECT...;#yourqueryhere4SELECT*FROMINFORMATION_SCHEMA.OPTIMIZER_TRACE;5#possiblymorequeries...6#Whendonewithtracing,disableit:7SEToptimizer_trace=\u0026#34;enabled=off\u0026#34;;得到结果：\n1\u0026#34;filesort_priority_queue_optimization\u0026#34;: { 2 \u0026#34;limit\u0026#34;: 1000, 3 \u0026#34;chosen\u0026#34;: false, 4 \u0026#34;cause\u0026#34;: \u0026#34;sort_is_cheaper\u0026#34; 5}, 6\u0026#34;filesort_summary\u0026#34;: { 7 \u0026#34;memory_available\u0026#34;: 262144, 8 \u0026#34;key_size\u0026#34;: 248, 9 \u0026#34;row_size\u0026#34;: 622, 10 \u0026#34;max_rows_per_buffer\u0026#34;: 421, 11 \u0026#34;num_rows_estimate\u0026#34;: 15, 12 \u0026#34;num_rows_found\u0026#34;: 131072, 13 \u0026#34;num_initial_chunks_spilled_to_disk\u0026#34;: 141, 14 \u0026#34;peak_memory_used\u0026#34;: 262144, 15 \u0026#34;sort_algorithm\u0026#34;: \u0026#34;std::stable_sort\u0026#34;, 16 \u0026#34;sort_mode\u0026#34;: \u0026#34;\u0026lt;fixed_sort_key, packed_additional_fields\u0026gt;\u0026#34; 17} 可以看到num_initial_chunks_spilled_to_disk:141，写了141个临时文件。\n让filesort在内存中发生的相关系统参数有：\n sort_buffer_size ，规定了用于排序的缓存大小（字节），默认262144=256K。如果排序的数据在此buffer中能hold住，那么就会避免写磁盘。 max_sort_length ，规定了排序时，每行最多取前多少个字节，如果行的尺寸超出该值，MySQL也就只会使用前多少个字节进行比较，该参数默认1024=1K。 Sort_merge_passes ，是一个状态变量，表示了排序合并的次数。  我们先设置sort_buffer_size到1M（默认256K）\n1setsort_buffer_size=1048576;#只针对当前session有效2setpersistsort_buffer_size=1048576;#全局有效执行SQL，注意添加了LIMIT：\n1selectaccount.ACCOUNT_NAME2fromTB_B_ACCOUNTaccount3where1=14and(5account.ACCOUNT_NAMElike\u0026#39;user%\u0026#39;6ORaccount.USER_NAMElike\u0026#39;user%\u0026#39;7ORaccount.IDENTITY_TYPE_IDin(selectaccountIdentity.IDfromTB_B_IDENTITY_TYPEaccountIdentitywhereaccountIdentity.NAMElike\u0026#39;user%\u0026#39;)8ORaccount.ORGANIZATION_IDin(selectaccountOrganization.IDFROMTB_B_ORGANIZATIONaccountOrganizationwhereaccountOrganization.NAMElike\u0026#39;user%\u0026#39;)9)10andaccount.USER_NAMElike\u0026#39;user%\u0026#39;11andaccount.ACCOUNT_NAMElike\u0026#39;user%\u0026#39;12andaccount.ORGANIZATION_IDin13(selectaccountOrganization.IDFROMTB_B_ORGANIZATIONaccountOrganizationwhereDELETED=0)14ORDERBYlength(account.ACCOUNT_NAME),account.ACCOUNT_NAME15LIMIT20;然后跟踪优化器：\n1\u0026#34;filesort_priority_queue_optimization\u0026#34;: { 2 \u0026#34;limit\u0026#34;: 1000, 3 \u0026#34;chosen\u0026#34;: true 4}, 5\u0026#34;filesort_summary\u0026#34;: { 6 \u0026#34;memory_available\u0026#34;: 1048576, 7 \u0026#34;key_size\u0026#34;: 248, 8 \u0026#34;row_size\u0026#34;: 618, 9 \u0026#34;max_rows_per_buffer\u0026#34;: 1001, 10 \u0026#34;num_rows_estimate\u0026#34;: 7623, 11 \u0026#34;num_rows_found\u0026#34;: 131072, 12 \u0026#34;num_initial_chunks_spilled_to_disk\u0026#34;: 0, 13 \u0026#34;peak_memory_used\u0026#34;: 626626, 14 \u0026#34;sort_algorithm\u0026#34;: \u0026#34;std::stable_sort\u0026#34;, 15 \u0026#34;unpacked_addon_fields\u0026#34;: \u0026#34;using_priority_queue\u0026#34;, 16 \u0026#34;sort_mode\u0026#34;: \u0026#34;\u0026lt;fixed_sort_key, additional_fields\u0026gt;\u0026#34; 17} 可以看到filesort_priority_queue_optimization启用了，同时num_initial_chunks_spilled_to_disk变成了0。\nfilesort_priority_queue_optimization启用意味着MySQL采用了优先级队列（堆）来从结果集中取最小的N个元素。\n在业务场景下，大部分分页每页20条，极少超过10页，因此这里不考虑深分页问题，所以加上LIMIT 200, 220看看：\n1selectaccount.ACCOUNT_NAME2fromTB_B_ACCOUNTaccount3where1=14and(5account.ACCOUNT_NAMElike\u0026#39;user%\u0026#39;6ORaccount.USER_NAMElike\u0026#39;user%\u0026#39;7ORaccount.IDENTITY_TYPE_IDin(selectaccountIdentity.IDfromTB_B_IDENTITY_TYPEaccountIdentitywhereaccountIdentity.NAMElike\u0026#39;user%\u0026#39;)8ORaccount.ORGANIZATION_IDin(selectaccountOrganization.IDFROMTB_B_ORGANIZATIONaccountOrganizationwhereaccountOrganization.NAMElike\u0026#39;user%\u0026#39;)9)10andaccount.USER_NAMElike\u0026#39;user%\u0026#39;11andaccount.ACCOUNT_NAMElike\u0026#39;user%\u0026#39;12andaccount.ORGANIZATION_IDin13(selectaccountOrganization.IDFROMTB_B_ORGANIZATIONaccountOrganizationwhereDELETED=0)14ORDERBYlength(account.ACCOUNT_NAME),account.ACCOUNT_NAME15LIMIT200,220;跟踪优化器结果：\n1\u0026#34;filesort_priority_queue_optimization\u0026#34;: { 2 \u0026#34;limit\u0026#34;: 420, 3 \u0026#34;chosen\u0026#34;: true 4}, 5\u0026#34;filesort_summary\u0026#34;: { 6 \u0026#34;memory_available\u0026#34;: 1048576, 7 \u0026#34;key_size\u0026#34;: 248, 8 \u0026#34;row_size\u0026#34;: 618, 9 \u0026#34;max_rows_per_buffer\u0026#34;: 421, 10 \u0026#34;num_rows_estimate\u0026#34;: 7623, 11 \u0026#34;num_rows_found\u0026#34;: 131072, 12 \u0026#34;num_initial_chunks_spilled_to_disk\u0026#34;: 0, 13 \u0026#34;peak_memory_used\u0026#34;: 263546, 14 \u0026#34;sort_algorithm\u0026#34;: \u0026#34;std::stable_sort\u0026#34;, 15 \u0026#34;unpacked_addon_fields\u0026#34;: \u0026#34;using_priority_queue\u0026#34;, 16 \u0026#34;sort_mode\u0026#34;: \u0026#34;\u0026lt;fixed_sort_key, additional_fields\u0026gt;\u0026#34; 17} 可以看到filesort_priority_queue_optimization依然启用，而且num_initial_chunks_spilled_to_disk依然是0。\n结论 做了以下优化：\n WHERE用到的字段都加上索引。 LIKE改写成前缀匹配，这样可以利用索引。 避免JOIN，分两次查询，第一次先查ACCOUNT_NAME，第二次根据ACCOUNT_NAME查询想要的数据。 增加sort_buffer_size，避免filesort排序时写磁盘，并且利用堆+LIMIT来优化排序。  参考资料  MySQL EXPLAIN解读  MySQL LIMIT 优化  MySQL ORDER BY 优化  MySQL filesort with small LIMIT optimization  MySQL 优化器跟踪  ","date":"2021-09-27","img":"","permalink":"/post/mysql/sql-opt-join-limit-order-by/","series":null,"tags":["mysql","性能调优"],"title":"SQL优化:一个含有JOIN+LIMIT+ORDER BY的SQL(上)"},{"categories":null,"content":"参考自 极客时间 - Linux性能优化实战 ，根据Linux调整内核参数 的方法调整以下参数值。\ntcp参数 1# 增大处于 TIME_WAIT 状态的连接数量 2net.ipv4.tcp_max_tw_buckets=1048576 3# 增大跟踪连接表大小 4net.netfilter.nf_conntrack_max=1048576 5 6# 缩短处于 TIME_WAIT 状态的超时时间 7net.ipv4.tcp_fin_timeout=15 8# 缩短跟踪连接表中处于 TIME_WAIT 状态连接的超时时间 9net.netfilter.nf_conntrack_tcp_timeout_time_wait=30 10 11# 允许 TIME_WAIT 状态占用的端口还可以用到新建的连接中 12net.ipv4.tcp_tw_reuse=1 13# 开上一个必须要开这个 14net.ipv4.tcp_timestamps=1 15 16# 增大本地端口号的范围 17net.ipv4.ip_local_port_range=10000 65000 18 19# 增大进程的最大文件描述符数 20fs.nr_open=1048576 21# 系统的最大文件描述符数 22fs.file-max=1048576 23 24# 增加半连接的最大数量 25net.ipv4.tcp_max_syn_backlog=16384 26# 开启 SYN Cookies 27net.ipv4.tcp_syncookies=1 28# 减少 SYN_RECV 状态的连接重传 SYN+ACK 包的次数 29net.ipv4.tcp_synack_retries=1 30 31# 缩短Keepalive探测包的间隔时间 32net.ipv4.tcp_keepalive_intvl=30 33# 缩短最后一次数据包到Keepalive探测包的间隔时间 34net.ipv4.tcp_keepalive_time=600 35# 减少Keepalive探测失败后通知应用程序前的重试次数 36net.ipv4.tcp_keepalive_probes=3 ","date":"2021-09-08","img":"","permalink":"/post/linux/net-params/","series":null,"tags":["linux","cheatsheet","network","性能调优"],"title":"常用网络内核参数优化"},{"categories":null,"content":"环境 一台Tomcat服务器，监听8080端口，注意这里采用host网络没有NAT：\n1docker run -d --name tomcat-8080 --network=host tomcat:8.5-alpine 用wrk做压测，连接数100，压5分钟，注意这里故意访问了一个不存在的地址，这是为了降低Tomcat CPU以及流量：\n1wrk -c 100 -t 2 -d 300 http://192.168.100.12:8080/abc 【服务端侧】Tomcat，netstat得到大量 TIME_WAIT 的连接：\n1$ sudo netstat -antpl | grep \u0026#39;192.168.100.12:8080\u0026#39; | gawk -F\u0026#39; \u0026#39; \u0026#39;{ print $6 }\u0026#39; | sort | uniq -c 2 93 ESTABLISHED 3 19980 TIME_WAIT 4 5$ sudo conntrack -L -o extended | awk \u0026#39;{print $6 \u0026#34; \u0026#34; $7 \u0026#34; \u0026#34; $8}\u0026#39; | sort | uniq -c | sort -nr | head -n 10 6conntrack v1.4.3 (conntrack-tools): 6566 flow entries have been shown. 7 12361 TIME_WAIT src=192.168.100.21 dst=192.168.100.12 8 ... 【客户端侧】wrk，netstat得到TIME_WAIT 连接在4000左右，conntrack的连接在 6400左右：\n1$ sudo netstat -antpl | grep \u0026#39;192.168.100.12:8080\u0026#39; | gawk -F\u0026#39; \u0026#39; \u0026#39;{ print $6 }\u0026#39; | sort | uniq -c 2 101 ESTABLISHED 3 1 SYN_SENT 4 11782 TIME_WAIT 5 6$ sudo conntrack -L -o extended | awk \u0026#39;{print $6 \u0026#34; \u0026#34; $7 \u0026#34; \u0026#34; $8}\u0026#39; | sort | uniq -c | sort -nr | head -n 10 7conntrack v1.4.3 (conntrack-tools): 9972 flow entries have been shown. 8 21081 TIME_WAIT src=192.168.100.21 dst=192.168.100.12 9 ... 分析 【客户端侧】wrk连接数才100个就产生了近 12000 个TIME_WAIT连接，极大浪费了本地端口资源。\n【服务端侧】在Tomcat侧也有近 20000 个TIME_WAIT，虽然不浪费端口资源但是浪费内核资源。\nTIME_WAIT 状态代表socket已经关闭，走完了4次挥手流程，在等待网络里是否还有包传输过来：\n1$ man netstat 2TIME_WAIT 3 The socket is waiting after close to handle packets 4 still in the network. 联想到内核tcp相关参数：\n1$ man tcp 2 3tcp_tw_reuse (Boolean; default: disabled; since Linux 2.4.19/2.6) 4 Allow to reuse TIME_WAIT sockets for new connections 5 when it is safe from protocol viewpoint. It should 6 not be changed without advice/request of technical experts. 调整参数 观察 net.ipv4.tcp_tw_reuse内核参数发现没有开启：\n1$ sysctl net.ipv4.tcp_tw_reuse 20 将其打开（如果要永久开启请看Linux调整Limits ）：\n1$ sudo sysctl -w net.ipv4.tcp_tw_reuse=1 【客户端】wrk TIME_WAIT连接数 7000左右，比之前 12000 好很多：\n1$ sudo netstat -antpl | grep \u0026#39;192.168.100.12:8080\u0026#39; | gawk -F\u0026#39; \u0026#39; \u0026#39;{ print $6 }\u0026#39; | sort | uniq -c 2 1 CLOSING 3 99 ESTABLISHED 4 7018 TIME_WAIT 【服务端】Tomcat TIME_WAIT连接数 13000左右，比之前的 20000 好很多：\n1$ sudo netstat -antpl | grep \u0026#39;192.168.100.12:8080\u0026#39; | gawk -F\u0026#39; \u0026#39; \u0026#39;{ print $6 }\u0026#39; | sort | uniq -c 2 103 ESTABLISHED 3 13628 TIME_WAIT 扩展 可以参考常用网络内核参数优化 给内核网络参数做一个完整的优化。\n","date":"2021-09-07","img":"","permalink":"/post/linux/too-many-time-wait-troubleshooting/","series":null,"tags":["nginx","troubleshooting"],"title":"压测时大量TIME_WAIT问题排查"},{"categories":null,"content":"man tcp 查看tcp协议的内核文档，相关内核参数。\nnetstat 根据连接状态分类统计：\n1$ netstat -antpl | gawk -F\u0026#39; \u0026#39; \u0026#39;{ print $6 }\u0026#39; | sort | uniq -c 2 1 established) 3 5 ESTABLISHED 4 1 Foreign 5 4 LISTEN 6 2 TIME_WAIT 各协议统计：\n1$ netstat -s 2 3Ip: 4 36011721975 total packets received 5 4 with invalid addresses 6 25054109504 forwarded 7 0 incoming packets discarded 8... 9Tcp: 10 506169163 active connections openings 11 28177249 passive connection openings 12 143466 failed connection attempts 13 48873 connection resets received 14... 关注套接字统计信息：\n1$ netstat -s | grep socket 2 73 resets received for embryonic SYN_RECV sockets 3 308582 TCP sockets finished time wait in fast timer 4 8 delayed acks further delayed because of locked socket 5 290566 times the listen queue of a socket overflowed 6 290566 SYNs to LISTEN sockets dropped conntrack 统计总的连接跟踪数：\n1$ conntrack -L -o extended | wc -l 2100 统计TCP协议各个状态的连接跟踪数：\n1$ conntrack -L -o extended | awk \u0026#39;/^.*tcp.*$/ {sum[$6]++} END {for(i in sum) print i, sum[i]}\u0026#39; 2 3conntrack v1.4.3 (conntrack-tools): 3349 flow entries have been shown. 4CLOSE_WAIT 17 5CLOSE 31 6ESTABLISHED 758 7TIME_WAIT 387 8SYN_SENT 72 统计各个源IP的连接跟踪数：\n1$ conntrack -L -o extended | awk \u0026#39;{print $7}\u0026#39; | cut -d \u0026#34;=\u0026#34; -f 2 | sort | uniq -c | sort -nr | head -n 10 2conntrack v1.4.3 (conntrack-tools): 2693 flow entries have been shown. 3 1048 192.168.100.21 4 669 192.168.100.5 5 504 10.42.3.94 6 61 10.42.3.171 7 44 10.42.3.128 8 41 10.42.3.3 9 38 10.43.0.10 10 26 10.42.3.70 11 18 10.42.3.27 12 16 10.42.3.41 统计各个四元组的连接跟踪数：\n1$ conntrack -L -o extended | awk \u0026#39;{print $6 \u0026#34; \u0026#34; $7 \u0026#34; \u0026#34; $8}\u0026#39; | sort | uniq -c | sort -nr | head -n 10 2 3conntrack v1.4.3 (conntrack-tools): 3357 flow entries have been shown. 4 500 ESTABLISHED src=10.42.3.94 dst=10.42.4.129 5 30 TIME_WAIT src=192.168.100.21 dst=10.42.3.167 6 30 TIME_WAIT src=192.168.100.21 dst=10.42.3.156 7 30 TIME_WAIT src=192.168.100.21 dst=10.42.3.133 8 30 TIME_WAIT src=192.168.100.21 dst=10.42.3.132 9 21 ESTABLISHED src=10.42.3.70 dst=10.43.239.23 10 19 CLOSE src=10.42.3.128 dst=10.43.117.95 11 15 SYN_SENT src=10.42.3.27 dst=10.43.161.131 12 13 SYN_SENT src=10.42.3.41 dst=10.43.223.88 13 12 TIME_WAIT src=192.168.100.21 dst=10.42.3.71 ss 查看连接状态统计：\n1$ ss -s 2Total: 9190 (kernel 0) 3TCP: 2450 (estab 30, closed 2309, orphaned 0, synrecv 0, timewait 1135/0), ports 0 4 5Transport Total IP IPv6 6*\t0 - - 7RAW\t0 0 0 8UDP\t2 2 0 9TCP\t141 75 66 10INET\t143 77 66 11FRAG\t0 0 0 hping3 测试网络延迟Round-Trip Time：\n1 2# -c表示发送3次请求，-S表示设置TCP SYN，-p表示端口号为80 3$ hping3 -c 3 -S -p 80 baidu.com 4HPING baidu.com (eth0 123.125.115.110): S set, 40 headers + 0 data bytes 5len=46 ip=123.125.115.110 ttl=51 id=47908 sport=80 flags=SA seq=0 win=8192 rtt=20.9 ms 6len=46 ip=123.125.115.110 ttl=51 id=6788 sport=80 flags=SA seq=1 win=8192 rtt=20.9 ms 7len=46 ip=123.125.115.110 ttl=51 id=37699 sport=80 flags=SA seq=2 win=8192 rtt=20.9 ms 8 9--- baidu.com hping statistic --- 103 packets transmitted, 3 packets received, 0% packet loss 11round-trip min/avg/max = 20.9/20.9/20.9 ms traceroute 1# --tcp表示使用TCP协议，-p表示端口号，-n表示不对结果中的IP地址执行反向域名解析 2$ traceroute --tcp -p 80 -n baidu.com 3traceroute to baidu.com (123.125.115.110), 30 hops max, 60 byte packets 4 1 * * * 5 2 * * * 6 3 * * * 7 4 * * * 8 5 * * * 9 6 * * * 10 7 * * * 11 8 * * * 12 9 * * * 1310 * * * 1411 * * * 1512 * * * 1613 * * * 1714 123.125.115.110 20.684 ms * 20.798 ms traceroute 会在路由的每一跳发送三个包，并在收到响应后，输出往返延时。如果无响应或者响应超时（默认 5s），就会输出一个星号。\nsar 安装：\n1yum install -y sysstat 观察 PPS（每秒收发的报文数）和BPS（每秒收发的字节数）：\n1$ sar -n DEV 1 208:55:49 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil 308:55:50 docker0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 408:55:50 eth0 22274.00 629.00 1174.64 37.78 0.00 0.00 0.00 0.02 508:55:50 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ","date":"2021-09-07","img":"","permalink":"/post/linux/net-debug-scripts/","series":null,"tags":["linux","cheatsheet","network"],"title":"网络监控实用脚本"},{"categories":null,"content":"现象 redis-server Pod启动不起来。\n观察Pod日志，看到：\n1Bad file format reading the append only file: make a backup of your AOF file, then use ./redis-check-aof --fix \u0026lt;filename\u0026gt; 修复 错误很明确了，AOF文件破损，了解到之前因为Node出问题，把Pod强制删除过，应该是这个原因造成的。\n修改Yaml，设置启动命令为/bin/sh，开启tty和stdin，注释掉所有Probe：\n1...2tty:true3stdin:true4command:5- /bin/sh6...7# livenessProbe: ...8# readinessProbe: ...容器启动后，因为用的是bitnami redis镜像，所以进入容器shell执行：\n1redis-check-aof /bitnami/redis/data/appendonly.aof 2... 3Continue [y/N]: y 然后再把上述修改撤回，重启Pod，问题修复。\n","date":"2021-09-07","img":"","permalink":"/post/redis/redis-bad-aof/","series":null,"tags":["redis","k8s","troubleshooting"],"title":"K8S中Redis损坏的AOF文件排查"},{"categories":null,"content":"现象 某节点出现故障，在Rancher上看到的是Inactive状态。但是这个机器上的Pod一个都没有被迁移，导致业务无法运行。\n分析：首先这个Node不光kubelet坏了，上面的Pod也受损了，其次K8S没有把它们迁移到健康Node上。\n排查 查了Google后得到，如果Node变成NotReady、Unkonwn等非正常情况，但是Pod没有正确的从这些Node移除迁移到其他Node，这是一个K8S的Bug。 这个Bug在 v1.19.9及以后, v1.20.5及以后，v1.21.0 及以后才被修复。 现在的K8S版本是 v1.17.3 。\n相关issue：https://github.com/kubernetes/kubernetes/issues/55713\n","date":"2021-09-07","img":"","permalink":"/post/k8s/pod-not-evicted-from-notready-nodes/","series":null,"tags":["k8s","troubleshooting"],"title":"Pod没有从NotReady节点迁出的排查"},{"categories":null,"content":"某次压力测试时，Jmeter得到大量connection reset、connect timeout的错误。\n拓扑 1Jmeter -\u0026gt; nginx[:9001] -\u0026gt; k8s worker[:80](ingress-nginx) -\u0026gt; k8s pod[:10080] 观察nginx nginx采用的是四层代理，用的是stream模块 查看 /var/log/nginx/error.log，看到大量too many open files的错误。\n观察ulimit -a得到open files (-n) 1024，这个值太小了，采用这个方式调大 。\n优化nginx 再优化nginx，调整 /etc/nginx/nginx.conf 。\n调整worker_processes ，默认值是 1，改为auto。\n1worker_processes auto; 调整worker_connections ，默认值是512太小了，压测并发有15000，因为服务器有10核，woker_processes的实际值是10，所以调整到1600，那么总共就是16000。\n1worker_connections 1600; 调整worker_rlimit_nofile 到16000，该值小于不能总的worker_connections：\n1worker_rlimit_nofile 16000; 再次压测后，Jmeter得到502 bad gateway等错误。\n观察nginx的 /var/log/nginx/error.log ，没有新的错误日志产生。\n观察ingress nginx 先设置ingress nginx配置 disable-access-log=true ，关闭access log打印，可以让我们专注在错误日志上。\n观察ingress nginx日志，发现先有大量Connection timed out错误：\n1[error] 46#46: *7495 upstream timed out (110: Connection timed out) while connecting to upstream 2.... 然后出现大量Cannot assign requested address的错误：\n1[crit] 46#46: *10527 connect() to 10.42.5.220:10080 failed (99: Cannot assign requested address) while connecting to upstream 看来是ingress nginx和Pod的连接超时了，根据ingress nginx文档 ，proxy-connection-timeout默认值5秒，太短了，调整到60秒。\n再次压测后Connection timed out问题没有了，而且Cannot assign requested address也没有了。\n","date":"2021-09-07","img":"","permalink":"/post/nginx/benchmark-toubleshooting/","series":null,"tags":["nginx","troubleshooting","性能调优"],"title":"某次压力测试中对Nginx的排障"},{"categories":null,"content":"配置方法 查看内核限制 1ulimit -a 系统级调整 添加配置\n1vi /etc/sysctl.conf 生效配置\n1sysctl -p 用户级调整 修改配置\n1vi /etc/security/limits.conf 常用配置 max open files 系统级：\n1fs.file-max=500000 验证：\n1cat /proc/sys/fs/file-max 用户级：\n1## Example hard limit for max opened files 2\u0026lt;domain\u0026gt; hard nofile 4096 3## Example soft limit for max opened files 4\u0026lt;domain\u0026gt; soft nofile 1024 ","date":"2021-09-07","img":"","permalink":"/post/linux/limits/","series":null,"tags":["linux","cheatsheet"],"title":"Linux内核参数/Limits调整方法"},{"categories":null,"content":"现象 机房断电，通电后，K8S集群的某些Node一直处于NotReady状态。\n查看kubelet日志 到Node上，查看Kubelet日志：\n1$ journalctl -u kubelet 2 3Sep 01 09:24:20 node30 kubelet[1399]: I0901 09:24:20.953854 1399 csi_plugin.go:945] Failed to contact API server when waiting for CSINode publishing: Unauthorized 4Sep 01 09:24:20 node30 kubelet[1399]: E0901 09:24:20.960125 1399 controller.go:136] failed to ensure node lease exists, will retry in 3.2s, error: Unauthorized 5Sep 01 09:24:21 node30 kubelet[1399]: E0901 09:24:21.051942 1399 kubelet.go:2267] node \u0026#34;node30\u0026#34; not found 6Sep 01 09:24:21 node30 kubelet[1399]: E0901 09:24:21.152071 1399 kubelet.go:2267] node \u0026#34;node30\u0026#34; not found 7Sep 01 09:24:21 node30 kubelet[1399]: I0901 09:24:21.152502 1399 kubelet_node_status.go:294] Setting node annotation to enable volume controller attach/detach 8Sep 01 09:24:21 node30 kubelet[1399]: I0901 09:24:21.152782 1399 setters.go:77] Using node IP: \u0026#34;210.45.193.149\u0026#34; 9Sep 01 09:24:21 node30 kubelet[1399]: I0901 09:24:21.177629 1399 kubelet_node_status.go:486] Recording NodeHasSufficientMemory event message for node node30 10Sep 01 09:24:21 node30 kubelet[1399]: I0901 09:24:21.177658 1399 kubelet_node_status.go:486] Recording NodeHasNoDiskPressure event message for node node30 11Sep 01 09:24:21 node30 kubelet[1399]: I0901 09:24:21.177666 1399 kubelet_node_status.go:486] Recording NodeHasSufficientPID event message for node node30 12Sep 01 09:24:21 node30 kubelet[1399]: I0901 09:24:21.177686 1399 kubelet_node_status.go:70] Attempting to register node node30 13Sep 01 09:24:21 node30 kubelet[1399]: E0901 09:24:21.179746 1399 kubelet_node_status.go:92] Unable to register node \u0026#34;node30\u0026#34; with API server: Unauthorized 14Sep 01 09:24:21 node30 kubelet[1399]: E0901 09:24:21.184238 1399 reflector.go:178] k8s.io/client-go/informers/factory.go:135: Failed to list *v1.CSIDriver: Unauthorized 15Sep 01 09:24:21 node30 kubelet[1399]: E0901 09:24:21.252222 1399 kubelet.go:2267] node \u0026#34;node30\u0026#34; not found 16Sep 01 09:24:21 node30 kubelet[1399]: E0901 09:24:21.340245 1399 reflector.go:178] k8s.io/kubernetes/pkg/kubelet/kubelet.go:526: Failed to list *v1.Node: Unauthorized 17Sep 01 09:24:21 node30 kubelet[1399]: E0901 09:24:21.352382 1399 kubelet.go:2267] node \u0026#34;node30\u0026#34; not found 注意到关键日志：\n1Sep 01 09:24:21 node30 kubelet[1399]: E0901 09:24:21.179746 1399 kubelet_node_status.go:92] Unable to register node \u0026#34;node30\u0026#34; with API server: Unauthorized 意思是Node无法注册到Api Server，初步判断是这个原因导致的Node一直处于NotReady状态。\n重启kubelet 1systemctl restart kubelet 问题依旧。\n查资料 查询资料，没有找到类似问题，也没有解决办法。\n探究为何与Api Server通信被拒绝 1Sep 01 09:24:21 node30 kubelet[1399]: E0901 09:24:21.179746 1399 kubelet_node_status.go:92] Unable to register node \u0026#34;node30\u0026#34; with API server: Unauthorized 日志的意思上看，是kubelet和Api Server通信的时候被拒绝了，拒绝原因是未授权。\n那么kubelet的和Api Server的通信配置在哪里呢？\n1$ ps -ef | grep kubelet 2 3/usr/local/bin/kubelet --logtostderr=true --v=2 --node-ip=... 4--hostname-override=node30 5--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf 6--config=/etc/kubernetes/kubelet-config.yaml 7--kubeconfig=/etc/kubernetes/kubelet.conf 8--pod-infra-container-image=harbor.supwisdom.com/gcr-image/pause:3.2 9--runtime-cgroups=/systemd/system.slice 10--network-plugin=cni --cni-conf-dir=/etc/cni/net.d --cni-bin-dir=/opt/cni/bin 注意到--kubeconfig=/etc/kubernetes/kubelet.conf，查看这个文件内容：\n1apiVersion:v12clusters:3- cluster:4certificate-authority-data:[Base64]5server:https://localhost:64436name:default-cluster7contexts:8- context:9cluster:default-cluster10namespace:default11user:default-auth12name:default-context13current-context:default-context14kind:Config15preferences:{}16users:17- name:default-auth18user:19client-certificate:/var/lib/kubelet/pki/kubelet-client-current.pem20client-key:/var/lib/kubelet/pki/kubelet-client-current.pem对比其他好的Node的certificate-authority-data字段，发现是一样的。\n再对比其他好的Node的/var/lib/kubelet/pki/kubelet-client-current.pem，发现是不一样的，问题可能出在这个文件里。推测每个Node作为一个独立的Api Server客户端有自己独特的证书。\n查看kubelet-client-current.pem 这个文件是一个x509证书，显然Api Server用来做客户端认证的，kubelet也是Api Server的客户端，看一下这个文件。\n1$ ls -l /var/lib/kubelet/pki/ 2-rw-------. 1 root root 1090 Nov 6 2020 kubelet-client-2020-11-06-02-48-49.pem 3-rw-------. 1 root root 1090 Sep 1 2021 kubelet-client-2021-09-01-13-21-24.pem 4lrwxrwxrwx. 1 root root 59 Sep 1 2021 kubelet-client-current.pem -\u0026gt; /var/lib/kubelet/pki/kubelet-client-2021-09-01-13-21-24.pem 5-rw-r--r--. 1 root root 2279 Nov 6 2020 kubelet.crt 6-rw-------. 1 root root 1679 Nov 6 2020 kubelet.key 发现这个文件是一个软连接，指向的是kubelet-client-2021-09-01-13-21-24.pem，但笔者在排查问题时的时间是9月1日早上11点左右，这个文件显然是超前了。\n再查看这个文件内容：\n1openssl x509 -in kubelet-client-2021-09-01-13-21-24.pem -noout -text 2 3Certificate: 4 Data: 5 Version: 3 (0x2) 6 Serial Number: 7 [hex block] 8 Signature Algorithm: sha256WithRSAEncryption 9 Issuer: CN = kubernetes 10 Validity 11 Not Before: Sep 1 05:11:39 2021 GMT 12 Not After : Sep 1 05:11:39 2022 GMT 13 Subject: O = system:nodes, CN = system:node:node30.eams.supwisdom.com 14 Subject Public Key Info: 15 Public Key Algorithm: id-ecPublicKey 16 Public-Key: (256 bit) 17 pub: 18 [hex block] 19 ASN1 OID: prime256v1 20 NIST CURVE: P-256 21 X509v3 extensions: 22 X509v3 Key Usage: critical 23 Digital Signature, Key Encipherment 24 X509v3 Extended Key Usage: 25 TLS Web Client Authentication 26 X509v3 Basic Constraints: critical 27 CA:FALSE 28 Signature Algorithm: sha256WithRSAEncryption 29 [hex block] 发现证书有效期从 2021年9月1日13:11:39 ～2022年9月1日13:11:39（GMT转换成东八区），这个是不对的。\n解决办法 因为同目录下还有一个 kubelet-client-2020-11-06-02-48-49.pem，所以尝试把软连接指向这个文件，然后再启动kubelet试试。\n1$ rm /var/lib/kubelet/pki/kubelet-client-current.pem 2$ ln -s /var/lib/kubelet/pki/kubelet-client-2020-11-06-02-48-49.pem /var/lib/kubelet/pki/kubelet-client-current.pem 3$ systemctl restart kubelet 问题解决，Node恢复成Ready状态。\n后续 因为Node上的还有断电前的容器，为了把Node清理干净，把kubelet停止，删除所有容器，再启动kubelet。\n","date":"2021-09-01","img":"","permalink":"/post/k8s/node-can-not-register-troubleshooting/","series":null,"tags":["k8s","troubleshooting"],"title":"K8S Node无法注册故障排查"},{"categories":null,"content":"现象 在清空浏览器缓存的情况下，访问 某网站 网页加载很慢，长达20～30秒。\n下图只显示了10秒左右，但这个只是个别情况，大多数情况在20～30秒左右：\n据开发人员称，之前做了一些优化：\n 调整了Tomcat的连接池和一些timeout 调整了Nginx的work数量和CPU affinity（这个其实多余的）  排查JVM 在访问门户网站的时候，用jstack导出线程堆栈，传到 fasttread.io 上看，发现1000个tomcat http线程都闲着，并没有在工作。\n用jstat -gcutil查看JVM的垃圾收集情况，访问期间并发生FCG。\n小节：JVM工作正常。\n排查CPU 查看Nginx服务器和Tomcat服务器的CPU，CPU利用率都很低。\n小节：没有异常。\n用ab压测 找了一个静态资源，用ab做压力测试（5线程，时间10秒，-c 5 -t 10），10秒内完成了2483个请求，最大响应时间213ms：\n陷入僵局 总结一下目前的情况：\n Nginx服务器CPU没问题 Tomcat服务器CPU没问题 JVM没问题 用ab做压测，结果非常好，比浏览器访问快多了  排查网络请求 打开Chrome的开发者模式采集网络请求，看到整个网站的请求数量多达200+个，且大多数请求都是下载小尺寸资源。\n和开发人员沟通后表示，同版本网站在另一个客户打开时间只需要2-3秒，且同样是在内网环境。\n仔细查看每个请求的Timing，发现Stalled的时间非常长，有的光Stalled就有 \u0026gt; 2秒。\n根据Chrome对于Stalled的解释 ，有三个原因：\n There are higher priority requests. There are already six TCP connections open for this origin, which is the limit. Applies to HTTP/1.0 and HTTP/1.1 only. The browser is briefly allocating space in the disk cache  分析一下这三个原因：\n 第一个原因不成立，因为并不存在更高优先级的请求 第二个原因不成立，因为ab用的是5线程，chrome用6线程，ab结果比chrome好太多，应该不是这个原因 第三个原因牵涉到浏览器缓存落磁盘，这个应该不是瓶颈。  小节：再次陷入僵局。\n奇怪的无痕模式 在无意中发现，Chrome无痕模式下访问速度很快，可以在2-3秒内完成。\n对比Stalled 发现下载相同的资源无痕模式下Stalled只有~100ms，比正常模式的~2s快好多，这个结果也接近ab测试的结果：\n对比请求 难道是无痕模式和正常模式的请求不一样，导致nginx/tomcat/程序走了不一样的逻辑？\n对比发现，请求头一模一样。\n同时查看nginx配置文件也没发现特别之处。\n同时也可以排除防火墙的原因，因为请求都一模一样，防火墙不可能做出不一样的策略的。\n对比tcpdump 在Nginx对做tcpdump，看看无痕模式的抓包和正常模式的抓包有何区别。\n结果是没有发现特别之处。\nchrome://net-export Chrome打开chrome://net-export ，正常模式下访问门户时抓网络事件。\n然后使用 https://netlog-viewer.appspot.com/#import 打开。\n没有发现特别的地方。\nPC的磁盘 回顾根据Chrome关于Stalled的解释 ，有三个原因：\n There are higher priority requests. There are already six TCP connections open for this origin, which is the limit. Applies to HTTP/1.0 and HTTP/1.1 only. The browser is briefly allocating space in the disk cache  前两个原因已经排除，默非真的是因为PC的磁盘不给力？\n在google搜索The browser is briefly allocating space in the disk cache incognito在Chromium的wiki 中发现无痕模式的Cache采用的是内存实现，普通模式采用的是磁盘实现：\n Chromium has two different implementations of the cache interfaces: while the main one is used to store info on a given disk, there is also a very simple implementation that doesn’t use a hard drive at all, and stores everything in memory. The in-memory implementation is used for the Incognito mode \u0026hellip;\n 再次查看网络事件 再次查看 chrome://net-export 导出的网络事件，发现正常模式下的Disk Cache还真的是很慢，比如下面这个图片，写Disk缓存的用了3686ms：\n再次用ab来测试 之前的ab之所以快怀疑是因为ab也把下载的文件写到内存而不是磁盘，但是查看ab的文档后，并不存在可以把下载结果写到磁盘的参数。\n抓无痕模式下的网络事件 再次用 chrome://net-export 抓无痕模式下的网络事件。\n总结 在排除一切可能性之后，目前最大的可能是PC的磁盘不给力，导致了这个现象。\n后续工作：找一台配置更好的PC来访问网站看看，验证一下这个结果。\n","date":"2021-07-13","img":"","permalink":"/post/pc-disk-slow-site/","series":null,"tags":["troubleshooting","性能调优"],"title":"PC磁盘性能地下导致访问网站很慢问题排查记录"},{"categories":null,"content":"A客户现场反馈，访问我司某应用时，页面加载需要10~20秒，而同样应用在B客户只需要3秒。在排查这个问题的过程中无意中发现，使用Chrome的无痕模式（Incognito）和正常模式访问，页面加载速度天差地别，隐私模式只需2~3秒。\n正常模式：\n无痕模式：\n仔细对比之后发现，对于同一个资源的下载，正常模式的Stalled时间高处无痕模式更长。\n正常模式：\n无痕模式：\n根据Chrome对于Stalled的解释 ，有三个原因：\n There are higher priority requests. There are already six TCP connections open for this origin, which is the limit. Applies to HTTP/1.0 and HTTP/1.1 only. The browser is briefly allocating space in the disk cache  因为访问的是同一个网站，发出的请求是一样的，因此前两条排除，那么只有可能是最后一条——磁盘缓存阻塞。\n在Chromium的wiki 中发现无痕模式的Cache采用的是内存实现，普通模式采用的是磁盘实现：\n Chromium has two different implementations of the cache interfaces: while the main one is used to store info on a given disk, there is also a very simple implementation that doesn’t use a hard drive at all, and stores everything in memory. The in-memory implementation is used for the Incognito mode\n","date":"2021-07-13","img":"","permalink":"/post/chrome-incognito-mode-faster/","series":null,"tags":["troubleshooting","network","chrome","性能调优"],"title":"Chrome隐私模式网页加载速度更快"},{"categories":null,"content":"步骤 在Rancher中添加Grafana应用商店：https://grafana.github.io/helm-charts\n部署loki-stack\n在应答中配置参数\n下面是一个参数参考列表\n   参数 说明 参考值     grafana.enabled 是否安装Grafana true   grafana.ingress.enabled Grafana是否部署Ingress true   grafana.ingress.hosts Grafana Ingress域名 {grafana.xxx.com}   grafana.persistence.enabled Grafana是否启用持久卷 true   grafana.persistence.storageClassName Grafana持久卷的StorageClass    loki.persistence.enabled Loki是否启用持久卷 true   loki.persistence.size Loki持久卷的大小 5Gi   loki.persistence.storageClassName Loki持久卷的StorageClass    prometheus.enabled 是否安装Prometheus false   prometheus.alertmanager.enabled 是否安装Alertmanager false    访问Grafana：访问 grafana.ingress.hosts 配置的值。使用admin/admin账号登录。\n在Rancher的服务发现中找到loki的Service\nGrafana中配置Loki数据源：\n选择Loki数据源，配置Loki的地址为：http://\u0026lt;loki-svc\u0026gt;:3100\n搜索日志（要学习LogQL ）：\n参考文档  Helm安装Grafana Loki  LogQL  ","date":"2021-05-31","img":"","permalink":"/post/rancher-grafana-loki/","series":null,"tags":["grafana","监控","日志"],"title":"Rancher安装Grafana Loki"},{"categories":null,"content":"本方案用到了MySQL企业版的监控管理，请自行决定是否存在商业版授权的问题。\n架构上分为两个部分：\n Service Manager（监控管理后台） Monitor Agent（采集器）运行在MySQL服务器上  下载软件 访问 https://edelivery.oracle.com/ ，需要登录，可自行注册账号。\n搜索 MySQL Enterprise Monitor，根据下图的顺序点击：\n选择Linux x86-64 平台，然后下一步：\n阅读授权，然后下一步：\n可以点击文件名直接浏览器下载，也可以点击Download下载一个下载器，然后再下载：\n文件说明 两个文件下载完之后，解压缩，你可以看到一些文档文件和几个可执行文件（bin文件）：\n mysqlmonitor-8.0.25.1328-linux-x86_64-installer.bin mysqlmonitor-8.0.25.1328-linux-x86_64-update-installer.bin mysqlmonitoragent-8.0.25.1328-linux-x86-64bit-installer.bin mysqlmonitoragent-8.0.25.1328-linux-x86-64bit-update-installer.bin  首次安装只需要*-installer.bin就可以了，如果是对已有安装的升级需要*-update-installer.bin。这里讲的是首次安装。\n安装Service Manager 找任意一台服务器，把mysqlmonitor-8.0.25.1328-linux-x86_64-installer.bin传上去，然后安装：\n1$ ./mysqlmonitor-8.0.25.1328-linux-x86_64-installer.bin --mode text 2 3Language Selection 4 5Please select the installation language 6[1] English - English 7[2] Japanese - 日本語 8[3] Simplified Chinese - 简体中文 9Please choose an option [1] : 3 \u0026lt;选择3\u0026gt; 10信息: 安装过程中要求您输入 Enterprise Monitor 使用的多个用户名和密码。请将这些密码保存至安全场所，以备恢复使用。 11按 [Enter] 继续：\u0026lt;回车\u0026gt; 12---------------------------------------------------------------------------- 13欢迎使用 MySQL Enterprise Monitor 安装向导 14 15---------------------------------------------------------------------------- 16请指定 MySQL Enterprise Monitor 的安装目录 17 18安装目录 [/home/ubuntu/mysql/enterprise/monitor]: \u0026lt;回车\u0026gt; 19 20 21---------------------------------------------------------------------------- 22Select Requirements 23 24选择要求 25 26请指明监视范围，安装初始过程中将相应地配置内存使用。注意: 该设置对性能有极大影响。手册中包含相关内容，如有需要，您可以之后更新该配置。该安装将监视: 27 28系统容量 29 30[1] 小型系统: 使用笔记本电脑或不超过4GB内存的低档服务器监视 1 至 5 个 MySQL 服务器 31[2] 中型系统: 使用一个共享4 GB 到8 GB内存的中型服务器上监视多达100个 MySQL 服务器 32[3] 大型系统: 使用超过8 GB内存的 MEM 专用服务器监视超过100个 MySQL 服务器 33请选择选项 [2] : 1 \u0026lt;选择1\u0026gt; 34 35 36---------------------------------------------------------------------------- 37Tomcat 服务器选项 38 39请为绑定的 Tomcat 服务器指定以下参数 40 41Tomcat 服务器端口 [18080]: \u0026lt;回车\u0026gt; 42 43 44Tomcat SSL 端口 [18443]: \u0026lt;回车\u0026gt; 45---------------------------------------------------------------------------- 46安装数据库 47 48请选择希望配置使用的数据库 49 50[1] 使用 MEM 绑定的 MySQL 数据库 51[2] 使用既存的 MySQL 数据库 * 52请选择选项 [1] : \u0026lt;回车\u0026gt; 53 54* 在安装过程中将验证既存 MySQL 数据库的版本. 查阅文档获取最低版本要求信息。 55 56* 重要: 如果您的既存 MySQL 数据库中已经存在了另一个 MySQL Enterprise Monitor 57存储库，继续保留该存储库，请在下一个画面的\u0026#34;MySQL Database Name\u0026#34;区域内指定一个唯一名称。 58 59 60 61访问下记 URL 获取更多信息: 62 63http://dev.mysql.com/doc/mysql-monitor/8.0/en/mem-install-server.html 64 65---------------------------------------------------------------------------- 66配置存储库 67 68请指定 bundled MySQL 服务器的下记参数 69 70存储库用户名称 [service_manager]: \u0026lt;回车\u0026gt; 71 72密码 : \u0026lt;输入密码\u0026gt; 73再次输入 : \u0026lt;输入密码\u0026gt; 74MySQL 数据库端口 [13306]: \u0026lt;回车\u0026gt; 75 76MySQL 数据库名称 [mem]: \u0026lt;回车\u0026gt; 77 78---------------------------------------------------------------------------- 79配置报告 80 81 82 83没有使用root用户安装 MySQL Enterprise Monitor。因此无法配置为重启后自动运行。参阅 MySQL Enterprise Monitor 84文档的安装部分获得手动安装的详细信息 85 86按 [Enter] 继续：\u0026lt;回车\u0026gt; 87---------------------------------------------------------------------------- 88准备安装 MySQL Enterprise Monitor 至您的计算机。 89 90您确定要继续吗？ [Y/n]: \u0026lt;回车\u0026gt; 91 92---------------------------------------------------------------------------- 93正在安装 MySQL Enterprise Monitor 至您的电脑中，请稍候。 94 95 正在安装 96 0% ______________ 50% ______________ 100% 97 ######################################### 98 99 ---------------------------------------------------------------------------- 100完成安装文件 101 102 103 104完成 MySQL Enterprise Monitor 安装文件在您的计算机 105 106卸载 MySQL Enterprise Monitor 文件调用: 107/home/ubuntu/mysql/enterprise/monitor/uninstall 108 109完成安装，启动 MySQL Enterprise Monitor 监视面板并完成初始配置。请参阅自述文件以获得更多信息和已知问题列表。 110 111 112按 [Enter] 继续： \u0026lt;回车\u0026gt; 113 114---------------------------------------------------------------------------- 115完成安装文件 116 117警告: 为提升安全性，与服务管理器的通信采用 118SSL。因为在安装服务管理器时包含基本的自签署安全证书，所以您的浏览器很可能会显示一个关于不可信连接的警告。请安装您自己的证书或为服务管理器的 URL 119添加一个安全例外。查阅文档获取更多信息。 120 121http://dev.mysql.com/doc/mysql-monitor/8.0/en/mem-ssl-installation.html 122按 [Enter] 继续： \u0026lt;回车\u0026gt; 123 124---------------------------------------------------------------------------- 125安装程序已经将 MySQL Enterprise Monitor 安装于您的电脑中。 126 127查看自述文件 [Y/n]: \u0026lt;回车\u0026gt; 128 129信息: 配置 MySQL Enterprise Monitor 请访问下记页面: https://localhost:18443 130按 [Enter] 继续：\u0026lt;回车\u0026gt; 访问https://\u0026lt;ip\u0026gt;:18443，初始化配置一下Service Monitor：\n 设置 manager 角色的账号，以后访问Service Manager就用它 设置 agent 角色的账号，之后 Agent 和 Service Manager通信的时候，需要使用这个账号 设置数据保留期，根据情况自行设置 关闭自动在线检查更新 完成设置  然后你会进入首页，提示你设置时区和语言：\n安装Agent 上传mysqlmonitoragent-8.0.25.1328-linux-x86-64bit-installer.bin到MySQL服务器，然后安装：\n1$ ./mysqlmonitoragent-8.0.25.1328-linux-x86-64bit-installer.bin --mode text 2 3Language Selection 4 5Please select the installation language 6[1] English - English 7[2] Japanese - 日本語 8[3] Simplified Chinese - 简体中文 9Please choose an option [1] : 3 \u0026lt;选择3\u0026gt; 10---------------------------------------------------------------------------- 11欢迎使用 MySQL Enterprise Monitor Agent 安装向导。 12 13---------------------------------------------------------------------------- 14安装目录 15 16 17请指定 MySQL Enterprise Monitor Agent 安装位置 18 19 20安装目录 [/home/ubuntu/mysql/enterprise/agent]: \u0026lt;回车\u0026gt; 21 22agent 连接方式？ 23 24 25[1] TCP/IP 26[2] Socket 27请选择选项 [1] : \u0026lt;回车\u0026gt; 28---------------------------------------------------------------------------- 29监视选项 30 31您可以配置 Agent 用于监视主机。(文件系统， CPU， RAM， 等等。) 使用监视面板为当前或之后运行的 MySQL 实例提供连接参数。 32Agent所识别的每个实例可以自动或手动进行添加。(注意: Windows上无法提供运行中MySQL的进程扫描功能， 33但是您可以通过监视面板手动添加连接和参数。) 34 35访问下记 URL 获取更多信息: 36http://dev.mysql.com/doc/mysql-monitor/8.0/en/mem-qanal-using-feeding.html 37 38监视选项: 39 40[1] 仅主机: 配置 Agent 去监视主机并使用监视面板为当前或之后运行的 MySQL 实例提供连接参数。 41[2] 主机和数据库: 配置 Agent 去监视主机并为指定的 MySQL 实例提供连接参数。 该过程可以脚本化。一旦安装， Agent 将持续寻找新的MySQL实例并监视。 42请选择选项 [2] : \u0026lt;回车\u0026gt; 43 44---------------------------------------------------------------------------- 45准备将 MySQL Enterprise Monitor Agent 安装至您的计算机。 46 47您确定要继续吗？ [Y/n]: \u0026lt;回车\u0026gt; 48 49---------------------------------------------------------------------------- 50请等待安装 MySQL Enterprise Monitor Agent 至您的计算机。 51 52 正在安装 53 0% ______________ 50% ______________ 100% 54 ######################################### 55 56---------------------------------------------------------------------------- 57MySQL Enterprise Monitor 选项 58 59主机名称或 IP 地址 []: \u0026lt;输入Service Manager的IP\u0026gt; 60 61Tomcat SSL 端口 [18443]: \u0026lt;回车\u0026gt; 62 63Agent使用下记用户名称和密码连接到 Monitor。它们在您安装 Monitor 时定义，可以在设置里面修改， 管理用户。它们的角色定义为 \u0026#34;agent\u0026#34;。 64 65Agent 用户名称 [agent]: \u0026lt;回车\u0026gt; \u0026lt;这里用到的就是之前配置的Agent角色的账号\u0026gt; 66 67Agent 密码 : \u0026lt;agent账号密码\u0026gt; 68再次输入 : \u0026lt;agent账号密码\u0026gt; 69 70---------------------------------------------------------------------------- 71监视数据库配置选项 72 73 74 75验证主机名称，端口，和管理账户权限 [Y/n]: \u0026lt;回车\u0026gt; 76 77配置用户账户加密 [y/N]: \u0026lt;回车\u0026gt; 78 79配置少权限用户账户 [y/N]: \u0026lt;回车\u0026gt; 80 81---------------------------------------------------------------------------- 82监视对象数据库的信息 83 84重要: 以下管理用户需要特别的 MySQL 权限。 85 86访问下记 URL 获取更多信息: 87http://dev.mysql.com/doc/mysql-monitor/8.0/en/mem-agent-rights.html 88 89MySQL 主机名称或 IP 地址 [localhost]: 90 91MySQL 端口 [3306]: \u0026lt;回车\u0026gt; 92 93管理用户 []: root 94 95管理密码 : \u0026lt;root账号密码\u0026gt; 96再次输入密码 : \u0026lt;root账号密码\u0026gt; 97监视组 []: \u0026lt;回车\u0026gt; 98 99---------------------------------------------------------------------------- 100配置报告 101 102 103 104MySQL Enterprise Monitor Agent (Version 8.0.25.1328) 105 106指定的设置如下 107 108注意使用连接器收集查询分析器数据， 109您需要一些设置去配置连接器。 参照 110下记信息: 111http://dev.mysql.com/doc/mysql-monitor/8.0/en/mem-qanal-using-feeding.html 112 113安装目录: /home/ubuntu/mysql/enterprise/agent 114 115MySQL Enterprise Monitor UI: 116------------------------- 117主机名称或 IP 地址: \u0026lt;...\u0026gt; 118Tomcat Server 端口: 18443 119使用 SSL: yes 120 121监视 MySQL 数据库: 122------------------------- 123主机名称或 IP 地址: localhost 124端口: 3306 125按 [Enter] 继续： \u0026lt;回车\u0026gt; 126 127---------------------------------------------------------------------------- 128启动 MySQL Enterprise Monitor Agent 129 130启动 MySQL Enterprise Monitor Agent 信息 131 132MySQL Enterprise Monitor Agent 成功安装。启动 Agent 请调用: 133/home/ubuntu/mysql/enterprise/agent/etc/init.d/mysql-monitor-agent start 134 135按 [Enter] 继续： \u0026lt;回车\u0026gt; 136 137---------------------------------------------------------------------------- 138已在您的计算机完成安装 MySQL Enterprise Monitor Agent 。 然后启动Agent：\n1$ /home/ubuntu/mysql/enterprise/agent/etc/init.d/mysql-monitor-agent start 2Starting MySQL Enterprise Agent service... 在Service Manager上查看 如果一切正常，那么你可以在Service Manager上看到两个MySQL实例：\n xxxx:3306 是刚才安装的Agent所在的实例 xxxx:13306 则是Service Monitor自己用的MySQL的实例  文档 https://dev.mysql.com/doc/mysql-monitor/8.0/en/preface.html ","date":"2021-05-18","img":"","permalink":"/post/mysql-enterprise-monitor-install/","series":null,"tags":["mysql"],"title":"MySQL 企业版监控安装和使用"},{"categories":null,"content":"现象 在Rancher中观察到K8S集群的etcd组件不健康：\n观察Etcd的监控 因Rancher启用的集群监控，因此可以很方便的观察etcd的历史情况：\n发现在历史上存在，磁盘同步耗时高达8秒的情况（图中尖刺）\n同时根据 这篇文章 查询 wal_fsync 和 disk_commit 两个指标的P99值正常情况应该是在 25毫秒以内的。\n查询wal_fsync，发现P99高达8秒：：\n1histogram_quantile(0.99, rate(etcd_disk_wal_fsync_duration_seconds_bucket[5m])) 查询disk_commit，发现P99页高达8秒：\n1histogram_quantile(0.99, rate(etcd_disk_backend_commit_duration_seconds_bucket[5m])) 观察节点的磁盘IO 这时就怀疑磁盘问题了，观察节点的Disk IO指标，发现磁盘IO最高只有20 IOPS，也许这个就是磁盘的最高IOPS了：\n初步怀疑是磁盘能提供的IOPS较低造成的，根据Rancher文档 ，Etcd服务器的顺序IOPS应该最低50，推荐500。下面进一步验证。\n测试磁盘IO 在Etcd服务器上执行下列指令测试顺序写的IOPS：\n1fio -filename=/var/test.file -direct=1 \\ 2 -iodepth 1 -thread -rw=write \\ 3 -ioengine=psync -bs=16k -size=2G -numjobs=10 \\ 4 -runtime=60 -group_reporting -name=test_w 得到382 IOPS：\n磁盘IOPS也算基本可用，应该不存在问题。\n观察etcd日志 1docker logs --since \u0026#39;2021-04-26T16:00:00\u0026#39; --until \u0026#39;2021-04-26T16:30:00\u0026#39; etcd 2\u0026gt;\u0026amp;1 | less 存在大量落磁盘太慢的错误，以及请求超时的错误（etcd响应慢）。\n到这里似乎走进了死胡同。\n网络搜索类似问题 有人遇到同样问题 ，解决办法是更换了一块更快的硬盘。\n那么为何性能测试IOPS还行，但是实际上却不行呢？尝试换个思路来排查。\n观察磁盘IO延迟以及其他指标 执行命令：\n1iostat -d -x 1 vda 观察到：\n 磁盘IO写入完成等待时间波动比较大，在50ms到1000ms不等 平均写入请求的大小也在 8到11K左右 磁盘IO利用率在90%左右  观察etcd进程的IO请求 执行命令\n1pidstat -t -d 1 发现etcd有多个线程在进行磁盘的写操作，但这个是否会存在IO竞争从而导致写入完成等待时间超长，目前存疑。\n跟踪etcd的系统调用 1strace -p $(pgrep etcd) -e trace=write -o etcd_strace.log 得到的write实在太多，不具无法提取有效信息。\n跟踪etcd的打开文件 1lsof -p $(pgrep etcd) | egrep \u0026#39;REG|DIR\u0026#39; 看到它打开的是wal以及db文件，这个和之前观察到的wal_fsync 和 disk_commit 对应的上。\n思考一下 到这里，实际上已经从历史情况+当前情况应证了，etcd的确在做disk commit和wal fsync的事情，而且这两件事情的磁盘IO等待比较长。因此，就算性能测试下来结果还行，但依然有很大概率是磁盘IO性能不佳导致的问题。\n结果 和客户沟通后，更换了超融合平台的存储，etcd服务器的IO等待降低到了正常水平，问题解决。\n","date":"2021-05-14","img":"","permalink":"/post/slow-disk-etcd-troubleshooting/","series":null,"tags":["k8s","etcd","troubleshooting","性能调优"],"title":"慢磁盘导致etcd不健康问题排查"},{"categories":null,"content":"现象 在公司自己研发的网关上观察到在每天的某段时间内API调用失败量剧增，之后又缓慢恢复的情况。\n观察网关日志 查阅日志发现，在同一时间段内，得到503 service unavailable的错误：\n注意到在大量503出现之前，有少量502：\n收集到的对应API调用则是：\n而网关的逻辑是如果对API提供方（本例中是用户API）连续调用失败超过一定次数（目前设置是50次），那么就会对API进行熔断，直接返回503。\n可以推断出在这段时间里，用户API处于不可用状态。\n观察POA 控制台日志 的确能够看到和用户服务的通信错误：\n且这种错误出现了600多次，集中在00:02 前后：\n印证了上面的推断。\n观察用户API的日志 出现大量从数据库连接池获取连接超时的异常：\n总共1293多次，时间在00:01:20 ～ 00:02:30\n可以看到用户API的数据库连接池配置的小了，从日志可以看到只配置了50，可以适当加大。\n但是，用户API数据库连接获取不到的异常只会让请求响应500一类的错误，并不会造成 dialing to the given TCP address timed out 或者 connect: no route to host 的问题。需要进一步排查。\n排查 connect: no route to host 的问题 如果你熟悉K8S，就会知道产生这个问题的可能性有两个：\n Pod重启了 ReadinessProbe探测失败，K8S断掉通网Pod的流量  观察用户API是否重启过 查看日志，并没有重启过。\n排查readinessProbe探测失败的原因 目前的readinessProbe的配置如下：\n一个很典型的spring boot应用的配置。\n但是很诡异的是，在K8S中，没有记录下Pod的readinessProbe探测失败的事件。\n于是直接到Pod所在服务器上查看kubelet的日志：\n1docker logs --since \u0026#39;2021-04-21T23:55:00\u0026#39; --until \u0026#39;2021-04-22T00:20:00\u0026#39; kubelet 2\u0026gt;\u0026amp;1 | grep user-data-service 得到了相应的日志：\n接下来找为何会探测失败，猜测两个原因：\n Tomcat的Http连接用满，新连接排队等待造成。 Tomcat处于Full GC，整个JVM停顿导致超时  排查tomcat的http连接池 配置的线程数是800，在最高峰链接倏才只有\u0026lt;300，因此这个可能性排除。\n排查tomcat的gc情况 发现内存使用情况正常，也没有触发过FullGC\n思考一下 tomcat的http连接池够用，内存也够用，那么为何会产生readinessProbe探测失败呢？从下面起走了弯路。\n观察内核日志 那么问题是否会出在内核上，跑到Pod所在服务器上查询：\n1journalctl --since=\u0026#39;2021-04-21 23:55:00\u0026#39; --until=\u0026#39;2021-04-22 00:20:00\u0026#39; 服务器1上没有问题，服务器2（因为总共有2个Pod，分别在不同服务器上）上有些貌似可疑的日志：\n关键内容是：\n1slab_out_of_memory: 4225 callbacks suppressed 2 3SLUB: Unable to allocate memory on node -1 (gfp=0x2088020) 4 5cache: kmalloc-64(1701:d3f8dc94598f0a15cfbb6417c5117690af06c0554667b9334bfc20381e280c62), object size: 64, buffer size: 64, default order: 0, min order: 0 6 7node 0: slabs: 399, objs: 25536, free: 0 这个错误的意思是内核内存不足，不足的原因可能是存在内存泄漏的情况。\n但是服务器2有这个异常，服务器1上没有，因此大概率和readinessProbe探测失败不存在因果关系，因为只有两个Pod都探测失败的时候，才会导致本文一开始提到的问题。\n回到 /actuator/health 到这里走到思路，那么看看spring boot actuator的源码，这里面的逻辑到底怎样的。\n查看/actuator/health的源码，发现它是Spring Boot Actuator的HealthEndpoint，内部使用的是 CompositeHealthIndicator，它是一个Health聚合器，其中包含了DataSourceHealthIndicator、RedisHealthIndicator 等等。\n它的运行逻辑是它会挨个去询问这些HealthIndicator，如果大家都OK，那么状态就是健康，如果有一个不OK，那么状态就不健康。\n那么为何ReadinessProbe会timeout呢？问题就出在DataSourceHealthIndicator，结合前面的日志用户API存在从数据库连接池获取连接超时的异常，在系统繁忙的时候，连接池会不够用。且连接池这个超时时间为30秒，ReadinessProbe的超时时间为5秒，所以会得到timeout的结果，然后会被判定为探测失败。\n结果 用户API的数据库连接数太小了，导致 ReadinessProbe 探测 /actuator/health 时失败，使得K8S把Pod和Service脱钩，导致网关无法与用户API的建立连接。后来把连接池调整到150之后，问题解除。\n","date":"2021-05-14","img":"","permalink":"/post/lack-connection-pool-api-bad/","series":null,"tags":["k8s","troubleshooting"],"title":"缺少数据库连接池导致的API调用失败排查"},{"categories":null,"content":"现象 在公司自己研发的网关上观察到在每天的某段时间内API调用失败量剧增，之后又缓慢恢复的情况。\n观察网关日志 查阅日志发现，在同一时间段内，发生与user-data-service（提供API的某个服务）通信失败的错误：\n1dial tcp xxx.xxx.xxx.xxx:8080: connect: no route to host 观察user-data-service的日志 看到这个情况就怀疑该服务存在重启，因此在日志中搜索 started 关键词，找到以下内容：\n发现在同时间段内，发生过几次重启。\n再观察重启前后的日志，发现几种情况：\n情况一：重启前，没有异常日志\n情况二：前一次重启未成功，然后发生了另一次重启\n观察容器内的JVM日志文件 该服务的镜像提供了保存JVM GC、JVM崩溃日志的功能，但可惜部署的时候没有给日志目录挂载emptyDir卷，因此Pod重启之后内容就丢失了。\n观察Deployment的设置 发现配置了ReadinessProbe：\n但是ReadinessProbe在探测失败的时候，只会切断Service-\u0026gt;Pod的流量，重启Pod。\n内存配置的有点小，只有512Mi：\n结果 把内存调整到1024Mi之后，观察一天，该问题消除。\n","date":"2021-05-14","img":"","permalink":"/post/lack-memory-api-bad/","series":null,"tags":["k8s","troubleshooting"],"title":"因内存不够导致的API调用失败排查"},{"categories":null,"content":"现象 在公司自己研发的网关上观察到在每天的某段时间内API调用失败量剧增，之后又缓慢恢复的情况。\n观察网关日志 查阅日志发现，在同一时间段内，发生与redis通信失败的错误：\n1dail tcp xxx.xxx.xxx.xxx:6379: i/o timeout 观察Redis日志 在这段时间内Redis没有错误日志。且Redis没有重启过。\n观察K8S节点情况 在Rancher的监控管理里，观察Redis所在节点的情况：\n发现在这个时间段内的指标信息都缺失了。再查看其他节点的监控，同样的情况。\n因此怀疑，在这段时间内整个K8S集群遇到了网络故障。\n结果 因为这个情况每天都会有，于是与客户沟通，得到的反馈是每天这个时间段在对虚拟化平台的所有虚拟机做磁盘快照，让客户修改了快照策略后，问题消除。\n","date":"2021-05-14","img":"","permalink":"/post/vm-disk-snapshot-api-bad/","series":null,"tags":["k8s","troubleshooting"],"title":"因集群磁盘快照导致的API调用失败排查"},{"categories":null,"content":"现象 在rancher中发现所有的Ingress都是黄色的Initializing状态，但是访问应用没有问题。\n检查ingress对象 查看ingress的status，会看到status.loadBalancer 字段是空的：\n对比一个正常：\n查看Nginx ingress的日志 在三个Pod（共10个）上看到了以下日志：\n怀疑受到攻击，导致nginx-ingress-controller异常。\n尝试重启Ingress controller 删掉这三个Pod重启，没用。\n重启所有ingress-controller，也没用。\n观察master服务器上etcd的日志 在master-1上看到如下内容：\n在master-2上看到如下内容：\nmaster-3上没有这些warning。\n因为K8S对象都保存在etcd中的，怀疑如果etcd出了问题，那么对象的状态是过时的，也会造成无法更新的问题。\n校准服务器时间，问题依旧。\n检查Ingress Controller和kube apiserver的通信 K8S的Controller模型告诉我们，都必须和Apiserver通信，那么是不是Ingress Controller和Apiserver的通信出了问题呢？\n进入某个ingress controller容器，执行下列命令：\n1TOKEN=`cat /var/run/secrets/kubernetes.io/serviceaccount/token` 2curl -k https://10.43.0.1:443/api --header \u0026#34;Authorization: Bearer $TOKEN\u0026#34; 发现和API Server的通信是OK的。\n检查Ingress Controller的Service Account的权限是否足够 因为调用Kube ApiServer需要权限，检查一下：\n1\u0026gt; kubectl -n ingress-nginx get sa 2NAME SECRETS AGE 3default 1 440d 4nginx-ingress-serviceaccount 1 440d 5 6\u0026gt; kubectl -n ingress-nginx get rolebinding 7NAME AGE 8clusterrolebinding-2ltlc 440d 9clusterrolebinding-6sk8h 440d 10clusterrolebinding-964mz 440d 11clusterrolebinding-znvvl 440d 12nginx-ingress-role-nisa-binding 440d 13 14\u0026gt; kubectl -n ingress-nginx get rolebinding nginx-ingress-role-nisa-binding 15… 16roleRef: 17 apiGroup: rbac.authorization.k8s.io 18 kind: Role 19 name: nginx-ingress-role 20subjects: 21- kind: ServiceAccount 22 name: nginx-ingress-serviceaccount 23 namespace: ingress-nginx 24 25\u0026gt; kubectl -n ingress-nginx get role nginx-ingress-role -o yaml 26… 27rules: 28- apiGroups: 29 - \u0026#34;\u0026#34; 30 resources: 31 - configmaps 32 - pods 33 - secrets 34 - namespaces 35 verbs: 36 - get 37- apiGroups: 38 - \u0026#34;\u0026#34; 39 resourceNames: 40 - ingress-controller-leader-nginx 41 resources: 42 - configmaps 43 verbs: 44 - get 45 - update 46- apiGroups: 47 - \u0026#34;\u0026#34; 48 resources: 49 - configmaps 50 verbs: 51 - create 52- apiGroups: 53 - \u0026#34;\u0026#34; 54 resources: 55 - endpoints 56 verbs: 57 - get 发现权限是足够的，而且和一个正常的集群对比，结果也是一样的。\n再次观察ingress controller的日志 调整ingress controller的参数，把access log关掉 ，能够更清楚的看到controller的日志。\n发现这么一条：\n1I0512 03:52:31.256060 6 status.go:86] new leader elected: nginx-ingress-controller-qxlt8 所有ingress-controller推举leader为 nginx-ingress-controller-qxlt8。\n但是在K8S里根本就不存在名字是这个的Pod。\n阅读源码 得知，只有leader才会负责更新Ingress对象的status字段。\n查找 nginx-ingress-controller-qxlt8 怀疑是不是etcd里有，但是这个没有K8S查不到，于是到etcd上查询。\n1\u0026gt; docker exec -it etcd etcdctl get / --prefix --keys-only | grep ingress-controller 2 3/registry/configmaps/ingress-nginx/ingress-controller-leader-nginx 4/registry/configmaps/kube-system/rke-ingress-controller 5/registry/controllerrevisions/ingress-nginx/nginx-ingress-controller-544c7854f8 6/registry/controllerrevisions/ingress-nginx/nginx-ingress-controller-668ccb87b6 7/registry/controllerrevisions/ingress-nginx/nginx-ingress-controller-678b59dd78 8/registry/controllerrevisions/ingress-nginx/nginx-ingress-controller-6c4d466577 9/registry/controllerrevisions/ingress-nginx/nginx-ingress-controller-7577d75bc9 10/registry/controllerrevisions/ingress-nginx/nginx-ingress-controller-767b694845 11/registry/controllerrevisions/ingress-nginx/nginx-ingress-controller-779b9c5dc8 12/registry/controllerrevisions/ingress-nginx/nginx-ingress-controller-7854ff6b8d 13/registry/controllerrevisions/ingress-nginx/nginx-ingress-controller-7f8fdf4c75 14/registry/controllerrevisions/ingress-nginx/nginx-ingress-controller-8446bfc58 15/registry/controllerrevisions/ingress-nginx/nginx-ingress-controller-9cc858b66 16/registry/daemonsets/ingress-nginx/nginx-ingress-controller 17/registry/jobs/kube-system/rke-ingress-controller-deploy-job 18/registry/pods/ingress-nginx/nginx-ingress-controller-2f6nf 19/registry/pods/ingress-nginx/nginx-ingress-controller-2zk9s 20/registry/pods/ingress-nginx/nginx-ingress-controller-6lzr4 21/registry/pods/ingress-nginx/nginx-ingress-controller-c9gxl 22/registry/pods/ingress-nginx/nginx-ingress-controller-fj94z 23/registry/pods/ingress-nginx/nginx-ingress-controller-gstz8 24/registry/pods/ingress-nginx/nginx-ingress-controller-kks2w 25/registry/pods/ingress-nginx/nginx-ingress-controller-ntmqm 26/registry/pods/ingress-nginx/nginx-ingress-controller-qjwkw 27/registry/pods/ingress-nginx/nginx-ingress-controller-rfbls 28/registry/pods/ingress-nginx/nginx-ingress-controller-rt5bp 29/registry/pods/ingress-nginx/nginx-ingress-controller-xjcgl 30/registry/pods/kube-system/rke-ingress-controller-deploy-job-2vmwq 没有 nginx-ingress-controller-qxlt8 这个Pod。\n但是注意到 configmap ingress-controller-leader-nginx。\n打开之后看到：\n1apiVersion:v12kind:ConfigMap3metadata:4annotations:5control-plane.alpha.kubernetes.io/leader:\u0026#39;{\u0026#34;holderIdentity\u0026#34;:\u0026#34;nginx-ingress-controller-qxlt8\u0026#34;,\u0026#34;leaseDurationSeconds\u0026#34;:30,\u0026#34;acquireTime\u0026#34;:\u0026#34;2021-05-10T13:38:53Z\u0026#34;,\u0026#34;renewTime\u0026#34;:\u0026#34;2021-05-12T06:28:50Z\u0026#34;,\u0026#34;leaderTransitions\u0026#34;:11}\u0026#39;6creationTimestamp:\u0026#34;2020-02-26T10:37:12Z\u0026#34;7name:ingress-controller-leader-nginx8namespace:ingress-nginx9resourceVersion:\u0026#34;230445553\u0026#34;10selfLink:/api/v1/namespaces/ingress-nginx/configmaps/ingress-controller-leader-nginx11uid:14a0deec-eab4-44d1-aff1-36979b52a1e1这个configmap是ingress-controller维护的，目前的值显然是错了。\n再次研究ingress-controller的leader推举机制 查了代码之后发现，ingress-controller其实并不是想象中的分布式共识协议推举leader，而是最简单的抢座位的方式来定leader。\n只要有一个controller在其他controller之前占有锁（就是前面提到的configmap），并且在lease之前（30秒）刷新这个锁，那它就是leader。\n而且只有leader才会负责更新Ingress对象的status字段。\n手动修改configmap 手动修改configmap，把leader指向一个存在的Pod。\n所有Ingress上的status字段状态都更新了。\n排查游离在K8S集群之外的节点 现在可以推断存在游离在K8S集群之外，但是可以和K8S通信的服务器，后来果然在一台不在集群范围内的机器上找到了：\n1$ docker ps -a|grep ingress 2... 3f4c861555842 a80ffa0b898e \u0026#34;/usr/bin/dumb-init â€¦\u0026#34; 5 months ago Up 5 months k8s_nginx-ingress-controller_nginx-ingress-controller-qxlt8_ingress-nginx_40487677-32c0-4936-bd1a-3e3cb99fbfa1_0 4... 印证了之前的推断。\n把这台服务器上的kubelet、kube-proxy和ingress-controller容器停掉。\n总结 本次排查发现三个问题：\n  Ingress对象的status字段不更新的问题。\n  问题1产生的原因可能是，存在游离在K8S集群之外，但是可以和K8S通信的服务器。\n  集群的nginx接入点疑似收到攻击。\n ","date":"2021-05-14","img":"","permalink":"/post/ingress-status-not-update-troubleshooting/","series":null,"tags":["k8s","ingress","troubleshooting"],"title":"排查Ingress对象status字段不更新的问题"},{"categories":null,"content":"现象 Harbor上的同步任务都是失败的：\n且点击任务看不到日志：\n查看harbor日志 到harbor服务器的 /var/log/harbor 上查看日志，找到 postgresql.log 里有一些错误日志：\n到harbor-db 查看Lock表 最终在 postgres database里找到lock表：\n1docker stop harbor-core 2docker exec -it harbor-db /bin/bash 3psql postgres 4select * from lock; 把这个表清空。\n问题依旧。\n查看其他日志 看到 jobservice.log 有以下日志：\n但是时间不匹配。\n尝试重启harbor 1cd /path/to/harbor-installer-dir 2docker-compose down -v 发现 harbor-jobservice 删除不掉，于是强制删除：\n1docker rm –force harbor-jobservice 然后再启动harbor：\n1docker-compose up -d 得到提示：\n尝试删除 harbor_harbor network：\n1docker network rm harbor_harbor 得到提示：\n观察这个network：\n1docker network inspect harbor_harbor 看到上面存在幽灵容器 harbor-jobservice的注册记录，而这个容器之前已经删除了。因为docker network rm 没有 --force 选项，所以重启docker看看能不能修复数据。\n1systemctl restart docker 之后再观察harbor_harbor network 就正常了。\n然后重启harbor成功，同步任务也能顺利执行。\n总结 排查的过程中走了一些弯路，其实如果一开始就观察harbor容器的状况就有可能定位问题所在。\n这个事情发生的原因是 harbor-jobservice 处于一种不健康的状态，具体原因因为破坏了现场，所以不无法知晓了，有可能和5月11号redis通信异常有关。\n","date":"2021-05-14","img":"","permalink":"/post/harbor-job-fail-troubleshooting/","series":null,"tags":["docker","harbor","troubleshooting"],"title":"排查Harbor定时任务无法执行的问题"},{"categories":null,"content":"本文分析Prometheus的Alerting Rule 的执行逻辑。\n领域模型 在Prometheus的定义中，报警规则由AlertingRule来描述，而AlertingRule则被归到Group 中，比如下面的配置文件例子：\n1groups:2- name:example3interval:30s4rules:5- alert:HighRequestLatency6expr:job:request_latency_seconds:mean5m{job=\u0026#34;myjob\u0026#34;} \u0026gt; 0.57for:10m8labels:9severity:page10annotations:11summary:High request latency每个AlertingRule在运行时还维护具体的报警对象（Alert）。\n下面是领域模型：\n报警逻辑 Prometheus会根据group.interval规定的时间，定时来执行AlertingRule（执行Eval方法），然后发送报警到Alertmanager，最后再更新AlertingRule的状态、Group的状态。\n规则执行逻辑 上图已经说明了，执行报警规则第一步是执行表达式（expr属性），然后是根据表达式执行结果，管理Alert对象，逻辑如下：\nAlert对象有三个状态：\n Pending：活跃但是还未发送给Alertmanager，是Alert对象的初始状态。 Firing：长发送到Alertmanager。 Inactive：不活跃，即当前没有触发报警。 虚拟状态“被删除”  三种状态的迁移逻辑：\nPending -\u0026gt; Firing\nAlert对象当前处于Pending，触发报警规则，且距离初次活跃时间（Alert.ActiveAt）超过\u0026lt;for\u0026gt;（AlertingRule.holdDuration）的时长，那么这个Alert对象就会变成Firing状态。\nPending -\u0026gt; 被删除\nAlert对象当前处于Pending状态，不触发报警规则，那么这个Alert对象就直接被删除。\nFiring -\u0026gt; Inactive\nAlert对象当前处于Firing状态，不触发报警规则，那么这个Alert对象会变成Inactive状态。\nInactive -\u0026gt; Pending\nAlert对象当前处于Inactive状态，触发报警规则，那么这个Alert对象会重置为Pending状态。\nInactive -\u0026gt; 被删除\nAlert对象当前处于Inactive状态，且保持超过了resolved_retention时长，则被删除。\n报警发送的逻辑 AlertingRule执行之后，会把Firing状态的Alert发送出去，逻辑如下：\n更新AlertingRule规则 最后更新AlertingRule的状态，逻辑如下：\n","date":"2021-02-26","img":"","permalink":"/post/p8s-alerting-rule-logic/","series":null,"tags":["prometheus"],"title":"Prometheus报警逻辑分析"},{"categories":null,"content":"发现容器内无法访问公网资源，运行下列命令卡住不动了：\n1docker run --rm -it busybox 2\u0026gt; wget http://mirrors.aliyun.com/alpine/v3.12/main/x86_64/APKINDEX.tar.gz 排查主机网络通性 检查主机网络通性，在主机上执行相同命令，没有问题，说明问题出在docker上。\n排查docker配置 在一台没有问题的机器上对比docker info，没有发现区别\n在一台没有问题的机器上对比docker network inspect bridge，发现com.docker.network.driver.mtu值不一样，好的机器是1450，坏的机器是1500。\n查看docker0设备的mtu也是1500：\n1ip a 2... 33: docker0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default 4... 排查mtu问题 用ping确认mtu的合适大小 在坏的主机上ping 1422+28=1450 字节（28字节是ICMP协议的头大小）：\n1docker run --rm -it nicolaka/netshoot:latest /bin/bash 2\u0026gt; ping -c 3 -M do -s 1422 baidu.com 3PING baidu.com (220.181.38.148) 1422(1450) bytes of data. 41430 bytes from 220.181.38.148 (220.181.38.148): icmp_seq=1 ttl=48 time=27.6 ms 可以看到结果正常，如果ping 1423+28=1451字节，就不行了：\n1\u0026gt; ping -c 3 -M do -s 1423 baidu.com 2PING baidu.com (39.156.69.79) 1423(1451) bytes of data. 3ping: local error: message too long, mtu=1450 这个就说明mtu最大只能是1450。\n修改设备mtu 现在已经知道问题是docker0设备的mtu引起的，那么执行下列命令修改：\n1sudo ip link set docker0 mtu 1450 同时修改/etc/docker/daemon.json：\n1{ 2 ... 其他配置不变 3 \u0026#34;mtu\u0026#34;: 1450 4} 然后重启docker：\n1sudo systemctl restart docker 最后再试验就成功了：\n1docker run --rm -it busybox 2\u0026gt; wget http://mirrors.aliyun.com/alpine/v3.12/main/x86_64/APKINDEX.tar.gz ","date":"2021-02-25","img":"","permalink":"/post/docker/docker0-mtu/","series":null,"tags":["docker","troubleshooting"],"title":"Docker0 Eth设备MTU不正确导致容器无法访问外网"},{"categories":null,"content":"本文分析Kibana Alerting 的实现。\nAlerting的配置 基本信息  Name，报警的名称。 Tags，可选。 Check every N second/minute/hour/day，隔多久检查一次，这个应该是fixed rate（固定频率，不管上一次是否执行完成，因此可能产生重叠），而不是fixed delay（上次执行完成后等待固定时间再执行）。 Notify every N second/minute/hour/day，在报警激活的情况下，隔多久发送一次通知。  Index 求值配置  Index，被查询的Index名字或者Index Pattern，可以是多个。  time field，date类型 的字段   When，配置怎么计算值，有count、average、sum、min、max：  Of，聚合字段，必须是keyword mapping 的，count时不需要填   Over/Group Over，有两种：  all documents，不对结果进行分组 top N by field，根据field字段对结果进行分组，取doc数量前N个的组。field字段必须是keyword mapping 的。报警会根据每个组的情况分别触发。    Index 阈值触发条件  Threshold，is above, is above or equals, is below, is below or equals, 和 is between，然后是具体值value。 时间窗口，只支持For the last N second/minute/hour/day，即从当前时间开始往前推多少时间的数据。其实就是range query 加上date math （注意不需要做rounding）：  1GET /\u0026lt;index\u0026gt;/_search 2{ 3 \u0026#34;query\u0026#34;: { 4 \u0026#34;range\u0026#34;: { 5 \u0026#34;@timestamp\u0026#34;: { 6 \u0026#34;gte\u0026#34;: \u0026#34;now-1h\u0026#34;, 7 \u0026#34;lt\u0026#34;: \u0026#34;now\u0026#34; 8 } 9 } 10 } 11} Alerting配置的要点  不是所有Index都支持配置Alerting，必须得有date类型 字段才行。 只支持对最近的数据进行统计，从now-duration到now的范围内的数据做一些统计工作。  Index求值模式 Index求值模式由两个维度组成，共四种：\n 是否分组，如果分组则用到terms agg 和sub aggregation  是否聚合  不分组，不聚合 count是唯一不聚合的查询，就是取返回结果的total count，对应的ES Query DSL：\n1GET /\u0026lt;index\u0026gt;/_search 2{ 3 \u0026#34;query\u0026#34;: { 4 \u0026#34;range\u0026#34;: { 5 \u0026#34;@timestamp\u0026#34;: { 6 \u0026#34;gte\u0026#34;: \u0026#34;now-1h\u0026#34;, 7 \u0026#34;lt\u0026#34;: \u0026#34;now\u0026#34; 8 } 9 } 10 }, 11 \u0026#34;size\u0026#34;: 0 12} 因为我们只对total count感兴趣不需要具体的doc，所以设置\u0026quot;size\u0026quot;: 0。\n返回的结果，注意看hits.total.value字段，同时hits.hits数组是空的，因为我们设置了size=0：\n1{ 2 ... 3 \u0026#34;hits\u0026#34; : { 4 \u0026#34;total\u0026#34; : { 5 \u0026#34;value\u0026#34; : 9339, 6 \u0026#34;relation\u0026#34; : \u0026#34;eq\u0026#34; 7 }, 8 \u0026#34;hits\u0026#34; : [ ], 9 ... 10 } 11} 不分组，聚合 average 、sum 、min 、max 都是聚合查询，需要配置聚合字段，字段必须是keyword mapping 的，比如：\n1GET /\u0026lt;index\u0026gt;/_search 2{ 3 \u0026#34;query\u0026#34;: { 4 \u0026#34;range\u0026#34;: { 5 \u0026#34;@timestamp\u0026#34;: { 6 \u0026#34;gte\u0026#34;: \u0026#34;now-1h\u0026#34;, 7 \u0026#34;lt\u0026#34;: \u0026#34;now\u0026#34; 8 } 9 } 10 }, 11 \u0026#34;size\u0026#34;: 0, 12 \u0026#34;aggs\u0026#34;: { 13 \u0026#34;avg_timeElapse\u0026#34;: { 14 \u0026#34;avg\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;api_call.timeElapse\u0026#34; } 15 } 16 } 17} 响应结果，我们不需要看hits字段，只要看aggregations.avg_timeElapse.value字段就行了：\n1{ 2 ... 3 \u0026#34;aggregations\u0026#34; : { 4 \u0026#34;avg_timeElapse\u0026#34; : { 5 \u0026#34;value\u0026#34; : 240.7022207635926 6 } 7 } 8} 分组，不聚合 因为count不是聚合查询，所以只需要用terms agg 分组，同样分组的字段必须是keyword mapping 的，同时配置了aggs.apiSvcPerOp_buck.terms.size=2对应top N语义：\n1GET /\u0026lt;index\u0026gt;/_search 2{ 3 \u0026#34;query\u0026#34;: { 4 \u0026#34;range\u0026#34;: { 5 \u0026#34;@timestamp\u0026#34;: { 6 \u0026#34;gte\u0026#34;: \u0026#34;now-1h\u0026#34;, 7 \u0026#34;lt\u0026#34;: \u0026#34;now\u0026#34; 8 } 9 } 10 }, 11 \u0026#34;size\u0026#34;: 0, 12 \u0026#34;aggs\u0026#34;: { 13 \u0026#34;apiSvcPerOp_buck\u0026#34;: { 14 \u0026#34;terms\u0026#34;: { 15 \u0026#34;field\u0026#34;: \u0026#34;api_call.apiSvcVerOp.keyword\u0026#34;, 16 \u0026#34;size\u0026#34;: 2 17 } 18 } 19 } 20} 21 注意看结果的aggregations.apiSvcPerOp_buck.buckets[].doc_count，可以看到返回了各个keyword的doc_count\n1{ 2 ... 3 \u0026#34;aggregations\u0026#34; : { 4 \u0026#34;apiSvcPerOp_buck\u0026#34; : { 5 \u0026#34;doc_count_error_upper_bound\u0026#34; : 52, 6 \u0026#34;sum_other_doc_count\u0026#34; : 4739, 7 \u0026#34;buckets\u0026#34; : [ 8 { 9 \u0026#34;key\u0026#34; : \u0026#34;user_v1_loadUserInfoByAccountName\u0026#34;, 10 \u0026#34;doc_count\u0026#34; : 1829 11 }, 12 { 13 \u0026#34;key\u0026#34; : \u0026#34;user_v1_listAccountGroups\u0026#34;, 14 \u0026#34;doc_count\u0026#34; : 1297 15 } 16 ] 17 } 18 } 19} 分组，聚合 针对average 、sum 、min 、max 的分组查询则是，先用terms agg 然后把avg等作为它的sub aggregation ：\n1GET /\u0026lt;index\u0026gt;/_search 2{ 3 \u0026#34;query\u0026#34;: { 4 \u0026#34;range\u0026#34;: { 5 \u0026#34;@timestamp\u0026#34;: { 6 \u0026#34;gte\u0026#34;: \u0026#34;now-1h\u0026#34;, 7 \u0026#34;lt\u0026#34;: \u0026#34;now\u0026#34; 8 } 9 } 10 }, 11 \u0026#34;size\u0026#34;: 0, 12 \u0026#34;aggs\u0026#34;: { 13 \u0026#34;apiSvcPerOp_buck\u0026#34;: { 14 \u0026#34;terms\u0026#34;: { 15 \u0026#34;field\u0026#34;: \u0026#34;api_call.apiSvcVerOp.keyword\u0026#34;, 16 \u0026#34;size\u0026#34;: 3 17 }, 18 \u0026#34;aggs\u0026#34;: { 19 \u0026#34;avg_timeElapse\u0026#34;: { 20 \u0026#34;avg\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;api_call.timeElapse\u0026#34; } 21 } 22 } 23 } 24 } 25} 注意结果中的aggregations.apiSvcPerOp_buck.buckets[*].avg_timeElapse.value字段，就是每个分组的聚合结果：\n1{ 2 ... 3 \u0026#34;aggregations\u0026#34; : { 4 \u0026#34;apiSvcPerOp_buck\u0026#34; : { 5 \u0026#34;doc_count_error_upper_bound\u0026#34; : 52, 6 \u0026#34;sum_other_doc_count\u0026#34; : 4739, 7 \u0026#34;buckets\u0026#34; : [ 8 { 9 \u0026#34;key\u0026#34; : \u0026#34;user_v1_loadUserInfoByAccountName\u0026#34;, 10 \u0026#34;doc_count\u0026#34; : 1829, 11 \u0026#34;avg_timeElapse\u0026#34; : { 12 \u0026#34;value\u0026#34; : 51.38928376161837 13 } 14 }, 15 { 16 \u0026#34;key\u0026#34; : \u0026#34;user_v1_listAccountGroups\u0026#34;, 17 \u0026#34;doc_count\u0026#34; : 1297, 18 \u0026#34;avg_timeElapse\u0026#34; : { 19 \u0026#34;value\u0026#34; : 445.27370855821124 20 } 21 } 22 ] 23 } 24 } 25} ","date":"2021-01-27","img":"","permalink":"/post/es/kibana-alerting-es-query/","series":null,"tags":["elasticsearch","kibana"],"title":"Kibana Alerting的实现分析"},{"categories":null,"content":"grep docker log 1docker logs nginx 2\u0026gt;\u0026amp;1 | grep \u0026#34;127.\u0026#34; 2 3# ref: http://stackoverflow.com/questions/34724980/finding-a-string-in-docker-logs-of-container 返回json 给docker命令添加 --format '{{ json .}}'参数，能够使得返回结果变成JSON，知道JSON结构后你可以很方便的利用--format做其他事情，比如：\n1$ docker image ls --format \u0026#39;{{json .}}\u0026#39; 镜像 删除所有镜像 利用--format参数得到镜像ID，然后删除：\n1docker image ls --format \u0026#39;{{ .ID}}\u0026#39; | xargs -n1 -I{} docker image rm {} 得到镜像的pull命令 1docker image ls --format \u0026#39;docker pull {{.Repository}}:{{.Tag}}\u0026#39; save/load镜像 1docker save \u0026lt;image\u0026gt; \u0026lt;image\u0026gt;... | gzip \u0026gt; \u0026lt;name\u0026gt;.tar.gz 2docker load --input \u0026lt;name\u0026gt;.tar.gz 容器 得到容器的PID 1$ docker inspect --format \u0026#39;{{.State.Pid}}\u0026#39; \u0026lt;container-name/id\u0026gt; 列出所有容器的PID 1$ docker ps -q | xargs docker inspect --format \u0026#39;{{.State.Pid}}, {{.Name}}\u0026#39; 列出所有关闭的容器 1docker ps -a --format \u0026#39;Container: {{ .Names }} Status: {{ json .Status }}\u0026#39; | grep \u0026#39;Exited\u0026#39; 列出容器暴露的端口 1$ docker inspect --format \u0026#39; 2{{- range $port, $hostPorts := .NetworkSettings.Ports }} 3container port: {{ $port }}, host ports: {{json $hostPorts}} 4{{- end -}}\u0026#39; \u0026lt;container-name/id\u0026gt; 列出所有容器暴露的端口 1$ docker ps -q | xargs docker inspect --format \u0026#39; 2Pid:{{.State.Pid}}, Name:{{ .Name }} 3{{- range $port, $hostPorts := .NetworkSettings.Ports }} 4container port: {{ $port }}, host ports: {{json $hostPorts}} 5{{- end -}}\u0026#39; 观察网络命名空间 docker使用linux network namespace来隔离网络设备，下面将你怎么在host上debug容器网络命名空间。\n1# 得到容器进程id 2$ container_id=\u0026lt;container_id\u0026gt; 3$ pid=$(docker inspect -f \u0026#39;{{.State.Pid}}\u0026#39; ${container_id}) 4 5# 创建 netns 目录 6$ mkdir -p /var/run/netns/ 7 8# 创建命名空间软连接 9$ ln -sfT /proc/$pid/ns/net /var/run/netns/${container_id} 10 11# 运行ip netns命令访问这个命名空间 12$ ip netns exec ${container_id} ip a 13 14# 运行 nsenter 进入命名空间，用 netstat 命令查看容器进程的tcp/udp连接情况 15$ nsenter -t $pid -n netstat -antpl 参考文档：How to Access Docker Container’s Network Namespace from Host overlay2 storage driver 根据overlay目录反查容器 假设你在/var/lib/docker/overlay2下看到了某个目录（比如：608b180efc64419c27e5e54ca79511d1066475b3636535f5e2134a9f6187c35b），那么你想知道这个目录所属哪个容器：\n1docker ps -a --format \u0026#39;{{ .Names }}\u0026#39; \\ 2| xargs -n1 -I{} docker inspect {} --format \u0026#39;Container: {{ .Name }} Dir: {{ .GraphDriver.Data.LowerDir }}\u0026#39; \\ 3| grep \u0026#39;608b180efc64419c27e5e54ca79511d1066475b3636535f5e2134a9f6187c35b\u0026#39; 有时候会得到多个结果，这是因为多个容器所使用的镜像共享了同一个层。\n根据overlay目录反查镜像 在上面的结果里找到了多个结果后，想要找一个这个层从哪一个镜像引入的，可以这样：\n1docker image ls --format \u0026#39;{{ .ID }}\u0026#39; \\ 2| xargs -n1 -I{} docker image inspect {} --format \u0026#39;Image: {{ .RepoTags }} Dir: {{ .GraphDriver.Data.LowerDir }}\u0026#39; \\ 3| grep \u0026#39;608b180efc64419c27e5e54ca79511d1066475b3636535f5e2134a9f6187c35b\u0026#39; ","date":"2021-01-07","img":"","permalink":"/post/docker/scripts/","series":null,"tags":["docker","cheatsheet"],"title":"Docker实用小脚本"},{"categories":null,"content":"如果Rancher里启用了监控 ，那么Rancher会为你安装一套Prometheus+Grafana，本文介绍如何连接这个Prometheus的方法。\n找到Prometheus的连接密码  进入System项目 找到cattle-prometheus下的 prometheus-cluster-monitoring StatefulSets 选择prometheus-proxy容器，进入命令行终端 cat /var/cache/nginx/nginx.conf查看Nginx配置，可以发现下面内容：  1proxy_set_header Authorization \u0026#34;Bearer ...\u0026#34;; 记住这个Authorization请求头，还有它的值（包含Bearer部分）。\n之后每次请求Prothemeus的时候都需要带上这个请求头。\n这个Prometheus的集群内访问地址是：http://prometheus-operated.cattle-prometheus.svc:9090\n在Grafana中配置数据源 如果你有自己的Grafana，那么需要配置Custom HTTP Headers，把上面的Authorization请求头配置上去，这样就能够连接到了。\n","date":"2021-01-06","img":"","permalink":"/post/k8s/rancher-p8s-connect/","series":null,"tags":["k8s","prometheus","rancher"],"title":"连接Rancher中的Prometheus的方法"},{"categories":null,"content":"https://www.oracle.com/java/technologies/javase/vmoptions-jsp.html ","date":"2021-01-04","img":"","permalink":"/post/jvm/jvm-options/","series":null,"tags":["cheatsheet","jvm"],"title":"JVM 参数"},{"categories":null,"content":"磁盘读写 使用fio 对磁盘做性能测试：\n顺序读测试：\n1fio -filename=/var/test.file -direct=1 \\ 2 -iodepth 1 -thread -rw=read \\ 3 -ioengine=psync -bs=16k -size=2G -numjobs=10 \\ 4 -runtime=60 -group_reporting -name=test_r 随机写测试：\n1fio -filename=/var/test.file -direct=1 \\ 2 -iodepth 1 -thread -rw=randwrite \\ 3 -ioengine=psync -bs=16k -size=2G -numjobs=10 \\ 4 -runtime=60 -group_reporting -name=test_randw 顺序写测试：\n1fio -filename=/var/test.file -direct=1 \\ 2 -iodepth 1 -thread -rw=write \\ 3 -ioengine=psync -bs=16k -size=2G -numjobs=10 \\ 4 -runtime=60 -group_reporting -name=test_w 混合随机读写测试：\n1fio -filename=/var/test.file -direct=1 \\ 2 -iodepth 1 -thread -rw=randrw \\ 3 -rwmixread=70 -ioengine=psync -bs=16k -size=2G -numjobs=10 \\ 4 -runtime=60 -group_reporting -name=test_r_w -ioscheduler=noop 网络带宽 使用iperf3 测试服务器间的网络带宽。\n现在要测试A到B的网络带宽，先在B启动iperf服务端\n1iperf3 -s 再到A上启动iperf客户端：\n1iperf3 -c \u0026lt;ip-to-b\u0026gt; 参考资料  3 个方便的命令行网速度测试工具  Linux如何查看与测试磁盘IO性能  ","date":"2020-12-14","img":"","permalink":"/post/k8s/k8s-server-perf-test/","series":null,"tags":["k8s","troubleshooting","性能调优"],"title":"K8S服务器性能测试"},{"categories":null,"content":"Docker  Docker architecture ，Container不是运行在Docker之上的 Linux Container Internals 2.0 - Lab 1: Introduction to Containers ，Container is just a fancy process Limit a container\u0026rsquo;s resources ，如何控制container的内存、CPU使用上限  Java in container\n Java SE support for Docker CPU and memory limits ，Java SE 8u131之后能感知容器内存使用上限 Java inside docker: What you must know to not FAIL ，为何我的Java程序container OOMKilled OpenJDK and Containers ，补充OpenJDK运行在container的注意事项  Networking\n Docker Reference Architecture: Designing Scalable, Portable Docker Container Networks   K8S  Troubleshooting  深入浅出Kubernetes 实践篇 （一）：节点就绪问题之一  深入浅出Kubernetes 实践篇 （二）：节点就绪问题之二    华为K8S视频培训（免费）  CKA考纲与K8S基础概念解读  K8S调度管理实训  K8S日志、监控与应用管理实训  K8S网络管理实训  K8S存储管理实训  K8S安全管理实训  K8S集群运维与安装配置实训  K8S问题排查实训    Configure RBAC In Your Kubernetes Cluster ，这篇文章写的很好，通俗易懂。  Rancher  Rancher 2.1培训  Kubernetes集群管理的轻松之道（上） , Q\u0026amp;A  Kubernetes集群管理的轻松之道（下） , Q\u0026amp;A  基于Kubernetes的CI/CD流水线构建 , Q\u0026amp;A  Kubernetes应用管理 , Q\u0026amp;A  Rancher 2.1新功能演示分享 , Q\u0026amp;A  PPT资料链接 提取码：aqrf   RancherLabs B站  ","date":"2020-12-04","img":"","permalink":"/post/bookmarks/bookmarks-container/","series":null,"tags":["收藏夹"],"title":"收藏夹 - 容器技术（持续更新）"},{"categories":null,"content":"docker 拿到dockerd的thread dump 执行下列命令（不会kill掉进程）：\n1kill -SIGUSR1 $(pidof dockerd) 用journalctl -u docker.service可以看到输出到哪里：\n1Dec 04 07:08:11 docker-learn-5 dockerd[2090]: time=\u0026#34;2020-12-04T07:08:11.362055588Z\u0026#34; level=info msg=\u0026#34;goroutine stacks written to /var/run/docker/goroutine-stacks-2020-12-04T070811Z.log\u0026#34; 参考文档 containerd 拿到thread dump 执行下列命令（不会kill掉进程）：\n1kill -SIGUSR1 $(pidof containerd) 用journalctl -u containerd.service直接查看thread dump。\n如果是containerd-shim，则需要先启用shim_debug，然后\n1kill -SIGUSR1 $(pidof containerd-shim) 参考文档 k8s 拿到kubelet的thread dump 方法一（不会kill进程）：\n在一个终端执行：\n1kubectl proxy 如果是rancher，则使用直接连接到某台master的context配置。\n在另一个终端执行：\n1curl \u0026#39;http://localhost:8001/api/v1/nodes/\u0026lt;node name\u0026gt;/proxy/debug/pprof/goroutine?debug=2\u0026#39; 实际上这个方法就是go的pprof，你可以利用这个做很多事情。\n方法二（会kill进程）：\n1kill -SIGABRT $(pidof kubelet) 参考文档 ","date":"2020-12-04","img":"","permalink":"/post/k8s/container-troubleshoot-cheatsheat/","series":null,"tags":["k8s","docker","cheatsheet"],"title":"Docker/K8S故障排查Cheatsheet"},{"categories":null,"content":"环境 服务器：172.17.17.20-22 三个服务器 （深信服aCloud虚拟化平台）\n操作系统版本：CentOS 7.8\n内核版本：3.10\n现象 在20-22三台上安装K8S集群（通过rancher的rke安装），安装完毕后，发现访问各个节点的80端口，只有20服务器能够正常返回，其余的都是Gateway Timeout。使用Rancher的提供的这个办法 得知Overlay网络不通。\n排查过程 排查网络通性 根据Rancher文档上提到的 ，Host的8472/udp端口是Flannel/Calico的VXLAN Overlay网络专用端口，即所有跨Host的容器间网络通信都走这个端口。因此：\n在172.17.17.22上，用tcpdump抓发出的包：\n1tcpdump -nn \u0026#39;udp and src host 172.17.17.22 and dst port 8472\u0026#39; 另开一个22的终端，执行 curl http://localhost 能够看到 22-\u0026gt;20 的UDP包，见下图：\n在172.17.17.20上，用tcpdump抓收到的包：\n1tcpdump -nn \u0026#39;udp and src host 172.17.17.22 and dst port 8472\u0026#39; 结果是没有抓到任何包。\n排查虚拟机网络安全组 合理怀疑虚拟机网络安全组没有放开8472/udp端口的访问权限，在22上使用netcat发送数据：\n1nc -u 172.17.17.20 8472 随便打点字回车传输，如下图：\n结果在20上能够抓到收到的包：\n这说明网络安全组并没有阻拦8472/udp端口的访问。\n初步假设 怀疑这些数据在深信服aCloud虚拟化平台的网络中被过滤掉了。基于以下理由：\n k8s使用的是基于VXLAN的Overlay network，VNI=1，并且是基于UDP协议。而深信服aCloud高概率也使用VXLAN做Overlay网络。 普通的udp协议数据传输tcpdump能够抓到包（见前面） tcpdump在网络栈中的位置inbound在iptables之前，outbound在iptables之后（资料 ）。如果tcpdump能够抓到发出的包，那么说明是真的发出了。如果inbound没有抓到接受的包，那么就说明这个包没有到达网卡。  解决办法 和深信服的同学沟通后，其确认是物理机也是用了8472/udp端口做Overlay网络，两者冲突了，因此当UDP包内包含了OTV数据内容后，先一步被aCloud拦截，结果就是虚拟机的8472/udp端口收不到数据。\n将物理机的8472/udp端口改掉后，问题解决。\nPS. 8472/udp还是一个著名端口 解决办法2 也可以在rke创建k8s集群的时候修改flannel的端口，需要修改cluster.yml（参考文档 ）。\n如果你用的是canal网络插件（默认）：\n1...2network:3plugin:canal4options:5canal_flannel_backend_type:vxlan6canal_flannel_backend_port:\u0026#34;8872\u0026#34;7...如果用的是flannel网络插件：\n1...2network:3plugin:flannel4options:5flannel_backend_type:vxlan6flannel_backend_port:\u0026#34;8872\u0026#34;7...在Rancher中创建自定义集群的时候，需要自定义集群参数来修改端口（参考文档 ）。\n如果用的是canal网络插件（默认）：\n1rancher_kubernetes_engine_config:2...3network:4options:5flannel_backend_type:vxlan6flannel_backend_port:\u0026#34;8872\u0026#34;7plugin:canal如果用的是flannel网络插件：\n1rancher_kubernetes_engine_config:2...3network:4options:5flannel_backend_type:vxlan6flannel_backend_port:\u0026#34;8872\u0026#34;7plugin:flannel","date":"2020-11-10","img":"","permalink":"/post/k8s/vxlan-8472-port-conflict/","series":null,"tags":["k8s","rancher","troubleshooting"],"title":"记一次K8S VXLAN Overlay网络8472端口冲突问题的排查"},{"categories":null,"content":"MySQL默认对于字符串类型字段的查询大小写不敏感，比如字段值为ABC，你查询WHERE COL='abc' 也能够查询到。\nMySQL的这个行为大多数情况下问题不大，这个行为对于查询来说是很便利的，比如你可以直接LIKE 'a%' 就能够查询到ABC。\n但是要注意，如果你有一个UNIQUE的字段，那么在插入A0001和a0001的时候，会告诉你违反唯一约束。\n如果你的UNIQUE字段在业务上需要通过大小写来区分，那么你需要在建表时给字段添加上CHARACTER SET utf8 COLLATE utf8_bin NOT NULL UNIQUE，比如：\n1CREATETABLEWORDS(2WORDVARCHAR(128)CHARACTERSETutf8COLLATEutf8_binNOTNULLUNIQUE,3);如果你的UNIQUE字段在业务上不需要/不应该通过大小写来区分，那么就什么都不需要做，因为在这种业务下，a0001可以认为是一种错误数据。\n参考资料：\nhttps://stackoverflow.com/questions/6448825/sql-unique-varchar-case-sensitivity-question ","date":"2020-09-30","img":"","permalink":"/post/mysql-case-insensitive-query/","series":null,"tags":["mysql"],"title":"Mysql字符串字段查询默认大小写不敏感"},{"categories":null,"content":"Rancher中启动监控后，Prometheus采集到的cpu、memory、network的指标存在重复，见这个issue ，该问题在2.3.0～2.4.x中都存在。下面讲解决办法：\n先设置Grafana的admin密码，进入System项目，cattle-prometheus命名空间，找到grafana-cluster-monitoring，进入其Shell：\n 执行：\n1grafana-cli admin reset-admin-password \u0026lt;新密码\u0026gt; 然后随便进入一个Deployment/StatefulSets，进入Grafana：\n 用admin账号和你刚才设置的密码登录进去，进入管理页面导入Dashboard：\n 导入修正后的Dashboard：\n ID 13087，Rancher DaemonSet(fixed)  ID 13088，Rancher Deployment(fixed)  ID 13089，Rancher Pods(fixed)  ID 13090，Rancher StatefulSet(fixed)  ","date":"2020-09-29","img":"","permalink":"/post/k8s/fix-rancher-grafana-double-metrics/","series":null,"tags":["k8s","prometheus","rancher"],"title":"解决Rancher自带监控CPU和内存显示用量为实际用量的2倍的方法"},{"categories":null,"content":"查找没有设置Resources Quota(Limits)的Pod 1kubectl get --all-namespaces pods -o go-template=\u0026#39; 2{{ range .items -}} 3{{ $pod := .metadata.name -}} 4{{ $ns := .metadata.namespace -}} 5{{- range .spec.containers }} 6{{- if or (not .resources) (not .resources.limits) }} 7NAMESPACE: {{ $ns }} POD: {{ $pod }} 8Container: {{ .name }} 9Resources: {{ .resources }} 10{{ end }} 11{{- end }} 12{{- end }}\u0026#39; 查找设置了Requests CPU的Pod 1kubectl get --all-namespaces pods -o go-template=\u0026#39; 2{{ range .items -}} 3{{ $pod := .metadata.name -}} 4{{ $ns := .metadata.namespace -}} 5{{- range .spec.containers }} 6{{- if and (.resources) (.resources.requests) (.resources.requests.cpu) }} 7NAMESPACE: {{ $ns }} POD: {{ $pod }} 8Container: {{ .name }} 9Requests CPU: {{ .resources.requests.cpu }} 10{{ end }} 11{{- end }} 12{{- end }}\u0026#39; 查找运行在某个Host上的Pod 替换下面脚本的IP：\n1kubectl get --all-namespaces pods -o go-template=\u0026#39; 2{{ range .items -}} 3{{ $pod := .metadata.name -}} 4{{ $ns := .metadata.namespace -}} 5{{- if eq .status.hostIP \u0026#34;IP\u0026#34; }} 6NAMESPACE: {{ $ns }} POD: {{ $pod }} 7{{- end }} 8{{- end }}\u0026#39; 查找运行在某个Node上的pod 1kubectl get --all-namespaces pods --field-selector=spec.nodeName=\u0026lt;node name\u0026gt; ","date":"2020-09-10","img":"","permalink":"/post/k8s/kubectl-scripts/","series":null,"tags":["k8s","cheatsheet"],"title":"Kubectl 实用小脚本"},{"categories":null,"content":"使用Kubebuilder +k8s.io/code-generator 编写CRD。\n本项目代码在 这里 。\n概览 和k8s.io/code-generator 类似，是一个码生成工具，用于为你的CRD生成kubernetes-style API 实现。区别在于：\n Kubebuilder不会生成informers、listers、clientsets，而code-generator会。 Kubebuilder会生成Controller、Admission Webhooks，而code-generator不会。 Kubebuilder会生成manifests yaml，而code-generator不会。 Kubebuilder还带有一些其他便利性设施。  Resource + Controller = Operator，因此你可以利用Kubebuilder编写你自己的Operator。\n如果你不想做Operator，如果你不会直接or间接生成Pod，只是想存取CRD（把K8S当作数据库使用）。那你可以使用Kubebuilder生成CRD和manifests yaml，再使用code-generator生成informers、listers、clientsets。\n本文讲的就是这个方法。\n准备工作：安装Kubebuilder 参考这里 安装kubebuilder。\n第一步：初始化项目 1MODULE=example.com/foo-controller 2go mod init $MODULE 3kubebuilder init --domain example.com 4kubebuilder edit --multigroup=true 会生成以下文件：\n1. 2├── Dockerfile 3├── Makefile 4├── PROJECT 5├── bin 6│ └── manager 7├── config 8│ ├── certmanager 9│ ├── default 10│ ├── manager 11│ ├── prometheus 12│ ├── rbac 13│ └── webhook 14├── hack 15│ └── boilerplate.go.txt 16└── main.go 第二步：生成Resource和manifests 1kubebuilder create api --group webapp --version v1 --kind Guestbook 2Create Resource [y/n] 3y 4Create Controller [y/n] 5n 会生成以下文件go代码和manifests文件：\n1. 2├── apis 3│ └── webapp 4│ └── v1 5│ ├── groupversion_info.go 6│ ├── guestbook_types.go 7│ └── zz_generated.deepcopy.go 8└── config 9 ├── crd 10 │ ├── kustomization.yaml 11 │ ├── kustomizeconfig.yaml 12 │ └── patches 13 │ ├── cainjection_in_guestbooks.yaml 14 │ └── webhook_in_guestbooks.yaml 15 ├── rbac 16 │ ├── guestbook_editor_role.yaml 17 │ ├── guestbook_viewer_role.yaml 18 └── samples 19 └── webapp_v1_guestbook.yaml 添加文件apis/webapp/v1/rbac.go，这个文件用生成RBAC manifests：\n1// +kubebuilder:rbac:groups=webapp.example.com,resources=guestbooks,verbs=get;list;watch;create;update;patch;delete 2// +kubebuilder:rbac:groups=webapp.example.com,resources=guestbooks/status,verbs=get;update;patch 3 4package v1 然后生成CRD manifests：\n1make manifests 得到：\n1config2├── crd3│ └── bases4│ └── webapp.example.com_guestbooks.yaml5└── rbac6└── role.yaml注意：\n如果你修改了guestbook_types.go的结构，你需要执行以下命令来更新代码和manifests：\n1make \u0026amp;\u0026amp; make manifests 第三步：使用code-generator 1）准备脚本 在hack目录下准备以下文件：\n1. 2└── hack 3 ├── tools.go 4 ├── update-codegen.sh 5 └── verify-codegen.sh 新建hack/tools.go文件：\n1// +build tools 2 3package tools 4 5import _ \u0026#34;k8s.io/code-generator\u0026#34; 新建hack/update-codegen.sh，注意修改几个变量：\n MODULE和go.mod保持一致 API_PKG=apis，和apis目录保持一致 OUTPUT_PKG=generated/webapp，生成Resource时指定的group一样 GROUP_VERSION=webapp:v1和生成Resource时指定的group version对应  1#!/usr/bin/env bash 2 3set -o errexit 4set -o nounset 5set -o pipefail 6 7# corresponding to go mod init \u0026lt;module\u0026gt; 8MODULE=example.com/foo-controller 9# api package 10APIS_PKG=apis 11# generated output package 12OUTPUT_PKG=generated/webapp 13# group-version such as foo:v1alpha1 14GROUP_VERSION=webapp:v1 15 16SCRIPT_ROOT=$(dirname \u0026#34;${BASH_SOURCE[0]}\u0026#34;)/.. 17CODEGEN_PKG=${CODEGEN_PKG:-$(cd \u0026#34;${SCRIPT_ROOT}\u0026#34;; ls -d -1 ./vendor/k8s.io/code-generator 2\u0026gt;/dev/null || echo ../code-generator)} 18 19# generate the code with: 20# --output-base because this script should also be able to run inside the vendor dir of 21# k8s.io/kubernetes. The output-base is needed for the generators to output into the vendor dir 22# instead of the $GOPATH directly. For normal projects this can be dropped. 23bash \u0026#34;${CODEGEN_PKG}\u0026#34;/generate-groups.sh \u0026#34;client,lister,informer\u0026#34; \\ 24 ${MODULE}/${OUTPUT_PKG} ${MODULE}/${APIS_PKG} \\ 25 ${GROUP_VERSION} \\ 26 --go-header-file \u0026#34;${SCRIPT_ROOT}\u0026#34;/hack/boilerplate.go.txt \\ 27 --output-base \u0026#34;${SCRIPT_ROOT}\u0026#34; 28# --output-base \u0026#34;${SCRIPT_ROOT}/../../..\u0026#34; \\ 新建hack/verify-codegen.sh（文件内容请看github项目）。\n2）下载code-generator 先把code-generator 下载下来，注意这里的K8S版本号，得和go.mod里的k8s.io/client-go的版本一致：\n1K8S_VERSION=v0.18.5 2go get k8s.io/code-generator@$K8S_VERSION 3go mod vendor 然后给generate-groups.sh添加可执行权限：\n1chmod +x vendor/k8s.io/code-generator/generate-groups.sh 3）更新依赖版本 因为code-generator用的是v0.18.5，因此要把其他的k8s库也更新到这个版本：\n1K8S_VERSION=v0.18.5 2go get k8s.io/client-go@$K8S_VERSION 3go get k8s.io/apimachinery@$K8S_VERSION 4go get sigs.k8s.io/controller-runtime@v0.6.0 5go mod vendor 4）生成代码 你需要修改guestbook_types.go文件，添加上tag // +genclient：\n1// +genclient 2// +kubebuilder:object:root=true 3 4// Guestbook is the Schema for the guestbooks API 5type Guestbook struct { 新建apis/webapp/v1/doc.go，注意// +groupName=webapp.example.com：\n1// +groupName=webapp.example.com 2 3package v1 新建apis/webapp/v1/register.go，code generator生成的代码需要用到它：\n1package v1 2 3import ( 4\t\u0026#34;k8s.io/apimachinery/pkg/runtime/schema\u0026#34; 5) 6 7// SchemeGroupVersion is group version used to register these objects. 8var SchemeGroupVersion = GroupVersion 9 10func Resource(resource string) schema.GroupResource { 11\treturn SchemeGroupVersion.WithResource(resource).GroupResource() 12} 执行hack/update-codegen.sh：\n1./hack/update-codegen.sh 会得到example.com/foo-controller目录：\n1example.com 2└── foo-controller 3 └── generated 4 └── webapp 5 ├── clientset 6 ├── informers 7 └── listers 移动文件：\n example.com/foo-controller/generated直接移出来，放到项目根下面generated  例子程序 先apply manifests yaml：\n1kubectl apply -f config/crd/bases/webapp.example.com_guestbooks.yaml 2kubectl apply -f config/samples/webapp_v1_guestbook.yaml 然后执行项目的main.go 。\n参考资料  code-generator client-gen tag references  kubebuilder tag references  Kubernetes Deep Dive: Code Generation for CustomResources  kubebuilder sample project  ","date":"2020-07-01","img":"","permalink":"/post/k8s/mix-kubebuilder-and-code-generator/","series":null,"tags":["k8s"],"title":"混合kubebuilder与code Generator编写CRD"},{"categories":null,"content":"使用k8s.io/code-generator 编写CRD。\n本项目代码在 https://github.com/chanjarster/k8s-code-gen-how-to 概览 k8s.io/code-generator 是一个代码生成工具，用于为你的CRD生成kubernetes-style API 实现，这样你就可以管理K8S上你的自定义CRD资源了。\n第一步：初始化项目 1MODULE=example.com/foo-controller 2go mod init $MODULE 第二步：定义API 新建目录api/\u0026lt;group\u0026gt;/\u0026lt;version\u0026gt;，这个目录下得有以下几个文件：\n1. 2└── api 3 └── foo 4 └── v1alpha1 5 ├── doc.go 6 ├── register.go 7 └── types.go 执行命令：\n1GROUP=foo 2VERSION=v1alpha1 3mkdir -p api/$GROUP/$VERSION 编写文件api/\u0026lt;group\u0026gt;/\u0026lt;version\u0026gt;/doc.go，注意//+groupName=foo.example.com，你需要视情况修改：\n1// +k8s:deepcopy-gen=package 2// +groupName=foo.example.com 3 4// Package v1alpha1 is the v1alpha1 version of the API. 5package v1alpha1 编写文件api/\u0026lt;group\u0026gt;/\u0026lt;version\u0026gt;/types.go，注意视情况修改类名以及相关常量，Status字段并非必须的：\n1package v1alpha1 2 3import ( 4\tmetav1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; 5) 6 7// These const variables are used in our custom controller. 8const ( 9\tGroupName string = \u0026#34;foo.example.com\u0026#34; 10\tKind string = \u0026#34;Foo\u0026#34; 11\tVersion string = \u0026#34;v1alpha1\u0026#34; 12\tPlural string = \u0026#34;foos\u0026#34; 13\tSingluar string = \u0026#34;foo\u0026#34; 14\tShortName string = \u0026#34;foo\u0026#34; 15\tName string = Plural + \u0026#34;.\u0026#34; + GroupName 16) 17 18// +genclient 19// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object 20 21// Foo is a specification for a Foo resource 22type Foo struct { 23\tmetav1.TypeMeta `json:\u0026#34;,inline\u0026#34;` 24\tmetav1.ObjectMeta `json:\u0026#34;metadata,omitempty\u0026#34;` 25 26\tSpec FooSpec `json:\u0026#34;spec\u0026#34;` 27\tStatus FooStatus `json:\u0026#34;status\u0026#34;` 28} 29 30// FooSpec is the spec for a Foo resource 31type FooSpec struct { 32\tDeploymentName string `json:\u0026#34;deploymentName\u0026#34;` 33\tReplicas *int32 `json:\u0026#34;replicas\u0026#34;` 34} 35 36// FooStatus is the status for a Foo resource 37type FooStatus struct { 38\tAvailableReplicas int32 `json:\u0026#34;availableReplicas\u0026#34;` 39} 40 41// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object 42 43// FooList is a list of Foo resources 44type FooList struct { 45\tmetav1.TypeMeta `json:\u0026#34;,inline\u0026#34;` 46\tmetav1.ListMeta `json:\u0026#34;metadata\u0026#34;` 47 48\tItems []Foo `json:\u0026#34;items\u0026#34;` 49} 编写文件api/\u0026lt;group\u0026gt;/register.go\n1package v1alpha1 2 3import ( 4\tmetav1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; 5\t\u0026#34;k8s.io/apimachinery/pkg/runtime\u0026#34; 6\t\u0026#34;k8s.io/apimachinery/pkg/runtime/schema\u0026#34; 7) 8 9var ( 10\t// SchemeBuilder initializes a scheme builder 11\tSchemeBuilder = runtime.NewSchemeBuilder(addKnownTypes) 12\t// AddToScheme is a global function that registers this API group \u0026amp; version to a scheme 13\tAddToScheme = SchemeBuilder.AddToScheme 14) 15 16// SchemeGroupVersion is group version used to register these objects. 17var SchemeGroupVersion = schema.GroupVersion{ 18\tGroup: GroupName, 19\tVersion: Version, 20} 21 22func Resource(resource string) schema.GroupResource { 23\treturn SchemeGroupVersion.WithResource(resource).GroupResource() 24} 25 26func addKnownTypes(scheme *runtime.Scheme) error { 27\tscheme.AddKnownTypes(SchemeGroupVersion, 28\t\u0026amp;Foo{}, 29\t\u0026amp;FooList{}, 30\t) 31\tmetav1.AddToGroupVersion(scheme, SchemeGroupVersion) 32\treturn nil 33} 然后添加依赖：\n1K8S_VERSION=v0.18.5 2go get k8s.io/apimachinery@$K8S_VERSION 第三步：代码生成 1）准备脚本 新建目录hack，我们需要在hack目录下有以下几个文件：\n1. 2└── hack 3 ├── boilerplate.go.txt 4 ├── tools.go 5 ├── update-codegen.sh 6 └── verify-codegen.sh 执行命令：\n1mkdir hack 2touch hack/boilerplate.go.txt 新建hack/tools.go文件：\n1// +build tools 2 3package tools 4 5import _ \u0026#34;k8s.io/code-generator\u0026#34; 新建hack/update-codegen.sh，注意修改几个变量：\n MODULE和go.mod保持一致 API_PKG=api，和我们的目录保持一致 OUTPUT_PKG GROUP_VERSION=foo.v1alpha1而不是foo.example.com:v1alpha1，因为code generator会读取我们之前写的api/\u0026lt;group\u0026gt;/\u0026lt;version\u0026gt;下的代码，因此得要对应上这个路径：  1#!/usr/bin/env bash 2 3set -o errexit 4set -o nounset 5set -o pipefail 6 7# corresponding to go mod init \u0026lt;module\u0026gt; 8MODULE=example.com/foo-controller 9# api package 10APIS_PKG=api 11# generated output package 12OUTPUT_PKG=generated 13# group-version such as foo:v1alpha1 14GROUP_VERSION=foo:v1alpha1 15 16SCRIPT_ROOT=$(dirname \u0026#34;${BASH_SOURCE[0]}\u0026#34;)/.. 17CODEGEN_PKG=${CODEGEN_PKG:-$(cd \u0026#34;${SCRIPT_ROOT}\u0026#34;; ls -d -1 ./vendor/k8s.io/code-generator 2\u0026gt;/dev/null || echo ../code-generator)} 18 19# generate the code with: 20# --output-base because this script should also be able to run inside the vendor dir of 21# k8s.io/kubernetes. The output-base is needed for the generators to output into the vendor dir 22# instead of the $GOPATH directly. For normal projects this can be dropped. 23bash \u0026#34;${CODEGEN_PKG}\u0026#34;/generate-groups.sh \u0026#34;all\u0026#34; \\ 24 ${MODULE}/${OUTPUT_PKG} ${MODULE}/${APIS_PKG} \\ 25 ${GROUP_VERSION} \\ 26 --go-header-file \u0026#34;${SCRIPT_ROOT}\u0026#34;/hack/boilerplate.go.txt \\ 27 --output-base \u0026#34;${SCRIPT_ROOT}\u0026#34; 28# --output-base \u0026#34;$(dirname \u0026#34;${BASH_SOURCE[0]}\u0026#34;)/../../..\u0026#34; \\ 29 30# To use your own boilerplate text append: 31# --go-header-file \u0026#34;${SCRIPT_ROOT}\u0026#34;/hack/custom-boilerplate.go.txt 新建hack/verify-codegen.sh（文件内容请看github项目）。\n2）下载code-generator 先把code-generator 下载下来，注意这里的K8S版本号，得和前面是一致的：\n1K8S_VERSION=v0.18.5 2go get k8s.io/code-generator@$K8S_VERSION 3go mod vendor 然后给generate-groups.sh添加可执行权限：\n1chmod +x vendor/k8s.io/code-generator/generate-groups.sh 3）生成代码 执行hack/update-codegen.sh：\n1./hack/update-codegen.sh 代码会生成在example.com/foo-controller目录下（回忆前面的MODULE=example.com/foo-controller和OUTPUT_PKG=generated参数）：\n1example.com 2└── foo-controller 3 ├── api 4 │ └── foo 5 │ └── v1alpha1 6 │ └── zz_generated.deepcopy.go 7 └── generated 8 ├── clientset 9 ├── informers 10 └── listers 移动文件：\n zz_generated.deepcopy.go移动到api/\u0026lt;group\u0026gt;/\u0026lt;version\u0026gt;下 example.com/foo-controller/generated直接移出来，放到项目根下面generated 如果后面你修改了types.go，重新执行./hack/update-codegen.sh就行了。  对于生成代码的说明：\n clientset：用于操作foos.foo.example.comCRD资源 informers：Informer接收来自服务器的CRD的变更事件 listers：Lister提供只读的cache layer for GET和LIST请求  关于Controller controller代码可以看项目的main.go 。\n本例子里controller读取环境变量KUBECONFIG来启动Clientset以及和K8S通信，这个也符合k8s.io/client-go out-of-cluster example 。在实际生产环境中，可以参考k8s.io/client-go in-cluster example 。\n如果你想要更灵活的做法，比如当提供了--kubeconfig的时候采用out-of-cluster模式，否则则尝试in-cluster模式（看/var/run/secrets/kubernetes.io/serviceaccount），可以参考prometheus-operator k8sutil.go 的做法\n参考文档  Kubernetes Deep Dive: Code Generation for CustomResources  Programming Kubernetes CRDs  Sample Controller  code-generator  client-go  client-gen tag docs  ","date":"2020-06-30","img":"","permalink":"/post/k8s/use-code-generator/","series":null,"tags":["k8s"],"title":"使用code-Generator编写CRD"},{"categories":null,"content":"概要 在Java 9中，String对象底层从原来的char[]变成了byte[]，这一变化带来的直接好处就是更节省内存了，因此也被称为Compact Strings Improvement。为什么呢？因为在Java中char占有2个字节，byte占用1个字节，而一个Unicode字符的表示并不一定需要2个字节，至少ASCII字符只需要1个字节就搞定了。也就是说，如果你的字符串里都是ASCII字符，如果用char的话就会浪费一半的空间。\n简要Unicode说明 说到这里不得不提一下Unicode编码，以及它的Code Point（码点）和Code Unit。可以把Unicode想象成一张巨大的表格，每个字符都有一个唯一对应的数字。\n一个Code Point代表了一个Unicode字符的在表中的序号：\n1\u0026gt; \u0026#39;A\u0026#39;.codePointAt(0).toString(16) 2\u0026#39;41\u0026#39; 3\u0026gt; \u0026#39;π\u0026#39;.codePointAt(0).toString(16) 4\u0026#39;3c0\u0026#39; 5\u0026gt; \u0026#39;🙂\u0026#39;.codePointAt(0).toString(16) 6\u0026#39;1f642\u0026#39; 一个或者多个Code Unit代表了一个Code Point，Code Unit是用来存储和传输Unicode字符的，以下是UTF-8编码：\n   Character Code point Code units     A 0x0041 01000001   π 0x03C0 11001111, 10000000   🙂 0x1F642 11110000, 10011111, 10011001, 10000010    UTF-8的Code Unit占用8位（1字节），UTF-16的Code Unit占用16位（2字节），UTF-32的Code Unit占用32位（4字节），除了UTF-32之外，UTF-8/16都是变长编码，也就是说在对一个Code Point转换成Code Unit的时候，根据情况使用1个或多个Code Unit（上面表格已经说明了）。\n所以，当Java 9 String底层从char[]改成byte[]，除非使用UTF-32编码（定长编码），那么它肯定是变长编码，使得内存占用更紧凑。也因此Java 9 String API中添加了关于Code Point的方法。\n参考文档  Unicode – a brief introduction  Java 9 – Compact Strings Improvement [JEP 254]  Java 9 String API  ","date":"2020-05-21","img":"","permalink":"/post/jvm/string-in-9/","series":null,"tags":["jvm"],"title":"JVM - String对象在Java 9中的变化"},{"categories":null,"content":"强软弱虚引用 四种引用类型分别对应了四种可达性：\n 强可达：一个线程可以通过强引用达到一个对象，而不是通过软弱虚引用对象达到。 软可达：不是强可达，但是可以通过SoftReference达到 弱可达：不是强可达，也不是弱可达，可以通过WeakReference达到。当一个弱可达对象被清理了，那么它就变成了“可被finalization” 虚可达：对象不是以上三种可达，但是已经被finalized，然后有一些虚引用引用它。 不可达：不是以上四种可达，“可被回收”。  引用队列（ReferenceQueue） 当引用对象（软、弱、虚对象）的可达性发生变化的时候，它们就会被注册到ReferenceQueue 里。\n当一个软引用、弱引用被GC清理的时候（get()会返回null），他们会被追加到引用队列中。所以软、弱引用配合队列使用一般用处不大。除非你做了一个软、弱引用的子类，并且在里面添加了一些属性：\n1ReferenceQueue\u0026lt;Foo\u0026gt; fooQueue = new ReferenceQueue\u0026lt;Foo\u0026gt;(); 2 3class ReferenceWithCleanup extends WeakReference\u0026lt;Foo\u0026gt; { 4 Bar bar; 5 ReferenceWithCleanup(Foo foo, Bar bar) { 6 super(foo, fooQueue); 7 this.bar = bar; 8 } 9 public void cleanUp() { 10 bar.cleanUp(); 11 } 12} 13 14public Thread cleanupThread = new Thread() { 15 public void run() { 16 while(true) { 17 ReferenceWithCleanup ref = (ReferenceWithCleanup)fooQueue.remove(); 18 ref.cleanUp(); 19 } 20 } 21} 当一个对象编程虚可达的时候，它的虚引用就会被添加到引用队列，当虚引用对象被清理或者虚引用对象变得不可达的时候，对象就才会变成不可达。\n强引用（Strong Reference） 一般的引用\n软引用（Soft Reference） 当要发生OOM之前，JVM会回收SoftReference 所引用的对象。\n软引用一般用来实现Cache，这样实现的Cache不会对内存造成压力，因为会被回收掉。\n弱引用（Weak Reference） WeakReference 完全不影响垃圾回收，该回收的时候还是会被回收。\n弱引用的特性用代码表示是：\n1Object referent3 = weakReference2.get(); 2if (referent3 != null) { 3 // GC hasn\u0026#39;t removed the instance yet 4} else { 5 // GC has cleared the instance 6} 你可以用来实现，如果你不想保持对A对象的强引用，同时如果A对象没有被回收，那么我就可以干活，如果A对象被回收了，那我也无所谓的逻辑。\n虚引用（Phantom Reference） PhantomReference 完全不影响垃圾回收，该回收的时候还是会被回收。同时也无法得到所引用的对象，get()方法永远返回null。虚引用一定要配合ReferenceQueue来使用：\n1Object counter = new Object(); 2ReferenceQueue refQueue = new ReferenceQueue\u0026lt;\u0026gt;(); 3PhantomReference\u0026lt;Object\u0026gt; p = new PhantomReference\u0026lt;\u0026gt;(counter, refQueue); 4counter = null; 5System.gc(); 6try { 7 // Remove是一个阻塞方法，可以指定timeout，或者选择一直阻塞 8 Reference\u0026lt;Object\u0026gt; ref = refQueue.remove(1000L); 9 if (ref != null) { 10 // do something 11 } 12} catch (InterruptedException e) { 13 // Handle it 14} 前面可达性已经说了，“虚可达”后面的状态是“不可达”，那么一个对象变成“虚可达”的意思就是它现在已经被finalized，但是还没有被回收，配合ReferenceQueue，就能够得到“对象该清理的都清理了，都已经被finalized了，即将被回收”的事件。\nReachability Fence `java.lang.ref.Reference#reachabilityFence(Object ref) 静态方法用来将ref所指向的对象设置为强引用。\n这个是因为Java在垃圾回收的时候，会把下面的对象回收掉：\n1new Foo().action()； 因为GC依赖的是可达性分析，而Foo对象实际上并不可达，就算它在调用方法，也是不可达的。为了避免在action()方法执行时被回收，可以添加这段代码：\n1public void action() { 2 try { 3 // do some work 4 } finally { 5 Reference.reachabilityFence(this); 6 } 7} 这段代码的意思是在action()方法返回之前，Foo对象会保持强引用状态（虽然你会觉得代码位置不是应该放在第一行吗？但文档里是这么说的）。\n参考资料  强引用、软引用、弱引用、幻象引用有什么区别？  ReferenceQueue  SoftReference  WeakReference  PhantomReference  reachabilityFence  Reachability  ","date":"2020-05-19","img":"","permalink":"/post/jvm/reference-types-reachability-fence/","series":null,"tags":["jvm"],"title":"JVM - 强软弱虚引用以及Reachability Fence"},{"categories":null,"content":"概要 三色标记法是运用在GC并发标记过程中的算法，被扫描的对象们被分到三种集合里：\n 白色集合：还没被标记 or 没有被标记到（这个就可以认为是垃圾了） 灰色：标记到了，但是字段还没被标记完。 黑色：标记完了。  所有标记完成后，会把白色的作为垃圾回收掉（因为不可达）。\n步骤  创建：白、灰、黑 三个集合。 将所有对象放入白色集合中。 从GC Root开始遍历所有对象，把遍历到的对象从白色集合放入灰色集合(备注：这里放入灰色集合的都是GC Root的对象)。 遍历灰色集合，将灰色对象引用的对象（其实就是灰色对象的字段）从白色集合放入灰色集合，然后将分析过的灰色对象（所有字段都处理完毕的）放入黑色集合。 直到灰色中无任何对象。 通过写屏障（Pre-Write Barrier）检测对象有变化，重复以上操作(备注：因为 mark 和用户程序是并行的，所以在上一步执行的时候可能会有新的对象分配，写屏障是为了解决这个问题引入的)。 回收掉所有白色对象（垃圾）  关于Pre-Write Barrier：\n可以看到三色标记法有很多步骤，而这些步骤是和用户线程并发运行的，也就是说在标记过程中，用户还在创建新对象，或者抛弃老对象。\n先讲创建新对象的情况：\n A对象已经被标记为黑色 用户线程：A.field = new X()  这种情况下，X是白色的，而且按照三色标记法的规则，黑色的A是不会再次被标记的。如果不能把X变成灰色，那么它就会被垃圾回收掉，这个是是存在问题的。\n因此，在标记开始之后，需要在对象引用更新的地方添加一个Pre-Write Barrier，用来将X直接标记为灰色。\n注意：Pre-Write Barrier和Post-Write Barrier 作用的对象不同，前者是针对三色标记算法的缺陷，后者是针对Card Table。\n参考资料  Go垃圾回收之三色标记算法  Java Hotspot G1 GC的一些关键技术  ","date":"2020-05-15","img":"","permalink":"/post/jvm/tri-color/","series":null,"tags":["jvm"],"title":"JVM - 并发标记之三色标记法和Pre-Write Barriers"},{"categories":null,"content":"在前一篇G1垃圾收集器 里提到了Card Table是Remeber Set的一种特殊形式，它记录了外部Region的某个区域里有对象引用了我这个Region里对象的信息。\n为何会存在Card Table 下面的描述不是对G1的精确描述，而是逻辑上的描述：\nYGC的时候，理想情况下YGC只需要扫描GC Root（栈中的本地变量表，静态变量）就行了，看下图：\n但是老年代里也会存在对年轻代对象的引用，如果不扫描老年代就会误把一个对象当成是垃圾，看下图：\n我们又知道老年代的GC远没有年轻代频繁，也就造成了老年代的尺寸是很大的。同时，老年代存在对年轻代的引用的概率又很小，如果在YGC的时候对整个老年代进行扫描那么性价比太低。\n因此就有了Card Table，年轻代的Card Table里记录了老年代的X区域里的对象引用了年轻代的对象，然后只需要扫描那片区域就行了。\n也就是说Card Table是分代垃圾收集算法的特定产物。\nG1中的Card Table G1中的每个Region都有一个Remember Set，Remeber Set存在3种粒度形式，其中某一种就是Card Table。当然其他两种粒度形式存在的目的和Card Table一样，为了能够降低扫描耗时。\nCard Table结构 实际上Card Table是一个bitmap，每个bit代表着一个Card，一个Card代表了一块内存区域，那么Card到底多大呢？这个不重要，网上有说是512 byte的，有说是4K的。下面是一张图，图中的Gen1可以看作是老年代（因为是从.Net中抄的图）：\nPost-Write Barrier Post-Writer Barrier就是编译器在你更新引用的地方插入的一小段代码，用来更新Card Table的，更新old -\u0026gt; old 和 old -\u0026gt; young的信息。\n参考资料  Back To Basics: Generational Garbage Collection ，虽然是.Net的但是思路一样 Write-Barriers-in-Garbage-First-Garbage-Collector  ","date":"2020-05-15","img":"","permalink":"/post/jvm/card-table/","series":null,"tags":["jvm"],"title":"JVM - Card Table和Post-Write Barriers"},{"categories":null,"content":"特点 G1是一个：\n 并行算法 增量式垃圾收集器 具有可预测停顿时间的优势 具备内存整理功能  Region G1把整个heap分为～2048个Region，尺寸在1M-32M之间（得是2的指数）。\nRegion分为：Eden，Survior，H（巨大对象），Old区。Eden和Survivor组合成Young Region。H是Old区的一种。一个对象尺寸超过Region的1/2，就是巨大对象，巨大对象直接分配在Old区，并被标记为H。\n垃圾收集过程 Young GC YGC，采用复制算法，并行的。\nYGC逻辑上和其他GC算法一样的，也是\n并行阶段：\n 外部根扫描 更新Remembered Set（RSet） 处理Update Buffers 扫描RSet 对象复制，Eden和S-From -\u0026gt; S-To或Old 终止 其他工作  串行阶段：\n 选择Collection Set 引用处理，比如soft、weak、final、phantom引用 Reference En-queuing 释放CSet，同时也会释放RSet  并发标记 当Old Region使用空间超过整个Heap的某个比例会触发对Old Region并发标记（注意只标记，不回收），-XX:InitiatingHeapOccupancyPercent，默认45，\n并发标记的阶段：\n 初始标记（STW），在一个普通的YGC（STW）时同时完成的。 根Region扫描阶段，扫描前一个阶段幸存的Region，找到那些对Old Region的引用，标记被引用的对象。 并发标记， 再标记（STW），处理SATB buffer，跟踪在前面阶段里新生成的对象，同时处理引用关系。 清理（STW），如果某个Region全是垃圾，那么就直接回收掉了。如果不是，那么这个Region会记录到Collection Set里。  关于三色标记法 在标记过程中每个对象会被标记成三种颜色 ：\n 白色：没有被标记到。 灰色：标记到了，但是字段还没被标记完。 黑色：标记完了。  所有标记完成后，会把白色的作为垃圾回收掉（因为不可达）。\n和三色标记法相关的一个概念是Pre-Write Barrier。\nMixed GC 把Collection Set里的待回收的Old Region混合到YGC里慢慢消化掉。\nFull GC 如果Mixed GC来不及回收掉空间，那么就会触发Full GC。会停止整个JVM。\nOld GC（逻辑上）的阶段 Old GC是分层次进行的：\n 并发标记结束后，对于全垃圾的Region，在清理阶段会直接清理掉 对于部分垃圾的Region，则放到YGC中慢慢消化掉（比如每次YGC清理几个Old Region），这个成为Mixed GC 如果还是不行，才会对整个堆进行回收Full GC  H对象的回收 尺寸超过1/2 Region的对象被称为，H对象，直接分配在Old区里，这个区被标记为H。它要么在并发标记的清理阶段回收，要么在Full GC的时候回收。\nG1假设大对象不是短命对象，因此把他们放到H区里可以避免被YGC反复复制，提高性能。\n单如果你的大对象的确是短命的，那如果把他们放到H区里反而会增加Old GC的压力，还有可能导致Full GC。因此你可以通过调整-XX:G1HeapRegionSize=16M来调整Region的大小，从而使得你的大对象不被G1认定为H对象。\n几个数据结构 Remeber Set 每个Region都有，记录了外部引用的信息（其他Region到自己Region的引用信息）：\n old -\u0026gt; young的引用 old -\u0026gt; old的引用 注意不需要记录young -\u0026gt; young 和 young -\u0026gt; old，因为这些在YGC扫描Young Region的时候就能够得到  下面是一张图：\nRegion X是Young Region，Region Y和Z是Old Region。\n细箭头代表A Region里的对象引用B Region里的对象，粗箭头代表A Region被B Region引用了。\n仔细看可以发现粗箭头只存在 old -\u0026gt; young 和 old -\u0026gt; old。\n在YGC时，需要扫描Old Region里到Young Region里的引用，RSet可以提高扫描效率，而不需要遍历所有Old Region。\n同时，因为YGC采用的复制算法，而且是并行的，那么某一时刻某个对象同时出现在两块Region里（比如，Eden和S-To），为了YGC之后修复引用（正确的应该是引用到S-To里），Remeber Set配合Pre Write Barrier解决这个问题（以上个人猜测，未必准确）。\nRemeber Set 三种粒度（下面讲的不是很明白）：\n Sparse，稀疏矩阵，一个card索引的hash table 细粒度，一个开放hash table，bitmap，每个bit代表一个card 粗粒度，bitmap，每个bit代表一个外部Region  三种粒度的关系是：当某种粒度的空间满了，就切换到下一种，从而节省空间。但是节省空间的结果就是增加了扫描的时间，因为记录的信息也粗了。\nCard Table Card Table是一种特殊的Remember Set形式，它是一个bitmap，每个bit对应了Region中的一片区域，而这片区域里有对象引用了我这个Region里的对象。更多介绍看Card Table和Write Barriers 。\nPost-Write Barriers 编译器插在更新引用语句后面的代码，用来更新RSet。\nConcurrent refinement threads 并发更新RSet的线程。\nCollection Set 记录了需要收集的Region列表，这个在并发标记之后。对于YGC来说只有Young Region，对于Mixed GC来说，有Young也有Old。\n参考资料  Java核心技术面试精讲 - 第28讲 | 谈谈你的GC调优思路?  G1: One Garbage Collector To Rule Them All - By Monica Beckwith  Tips for Tuning the Garbage First Garbage Collector - By Monica Beckwith  Write-Barriers-in-Garbage-First-Garbage-Collector - By Monica Beckwith  jvm的card table数据结构  Java Hotspot G1 GC的一些关键技术  ","date":"2020-05-14","img":"","permalink":"/post/jvm/g1/","series":null,"tags":["jvm"],"title":"JVM - G1垃圾收集器"},{"categories":null,"content":"TODO\nhttps://zhuanlan.zhihu.com/p/43263751 redis setbit/getbit\nhttps://redis.io/commands/getbit https://redis.io/commands/setbit ","date":"2020-05-12","img":"","permalink":"/post/algo/32-bloom-filter/","series":null,"tags":["ARTS-A"],"title":"算法 - 布隆过滤器"},{"categories":null,"content":"问题：把10进制转换成N进制，可以使用52个大小写英文字母+10个数字来表达新数字\n解法：把数字不停的除以N，得到的余数则是N进制的位，然后对商再除以N，如此反复，直到商为0位置，把这些余数串起来就是N进制的表现形式了。\n116 | 255 2 ----- 316 | 15 余数: 15 (f) 4 ---- 5 0 余数: 15 (f) 6 7所以hex(255) = ff 8 916 | 254 10 ----- 1116 | 15 余数: 14 (e) 12 ---- 13 0 余数: 15 (f) 14 15所以hex(254) = fe 代码：\n1var ntab = []byte(\u0026#34;0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\u0026#34;) 2 3func convert(num int, radix int) string { 4\tr := make([]byte, 0) 5\tfor num != 0 { 6\td := num / radix 7\tm := num % radix 8\tr = append(r, ntab[m]) 9\tnum = d 10\t} 11\t// 把结果反转过来 12\tfor i := 0; i \u0026lt; len(r)/2; i++ { 13\toi := len(r) - 1 - i 14\tr[i], r[oi] = r[oi], r[i] 15\t} 16\treturn string(r) 17} ​\n","date":"2020-05-12","img":"","permalink":"/post/algo/31-radix-convert/","series":null,"tags":["ARTS-A"],"title":"算法 - 进制转换"},{"categories":null,"content":"如何实现短网址服务 哈希法 大致思路：对原始网址求哈希值，把这个哈希值作为key，原始网址作为value存在redis或数据库中。用户访问短网址的时候，到库中找，然后302重定向到原始网址。\n用什么哈希算法？\n你可以用SHA256、MD5、java的String#hashCode都可以。比较著名的是MurmurHash3算法 。MurmurHash比SHA和MD5性能高，因为它是非密码学算法，它可以产生32bit和128bit两种哈希值。\n如何把哈希值转换成短网址？\n虽然你可以采用32bit的版本得到一个int，直接把这个作为短网址，比如shorturl.cn/181338494，但是这样还不够短，可以把把十进制转换成十六进制，也可以转换成62进制，用52个大小写英文字母 + 10个数字来表示。算法代码看进制转换 。\n哈希值冲突了怎么办？\n分析冲突的原因：\n1）一种原因，用户用同样的原始网址求了两次短网址，那么哈希值肯定会冲突。解决思路有两个：\n 不管它，冲突消解，生成个新的短网址。优点是简单，容易缺点被攻击，浪费哈希槽位。 每次都到redis或数据库中取一下，如果存在那么对比原始网址是否一样，如果一样就直接返回之前的短网址，如果不一样就冲突消解。  2）另一个原因，就是两个不同的原始字符串的哈希值冲突了，没二话直接冲突消解。\n冲突消解的思路？\n有两个思路：\n （不推荐）采用开放寻址法，哈希值是32bit也就是一个int，那么把int++，看看有没有冲突。这个方法比较简单，缺点是要避免位溢出变成负数，占用了别人的位置了，哈希的分布不均匀，容易导致需要消解几次冲突。 追加特殊字符，在原始网址后面加上程序自己识别的字符，比如[DUP]，对其取哈希，看看有没有冲突。如果再有冲突则换一个特殊字符[DUP_AGAIN]。这个方法也简单，基本上第一次冲突就消解了，极个别的需要两次。  如何提升服务的性能？\n按照追加特殊字符的冲突消解的代码大致如下：\n1func shortify(url string) string { 2 for { 3 shorturl := hash(url) 4 if store.exists(shorturl) { 5 existedUrl := store.get(shorturl) 6 if existedUrl == url { 7 return shorturl 8 } 9 url = resolveConflict(url) // 修改url追加特殊字符 10 continue 11 } 12 store.save(shorurl, url) 13 return shorturl 14 } 15} 可以看到整个过程必须查询一次store.exists(shorturl)再保存一次store.save(shorturl, url)\n如何减少每次判断？\n1）可以利用redis的SETNX和数据库中添加唯一索引让这个过程变得只有一次：\n1func shortify(url string) string { 2 for { 3 shorturl := hash(url) 4 if store.save(shorurl, url) { 5 return shorturl 6 } 7 existedUrl := store.get(shorturl) 8 if existedUrl == url { 9 return shorturl 10 } 11 url = resolveConflict(url) // 修改url追加特殊字符 12 } 13} 2）可以利用布隆过滤器，布隆过滤器是比较节省内存的一种存储结构，长度是 10 亿的布隆过滤器 ，也只需要 125MB 左右的内存空间。\n自增ID法 数据库中自增ID生成作为短网址。\n相同的原始网址可能会对应不同的短网址\n解决思路：\n 不解决。反正用户关心的是能够跳转到原始网址。 和哈希法一样，到数据库中查询一下原始网址是否已经有短网址了。在数据库中需要给原始网址和短网址都加上索引，多一个索引会增加性能开销。对于redis来说则是建两套key，一个是 shorturl -\u0026gt; longurl 的，一个是 longurl -\u0026gt; shorturl 的。  如何实现高性能的 ID 生成器？\n因为ID不能重复，必须自增，那么它就会加锁，这样会影响性能。\n解决思路：\n 多个ID生成器，每个都有一个号段，号段问一个号段管理器要。号段用完了再要新的号段。这样可以增加并发效率。 多个ID生辰器，他们天然就不会生成相同的ID，比如一个只生成尾号为0的，一个只生成尾号为1的。再比如Twitter的雪花算法 。 ","date":"2020-05-12","img":"","permalink":"/post/algo/30-shorturl/","series":null,"tags":["ARTS-A"],"title":"算法 - 如何实现短网址服务"},{"categories":null,"content":"原理解释 在32位系统中，指针占4个字节。在64位系统中，指针占8个字节。更大的指针尺寸带来了：\n 更容易GC，因为占用空间更大了 降低CPU缓存命中率，因为一条cache line中能存放的指针数变少了  在JVM - 对象的内存布局 里提到，对象都是按照8字节对齐填充的，那么也就意味着指针的偏移量只会是8的倍数，而不会是下面中的1-7，只会是0或者8：\n1mem: | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 2 ^ ^ 那么我们是否可以在堆中记录0x0、0x1偏移量来代表实际上的0x0、0x8呢？比如这样：\n1mem: | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 2 ^ ^ 3 | ___________________________| 4 | | 5heap: | 0 | 1 | 答案是可以的。你只需在从heap里拿出来的时候做一下翻译，像左位移3位，就得到了在内存中实际位置。放到heap中的时候只需右移3位，就得到了在heap中记录的位置。\nJVM启用指针压缩后（默认开启），指针大小从8字节变成了4字节，也就是32位，而这个32位实际上能表达的地址范围是235=32G。\nJVM参数 开启压缩（默认开启的）：-XX:+UseCompressedOops\n关闭压缩：-XX:-UseCompressedOops\n参考资料  JVM之压缩指针（CompressedOops）  CompressedOops  ","date":"2020-05-11","img":"","permalink":"/post/jvm/oop-compress/","series":null,"tags":["jvm"],"title":"JVM - 指针压缩"},{"categories":null,"content":"JVM Spec中关于方法调用的指令有：\n invokedynamic，1.7加入，对于基于JVM的动态语言有用 invokeinterface，当前变量形式类型是接口时，用以调用接口方法，在运行时搜索一个实现了这个接口方法的对象，找出适合的方法进行调用。 invokespecial，用于调用一些需要特殊处理的实例方法，包括静态代码块，实例构造函数、实例初始化代码块、私有方法和父类方法。 invokestatic，用于调用类静态方法 invokevirtual，用于调用对象的实例方法，根据对象的实际类型进行分派  例子代码：\n1import java.lang.invoke.MethodHandle; 2import java.lang.invoke.MethodHandles; 3import java.lang.invoke.MethodType; 4import java.util.Arrays; 5import java.util.List; 6 7public class JVMMethodInstruction implements Runnable { 8 9 static { 10 System.out.println(\u0026#34;\u0026lt;clinit\u0026gt;\u0026#34;); 11 } 12 13 { 14 System.out.println(\u0026#34;\u0026lt;init block\u0026gt;\u0026#34;); 15 } 16 17 public JVMMethodInstruction() {} 18 static void staticMethod() {} 19 static void staticForMethodHandle(String str) {} 20 private void privateMethod() {} 21 void instanceMethod() {} 22 public void forMethodHandle(String str) {} 23 24 @Override 25 public void run() {} 26 27 public static void main(String[] args) throws Throwable { 28 /** 29* invoke special 30*/ 31 JVMMethodInstruction test = new JVMMethodInstruction(); 32 /** 33* invoke special 34*/ 35 test.privateMethod(); 36 /** 37* invoke virtual 38*/ 39 test.instanceMethod(); 40 /** 41* invoke static 42*/ 43 staticMethod(); 44 /** 45* invoke interface 46*/ 47 Runnable r = test; 48 r.run(); 49 /** 50* invoke dynamic instance method 51*/ 52 MethodHandles.Lookup lookup = MethodHandles.lookup(); 53 MethodHandle mh = lookup 54 .findVirtual(JVMMethodInstruction.class, \u0026#34;forMethodHandle\u0026#34;, 55 MethodType.methodType(void.class, String.class)); 56 System.out.println(mh); 57 mh.bindTo(test).invoke(\u0026#34;a\u0026#34;); 58 /** 59* invoke dynamic static method 60*/ 61 mh = lookup.findStatic(JVMMethodInstruction.class, \u0026#34;staticForMethodHandle\u0026#34;, 62 MethodType.methodType(void.class, String.class)); 63 mh.invoke(\u0026#34;static\u0026#34;); 64 /** 65* Java 8中，lambda表达式和默认方法时，底层会生成和使用invoke dynamic 66* invoke dynamic 67*/ 68 List\u0026lt;Integer\u0026gt; list = Arrays.asList(1, 2, 3, 4); 69 list.stream().forEach(System.out::println); 70 71 } 72} 编译然后反编译：\n1javac JVMMethodInstruction.java 2javap -c JVMMethodInstruction 得到反编译结果：\n1 public JVMMethodInstruction(); 2 Code: 3 0: aload_0 4 1: invokespecial #1 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 5 4: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 6 7: ldc #3 // String \u0026lt;init block\u0026gt; 7 9: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8 12: return 9 public static void main(java.lang.String[]) throws java.lang.Throwable; 10 Code: 11 0: new #5 // class JVMMethodInstruction 12 3: dup 13 4: invokespecial #6 // Method \u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 14 7: astore_1 15 8: aload_1 16 9: invokespecial #7 // Method privateMethod:()V 17 12: aload_1 18 13: invokevirtual #8 // Method instanceMethod:()V 19 16: invokestatic #9 // Method staticMethod:()V 20 19: aload_1 21 20: astore_2 22 21: aload_2 23 22: invokeinterface #10, 1 // InterfaceMethod java/lang/Runnable.run:()V 24 27: invokestatic #11 // Method java/lang/invoke/MethodHandles.lookup:()Ljava/lang/invoke/MethodHandles$Lookup; 25 30: astore_3 26 31: aload_3 27 32: ldc #5 // class JVMMethodInstruction 28 34: ldc #12 // String forMethodHandle 29 36: getstatic #13 // Field java/lang/Void.TYPE:Ljava/lang/Class; 30 39: ldc #14 // class java/lang/String 31 41: invokestatic #15 // Method java/lang/invoke/MethodType.methodType:(Ljava/lang/Class;Ljava/lang/Class;)Ljava/lang/invoke/MethodType; 32 44: invokevirtual #16 // Method java/lang/invoke/MethodHandles$Lookup.findVirtual:(Ljava/lang/Class;Ljava/lang/String;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/MethodHandle; 33 47: astore 4 34 49: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 35 52: aload 4 36 54: invokevirtual #17 // Method java/io/PrintStream.println:(Ljava/lang/Object;)V 37 57: aload 4 38 59: aload_1 39 60: invokevirtual #18 // Method java/lang/invoke/MethodHandle.bindTo:(Ljava/lang/Object;)Ljava/lang/invoke/MethodHandle; 40 63: ldc #19 // String a 41 65: invokevirtual #20 // Method java/lang/invoke/MethodHandle.invoke:(Ljava/lang/String;)V 42 68: aload_3 43 69: ldc #5 // class JVMMethodInstruction 44 71: ldc #21 // String staticForMethodHandle 45 73: getstatic #13 // Field java/lang/Void.TYPE:Ljava/lang/Class; 46 76: ldc #14 // class java/lang/String 47 78: invokestatic #15 // Method java/lang/invoke/MethodType.methodType:(Ljava/lang/Class;Ljava/lang/Class;)Ljava/lang/invoke/MethodType; 48 81: invokevirtual #22 // Method java/lang/invoke/MethodHandles$Lookup.findStatic:(Ljava/lang/Class;Ljava/lang/String;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/MethodHandle; 49 84: astore 4 50 86: aload 4 51 88: ldc #23 // String static 52 90: invokevirtual #20 // Method java/lang/invoke/MethodHandle.invoke:(Ljava/lang/String;)V 53 93: iconst_4 54 94: anewarray #24 // class java/lang/Integer 55 97: dup 56 98: iconst_0 57 99: iconst_1 58 100: invokestatic #25 // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer; 59 103: aastore 60 104: dup 61 105: iconst_1 62 106: iconst_2 63 107: invokestatic #25 // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer; 64 110: aastore 65 111: dup 66 112: iconst_2 67 113: iconst_3 68 114: invokestatic #25 // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer; 69 117: aastore 70 118: dup 71 119: iconst_3 72 120: iconst_4 73 121: invokestatic #25 // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer; 74 124: aastore 75 125: invokestatic #26 // Method java/util/Arrays.asList:([Ljava/lang/Object;)Ljava/util/List; 76 128: astore 5 77 130: aload 5 78 132: invokeinterface #27, 1 // InterfaceMethod java/util/List.stream:()Ljava/util/stream/Stream; 79 137: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 80 140: dup 81 141: invokevirtual #28 // Method java/lang/Object.getClass:()Ljava/lang/Class; 82 144: pop 83 145: invokedynamic #29, 0 // InvokeDynamic #0🉑(Ljava/io/PrintStream;)Ljava/util/function/Consumer; 84 150: invokeinterface #30, 2 // InterfaceMethod java/util/stream/Stream.forEach:(Ljava/util/function/Consumer;)V 85 155: return ","date":"2020-05-11","img":"","permalink":"/post/jvm/method-call/2-instrucions/","series":null,"tags":["JVM"],"title":"JVM执行方法调用（二）- 指令"},{"categories":null,"content":"一般对象  对象头  Mark word： 类型指针（Class Pointer）：   实例数据（instance data） 对齐填充（padding）  对象头 Mark word：hashCode、GC信息、锁信息。32位上4个字节，64位上8字节。\n类型指针（Class Pointer）：指向类信息。同样是4字节/8字节。在64位上开启指针压缩（-XX:+UseCompressedOops，默认开启）则是4字节。\n32位下的Mark word：\n1|-------------------------------------------------------|--------------------| 2| Mark Word (32 bits) | State | 3|-------------------------------------------------------|--------------------| 4| identity_hashcode:25 | age:4 | biased_lock:1 | lock:2 | Normal | 5|-------------------------------------------------------|--------------------| 6| thread:23 | epoch:2 | age:4 | biased_lock:1 | lock:2 | Biased | 7|-------------------------------------------------------|--------------------| 8| ptr_to_lock_record:30 | lock:2 | Lightweight Locked | 9|-------------------------------------------------------|--------------------| 10| ptr_to_heavyweight_monitor:30 | lock:2 | Heavyweight Locked | 11|-------------------------------------------------------|--------------------| 12| | lock:2 | Marked for GC | 13|-------------------------------------------------------|--------------------| 64位下的Mark word:\n1|------------------------------------------------------------------------------|--------------------| 2| Mark Word (64 bits) | State | 3|------------------------------------------------------------------------------|--------------------| 4| unused:25 | identity_hashcode:31 | unused:1 | age:4 | biased_lock:1 | lock:2 | Normal | 5|------------------------------------------------------------------------------|--------------------| 6| thread:54 | epoch:2 | unused:1 | age:4 | biased_lock:1 | lock:2 | Biased | 7|------------------------------------------------------------------------------|--------------------| 8| ptr_to_lock_record:62 | lock:2 | Lightweight Locked | 9|------------------------------------------------------------------------------|--------------------| 10| ptr_to_heavyweight_monitor:62 | lock:2 | Heavyweight Locked | 11|------------------------------------------------------------------------------|--------------------| 12| | lock:2 | Marked for GC | 13|------------------------------------------------------------------------------|--------------------| 各部分含义：\n   biased_lock lock 状态     0 01 无锁   1 01 偏向锁   0 00 轻量级锁   0 10 重量级锁   0 11 GC标记     biased_lock：对象是否启用偏向锁标记，只占1个二进制位。为1时表示对象启用偏向锁，为0时表示对象没有偏向锁。 age：4位的Java对象年龄。在GC中，如果对象在Survivor区复制一次，年龄增加1。当对象达到设定的阈值时，将会晋升到老年代。默认情况下，并行GC的年龄阈值为15，并发GC的年龄阈值为6。由于age只有4位，所以最大值为15，这就是-XX:MaxTenuringThreshold选项最大值为15的原因。 identity_hashcode：25位的对象标识Hash码，采用延迟加载技术。调用方法System.identityHashCode()计算，并会将结果写到该对象头中。当对象被锁定时，该值会移动到管程Monitor中。 thread：持有偏向锁的线程ID。 epoch：偏向时间戳。 ptr_to_lock_record：指向栈中锁记录的指针。 ptr_to_heavyweight_monitor：指向管程Monitor的指针。  实例数据 实例数据中的字段并非按照代码定义的顺序排列的，会JVM被重排序的（-XX:FieldsAllocationStyle）\n一个字段的起始位置（在对象内的偏移量），必须是其类型大小的整数倍，比如一个long字段的位置只能是0、8、16。如果开启指针压缩，那么对象头占了12字节，那么这个long字段只能放在16字节的位置。\n对于父子类，子类继承的父类的字段的布局肯定和父类一样，然后自己的第一个字段偏移量是4字节的倍数（开启指针压缩）或者8自己的倍数（关闭指针压缩）。下面验证一下：\n1\u0026lt;dependency\u0026gt; 2 \u0026lt;groupId\u0026gt;org.openjdk.jol\u0026lt;/groupId\u0026gt; 3 \u0026lt;artifactId\u0026gt;jol-core\u0026lt;/artifactId\u0026gt; 4 \u0026lt;version\u0026gt;0.9\u0026lt;/version\u0026gt; 5\u0026lt;/dependency\u0026gt; 1import org.openjdk.jol.info.ClassLayout; 2import org.openjdk.jol.vm.VM; 3 4/** 5* java 对象内存分布 6*/ 7 8class A{ 9 long i; 10} 11class B extends A{ 12 int j; 13} 14public class MemoryLayoutTest { 15 public static void main(String[] args){ 16 System.out.println(VM.current().details()); 17 System.out.println(ClassLayout.parseClass(A.class).toPrintable()); 18 System.out.println(ClassLayout.parseClass(B.class).toPrintable()); 19 } 20} 你可以看到：\n1memory.A object internals: 2 OFFSET SIZE TYPE DESCRIPTION VALUE 3 0 12 (object header) N/A 4 12 4 (alignment/padding gap) 5 16 8 long A.i N/A 6Instance size: 24 bytes 7Space losses: 4 bytes internal + 0 bytes external = 4 bytes total A.i字段偏移量为其类型（long）的倍数。\n1memory.B object internals: 2 OFFSET SIZE TYPE DESCRIPTION VALUE 3 0 12 (object header) N/A 4 12 4 (alignment/padding gap) 5 16 8 long A.i N/A 6 24 4 int B.j N/A 7 28 4 (loss due to the next object alignment) 8Instance size: 32 bytes 9Space losses: 4 bytes internal + 4 bytes external = 8 bytes total B从A继承来的字段偏移量和A一模一样，并且B.j的偏移量为4的倍数（默认开启了指针压缩）。\n对齐填充 JVM要求对象按照8字节对齐填充，及对象的尺寸为8字节的倍数，如果不足则填充。这个前面已经看到过了。\n数组对象 数组对象比在对象头上多了一个长度信息（Length）\n 对象头  Mark word： 类型指针（Class Pointer） 长度（Length）：4字节   实际数据（array data） 对齐填充（padding）  参考资料  聊聊java对象内存布局  Java对象头详解  ","date":"2020-05-11","img":"","permalink":"/post/jvm/object-layout/","series":null,"tags":["jvm"],"title":"JVM - 对象内存布局"},{"categories":null,"content":"求a和b的最小公倍数：\n1Input : 319, 377 2Output: 29 解法 最小公倍数和最大公约数之间的关系：gcd(a, b) * lcm(a, b) = ab\n1// 求最大公约数 Least Common Multiple 2func lcm(a, b int) int { 3 return a * b / gcd(a, b) 4} ","date":"2020-05-11","img":"","permalink":"/post/cracking-coding-interview/a003-lcm/","series":null,"tags":["ARTS-A"],"title":"算法题 - 最小公倍数"},{"categories":null,"content":"求a和b的最大公约数：\n1Input : 319, 377 2Output: 29 解法 采用欧几里德算法 （又称辗转相除法），定理：gcd(a,b) = gcd(b,a mod b)\n1// 求最大公约数 Greatest Common Divisor 2// 辗转相除法(欧几里德算法) 3func gcd(a, b int) int { 4\tif a \u0026lt; b { 5\treturn gcd(b, a) 6\t} 7\tfor { 8\tremain := a % b 9\tif remain == 0 { 10\treturn b 11\t} 12\ta = b 13\tb = remain 14\t} 15} ","date":"2020-05-11","img":"","permalink":"/post/cracking-coding-interview/a002-gcd/","series":null,"tags":["ARTS-A"],"title":"算法题 - 最大公约数"},{"categories":null,"content":"把 M 个同样的苹果放在 N 个同样的盘子里，允许有的盘子空着不放，问共有多少种不同的分法？注意：5、1、1 和 1、5、1 是同一种分法，即顺序无关。\n例子：\n1Input : 7,3 2Output: 8 分析 我们先穷举看看7个苹果3个盘子有多少种摆法，我们可以在尝试在第一个盘子放0-7个苹果，在第二个盘子放0-剩下的苹果，第三个盘子放剩下的苹果的思路来摆放：\n10 + 0 + 7 3 + 0 + 4 (dup) 20 + 1 + 6 3 + 1 + 3 (dup) 30 + 2 + 5 3 + 2 + 2 (dup) 40 + 3 + 4 3 + 3 + 1 (dup) 50 + 4 + 3 (dup) 3 + 4 + 0 (dup) 60 + 5 + 2 (dup) 70 + 6 + 1 (dup) 4 + 0 + 3 (dup) 80 + 7 + 0 (dup) 4 + 1 + 2 (dup) 9 4 + 2 + 1 (dup) 101 + 0 + 6 (dup) 4 + 3 + 0 (dup) 111 + 1 + 5 121 + 2 + 4 5 + 0 + 2 (dup) 131 + 3 + 3 5 + 1 + 1 (dup) 141 + 4 + 2 (dup) 5 + 2 + 0 (dup) 151 + 1 + 5 (dup) 161 + 6 + 0 (dup) 6 + 0 + 1 (dup) 17 6 + 1 + 0 (dup) 182 + 0 + 5 (dup) 192 + 1 + 4 (dup) 7 + 0 + 0 (dup) 202 + 2 + 3 3 + 0 + 4 (dup) 212 + 3 + 1 (dup) 3 + 1 + 3 (dup) 222 + 4 + 1 (dup) 3 + 2 + 2 (dup) 232 + 5 + 0 (dup) 3 + 3 + 1 (dup) 把重复的排除掉就得到，正好8个：\n10 + 0 + 7 20 + 1 + 6 30 + 2 + 5 40 + 3 + 4 51 + 1 + 5 61 + 2 + 4 71 + 3 + 3 82 + 2 + 3 你可以看到，我们的结果里，摆放的苹果数量是递增的。所以在摆放的时候要保证：\n 当前盘子的苹果 \u0026gt;= 前一个盘子的苹果 当前剩余的苹果 \u0026gt;= 前一个盘子的苹果  这样你就能得到去重的结果了。\n解法 代码：\n1// params: 2// apples: 苹果数量 3// dishes: 盘子数量 4func putApples(apples int, dishes int) int { 5\tif dishes == 0 { 6\treturn 0 7\t} 8\tresult := 0 9\tfill(\u0026amp;result, make([]int, dishes), 0, apples) 10\treturn result 11} 12 13// 把苹果放到盘子里，盘子里的苹果数量只能是递增的 14// 举例：盘子1的苹果数\u0026lt;=盘子2的苹果数\u0026lt;=盘子3的苹果数 15// params: 16// result, 成功摆法的数量 17// dishes, 盘子数组 18// dishIndex, 当前盘子的下标 19// remainingApples, 剩余的苹果数 20func fill(result *int, dishes []int, dishIndex int, remainingApples int) { 21 22\tprevApples := 0 23\tif dishIndex \u0026gt; 0 { 24\tprevApples = dishes[dishIndex-1] 25\t} 26\t// 剩余的值不能小于前一个数字 27\tif remainingApples \u0026lt; prevApples { 28\treturn 29\t} 30\t// 已经是最后一个盘子 31\tif dishIndex == len(dishes)-1 { 32\t// 把剩余苹果都放到最后一个盘子里 33\tdishes[dishIndex] = remainingApples 34\t// fmt.Println(dishes) 35\t*result++ 36\treturn 37\t} 38 39\t// prevApples \u0026lt;= 当前盘子放的苹果数量的尝试 \u0026lt;= remainingApples 40\tfor currApples := prevApples; currApples \u0026lt;= remainingApples; currApples++ { 41\tdishes[dishIndex] = currApples 42\tfill(result, dishes, dishIndex+1, remainingApples-currApples) 43\tdishes[dishIndex] = 0 44\t} 45 46} ","date":"2020-05-11","img":"","permalink":"/post/cracking-coding-interview/a001-put-apples/","series":null,"tags":["ARTS-A"],"title":"算法题 - 放苹果"},{"categories":null,"content":"channel类型 是否buffered：\n unbuffered： 1ch := make(chan int)  buffered 1ch := make(chan int, 100)   方向：\n 双向： 1chan int  只接收： 1\u0026lt;-chan int  只发送： 1chan\u0026lt;- int   发送到channel  unbuffered channel：阻塞，直到receiver准备好 buffered channel：阻塞，直到buffer有空间 已关闭的channel：panic nil channel：永远阻塞  从channel接收  unbuffered channel：阻塞，直到channel有值 buffered channel：同上 已关闭的channel：不阻塞，把channel中的值都消费光之后返回类型零值 nil channel：永远阻塞  关于从已关闭的channle接收的另一种形式：\n1x, ok := \u0026lt;-ch 如果ok为true：取出的值是channel被关闭之前发送的\n如果ok为false：channel已经被关闭了而且空了\n所以，从接收方来说你无法知道channel何时被关闭，因为关闭之后你还可以从buffer（如果有的话）中取值。\n关闭channel 1close(ch)  关闭只接收channel（\u0026lt;-chan int）：编译不通过 关闭nil channel：panic 关闭已关闭channel：panic  select channel 在一组发送和接收case中，选择一个不会阻塞case：\n1select { 2 case v, ok := \u0026lt;- ch: 3 // 从channel接收 4 case ch \u0026lt;- 1: 5 // 发送到channel 6 default: 7 // 上面两个case都会阻塞时 8} 规则：\n  根据源码顺序挨个尝试所有case。\n  case中的发送和接收操作遵循前面提到的规则。\n  有多个case可以执行时，随机选择其中一个（uniform pseudo-random selection）。\n  当所有case都会阻塞时，执行default。如果没有default则整个select操作阻塞，直到某个case不阻塞。\n  for range channel 从一个channel中接收：\n1for v := range ch { 2} 规则：\n 如果channel空了，则阻塞 如果channel已关闭，把buffer中的值都取完后，退出循环 如果nil channel，永远阻塞  参考资料  Channel types  Sending to channel  Receiving from channel  Making channel  Select statements  Close channel  For statement  ","date":"2020-04-28","img":"","permalink":"/post/go/channels-cheatsheat/","series":null,"tags":["go","cheatsheet"],"title":"Go Channels Cheatsheet"},{"categories":null,"content":"godoc: Tips \u0026amp; Tricks ","date":"2020-04-21","img":"","permalink":"/post/go/go-doc-cheatsheet/","series":null,"tags":["go","cheatsheet"],"title":"Go Doc Cheatsheet"},{"categories":null,"content":"运行时环境变量 GODEBUG GODEBUG是一个控制其他debugging变量的变量。它的值是逗号分割的name=val，比如GCDEBUG=name1=val1,name2=val2。\nruntime包的GODEBUG ，包含的内容比较广，这里只列举部分：\n1GODEBUG=gctrace=1 # print gc logs 2GODEBUG=gcpacertrace=1 #causes the garbage collector to 3print information about the internal state of the concurrent pacer. 4GODEBUG=memprofilerate=X # update the value of runtime.MemProfileRate net包的GODEBUG 1GODEBUG=netdns=go # DNS相关，force pure Go resolver 2GODEBUG=netdns=cgo # DNS相关，force cgo resolver 3GODEBUG=netdns=1 # DNS相关，print its decisions，这个比较有用会告诉你合适发生了DNS解析，以及DNS解析的尝试顺序 net/http包的GODEBUG :\n1GODEBUG=http2client=0 # disable HTTP/2 client support 2GODEBUG=http2server=0 # disable HTTP/2 server support 3GODEBUG=http2debug=1 # enable verbose HTTP/2 debug logs 4GODEBUG=http2debug=2 # ... even more verbose, with frame dumps GODEBUG=gctrace=1 如何解读gctrace见Garbage Collection In Go : Part II - GC Traces 。\nGODEBUG=gcpacertrace=1 TODO\nGOGC GOGC是初始的垃圾回收目标百分比，默认100。GOGC的意思是“新分配的数据尺寸“对”上次GC剩下的live data的数据尺寸“之比，如果这个比，比如说，达到了100%，也就是1:1，那么久触发GC。\n举个具体点的例子，上次GC上下了4M，那么现在新分配的数据也已经达到了4M，也就是说现在的内存总共占用了8M，这个时候触发GC。\n如果GOGC=off，那么就彻底关掉了GC。\n关于GOGC的更详细说明见runtime包 。也可见Garbage Collection In Go : Part II - GC Traces 。\npprof相关 pprof是go提供的profile工具，你可以很方便的得到CPU、内存、阻塞等方面的profile数据并分析。有以下几个profile类型 ：\n1goroutine - stack traces of all current goroutines 2heap - a sampling of memory allocations of live objects 3allocs - a sampling of all past memory allocations 4threadcreate - stack traces that led to the creation of new OS threads 5block - stack traces that led to blocking on synchronization primitives 6mutex - stack traces of holders of contended mutexes BlockProfile和MutexProfile需要设置采集频率才能采集到数据，因为它们默认不采集，相关文档如下：\n1$ go doc runtime.SetBlockProfileRate 2package runtime // import \u0026#34;runtime\u0026#34; 3 4func SetBlockProfileRate(rate int) 5 SetBlockProfileRate controls the fraction of goroutine blocking events that 6 are reported in the blocking profile. The profiler aims to sample an average 7 of one blocking event per rate nanoseconds spent blocked. 8 9 To include every blocking event in the profile, pass rate = 1. To turn off 10 profiling entirely, pass rate \u0026lt;= 0. 11 12$ go doc runtime.SetMutexProfileFraction 13package runtime // import \u0026#34;runtime\u0026#34; 14 15func SetMutexProfileFraction(rate int) int 16 SetMutexProfileFraction controls the fraction of mutex contention events 17 that are reported in the mutex profile. On average 1/rate events are 18 reported. The previous rate is returned. 19 20 To turn off profiling entirely, pass rate 0. To just read the current rate, 21 pass rate \u0026lt; 0. (For n\u0026gt;1 the details of sampling may change.) MemoryProfile频率也是可以设置的（默认是开启的，因此可以不动），同时GODEBUG=memprofilerate=X也可以控制这个参数：\n1$ go doc runtime.MemProfileRate 2package runtime // import \u0026#34;runtime\u0026#34; 3 4var MemProfileRate int = 512 * 1024 5 MemProfileRate controls the fraction of memory allocations that are recorded 6 and reported in the memory profile. The profiler aims to sample an average 7 of one allocation per MemProfileRate bytes allocated. 8 9 To include every allocated block in the profile, set MemProfileRate to 1. To 10 turn off profiling entirely, set MemProfileRate to 0. 11 12 The tools that process the memory profiles assume that the profile rate is 13 constant across the lifetime of the program and equal to the current value. 14 Programs that change the memory profiling rate should do so just once, as 15 early as possible in the execution of the program (for example, at the 16 beginning of main). 如何读懂pprof报告参考解读pprof报告 。\ngo tool pprof go tool pprof用来分析profile文件的\n1# 读取profile，cli交互式 2# source可以是文件，比如cpu-profile.out，也可以是一个url，看下面“程序中内嵌profile server” 3# url例子：http://localhost:6060/debug/pprof/heap 见下面http程序中内嵌profile 4# 如果url启用了http basic auth，那么 http://user:pass@localhost:6060/debug/pprof/heap 5go tool pprof \u0026lt;source\u0026gt; 6# 读取profile，并在http://localhost:1234 提供web ui供你查看 7go tool pprof -http=:1234 \u0026lt;profile file\u0026gt; 8# 分析的同时提供程序的二进制文件，用于在分析时反编译（disasemble） 9go tool pprof \u0026lt;binary\u0026gt; \u0026lt;source\u0026gt; 10# 实时采集基于时间的profile，一般是url 11go tool pprof -seconds \u0026lt;source\u0026gt; 在pprof中看到源码\n执行go tool pprof时所在目录为源码目录，那么可以在pprof里看到源码，比如：\n1go tool pprof \u0026lt;source\u0026gt; 2(pprof) list \u0026lt;search string\u0026gt; 3ROUTINE ======================== institute.supwisdom.com/poa/gateway/util.init.0.func1 in util/jsonencoderpool.go 4 0 512.03kB (flat, cum) 0.091% of Total 5 . . 26:\treturn UnsafeB2s(e.bf.B) 6 . . 27:} 7 . . 28: 8 . . 29:func init() { 9 . . 30:\tjsonEncoderPool.New = func() interface{} { 10 . 512.03kB 31:\tbf := bytebufferpool.Get() 11 . . 32:\treturn \u0026amp;JsonEncoder{ 12 . . 33:\tbf: bf, 13 . . 34:\tenc: json.NewEncoder(bf), 14 . . 35:\t} 15 . . 36:\t} 但有时候会找不到源码：\n1Error: open /gateway/apihandler/logging.go: no such file or directory 这个是因为编译时使用的源码目录和执行go tool pprof的目录不一样，一般来说都是前缀不同，你可以使用-trim_path将编译源码目录前缀删掉，比如这样：\n1go tool pprof -trim_path=/gateway \u0026lt;source\u0026gt; 这样pprof就会去搜索/apihandler/logging.go，而如果你的当前目录正好有apihandler/logging.go，那么就能够得到源码了。\n二进制文件的搜索路径\n1PPROF_BINARY_PATH Search path for local binary files 2 default: $HOME/pprof/binaries 3 searches $name, $path, $buildid/$name, $path/$buildid 更多用法\n更多用法参见go tool pprof -help\ngo test时产生profile 你可以在go test的时候启用profile，输出的文件可以给pprof食用，相关flag ：\n1-benchmem 2 Print memory allocation statistics for benchmarks. 3 4-blockprofile block.out 5 Write a goroutine blocking profile to the specified file 6 when all tests are complete. 7 Writes test binary as -c would. 8 9-blockprofilerate n 10 Control the detail provided in goroutine blocking profiles by 11 calling runtime.SetBlockProfileRate with n. 12 See \u0026#39;go doc runtime.SetBlockProfileRate\u0026#39;. 13 The profiler aims to sample, on average, one blocking event every 14 n nanoseconds the program spends blocked. By default, 15 if -test.blockprofile is set without this flag, all blocking events 16 are recorded, equivalent to -test.blockprofilerate=1. 17 18-cpuprofile cpu.out 19 Write a CPU profile to the specified file before exiting. 20 Writes test binary as -c would. 21 22-memprofile mem.out 23 Write an allocation profile to the file after all tests have passed. 24 Writes test binary as -c would. 25 26-memprofilerate n 27 Enable more precise (and expensive) memory allocation profiles by 28 setting runtime.MemProfileRate. See \u0026#39;go doc runtime.MemProfileRate\u0026#39;. 29 To profile all memory allocations, use -test.memprofilerate=1. 30 31-mutexprofile mutex.out 32 Write a mutex contention profile to the specified file 33 when all tests are complete. 34 Writes test binary as -c would. 35 36-mutexprofilefraction n 37 Sample 1 in n stack traces of goroutines holding a 38 contended mutex. http程序中内嵌profile 在你的包中引入net/http/pprof ，就可以给go tool pprof提供profile数据网页端：\n1import _ \u0026#34;net/http/pprof\u0026#34; 2go func() { 3\tlog.Println(http.ListenAndServe(\u0026#34;localhost:6060\u0026#34;, nil)) 4}() 用它来配合go tool pprof可以很方便的采集profile数据。\n总页面：\n1http://localhost:6060/debug/pprof/ heap：\n1http://localhost:6060/debug/pprof/heap cpu:\n1http://localhost:6060/debug/pprof/profile block:\n1http://localhost:6060/debug/pprof/block mutex:\n1http://localhost:6060/debug/pprof/mutex 程序中内嵌profile功能 你也可以在程序中内嵌生成profile的功能，详见runtime/pprof Trace相关 go tool trace cmd/trace 1# 在浏览器中打开trace.out，如何得到trace.out下面会讲 2go tool trace -http=:4231 trace.out 3# 把trace文件转换成pprof文件，\u0026lt;TYPE\u0026gt;可以是 4# - net: network blocking profile 5# - sync: synchronization blocking profile 6# - syscall: syscall blocking profile 7# - sched: scheduler latency profile 8go tool trace -pprof=\u0026lt;TYPE\u0026gt; trace.out http程序中内嵌trace net/http/pprof 中也提供了trace：\n1wget -O trace.out http://localhost:6060/debug/pprof/trace?seconds=5 go test时产生trace 相关flag ：\n1$ go test -trace=trace.out pkg 2 3-trace trace.out 4 Write an execution trace to the specified file before exiting. 参考资料  Profiling Go Programs  Garbage Collection In Go : Part II - GC Traces 。 ","date":"2020-04-12","img":"","permalink":"/post/go/go-debug-cheatsheet/","series":null,"tags":["go","cheatsheet","debug"],"title":"Go Debug Cheatsheet"},{"categories":null,"content":"   operation cost     CPU执行1条指令 ~1/12纳秒，也就是1纳秒可以执行12条指令   访问寄存器 \u0026lt;=1 clock cycles   访问CPU L1d ~3 clock cycles   访问CPU L2 ~14 clock cycle   访问CPU L3 ~40 clock cycles   访问主内存 ~100到~300 clock cycles       OS线程上下文切换 ~1000到~1500 nanosecond，相当于~12k到~18k条指令。   Go程上下文切换 ~200 nanoseconds，相当于~2.4k instructions条指令。    这几个数字出现在：\n Scheduling In Go : Part I - OS Scheduler 阅读笔记  What every programmer should know about memory, Part 2: CPU caches  ","date":"2020-04-02","img":"","permalink":"/post/kernel/hardware-kernel-op-cost-cheatsheet/","series":null,"tags":["kernel","cheatsheet"],"title":"硬件/内核操作代价Cheatsheet"},{"categories":null,"content":"原文：Scheduling In Go : Part III - Go Scheduling 几个数字    operation cost     1纳秒 可以执行12条指令   OS上下文切换 ~1000到~1500 nanosecond，相当于~12k到~18k条指令。   Go程上下文切换 ~200 nanoseconds，相当于~2.4k instructions条指令。   访问主内存 ~100到~300 clock cycles   访问CPU cache ~3到~40 clock cycles（根据不同的cache类型）    不是所有问题都可以concurrency 不论你遇到什么种类的问题，你应该先求出一个正确的sequential解，然后再看这个问题是否有可能作出concurrency解。\n什么是concurrency Concurrency意味着乱序执行，拿一组原本顺序执行的指令，把它们乱序执行依然能够得到相同的结果。对于你来说就要去权衡concurrency之后得到的性能好处和其带来的复杂度。而且有些问题乱序执行压根就没道理，只能顺序执行。\n并行和并发的区别在于，并行是指在不同的OS线程上，OS线程在不同的core上同时执行不相干的指令。\n 上图中，P1和P2有自己的OS线程，OS线程在不同的core上，因此G1和G2是并行的。\n但是在P1和P2自己看来，它有3个G要执行，而这三个G共享同一个OS线程/core，而且执行顺序是不定的，它们是并发执行的。\n工作负载 前面讲过，有两种类型的工作负载：\n CPU-Bound：永远不会使得Go程处于waiting状态，永远处于runnable/executing状态的纯计算型任务。 IO-Bound：天然的会使得Go程进入waiting状态。比如访问网络资源、syscall、访问文件。同时也把同步事件归到此类（atomic、mutex）  对于CPU-Bound任务来说，你需要利用并行。如果Go程数量多于OS线程/core数量，那么就会使得Go程被上下文切换，从而带来性能损失。\n对于IO-Bound任务来说，你可以不需要利用并行，一个OS线程/core可以很轻松的处理这种天然就会进出waiting状态的任务。Go程数量大于OS线程/core数量可以大大提高OS线程/core的利用率，提高任务的处理速度。Go程的上下文切换不会造成性能损失，因为你的任务自己就会停止。\n那么使用多个Go程能带来多大好处，以及多少个Go程能带来最大效果，那么就需要benchmark才能知道。\n","date":"2020-03-31","img":"","permalink":"/post/go/scheduling-in-go-part-3/","series":null,"tags":["go","kernel","thread","scheduling","arts","arts-r"],"title":"Scheduling in Go : Part III - Concurrency 阅读笔记"},{"categories":null,"content":"原文：Scheduling In Go : Part II - Go Scheduler 可以同步阅读：Go\u0026rsquo;s work-stealing scheduler ，不过没有本文写的明白。\n几个数字    operation cost     1纳秒 可以执行12条指令   OS上下文切换 ~1000到~1500 nanosecond，相当于~12k到~18k条指令。   Go程上下文切换 ~200 nanoseconds，相当于~2.4k instructions条指令。   访问主内存 ~100到~300 clock cycles   访问CPU cache ~3到~40 clock cycles（根据不同的cache类型）    逻辑组件   P：Logical Processor，你有多少个虚拟core就有多少个P。之所以说虚拟core是因为如果处理器支持支持一个core有多个硬件线程（Hyper-Threading，超线程），那么每个硬件线程就算作一个虚拟core。runtime.NumCPU()能够得到虚拟core的数量。\n  M：操作系统线程。这个线程依然由操作系统调度。每个P被分配一个M。\n  G：Go程。Go程实际上是协程（Coroutine ）。和操作系统线程有点像，只是操作系统线程上下文切换在core上，而Go程上下文切换在M上。Go程的上下文切换发生在用户空间，开销更低。\n  运行队列（队列中的G都是runnable的）：\n LRQ（Local Run Queue）。每个P会给一个LRQ，P负责把LRQ中的G上下文切换到M上。 GRQ（Global Run Queue），GRQ放还未分配到P的G。    这是一张全景图：\n 协作式调度器 和操作系统的抢占式调度器不同，Go采用的是协作式调度器。Go调度器是Go运行时的一部分，而Go运行时在内置在你的程序里。所以Go调度器运行在用户空间。\nGo调度器运行在用户空间，那么就需要定义明确的发生在safepoint的用户空间事件来做调度决策。不过程序员不需要太多关心这个，同时也无法控制调度行为，所以Go调度器虽然是协作式的但看起来像是抢占式的。\nGo程状态  Waiting：Go程停止了，且在等待什么事情发生。比如等待操作系统（syscall）、同步调用（atomic和mutex操作） Runnable：Go程想要M的时间来执行指令。越多的Go程想要时间，就以为着等待越长的时间，每个Go程能分到的时间就越少。 Executing：Go程正在M上执行指令。  上下文切换 Go调度程序需要定义明确的用户空间事件，这些事件发生在代码中的安全点，以便进行上下文切换。安全点体现在函数调用中。所以函数调用很重要。在Go 1.11之前，如果程序在跑一个很长的循环且循环里没有函数调用，那么就会导致调度器和GC被推迟。\n4类事件允许调度器做调度决策，注意调度不一定会发生，而是给了调度器一个机会而已：\n 使用go 垃圾收集 系统调用 同步和编排（Synchronization and Orchestration）  使用go\ngo创建了一个新的Go程，自然调度器有机会做一个调度决策。\n垃圾收集\n垃圾收集跑在自己的Go程里，需要征用M来运行，因此调度器也需要做决策\n系统调用\n系统调用会导致Go程阻塞M。调度器有些时候会把这个G从M换下（上下文切换），然后把新的G换上M。也有可能创建一个新的M，用来执行P的LRQ中的G。\n同步和编排\n如果atomic、mutex、channel操作阻塞了一个G，调度器会把一个新的G去运行，等到它又能运行了（从阻塞中解除），那么再把它放到队列中，然后最终跑在到M上。\n异步系统调用 比如MacOS中的kqueue、Linux中的epoll、Windows的iocp都是异步网络库。G做这些异步系统调用并不会阻塞M，那么就意味着M可以用来执行LRQ中的其他M。下面是图解：\nG1准备做网络调用：\n G1移到了Net Poller，然后M可以跑G2\n G1就绪了，就回到LRQ中，等待被调度，整个过程不需要新的M：\n 同步系统调用 文件IO不是异步的，所以G会把M给阻塞，那么Go调度器会这么做：\nG1调用了阻塞系统调用：\n M1连带G1从P脱离（此时M1因为阻塞被操作系统上下文切换下去了），创建新的M2给P，把G2调度到M2上：\n 而后G1从阻塞中恢复，追加到LRQ中等待下次调度，M1则保留下来等待以后使用：\n Work Stealing 虽然名字叫做工作偷窃，但实际上是好事。简单来说就是当P1没有G时，把P2的LRQ中的G“偷”过来执行，借此来提高M的利用率。\n看下图中P1和P2都有3个G等待调度，GRQ中有一个G\n 这个时候P1先把自己的G都处理完了：\n P1会“偷”P2 LRQ中一半的G，偷窃算法如下，简单来说就是先偷P2的G，如果没有再从GRQ中取：\n1runtime.schedule() { 2 // only 1/61 of the time, check the global runnable queue for a G. 3 // if not found, check the local queue. 4 // if not found, 5 // try to steal from other Ps. 6 // if not, check the global runnable queue. 7 // if not found, poll network. 8}  当P2把G都做完了，然后P1没有G在LRQ中时：\n 根据前面讲的算法，P2会拿GRQ中的G来运行：\n 实际的例子 下面拿一个实际的例子来告诉你Go调度器是如何比你直接用OS线程做更多工作的。\n协作式OS线程程序 有两个OS线程，T1和T2，它们之间的交互式这样的：\n T2等待消息，T1发送消息，T1等待消息 T2接收消息，T2发送消息，T2等待消息 T1接收消息。。。 。。。  T1一开始在C1上，T2处于等待状态：\n T1发送消息给T2，进入等待，从C1脱离；T2收到消息后调度到C2上：\n T2发送消息给T1，进入等待，从C2脱离；T1收到消息后调度到C3上：\n 所以你可以看到T1和T2频繁发生OS上下文切换，而这个代价是很高的（见文头表格）。同时每次切换到不同core上，导致cache miss，所以还存在访问主内存的开销。\n协作式Go程程序 下面来看看Go调度器怎么做的：\nG1一开始在M1上，而M1和C1绑定，G2处于等待状态：\n G1发消息给G2，进入等待，从M1脱离；G2收到消息被调度到M1：\n G2发消息给G1，进入等待，从M1脱离；G1收到消息被调度到M1：\n 所以Go程调度的优势：\n OS线程始终保持运行，没有进入waiting Go程上下文切换不是发生在OS层面，代价相对低， ~200 nanoseconds 或 ~2.4k instructions。 始终都是在同一个core上，优化了cache miss的问题，这个对于NUMA架构 特别友好。 ","date":"2020-03-30","img":"","permalink":"/post/go/scheduling-in-go-part-2/","series":null,"tags":["go","kernel","thread","scheduling","arts","arts-r"],"title":"Scheduling in Go : Part II - Go Scheduler 阅读笔记"},{"categories":null,"content":"原文：Scheduling In Go : Part I - OS Scheduler 几个数字    operation cost     1纳秒 可以执行12条指令   OS上下文切换 ~1000到~1500 nanosecond，相当于~12k到~18k条指令。   Go程上下文切换 ~200 nanoseconds，相当于~2.4k instructions条指令。   访问主内存 ~100到~300 clock cycles   访问CPU cache ~3到~40 clock cycles（根据不同的cache类型）    操作系统线程调度器 你的程序实际上就是一系列需要执行的指令，而这些指令是跑线程里的。\n线程可以并发运行：每个线程轮流占用一个core；也可以并行运行：每个线程跑在不同core上。\n操作系统线程调度器负责保证充分利用core来执行线程。\n程序指令是如何执行的 程序计数器（program counter，PC），有时也称为指令指针（instruction pointer，IP），用来告诉线程下一个要执行的指令（注意不是当前正在执行的指令）的位置。它是一种寄存器（register）。\n每次执行指令的时候都会更新PC，因此程序才能够顺序执行。\n 线程状态  Waiting：等待中。原因：等待硬件（比如磁盘、网络）、正在系统调用（syscall）、阻塞在同步上（atomic、mutex） Runnable：可以运行，正在等待调度。越多线程等待调度，大家就等的越久，且分配到的时间就越少。 Executing：正在某个core上运行。  任务类型  CPU绑定：这种任务永远不会让线程进入Waiting状态，比如计算Pi。 IO绑定：这种任务会让线程进入Waiting状态。  上下文切换 Linux、Mac和Windows使用的是抢占式调度器，所以：\n 你无法预测调度器什么时候会运行哪个线程。线程优先级混合事件（比如接收网络数据），也使得预测调度器行为变得不可能。 如果你要有确定的行为，那么就应该对线程做同步和编排（synchronization and orchestration）。否则你观察到现在是这个样子的，无法保证下次还是这个样子的。  在一个core上切换线程的物理行为称为上下文切换（context switching）。调度器把一个线程从core上换下来，然后把另一个线程换上去。换上去的线程状态从Runnable-\u0026gt;Executing，换下来的线程的状态从Executing-\u0026gt;Runnable（如果依然可以运行），或者Executing-\u0026gt;Waiting（因为等待所以被换下来）。\n上下文切换的代价比较高，大概在**~1000到~1500 nanosecond之间，考虑到core大致每纳秒可以执行12条指令，那么就相当于浪费了~12k到~18k的指令**。\n如果是IO绑定任务，那么上下文切换能够有效利用CPU，因为A线程进入Waiting那么B线程就可以顶上使用CPU。\n如果是CPU绑定任务，那么上下文切换会造成性能损失，因为把CPU能力白白浪费在上下文切换上了（浪费了~12k到~18k的指令）。\n少即是多 越少的线程带来越少的调度开销，每个线程能分配到的时间就越多，那么就能完成越多的工作。\nCache line 访问主内存（main memory）的数据的延迟大概在**~100到~300 clock cycles**。\n访问cache的数据延迟大概在 ~3到~40 clock cycles（根据不同的cache类型）。\n CPU会把数据从主内存中copy到cache中，以cache line为单位，每条cache line为64 bytes。所以多线程修改内存会造成性能损失。\n多个并行运行的线程访问同一个数据或者相邻的数据，那么它们可能就会访问同一条cache line。任何线程跑在任何core上都有一份自己的cache line copy。所以就有了False Sharing问题：\n 只要一个线程操作了自己core上的某个cache line，那么这个cache line在其他core就会变脏（cache coherency），当一个线程访问一个脏cache line的时候，就要访问一下main memory（~100到~300 clock cycles）。当单处理器core变多的时候，以及当有多个处理器（处理器间通信）的时候，这个开销就变得很大了。\n","date":"2020-03-30","img":"","permalink":"/post/go/scheduling-in-go-part-1/","series":null,"tags":["go","kernel","thread","scheduling","arts","arts-r"],"title":"Scheduling in Go : Part I - OS Scheduler 阅读笔记"},{"categories":null,"content":"原文：Visualizing Garbage Collection Algorithms 用动画解释了4种GC算法\nCleanup at the end: No GC 就是没有GC，程序在执行完一个任务后自己去释放内存。\n动画黑色代表没有被使用的内存，闪烁的绿色和黄色代表内存被读或写，颜色变暗代表内存没有被使用（垃圾）。这个算法适合不需要考虑垃圾的程序。\nReference Counting Collector 对对象的被使用次数进行计数，如果计数变成0，那么就是垃圾，然后释放内存。\n引用计数的问题：\n 无法解决循环引用问题，计数永远到不了0，无法被回收 无法并发访问问题，因为要计数，所以得串行访问 就算内存使用没有增加，也要做计数 计数值要频繁从内存加载到CPU Cache，无法有效缓存，效率低  动画中的红色闪烁代表更新计数。有时候你会发现红色闪烁之后马上就变成黑色，引用计数算法可以立马发现垃圾然后清理掉。\n引用计数是一种分摊成本的算法，所以并不能保证pause time。虽然在程序运行过程中分摊下来pause time比较少，但是不排除某个task会出现pause time很长的情况。\nMark-Sweep Collector 标记清理算法就是标记Live对象，然后把死掉的对象清理掉。\n它放弃了立即清理垃圾，而是等到后面处理，所以动画中有一段时间没有红色闪烁（标记），然后突然一堆红色闪烁，然后一次性清理了垃圾。\n优点：\n 它不会有引用计数的循环引用问题，因为它是根据可达性来找出Live对象的，因此少了引用计数的开销。  问题：\n 必须遍历整个内存才能做好标记 清理之后产生内存碎片  Mark-Compact Collector 标记整理算法，和标记清理算法差不多，只是清理之后把内存压紧了一下，去掉了内存碎片。Oracle JVM的Old区采用的是这个算法。\n优点：\n 清理之后没有内存碎片 新对象总是在尾部创建，就和stack一样，因为是在heap里的，所以没有stack的大小限制 对象挨个存放之后，有助于CPU cache（见这篇文章 ）  问题：\n 额外的开销，因为对象的内存位置移动了，因此需要更新对象指针指向新地址  Copying Collector Copy算法同样也能消除内存碎片，但不是通过移动，而是copy。\n通过对两个内存区域的来回Copy实现无碎片垃圾清理。实践中会有多个“代区”，比如JVM的Young区里的S0和S1，已经对象从Young区promote到Old区用的就是这个算法。\n优点：\n 非常高效，无需标记，直接收集。在对Live对象的遍历过程中连带的对象就顺带被Copy了。  问题：\n 如果每次Copy没有垃圾可清理，那么这个回收就得不偿失了。所以你就需要tuning gc，使得每次GC的时候能够清理掉大部分对象。 一定要有空闲空间可供腾挪，否则就没法GC了。这也就意味着有一定的内存浪费，因此有算法尽量减少浪费。 ","date":"2020-03-27","img":"","permalink":"/post/article-review/visualizing-gc-algo/","series":null,"tags":["gc"],"title":"Visualizing Garbage Collection Algorithms阅读笔记"},{"categories":null,"content":"Profiling Go Programs 里详细举例说明了如何看pprof报告，但并没有清晰简明的告知读者提供数字的是什么意思，所以本文做一个归纳笔记。\n解读CPU 以文中提供的CPU Profile来举例说明，我们使用go tool pprof -http=0.0.0.0:4231 havlak1 havalk1.prof来观察\n解读Top 1(pprof) top10 2Total: 2525 samples 3 Flat Flat% Sum% Cum Cum% Name 4 298 11.8% 11.8% 345 13.7% runtime.mapaccess1_fast64 5 268 10.6% 22.4% 2124 84.1% main.FindLoops 6 251 9.9% 32.4% 451 17.9% scanblock 7 178 7.0% 39.4% 351 13.9% hash_insert 8 131 5.2% 44.6% 158 6.3% sweepspan 9 119 4.7% 49.3% 350 13.9% main.DFS 10 96 3.8% 53.1% 98 3.9% flushptrbuf 11 95 3.8% 56.9% 95 3.8% runtime.aeshash64 12 95 3.8% 60.6% 101 4.0% runtime.settype_flush 13 88 3.5% 64.1% 988 39.1% runtime.mallocgc 先了解是如何采样的：\n 采样频率是每秒100次 一个样本包含goroutine栈的程序计数器（program counters） 每次只会采样调用栈的前100行  原文中没有给出列名，这里给了出来，下面是解释：\n Total：总共采样次数，这里是2525次。 Flat：函数在样本中处于运行状态的次数。简单来说就是函数出现在栈顶的次数，而函数在栈顶则意味着它在使用CPU。 Flat%：Flat / Total。 Sum%：自己以及所有前面的Flat%的累积值。解读方式：表中第3行Sum% 32.4%，意思是前3个函数（运行状态）的计数占了总样本数的32.4% Cum：函数在样本中出现的次数。只要这个函数出现在栈中那么就算进去，这个和Flat不同（必须是栈顶才能算进去）。也可以解读为这个函数的调用次数。 Cum%：Cum / Total  解读图  方框：函数 方框尺寸：代表了Flat的次数 箭头：X调用Y 线条：记录了X调用Y的次数。数字越大，线条越粗。图中main.DFS有一个指向自己的箭头，说明存在递归调用，而且调用了21342次。 方框第一行数字：Flat (Flat%)，栈顶次数 方框第二行数字：Cum (Cum%)，调用次数  解读源码 下面是在pprof交互cli界面看到的报告：\n1(pprof) list DFS 2Total: 2525 samples 3ROUTINE ====================== main.DFS in /home/rsc/g/benchgraffiti/havlak/havlak1.go 4 119 697 Total samples (flat / cumulative) 5 3 3 240: func DFS(currentNode *BasicBlock, nodes []*UnionFindNode, number map[*BasicBlock]int, last []int, current int) int { 6 1 1 241: nodes[current].Init(currentNode, current) 7 1 37 242: number[currentNode] = current 8 . . 243: 9 1 1 244: lastid := current 10 89 89 245: for _, target := range currentNode.OutEdges { 11 9 152 246: if number[target] == unvisited { 12 7 354 247: lastid = DFS(target, nodes, number, last, lastid+1) 13 . . 248: } 14 . . 249: } 15 7 59 250: last[number[currentNode]] = lastid 16 1 1 251: return lastid 17(pprof)  第一列：Flat 第二列：Cum 第三列：行号  下面是在Web界面看到的报告（基本差不多，见这里 ）：\n1havlak1 2Total: 5758 samples 3main.DFS 4/home/rsc/g/benchgraffiti/havlak/havlak1.go 5 6Total: 225 2296 (flat / cumulative samples) 7 235 return false 8 236 } 9 237 10 238 // DFS - Depth-First-Search and node numbering. 11 239 // 12 240 3 3 func DFS(currentNode *BasicBlock, nodes []*UnionFindNode, number map[*BasicBlock]int, last []int, current int) int { 13 241 18 19 nodes[current].Init(currentNode, current) 14 242 166 number[currentNode] = current 15 243 16 244 2 2 lastid := current 17 245 167 167 for _, target := range currentNode.OutEdges { 18 246 17 508 if number[target] == unvisited { 19 247 10 1157 lastid = DFS(target, nodes, number, last, lastid+1) 20 248 } 21 249 } 22 250 7 273 last[number[currentNode]] = lastid 23 251 1 1 return lastid 24 252 } 25 253 26 254 // FindLoops 27 255 // 28 256 // Find loops and build loop forest using Havlak\u0026#39;s algorithm, which  第一列：行号 第二列：Flat 第三列：Cum  解读内存 以文中提供的内存Profile来举例说明，我们使用go tool pprof -http=0.0.0.0:4231 havlak3 havalk3.mprof来观察。\npprof提供了4种视角，默认是-inuse_space：\n -inuse_space ：live object占用内存 -inuse_objects ：live object的数量 -alloc_space ：程序启动到现在，总共分配的内存 -alloc_objects ：程序启动到现在总共object的数量  解读Top 1(pprof) top5 2Total: 82.4 MB 3 Flat Flat% Sum% Cum Cum% Name 4 56.3 68.4% 68.4% 56.3 68.4% main.FindLoops 5 17.6 21.3% 89.7% 17.6 21.3% main.(*CFG).CreateNode 6 8.0 9.7% 99.4% 25.6 31.0% main.NewBasicBlockEdge 7 0.5 0.6% 100.0% 0.5 0.6% itab 8 0.0 0.0% 100.0% 0.5 0.6% fmt.init 9(pprof) 采样频率：\n 每分配512K，采样一个block（具体啥意思不知道）  照例我们加上列：\n Total：总共占用内存 Flat：函数分配的内存，不包含它调用其他函数造成的内存分配。 Flat%：Flat / Total Sum%：自己和前面所有的Flat%累积值 Cum：这个函数分配的内存，以及它调用其他函数分配的内存之和。可以解读为因为这个函数所造成的所有内存分配。 Cum%：Cum / Total  解读源码 和CPU源码解读差不多：\n1(pprof) list FindLoops 2Total: 82.4 MB 3ROUTINE ====================== main.FindLoops in /home/rsc/g/benchgraffiti/havlak/havlak3.go 4 56.3 56.3 Total MB (flat / cumulative) 5... 6 1.9 1.9 268: nonBackPreds := make([]map[int]bool, size) 7 5.8 5.8 269: backPreds := make([][]int, size) 8 . . 270: 9 1.9 1.9 271: number := make([]int, size) 10 1.9 1.9 272: header := make([]int, size, size) 11 1.9 1.9 273: types := make([]int, size, size) 12 1.9 1.9 274: last := make([]int, size, size) 13 1.9 1.9 275: nodes := make([]*UnionFindNode, size, size) 14 . . 276: 15 . . 277: for i := 0; i \u0026lt; size; i++ { 16 9.5 9.5 278: nodes[i] = new(UnionFindNode) 17 . . 279: } 18... 19 . . 286: for i, bb := range cfgraph.Blocks { 20 . . 287: number[bb.Name] = unvisited 21 29.5 29.5 288: nonBackPreds[i] = make(map[int]bool) 22 . . 289: } 23... 可以发现L288占用了29.5M内存。用-inuse_objects来观察，可以看到分配次数：\n1$ go tool pprof --inuse_objects havlak3 havlak3.mprof 2Adjusting heap profiles for 1-in-524288 sampling rate 3Welcome to pprof! For help, type \u0026#39;help\u0026#39;. 4(pprof) list FindLoops 5Total: 1763108 objects 6ROUTINE ====================== main.FindLoops in /home/rsc/g/benchgraffiti/havlak/havlak3.go 7720903 720903 Total objects (flat / cumulative) 8... 9 . . 277: for i := 0; i \u0026lt; size; i++ { 10311296 311296 278: nodes[i] = new(UnionFindNode) 11 . . 279: } 12 . . 280: 13 . . 281: // Step a: 14 . . 282: // - initialize all nodes as unvisited. 15 . . 283: // - depth-first traversal and numbering. 16 . . 284: // - unreached BB\u0026#39;s are marked as dead. 17 . . 285: // 18 . . 286: for i, bb := range cfgraph.Blocks { 19 . . 287: number[bb.Name] = unvisited 20409600 409600 288: nonBackPreds[i] = make(map[int]bool) 21 . . 289: } 22... 23(pprof) 分析GC 你可以通过CPU Profile来分析GC：\n1(pprof) top10 2Total: 1173 samples 3 205 17.5% 17.5% 1083 92.3% main.FindLoops 4 138 11.8% 29.2% 215 18.3% scanblock 5 88 7.5% 36.7% 96 8.2% sweepspan 6 76 6.5% 43.2% 597 50.9% runtime.mallocgc 7 75 6.4% 49.6% 78 6.6% runtime.settype_flush 8 74 6.3% 55.9% 75 6.4% flushptrbuf 9 64 5.5% 61.4% 64 5.5% runtime.memmove 10 63 5.4% 66.8% 524 44.7% runtime.growslice 11 51 4.3% 71.1% 51 4.3% main.DFS 12 50 4.3% 75.4% 146 12.4% runtime.MCache_Alloc 13(pprof) 可以看到runtime.mallocgc的调用次数占了50.9%。\n查看系统为何进行垃圾收集的另一种方法是查看导致收集的分配，这些分配在mallocgc中花费了大部分时间。使用--nodefraction=0.1去掉占比小于10%的结果：\n可以看到main.FindLoops导致了大多数GC。\n在线Profile 如果你是一个Web应用，你可以使用net/http/pprof 来添加一个Handler，访问http://\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;/debug/pprof/可以得到功能列表：\n1/debug/pprof/ 2 3Types of profiles available: 4Count\tProfile 58 allocs 60\tblock 70\tcmdline 810\tgoroutine 98\theap 100\tmutex 110\tprofile 1219\tthreadcreate 130\ttrace 14... 然后你可以通过这样来用go tool pprof \u0026lt;url\u0026gt;来分析，比如：\n1# 分析CPU 2go tool pprof http://localhost:9090/debug/pprof/profile 3# 打开网页分析heap 4go tool pprof -http=0.0.0.0:4231 http://localhost:9090/debug/pprof/heap 在生产中，你需要对/debug/pprof/*做HTTP BasicAuth 保护（很简单，一个响应头和请求头罢了），那么你去抓取数据分析的时候得这样：\n1go tool pprof http://\u0026lt;user\u0026gt;:\u0026lt;password\u0026gt;@localhost:9090/debug/pprof/profile 参考资料  Profiling Go Programs  runtime/pprof  net/http/pprof  HTTP BasicAuth  Debugging performance issues in Go programs  ","date":"2020-03-17","img":"","permalink":"/post/go/pprof-explained/","series":null,"tags":["go","debug","cheatsheet"],"title":"解读pprof报告"},{"categories":null,"content":"见这篇文章：\nhttps://docs.docker.com/engine/security/https/#create-a-ca-server-and-client-keys-with-openssl 有详细的使用openssl创建TLS Server Auth / Client Auth证书的方法。\n","date":"2020-03-16","img":"","permalink":"/post/tls/openssl-tls-issuing/","series":null,"tags":["tls"],"title":"Openssl签发Tls证书"},{"categories":null,"content":" 一切优化要基于确切的报告，而不是靠猜。 我们只有通过压力测试才能知道程序性能几何。  压测前准备 我们应对单台应用服务器做压力测试，你只有知道了单台能够承受多少才能知道集群能承受多少。\n然后要确定单台应用服务器性能目标：\n 吞吐量，每秒处理多少请求 延迟，平均、P50、P90、P99的请求在多少时间内完成  如果客户要求吞吐量为2000rps，能提供2台服务器，那么每台的吞吐量则为1000rps。\n如果客户要求延迟P99 \u0026lt;= 2秒，那么和服务器就没有关系了，你需要优化程序算法。\n压测时的观察和调优 下面我们对单台应用服务器开始压力测试。\n保证CPU用满 压测期间我们首先要保证的是CPU利用率接近N * 100%（N为CPU核心数），如果CPU利用率不满那么压测报告就没有意义，因为机器并未全力运转。\n发现CPU没有用满，那么有这么几种可能\n 压力太小，可以调整压测工具来做到 线程阻塞，后面会讲  保证CPU花在非GC上 好了现在CPU用满了，那么我们要通过jstat -gcutil来观察JVM是否把CPU花在了GC上，你也可以添加-XX:+PrintGC -XX:+PrintGCTimeStamps -XX:+PrintGCDetails -Xloggc:/path/to/gc.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=1 -XX:GCLogFileSize=20M JVM参数得到更详细的GC日志。\n重点关注Full GC的次数和占用时间，如果发现Full GC很频繁，有三个解决思路：\n 增加内存 优化算法，降低内存利用率，可以通过jmap导出内存dump，再使用MAT分析 降低压力，可以是降低压测工具侧的压力，也可以是调小程序自身线程池  解决阻塞 用jstack导出thread dump来分析。\n线程阻塞是常见的CPU利用率不满的元凶，因为阻塞时不占用CPU，你可以在压测期间用jstack收集几次堆栈数据，然后观察里面的BLOCKED、WAITING、TIMED_WAITING状态的线程的堆栈，找到线索。\n如果发现阻塞不可避免，那么可以通过增加线程数的方式来利用CPU。\n如果阻塞发生在连接池相关，那么调整连接池大小。如果阻塞发生在执行SQL有关，那么优化SQL语句。如果阻塞发生在其他地方，那么做针对性优化。\n观察慢SQL 慢SQL是常见阻塞原因，找出这些慢SQL，对它进行优化，或者对数据库表做优化，提升程序响应速度，提高CPU利用率。\n观察执行次数异常的SQL 执行次数异常的SQL也是很重要的一点，抓住这些SQL，对代码进行优化。\n数据库连接池 连接池不够也是常见的阻塞元凶，线程在等待连接池导致CPU利用率上不去，不过还是那句话，不要盲目调整，你应该在jstack里看到大量获取jdbc connection的阻塞线程之后才去调整它。\n线程池 按照理论上来说，如果线程不阻塞，那么只需要N个线程就能把CPU占满（N是CPU核心数）。线程阻塞占用比例越大，就需要越多线程来占用空闲CPU时间。\n如果你优化之后把阻塞比例降低了，那么你也需要相应调小线程池尺寸。\n过多的线程池不会带来更多好处，白白占用内存而已。\n服务器异常日志 有时候服务器异常日志也会提供给你很好的线索，记得观察。特别是如果异常特别多的话，会直接影响性能的。\n观察、优化、验证的循环 当你做了一个优化点后，你再压一遍，看看是否有改善，同时需要调整其他相关参数，比如前面提到的调小线程池。\n同时，有些时候做了一个优化点之后，会发现新的问题，这个问题可能在之前被那个占大部分因素的性能瓶颈遮蔽掉了，现在大问题解决了，那这个小问题就显现出来了。此时，你需要针对这个新问题再收集报告，然后再优化。举个例子，原来是SQL慢，优化好之后会发现程序算法也有问题。\n一些工具 GC分析 https://gceasy.io 是一个在线分析GC日志的工具。把得到的gc.log日志。\nheap dump分析 利用下面命令得到heap dump，然后放到MAT中分析\njmap -dump:live,format=b,file=heap.bin \u0026lt;pid\u0026gt;\n有些时候你需要把垃圾一起dump下来，比如GC很频繁，那么去掉live参数：\njmap -dump:format=b,file=heap.bin \u0026lt;pid\u0026gt;\nthread dump分析 利用jstack得到thread dump，然后放到 https://fastthread.io/ 分析\n","date":"2020-03-05","img":"","permalink":"/post/jvm/jvm-perf-tuning-common-ways/","series":null,"tags":["jvm","高并发","cheatsheet","debug"],"title":"Java应用性能调优套路"},{"categories":null,"content":"有这么一个要求，实现一个缓存，缓存的key在5分钟之后过期，清除可以在另一个线程中做。\n实现思路：\n 一个Map\u0026lt;K, V\u0026gt;保存缓存 一个Queue用来保存put操作，并记录每个put动作所发生的时间 在对缓存put的时候，不仅对Map\u0026lt;K, V\u0026gt; put，也对Queue add。那么这个Queue就变成了一个按照时间顺序存放的队列。 弄一个线程定时  peek Queue 如果Queue是空的，啥都不做 如果头元素记录的时间已经距离当前时间超过5分钟，那么就remove它，然后重复第一步 如果不是，则结束    代码实现如下：\nExpiryPolicy：\n1public class ExpiryPolicy { 2 3 private long ttlMillis; 4 5 private Cache cache; 6 7 private ConcurrentLinkedQueue\u0026lt;Node\u0026gt; writeQueues = new ConcurrentLinkedQueue\u0026lt;\u0026gt;(); 8 9 private ScheduledExecutorService executor = Executors.newSingleThreadScheduledExecutor(); 10 11 public ExpiryPolicy(long ttlMillis, Cache cache) { 12 this.ttlMillis = ttlMillis; 13 this.cache = cache; 14 } 15 16 public void writeNode(Node node) { 17 writeQueues.add(node); 18 } 19 20 public void start() { 21 executor.scheduleWithFixedDelay(new ExpiringTask(), 22 ttlMillis, ttlMillis, TimeUnit.MILLISECONDS); 23 } 24 25 class ExpiringTask implements Runnable { 26 @Override 27 public void run() { 28 System.out.println(\u0026#34;Start purge expired keys\u0026#34;); 29 while (true) { 30 long now = System.currentTimeMillis(); 31 Node node = ExpiryPolicy.this.writeQueues.peek(); 32 if (node == null || now - node.getWriteTimestamp() \u0026lt; ttlMillis) { 33 break; 34 } 35 System.out.println(\u0026#34;Remove expired key: \u0026#34; + node.getKey()); 36 ExpiryPolicy.this.writeQueues.remove(node); 37 ExpiryPolicy.this.cache.remove(node.getKey()); 38 } 39 } 40 } 41} Cache：\n1public class Cache\u0026lt;K, V\u0026gt; { 2 3 private ConcurrentHashMap\u0026lt;K, Node\u0026lt;K, V\u0026gt;\u0026gt; cacheMap = new ConcurrentHashMap\u0026lt;\u0026gt;(); 4 5 private ExpiryPolicy expiryPolicy; 6 7 public void put(K key, V value) { 8 Node\u0026lt;K, V\u0026gt; node = new Node\u0026lt;\u0026gt;(key, value); 9 cacheMap.put(key, node); 10 expiryPolicy.writeNode(node); 11 } 12 13 public V remove(K key) { 14 Node\u0026lt;K, V\u0026gt; node = cacheMap.remove(key); 15 return node == null ? null : node.getValue(); 16 } 17 18 public V get(K key) { 19 Node\u0026lt;K, V\u0026gt; node = cacheMap.get(key); 20 return node == null ? null : node.getValue(); 21 } 22 23 public void setExpiryPolicy(ExpiryPolicy expiryPolicy) { 24 this.expiryPolicy = expiryPolicy; 25 } 26 27} Node：\n1public class Node\u0026lt;K, V\u0026gt; { 2 private K key; 3 private V value; 4 private long writeTimestamp; 5 6 public Node(K key, V value) { 7 this.key = key; 8 this.value = value; 9 this.writeTimestamp = System.currentTimeMillis(); 10 } 11 12 // getters, equals, hashCode 13} 用法：\n1public class CacheTest { 2 3 @Test 4 public void test() throws InterruptedException { 5 Cache\u0026lt;String, Integer\u0026gt; cache = new Cache\u0026lt;\u0026gt;(); 6 ExpiryPolicy expiryPolicy = new ExpiryPolicy(TimeUnit.SECONDS.toMillis(5), cache); 7 cache.setExpiryPolicy(expiryPolicy); 8 expiryPolicy.start(); 9 10 cache.put(\u0026#34;foo\u0026#34;, 1); 11 cache.put(\u0026#34;bar\u0026#34;, 2); 12 13 assertEquals(cache.get(\u0026#34;foo\u0026#34;), Integer.valueOf(1)); 14 assertEquals(cache.get(\u0026#34;bar\u0026#34;), Integer.valueOf(2)); 15 16 TimeUnit.SECONDS.sleep(8L); 17 18 assertEquals(cache.get(\u0026#34;foo\u0026#34;), null); 19 assertEquals(cache.get(\u0026#34;bar\u0026#34;), null); 20 } 21 22} 相关代码在这里 。\n","date":"2020-02-20","img":"","permalink":"/post/code-snippets/time-based-expiring-cache/","series":null,"tags":["ARTS-A","缓存"],"title":"算法 - 基于时间过期策略的缓存"},{"categories":null,"content":"有这么一个要求，要求在任意5分钟内请求数不得超过1000。\n在实现上可以使用队列，请求来的时候先看队列尺寸是否达到1000\n 如果没有达到，则将当前时间戳追加到队列尾部。 如果达到，则看队列的头部元素（也是时间戳）距离当前时间是否超过5分钟  如果没有超过，则说明最近5分钟里已经有1000个请求了，那么拒绝这个请求 如果超过，则删除队列头部元素，将当前时间戳追加到队列尾部。    这种方式的好处在于能够精确的控制请求速率，并且时间窗口可以比较大，具备一定的弹性，而且窗口是平滑的。缺点是需要维护一个队列，占用内存空间。\n代码实现如下：\n1public class SynchronizedSmoothRateLimiter implements SmoothRateLimiter { 2 3 /** 4* 时间窗口长度（单位ms） 5*/ 6 private final long windowLength; 7 8 /** 9* 时间窗口内能够有多少个请求 10*/ 11 private final int maxRequests; 12 13 /** 14* 时间窗口，内记录的是时间戳 15*/ 16 private final Queue\u0026lt;Long\u0026gt; window = new LinkedList\u0026lt;\u0026gt;(); 17 18 public SynchronizedSmoothRateLimiter(long windowLength, int maxRequests) { 19 this.windowLength = windowLength; 20 this.maxRequests = maxRequests; 21 } 22 23 @Override 24 public synchronized boolean tryAcquire() { 25 long now = System.currentTimeMillis(); 26 int windowSize = window.size(); 27 if (windowSize \u0026lt; maxRequests) { 28 window.add(now); 29 return true; 30 } 31 32 long head = window.peek().longValue(); 33 long distant = now - head; 34 if (distant \u0026lt;= windowLength) { 35 return false; 36 } 37 window.poll(); 38 window.add(now); 39 return true; 40 } 41 42} 相关代码在这里 。\n","date":"2020-02-20","img":"","permalink":"/post/code-snippets/smooth-rate-limit-jmh/","series":null,"tags":["ARTS-A","并发编程","限流"],"title":"算法 - 平滑窗口限流"},{"categories":null,"content":"假想有一个桶，它有容量上限（capacity），有一个人A按照一定速率（rate）往桶里扔令牌（issue），另一个人B则从这个桶里取令牌（acquire）。如果取的速度比扔的快，那么最终桶就会干涸，此时B的请求就被拒绝。如果取的速度比扔的慢，那么桶里的令牌也不会无限多，到其上限为止。\n令牌桶算法能够使得在高峰时动用低谷时积攒的令牌，使其在高峰能够抗一下，而不是粗暴的规定请求速度不能超过xxx/秒，具备一定的弹性。\n在实现上，并不需要有一个线程负责扔令牌，只需在拿令牌时取当前时间和上一次扔令牌的时间差 * 速率即可。示意代码如下：\n1public class SynchronizedTokenBucket implements TokenBucket { 2 3 private final int issueRatePerSecond; 4 5 private final int capacity; 6 7 private int tokens; 8 9 private long lastIssueTime; 10 11 @Override 12 public synchronized boolean tryAcquire() { 13 issueTokensIfNecessary(); 14 if (tokens \u0026gt; 0) { 15 tokens--; 16 return true; 17 } 18 return false; 19 } 20 21 private void issueTokensIfNecessary() { 22 long acquireTime = System.currentTimeMillis(); 23 int issueTokens = (int) ((acquireTime - lastIssueTime) / 1000L * issueRatePerSecond); 24 issueTokens = Math.min(capacity - tokens, issueTokens); 25 if (issueTokens \u0026lt;= 0) { 26 // \u0026lt; 0 是因为时间回拨问题 27 return; 28 } 29 lastIssueTime = acquireTime; 30 tokens += issueTokens; 31 } 32 33} 相关代码在这里 ，提供了三种线程安全的实现。\n","date":"2020-02-20","img":"","permalink":"/post/code-snippets/token-bucket/","series":null,"tags":["ARTS-A","并发编程","限流"],"title":"算法 - 令牌桶限流"},{"categories":null,"content":"数据同步方案 数据同步方案简单来说就是把数据从API提供方哪里复制到自己这里。\n这类方案的好处是：\n 不需要修改你原来的查询语句。  坏处：\n 同步的实时性问题  方案一：利用ETL工具做数据同步 如果你可以将从API提供方的数据库同步到你自己的库中，可以采用ELT工具定时同步的方法。\n方案二：使用时同步 这个方案和前一个方案案差不多，但数据同步的时机不一样。举个例子说明：\n有一个用户API，它是权威数据源。你的业务库中也有用户表，这张表当然现在什么数据都没有，你还有一张订单表关联了用户表。\n现在你的业务产生了一个订单，此时你得到了用户ID，但是用户的其他信息没有得到。那么在产生订单的时候，调用用户API，把用户数据同步到你自己的用户表中。这个是第一次同步的情况。\n你还有一个业务是查询订单详情，详情中要显示用户信息，你可以在这个时候调用用户API来更新一下用户表中的数据。这个则是同步用户数据更新的情况。\n总之，你可以根据自己的实际情况决定什么时候做第一次同步，什么时候做数据更新同步。\n自己模拟JOIN 这个方案的思路总体来说就是自己模拟数据库JOIN拼接结果。\n这个方案的好处是：\n 你不需要自己的表了，按照前面的例子来说就是你不需要用户表了。  缺点是：\n 有些复杂查询可能会无法支持 查询能力受制于API支持何种类型的查询 需要修改你的查询代码，有些场景下可能还很复杂  下面以查询订单详情为例，提供一些代码例子，在给代码之前先列出这个模拟JOIN所做的工作：\n 在你自己的库中查询到一系列订单 收集这些订单所关联的用户ID 拿着这些用户ID去用户API查询得到一系列用户对象 构建订单详情对象，将订单和用户对象按照原来的关系装配起来 返回订单详情对象  OderDetailService，负责查询订单详情：\n1public class OrderDetailService { 2 3 private UserService userService; 4 5 private OrderService orderService; 6 7 public List\u0026lt;OrderDetailDto\u0026gt; findByUserId(String userId) { 8 List\u0026lt;Order\u0026gt; orders = orderService.findByUserId(userId); 9 // 收集订单中的用户Id 10 Set\u0026lt;String\u0026gt; userIds = orders.stream().map(Order::getUserId).collect(Collectors.toSet()); 11 // 查询到用户 12 List\u0026lt;User\u0026gt; users = userService.findByIds(userIds); 13 // 构建用户id-\u0026gt;用户的map 14 Map\u0026lt;String, User\u0026gt; userId2UserMap = users.stream().collect(Collectors.toMap(User::getId, Function.identity())); 15 // 构建订单详情对象 16 return orders.stream().map(order -\u0026gt; { 17 User user = userId2UserMap.get(order.getUserId()); 18 OrderDetailDto orderDetail = new OrderDetailDto(); 19 orderDetail.setOrder(order); 20 orderDetail.setUser(user); 21 return orderDetail; 22 }).collect(Collectors.toList()); 23 } 24 25} 订单详情对象：\n1public class OrderDetailDto { 2 private Order order; 3 private User user; 4} 订单对象：\n1public class Order { 2 private String userId; 3 private Date createdAt; 4 private Double price; 5 private String productName; 6 private String productUrl; 7} 用户对象：\n1public class User { 2 private String name; 3 private String id; 4} 订单Service接口：\n1public interface OrderService { 2 List\u0026lt;Order\u0026gt; findByUserId(String userId); 3} 用户Service接口，你可以提供一个调用API的实现：\n1public interface UserService { 2 List\u0026lt;User\u0026gt; findByIds(Set\u0026lt;String\u0026gt; userIds); 3} 事实上只要你是基于接口编程的，你可以很方便的把任意Service改成调用API，只要它们的接收参数和返回结果一致就行了。\n","date":"2020-02-19","img":"","permalink":"/post/api-join-query/","series":null,"tags":["微服务"],"title":"调用API时如何做JOIN查询"},{"categories":null,"content":"Go和Java的区别（纯笔记，不系统）\n Go更像C，Java更像C++ Go不允许存在声明但是没有使用的东西，比如声明了多余的变量，import了多余的包 Go对不同平台有不同的编译结果 Go的function可以返回多个值 Go的function没有overload Go用defer实现try-finally和try-catch，可以运行时决定使用哪个 Go有function闭包，可以读写外部变量。Java的lambda有类似的，但是是基于匿名内部类的，且只能读外部变量：外部变量必须是final或者事实上是final的（即不会被修改） Go没有线程，而是Goroutine，Goroutine是由Go运行时管理的task，所以Go没有线程池。Goroutine可以类似于Green threads？ Go的类型方法通过function上加receiver来实现 Go中struct首字母大写字段是public的，首字母小写字段是private的 Go没有this Go没有显式的继承，而是嵌入，而且采用duck typing来判断A类型实例是否可以复制给B类型变量。 Go有指针，和值。Java里除了基本类型则都是引用 Go的变量赋值、参数传递是复制，指针类型复制的是地址（和Java的引用一样），其他类型复制的是内存中的数据。 Go中有些类型实例的复制就是两个实例，不共享数据，比如array。有些则不是，虽然是两个实例，但是共享数据，比如slice。没有明显规律。 Go没有NullPointerException，有些类型的nil值具有开箱即用的特性，有些则没有，没有明显规律 Go的Mutex是不可重入锁，比较接近操作系统底层mutex Go自带了单元测试、性能测试、CPU+Memory+Net的Profile库 ","date":"2020-02-10","img":"","permalink":"/post/go/go-java/","series":null,"tags":["Go"],"title":"Go和Java的区别"},{"categories":null,"content":"Rancher中可以很方便的开启监控功能，其使用的是Prometheus Operator + Grafana，那么我们也可以利用它来采集JVM数据。\n开启监控 首先，开启集群的监控：\n 然后，开启项目的监控（可选）：\n RBAC 给prometheus-operator的service account配置RBAC：\n1apiVersion:rbac.authorization.k8s.io/v1beta12kind:ClusterRole3metadata:4name:prometheus-all-ns5rules:6- apiGroups:[\u0026#34;\u0026#34;]7resources:8- nodes9- services10- endpoints11- pods12verbs:[\u0026#34;get\u0026#34;,\u0026#34;list\u0026#34;,\u0026#34;watch\u0026#34;]13- apiGroups:[\u0026#34;\u0026#34;]14resources:15- configmaps16verbs:[\u0026#34;get\u0026#34;]17- nonResourceURLs:[\u0026#34;/metrics\u0026#34;]18verbs:[\u0026#34;get\u0026#34;]19---20apiVersion:rbac.authorization.k8s.io/v1beta121kind:ClusterRoleBinding22metadata:23name:prometheus-all-ns24roleRef:25apiGroup:rbac.authorization.k8s.io26kind:ClusterRole27name:prometheus-all-ns28subjects:29- kind:ServiceAccount30name:prometheus-k8s31namespace:monitoring应用配置JMX Exporter 你的Java应用的镜像得配置JMX Exporter，配置方法见使用Prometheus+Grafana监控JVM ，我在这里选择将JMX Exporter端口设置为6060。\n然后在你的Deployment/StatefulSets 中配置这个端口：\n1apiVersion:apps/v12kind:Deployment3metadata:4name:...5namespace:...6spec:7selector:8matchLabels:9app:...10replicas:111template:12metadata:13labels:14app:...15spec:16containers:17- name:...18image:...19ports:20- containerPort:606021name:http-metrics22- ...和 Service 也一样：\n1apiVersion:v12kind:Service3metadata:4namespace:...5name:...6labels:7app:...8needMonitor:\u0026#39;true\u0026#39;9spec:10ports:11- port:606012targetPort:http-metrics13protocol:TCP14name:http-metrics15- ...16selector:17app:...可以看到，我把端口取了个名字叫做http-metrics，同时Service添加了Label needMonitor: 'true'\n添加ServiceMonitor 利用项目Prometheus采集 如果你前面开启了项目监控，并且想用项目Prometheus来收集数据，那么这么做：\nServiceMonitor是Prometheus Operator定义的CRD：\n1apiVersion:monitoring.coreos.com/v12kind:ServiceMonitor3metadata:4name:...5namespace:...6spec:7selector:8matchLabels:9needMonitor:\u0026#39;true\u0026#39;10endpoints:11- port:http-metrics12path:/metrics这样Prometheus就能把同namespace下的所有needMonitor: 'true'的Service的JMX Exporter都采集到。\n利用集群Prometheus采集 如果你想直接利用集群的Prometheus，那么你得把ServiceMonitor建在cattle-prometheus下，并且设置namespaceSelector属性：\n1apiVersion:monitoring.coreos.com/v12kind:ServiceMonitor3metadata:4name:...5namespace:cattle-prometheus6spec:7selector:8matchLabels:9needMonitor:\u0026#39;true\u0026#39;10endpoints:11- port:http-metrics12path:/metrics13namespaceSelector:14matchNames:15- namespace-116- namespace-2给Grafana添加JVM Dashboard 你需要给Grafana添加JVM Dashboard，在这之前你需要设置Grafana的admin密码，进入项目找到Grafana，进入其Shell：\n 执行：\n1grafana-cli admin reset-admin-password \u0026lt;新密码\u0026gt; 然后随便进入一个Deployment/StatefulSets，进入Grafana：\n 用admin账号和你刚才设置的密码登录进去，进入管理页面导入Dashboard：\n 到 https://grafana.com/orgs/chanjarster/dashboards 找到 JVM dashboard (for Prometheus Operator) ，看到它的编号是8878。把这个编号填到导入页面：\n 然后大功告成：\n","date":"2020-01-17","img":"","permalink":"/post/k8s/rancher-p8s-jvm/","series":null,"tags":["k8s","prometheus","rancher"],"title":"利用Rancher中的Prometheus采集JVM数据"},{"categories":null,"content":"在索引 里提到了索引占用的空间和索引占用值的关系。并提到了字符串可以使用最左N个字符作为索引值（最左前缀）。\n在数据库选错索引怎么办 里提到基数（cardinality）是选择使用哪个索引的很重要的指标。\n前缀索引 下面举个例子：\n1-- 使用整个字段做索引 2mysql\u0026gt;altertableSUseraddindexindex1(email);3-- 使用前6个字符做索引 4mysql\u0026gt;altertableSUseraddindexindex2(email(6));如果使用的是 index1（即 email 整个字符串的索引结构），执行顺序是这样的：\n 从 index1 索引树找到满足索引值是zhangssxyz@xxx.com的这条记录，取得 ID2 的值； 到主键上查到主键值是 ID2 的行，判断 email 的值是正确的，将这行记录加入结果集； 取 index1 索引树上刚刚查到的位置的下一条记录，发现已经不满足 email=`zhangssxyz@xxx.com `的条件了，循环结束。  如果使用的是 index2（即 email(6) 索引结构），执行顺序是这样的：\n 从 index2 索引树找到满足索引值是’zhangs’的记录，找到的第一个是 ID1； 到主键上查到主键值是 ID1 的行，判断出 email 的值不是’zhangssxyz@xxx.com’，这行记录丢弃；（回表） 取 index2 上刚刚查到的位置的下一条记录，发现仍然是’zhangs’，取出 ID2，再到 ID 索引上取整行然后判断，这次值对了，将这行记录加入结果集； 重复上一步，直到在 idxe2 上取到的值不是’zhangs’时，循环结束。  可以看到使用第二种方式建索引会导致回表，那么覆盖索引也用不上了。\n所以，如何给字符串建索引就成了空间（占用空间）和效率（基数）的权衡。前缀索引使用的好，就可以做到既节省空间，又不用额外增加太多的查询成本。\n如何确定前缀索引的长度 首先，你可以使用下面这个语句，算出这个列上有多少个不同的值：\n1mysql\u0026gt;selectcount(distinctemail)asLfromSUser;然后，依次选取不同长度的前缀来看这个值，比如我们要看一下 4~7 个字节的前缀索引，可以用这个语句：\n1mysql\u0026gt;select2count(distinctleft(email,4)）asL4,3count(distinctleft(email,5)）asL5,4count(distinctleft(email,6)）asL6,5count(distinctleft(email,7)）asL7,6fromSUser;使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如 5%。然后，在返回的 L4~L7 中，找出不小于 L * 95% 的值，假设这里 L6、L7 都满足，你就可以选择前缀长度为 6。\n前缀区分度不够怎么办 比如身份证号，字符串很长，前缀部分区分度很低，有两个方法：\n 倒序存储：把身份证倒过来存，因为身份证前几位区分度太低，但是后几位区分度很高：  1mysql\u0026gt;altertabletaddindexid_card_i(id_card(6));2mysql\u0026gt;selectfield_listfromtwhereid_card=reverse(\u0026#39;input_id_card_string\u0026#39;); 添加一个身份证的hash字段  1mysql\u0026gt;altertabletaddid_card_crcintunsigned,addindex(id_card_crc);2mysql\u0026gt;selectfield_listfromtwhereid_card_crc=crc32(\u0026#39;input_id_card_string\u0026#39;)andid_card=\u0026#39;input_id_card_string\u0026#39;这两个方法有个共同的缺点，不支持范围查询，只支持等值查询。\n","date":"2020-01-13","img":"","permalink":"/post/mysql/index-for-string/","series":null,"tags":["mysql"],"title":"MySQL - 给字符串加索引"},{"categories":null,"content":"在基础架构 里提到在执行查询时优化器负责选择使用哪个索引。\n实验1 建表：\n1CREATETABLE`t`(2`id`int(11)NOTNULL,3`a`int(11)DEFAULTNULL,4`b`int(11)DEFAULTNULL,5PRIMARYKEY(`id`),6KEY`a`(`a`),7KEY`b`(`b`)8)ENGINE=InnoDB；插入数据：\n1delimiter;;2createprocedureidata()3begin4declareiint;5seti=1;6while(i\u0026lt;=100000)do7insertintotvalues(i,i,i);8seti=i+1;9endwhile;10end;;11delimiter;12callidata();用explain`来观察MySQL会选择哪个索引：\n1mysql\u0026gt;explainselect*fromtwhereabetween10000and20000; 结果表明MySQL会选择索引a，并且预计扫描10001行，为什么是10001行而不是10000行？这是因为在扫描的时候要扫描到第一个不满足条件的数据为止，因此会多扫一行。\n选错索引的逻辑 优化器选择索引考虑的因素：\n cardinality（基数），基数代表区分度，基数越大区分度则越大，不同值越多则区分度越大，区分度大的索引被选择的概率大  1mysql\u0026gt;showindexfromt; 基数的值并非精确值而是一个估算值，InnoDB选取N个数据页统计不同值，计算基数平均值。当更新的行超过1/M时，重新计算基数。可以用innodb_stats_persistent来控制这个统计信息存在哪里。\n 预估执行该语句本身会扫描多少行，同时会预估回表的代价  纠正办法 重新统计索引信息：\n1ANALYZETABLEt;强制告诉使用哪个索引，force index：\n1select*fromtforceindex(a)where...其他tricky的方法，这里不做介绍了。\n","date":"2020-01-12","img":"","permalink":"/post/mysql/force-index/","series":null,"tags":["mysql"],"title":"MySQL - 数据库选错索引怎么办"},{"categories":null,"content":"原文：09 | 普通索引和唯一索引，应该怎么选择？ 数据页 在redo log和binlog —— 日志的2PC 里提到过：\n 如果该行所在数据页已经在内存中，则直接返回，如果不在则从磁盘中加载数据页，然后返回。这里很重要的信息是，更新操作首先是在内存中进行的，之后才会同步到磁盘。\n 这里提到了两个很重要的信息：\n 更新操作操作的是数据页 如果数据页不在内存中，那么要从磁盘中加载到内存中。  InnoDB的数据页默认大小是16K（由innodb_page_size控制），InnoDB不会只加载你想要的row，而是把附近的连带加载进来（有点像CPU的cache line）。下图中的第二行就是一个一个数据页：\n 那么问题来了，如果你每次更新的row所在的数据页不在内存中，那么每次都要从磁盘加载是极其低效的，因此change buffer来救你了。\nchange buffer change buffer顾名思义是更新操作的缓冲，它是buffer pool的一部分（由innodb_change_buffer_max_size控制占用百分比）。当你要更新的row所在的数据页不在内存中时，InnoDB把更新操作保存在change buffer中。PS. change buffer是持久化的。\nchange buffer不是万能的，如果你的更新操作能够利用change buffer（比如下面讲到的普通索引），但是每次更新之后都有查询，即加载数据页，那么change buffer带来的效益就没有了，反而增加了开销。\nchange buffer对于那些写多读少的表特别有用，比如订单表、日志表。\n索引 分别对普通索引和唯一索引的两种操作对比性能。\n查询操作  对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。  两者性能差别微乎其微。\n更新操作和change buffer  给普通索引insert记录时，可以直接将更新缓存在change buffer中。 给唯一索引insert记录时，必须判断插入值是否重复，那么就要加载数据页，然后判断，然后直接在数据页中更新。  所以，唯一索引的insert操作必须要求数据页已经在内存中，如果没有则要加载，它用不了change buffer，因此代价是很高的。\n如何选择索引 可以看到普通索引可以利用change buffer能够得到性能好处，你会倾向于使用普通索引，但是如果业务一定要求唯一索引，那你还是得用唯一索引。\n另一个场景是，如果你要把线上表做一个归档，你会建一个和线上表结构一样的归档表，然后把线上表的数据copy到归档表中，此时你可以把归档表中的唯一索引改成普通索引，这样能够极大的提高归档效率（因为可以利用change buffer）。\nchange buffer和redo log 更新过程 现在，我们要在表上执行这个插入语句：\n1mysql\u0026gt;insertintot(id,k)values(id1,k1),(id2,k2);我们假设当前 k 索引树的状态，查找到位置后，k1 所在的数据页在内存 (InnoDB buffer pool) 中，k2 所在的数据页不在内存中。下图 所示是带 change buffer 的更新状态图。\n 这条更新语句涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）。\n这条更新语句做了如下的操作（按照图中的数字顺序）：\n Page 1 在内存中，直接更新内存； Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息 将上述两个动作记入 redo log 中（图中 3 和 4）。  同时，图中的两个虚线箭头，是后台操作，不影响更新的响应时间。\n读过程 我们现在要执行 select * from t where k in (k1, k2)流程如下：\n  读 Page 1 的时候，直接从内存返回。 要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。这个动作称为merge。  可以看到，直到需要读 Page 2 的时候，这个数据页才会被读入内存。\n将change buffer应用到数据页，该操作称为merge，它的时机：\n 当下次数据页从磁盘加载到内存中时，会执行merge 系统后台定时触发merge 数据库shutdown时（正常关闭）会执行merge  merge 的执行流程是这样的：\n 从磁盘读入数据页到内存（老版本的数据页）； 从 change buffer 里找出这个数据页的 change buffer 记录 (可能有多个），依次应用，得到新版数据页； 写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。  redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。\n思考题 change buffer写入后断电了，数据会不会丢失。\n按照前面merge的执行流程，它的最后一步是写redo log，而按照redo log的约定，只有commit的redo log才选真正写入。因此只要redo log写了，且commit了，断电后数据会丢失的。如果没有写redo log，或者redo log没有commit，这个时候断电，数据会丢失的。\n不过好像具体情况更复杂，上面只是一个大概的意思。\n","date":"2020-01-07","img":"","permalink":"/post/mysql/page-change-buffer-index/","series":null,"tags":["mysql"],"title":"MySQL - 数据页、change Buffer和索引"},{"categories":null,"content":"前面提到过MySQL通过MVCC来实现事务隔离（准确的说是InnoDB引擎实现了MVCC）。那么接下来详细讲讲这个MVCC。\n先思考一下 下面是一个例子，这个例子中的数据库事务隔离级别是RR（Repeatable Read），并且auto commit=1。\n有一张表，且有(1,1)和(2,2)两条数据：\n1CREATETABLE`t`(2`id`int(11)NOTNULL,3`k`int(11)DEFAULTNULL,4PRIMARYKEY(`id`)5)ENGINE=InnoDB;6insertintot(id,k)values(1,1),(2,2);下面是三个事务的执行语句的情况，自上而下代表时间的先后。\n   事务A 事务B 事务C     start transaction with consistent snapshot      start transaction with consistent snapshot      update t set k=k+1 where id=1    update t set k=k+1 where id=1     select k from t where id=1    select k from t where id=1     commit;      commit;     start transaction with consistent snapshot代表了在开启一个事务的时候同时开启一个一致性视图，事务C因为开启了auto commit的关系，所以虽然只有一条语句但是也自成一个事务。\n现在问事务A的select得到的值是什么？事务B的select得到的又是什么？\n解答这个问题就要回答所谓的“一致性视图”到底是怎么实现的。\n一致性视图 一致性视图就相当于给数据库拍了一个快照，当然这个快照是逻辑的不是物理的。在MySQL - 事务隔离 里我们提到了可以通过undo log来得到read view，那么关键问题就变成了：如何能够得到所有表属于这个快照的read view。那先讲三点：\n 开启事务的时候，会得到一个全局唯一且单调递增的transaction id 每次更新行的时候，都会把这个transaciton id一并保存，并且将其记为row trx_id 每行都有多个read view，可以理解为多个版本，read view里记录了row trx_id  那么，如果你现在的transaction id是100，那么你在读一张表的时候就能够规定，只取row trx_id \u0026lt;= 100的read view，这样不就是相当于给数据库打了快照了吗？\n下面这张图就是一行有4个版本（read view）V1、V2、V3、V4，通过undo log U1、U2、U3能够得到它们，还有事务id。\n InnoDB的实现 在实现上InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。\n数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。\n而数据版本的可见性规则，就是基于数据的 row trx_id 和这个一致性视图的对比结果得到的。\n 这样，对于当前事务的启动瞬间来说，一个数据版本的 row trx_id，有以下几种可能：\n 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的； 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的； 如果落在黄色部分，那就包括两种情况  若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见； 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。    回过头来看例子 现在问事务A的select得到的值是什么？事务B的select得到的又是什么？\n假设：\n 事务 A 开始前，系统里面只有一个活跃事务 ID 是 99； 事务 A、B、C 的版本号分别是 100、101、102，且当前系统里只有这四个事务； 三个事务开始前，(1,1）这一行数据的 row trx_id 是 90。  那么，事务 A 的视图数组就是 [99,100], 事务 B 的视图数组是 [99,100,101], 事务 C 的视图数组是 [99,100,101,102]\n下面是时间线：\n 查询逻辑 可以看到事务A得到的结果是1，也就是row trx_id=90的那个版本，因为它处于低水位之下。\n更新逻辑 可以看到事务B把结果从2变成了3，按照道理说事务C[102]处于高水位之外，应该看不到才对啊。这是因为更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。因为如果不这么做事务C的更新就会被冲掉。\n从而，事务B后面的select得到的是3。\n开启事务的两种方式 前面已经看到了，可以使用start transaction with consistent snapshot来开启事务，同时它还会创建一个一致性视图。但是这个语句只有当事务隔离级别是RR的时候才有用，否则它和下面的begin/start transaction效果是一样的。\nbegin/start transaction也可以开启一个事务，但是它不会创建一个一致性视图，只有当后面执行第一条操作InnoDB表的语句才会创建一致性视图。\n下面是RC（Read Commit）级别下的时间线：\n 考虑到执行第一条快照读语句时才会创建一致性视图（也就是那个数组），那么可得出：\n A能够读到C提交的结果，2 B因为更新的时候当前读，所以得到结果3  小节 InnoDB 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据 row trx_id 和一致性视图确定数据版本的可见性。\n 对于可重复读（RR），查询只承认在事务启动前就已经提交完成的数据； 对于读提交（RC），查询只承认在语句启动前就已经提交完成的数据；而当前读，总是读取已经提交完成的最新版本。  思考题 下面描述了一个场景：数据明明没有变，为何却无法更新。\n1mysql\u0026gt;CREATETABLE`t`(2`id`int(11)NOTNULL,3`c`int(11)DEFAULTNULL,4PRIMARYKEY(`id`)5)ENGINE=InnoDB;6insertintot(id,c)values(1,1),(2,2),(3,3),(4,4);1mysql\u0026gt; begin; 2Query OK, 0 rows affected (0.00 sec) 3 4mysql\u0026gt; select * from t; 5+----+------+ 6| id | c | 7+----+------+ 8| 1 | 1 | 9| 2 | 2 | 10| 3 | 3 | 11| 4 | 4 | 12+----+------+ 134 rows in set (0.00 sec) 14 15mysql\u0026gt; update t set c=0 where id=c; 16Query OK, 0 rows affected (0.00 sec) 17Rows matched: 0 Changed: 0 Warnings: 0 18 19mysql\u0026gt; select * from t; 20+----+------+ 21| id | c | 22+----+------+ 23| 1 | 1 | 24| 2 | 2 | 25| 3 | 3 | 26| 4 | 4 | 27+----+------+ 284 rows in set (0.00 sec) 要怎样做才能产生这种情况呢？回顾这张图：\n  当row tx_id 在 红色区域里，对当前事务不可见 当row tx_id 在 黄色区域里，且在数组中时，对当前事务不可见  那么就有两种做法能够产生这个效果，第一种：\n   事务A 事务B     begin    select * from t     update t set c=c+1   update t set c=0 where id=c    select * from t      事务A的select产生transaction id 100 事务B在事务A之后开始，transaction id 101，更新行，row trx_id=101 事务A的update是当前读，所以没有行被更新 事务A的select看row tx_id（101）是在红色区域，那么对当前事务不可见，所以得到的结果还是没变的  第二种：\n   事务A 事务B      begin   begin update t set c=c+1   select * from t     commit   update t set c=0 where id=c    select * from t      事务B产生transaction id 100 事务B update，row tx_id=100 事务A产生transaction id 101，发现目前活跃事务100，形成数组[100, 101] 事务B commit（如果没有commit，后面的事务A的操作会阻塞住的） 事务A update，当前读，所以没有行被更新 事务A select，发现row trx_id(101)在数组内，是活跃事务提交的，因此不可见，得到的结果还是没变的 ","date":"2019-12-30","img":"","permalink":"/post/mysql/mvcc/","series":null,"tags":["mysql"],"title":"MySQL - MVCC和事务隔离"},{"categories":null,"content":"先导概念：\n 读锁：可以并发读，如果有写操作，则必须等读锁释放 写锁：不能并发读，也不能并发写，都必须等写锁释放才能继续  锁的类型：\n 全局锁 表级锁：表锁、MDL锁  全局锁 使用FLUSH TABLES WITH READ LOCK 会让你给整个数据库加一个读锁。这会阻塞所有DML、DDL、更新类事务的commit，直到被释放。\n全局锁的典型使用场景是MyISAM引擎做全库逻辑备份，为的是解决备份时数据不一致的问题。\n如果是InnoDB引擎的表，因为支持MVCC，可以通过mysqldump --single-transaction来解决备份时数据一致性问题。\n释放方法：\n1UNLOCKTABLES;表级锁 表锁 通过下面语句给表加上读锁或写锁，还有释放：\n1-- 加锁 2LOCKTABLES...read/write3-- 释放 4UNLOCKTABLES5-- 例如 6LOCKTABLESt1read,t2writeMySQL的锁不是可重入的，即加锁之后，当前连接/session也受制于这个锁。\n如果加的是读锁：\n 本session：可以读，不可写（直接报错） 其他session：可以读，阻塞写  如果加的是写锁：\n 本session：可以读、可以写 其他session：阻塞读、阻塞写  元数据锁（Metadata Lock，MDL） 访问表的时候会被自动加上（隐式）：\n 在CRUD一个表的时候，加上MDL读锁 对表结构变更的时候，加上MDL写锁  陷阱：MDL锁在语句开始时申请，但是要在事务提交之后才会释放。所以下面语句会导致很多数据库操作被阻塞：\n session A开启事务，查询，得到MDL读锁 session B查询，得到MDL读锁 session C加字段，要得到MDL写锁，阻塞 session D查询，要得到MDL读锁，但是前面有写锁在排队，阻塞  因为session A没有提交事务，所以就造成了后续一连串的阻塞。如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。\n解决办法：\n问题的本质在于一个MDL写锁在等待MDL读锁的释放，而读锁却在一个长事务里，导致后续的MDL读锁堆积。\n所以可以在执行DDL之前看有没有长事务在跑，如果有，Kill掉这个长事务，或者等待长事务结束再DDL。\n还可以给DDL添加超时时间，如果等待超时则放弃，然后人工再重试（MariaDB和AliSQL支持下面语法）：\n1ALTERTABLEtbl_nameNOWAITaddcolumn...2ALTERTABLEtbl_nameWAITNaddcolumn...行锁 InnoDB支持行锁，MyISAM不支持。所以行锁是做在存储引擎上的。\n比如下面：\n   事务A 事务B     begin;\nupdate t set k=k+1 where id=1;\nupdate t set k=k+2 where id=2;     begin;\nupdate t set k=k+2 where id=1;   commit;     很容易就能猜到，事务B会被阻塞，直到事务A提交。所以：\n 行锁在需要的时候才获取（执行具体语句时） 事务持有的行锁在事务提交时才会被释放。（这个和MDL锁一样一样的）  所以为了降低锁的影响，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放，这样锁持有的时间变短了，降低并发时事务之间产生的等待。\n下面两种写法也会加上行锁：\n select ... lock in share mode，加上读锁（S锁，共享锁） select ... for share，8.0 新增语法，效果同上 select ... for update，语义和UPDATE/DELETE一样，加上写锁（X锁，排他锁）  SELECT ... FOR SHARE/LOCK IN SHARE MODE 只会锁定扫描过程中使用的索引里的记录行，即如果你的查询正好使用了覆盖索引，那么只有这个索引里的记录行会被锁定，主键索引的记录行是不会被锁定的。\nSELECT ... FOR UPDATE除了会锁定扫描过程中使用的索引里的记录行，相关的索引的记录行也会被锁定。换句话说如果你使用了覆盖索引，但是主键索引里的记录行也会被锁定。而又因为主键索引就已经包含了所有字段，那么就相当于锁定表的整行记录。\n所以一定要注意，MySQL锁定的行实际上是索引上的行，只不过有时候锁定的是主键索引，看上去像锁定整行一样\n更多参考资料，详情见SELECT 语法 和Locking Reads 死锁 因为上面的两个特性，很容易造成死锁：\n   序号 事务A 事务B     1 begin; begin;   2 update t set k=k+1 where id=1;    3  update t set k=k+1 where id=2;   4 update t set k=k+1 where id=2;    5  update t set k=k+1 where id=1;   6 commit; commit;    其实在4和5的时候，事务A和事务B就都不能继续下去了，大家互相等待。\n解决办法：\n 系统参数innodb_lock_wait_timeout ，控制事务等待行锁的超时时间（秒）。默认50秒。 系统参数[innodb_deadlock_detect][7]，开启死锁检测。默认on。发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。  死锁检测的过程：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。\n死锁检测高并发情况下拖慢速度 假设有 1000 个并发线程要同时更新同一行，每个线程都要检测是否和其他线程形成死锁，那么死锁检测操作就是 100 万这个量级的。于是出现**“CPU 利用率很高，但是每秒却执行不了几个事务“**。\n解决办法：\n 保证程序不会出现死锁，然后把死锁检测关掉。不靠谱。 控制并发度，最好对同一行的修改串行化。依赖于中间件或者修改MySQL源码。 锁的条带化（Java并发编程里的概念），比如影院账号的例子，把账号分成10个，减少锁的冲突。  加锁的顺序 先给哪行加锁，后给哪行加锁，是有讲究的，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。。什么比如一个购票的业务：\n 从顾客 A 账户余额中扣除电影票价； 给影院 B 的账户余额增加这张电影票价； 记录一条交易日志。  显然更新影院B账户余额的并发度比更新顾客A账户余额高很多，应该把它放后面。可以按照3、1、2的顺序执行。\n","date":"2019-12-20","img":"","permalink":"/post/mysql/locks/","series":null,"tags":["mysql"],"title":"MySQL - 锁"},{"categories":null,"content":"索引是在存储引擎层实现的，不同引擎实现方式不同，下面讲的是InnoDB。\nInnoDB索引模型 表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。这个索引组织表的结构是B+树，是一颗N叉树。\n有一张表两个字段ID和k，ID是主键，k则是普通列+索引，这张表的存储形式如下图：\n  索引中的数据都是有序存储的。根据索引字段的顺序比如(a, b)就等于order by a, b 主键索引中存放的是ID的值+行。这种索引称为clustered index。 k索引中存放的则是k的值+ID。这种索引称为secondary index。  索引维护 索引以数据页的形式存在磁盘上，可以认为每页存放N个B+树的结点。\n 数据页有很多 数据页的大小是固定的（可参数调整） 数据页中的数据是按照索引字段排序的，前面的图里可以看到 在磁盘上是段连续的空间，因为机械磁盘顺序读写的速度快，随机读写的速度超级慢。  页分裂：插入一条数据需要写数据页，如果数据页满了，且插入位置在中间，那么存储引擎要申请一个新的数据页，把部分数据移动过去。数据插在尾部没有这个问题。\n页合并：删除一条数据，当页的利用率很低之后，就会合并页。\n页空洞：页分裂过程会产生**“页空洞”**，因为两个页都不满（分裂后只用50%），但是占用磁盘空间，页空洞是占用大量磁盘空间的一个很常见的原因。\n用什么作主键 自增ID做主键 用NOT NULL PRIMARY KEY AUTO_INCREMENT创建一个自增ID主键索引。两个好处：\n 节省空间：自增ID是数字，占用4个字节（int）或8个字节（bigint）。回想前面的图中普通索引存的是索引字段+主键。如果你有多个普通索引，那么这里省下的空间是比较可观的。 没有“页空洞”：因为是自增的，所以每次插入都插在数据页尾部，所以没有“页分裂”，所以就没有“页空洞”  业务主键做主键 比如拿身份证号做主键，和自增ID比，存在浪费空间，会产生页空洞的问题。但也有合适的时候：\n 只有一个索引 该索引必须是唯一索引  回表问题 什么是“回表”：\n select * from T where id=1，执行器只需到主键索引中查就行了 select * from T where k=5，执行器要先到K索引中查到ID，然后再拿ID到主键索引中查。这个就是回表。如果查到的ID是N个，那么就要N次回表。  所以避免回表是提升执行效率有效手段，方法有：\n 查询只用到主键索引，可以避免回表 查询字段在索引覆盖的范围内，比如select ID,k from T where k=5 覆盖索引：联合索引比如(k, t)，那么这种也能避免回表：select id, k, t from T where k=5  覆盖索引 覆盖索引可以避免回表问题，但也会占用空间。使用时需要权衡利弊。\n最左前缀原则 你可以建一个联合索引(a, b, c)来覆盖到以下查询：\n where a=1 where a=1 and b=1 where a=1 and b=1 and c=1 order by a order by a, b order by a, b, c where a=1 order by b  对于字符类型字段，则like 'xyz%'这种形式也符合最左前缀原则。\n不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。\n所以：\n 索引的创建要和业务查询相匹配 如果通过改变顺序能够少维护一个索引，那么就优先考虑这种方案 如果(a, b), (b)和(b, a), (a)都能满足要求，那么看哪种占用空间小就用哪个。其实就是看a和b哪个占用空间小。  索引下推 1select*fromtuserwherenamelike\u0026#39;张%\u0026#39;andage=10andismale=1;如果name和age都有索引，但是ismale没有，在MySQL 5.6之前是先根据name找到记录，然后就开始回表判断了。5.6之后则会先拿索引字段name和age来过滤，然后再回表。\n重建索引 为何要重建索引？为了解决数据页空洞，节省磁盘空间。\n重建主键索引会将其他索引一并重建。事实上无论是删除还是创建主键都会将整个表的索引都搞一遍。\n可以使用alter table T engine=InnoDB来重建。当然下面也是可以的：\n1altertableTdropindexk;2altertableTaddindex(k);34altertableTdropprimarykey;5altertableTaddprimarykey(id);","date":"2019-12-20","img":"","permalink":"/post/mysql/indices/","series":null,"tags":["mysql"],"title":"MySQL - 索引"},{"categories":null,"content":" 基础架构  隔离级别  redo log和binlog  索引  锁  幻读、间隙锁和next-key lock  诊断锁的方法  MVCC和事务隔离  数据页、change buffer和索引  数据库选错索引怎么办  给字符串加索引  常用命令及参数  ","date":"2019-12-20","img":"","permalink":"/post/mysql/index-page/","series":null,"tags":["mysql"],"title":"MySQL系列"},{"categories":null,"content":"隔离级别 在事务 - 本地事务 中已经讲过4种事务隔离级别，这里补充一些别的方面。\n   事务A 事务B     启动事务\n查询得到值1 启动事务    查询得到值1    将1改成2   查询得到值V1     提交事务B   查询得到值V2    提交事务A    查询得到值V3     在不同隔离级别下，V1、V2、V3得到的是什么值：\n read uncommitted：V1=2、V2=2、V3=2。 read committed：V1=1、V2=2、V3=2。 repeatable read：V1=1、V2=1、V3=2。 serializable：V1=1、V2=1，同时“提交事务将1改成2时”会被锁住，事务A提交后才能继续，然后V3=2。  repeatable read的试用场景，你希望两次读得到的结果都一样，即使期间有其他事务在修改这个值。比如：\n 假设你在管理一个个人银行账户表。一个表存了每个月月底的余额，一个表存了账单明细。这时候你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。\n 事务隔离的实现 在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。\n假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。\n 从“read-view A、B、C”看到的值分别是1、2、4。MySQL通过MVCC（多版本并发控制）来实现的。read-view A得到的1实际上是从read-view C（当前值）一路回退得到的。\n回滚日志什么时候删除？当没有比它更早的read-view的时候，比如只要上面的read-view A存在，那么上面3个回滚日志都必须存在。\n长事务会导致大量回滚日志，因为只要事务没提交，MySQL就要保留可能会被这个事务用到的所有回滚日志，从而占用大量空间，回滚日志是保存在文件中的。\n启动事务的方式  显式的：begin / start transaction, commit / rollback。 隐式的：你执行select也会开启一个事务。  什么时候关闭事务：\n 显式的：commit / rollback。 隐式的：set autocommit=1。  所以如果set autocommit=0，则会让你无意当中开启了一个事务而不提交结果就造成了长事务。\ncommit work and chain可以让你提交事务之后立即再开启一个事务：\n1begin;23select1fromdual;45commitworkandchain;67select1fromdual;89commit;下面语句可以查询出超过60秒的长事务：\n1select*frominformation_schema.innodb_trxwhereTIME_TO_SEC(timediff(now(),trx_started))\u0026gt;60避免长事务  确保客户端设置了autocommit=1 如果是只读事务（只有select），那么就不需要begin/commit 设置SET MAX_EXECUTION_TIME控制单个语句（只针对Select）的最大执行时长 ","date":"2019-12-19","img":"","permalink":"/post/mysql/isolation/","series":null,"tags":["mysql"],"title":"MySQL - 事务隔离"},{"categories":null,"content":"docker测试：\n1docker run -d --name mysql8 \\ 2-e MYSQL_ROOT_PASSWORD=12345 \\ 3-e MYSQL_USER=test \\ 4-e MYSQL_PASSWORD=test \\ 5-e MYSQL_DATABASE=test \\ 6mysql:8 7 8docker exec -it mysql8 mysql -u test -p test 常见命令：\n 查看数据库连接：show processlist 查看数据库参数：show variables也可以模糊查询show variables like '%wait%' 执行shell命令：system ... 查询超过60秒的长事务： select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))\u0026gt;60; 重建索引：alter table T engine=InnoDB FLUSH TABLES WITH READ LOCK ：全局读锁 show index from \u0026lt;table\u0026gt;，显示某表的索引 show table status like '...'\\G，显示某表的统计信息  系统参数：\n 设置全局参数：set global xxx=yyy 持久全局参数：set persist xxx=yyy wait_timeout ：控制数据库连接多少时间没有动静就断开，默认8小时。 慢日志查询相关参数：show variables like '%slow%;和long_query_time（单位秒） slow_query_log ：是否开启慢日志查询 transaction_isolation ，查看数据库隔离级别 max_execution_time ，SELECT语句的最大执行时长 innodb_lock_wait_timeout ，事务获得行锁的最大等待时间（秒）。默认50秒。 innodb_deadlock_detect ，开启死锁检测。默认on。 binlog_expire_logs_seconds ，binlog的保留时间（秒），默认30天。 join_buffer_size ，在JOIN时用到的内存空间（byte）  InnoDB 参数：\n innodb_page_size ，数据页大小，默认16K innodb_change_buffering ，change buffer模式，默认all innodb_change_buffer_max_size ，change buffer占用buffer pool的比例 innodb_stats_persistent ，控制analyze table统计结果存在哪里  session参数：\n 设置Session参数：set xxx=yyy sql_log_bin ：控制当前session是否产生binlog。 ","date":"2019-12-18","img":"","permalink":"/post/mysql/commands-params/","series":null,"tags":["mysql","cheatsheet"],"title":"MySQL - 常见命令及参数"},{"categories":null,"content":"MySQL有两个日志模块，redo log和binlog。\nredo log redo log属于InnoDB存储引擎。实际上就是WAL（Write-Ahead Log），在写磁盘前（数据页）先写日志。\n并且写好日志之后先更新内存，直到一下两种情况时才同步到磁盘：\n 系统闲的时候 redo log写满的时候  InnoDB的redo log大小是固定的，4个文件每个文件1G。逻辑上可以认为是一个环。write pos是当前写到的位置，checkpoint则是已经同步到数据库的位置，在write pos和checkpoint之间的空白的可写日志区域，checkpoint之后的则是还未同步到磁盘的内容，每次同步一点内容，checkpoint都会往后移动。\n binlog 属于Server层（见MySQL - 基础架构 ），在InnoDB出现之前，MySQL一直依赖于binlog。\nbinlog的作用是用来归档。存储引擎可以使用binlog。\n两者区别  redo log是InnoDB引擎特有的，binlog则是属于Server的。 redo log记录的是物理操作，即怎么写“在某个数据页上做了什么修改“，很符合存储引擎的特点。binlog记录的是逻辑操作，比如某行数据的某个字段变成了什么值。 redo log记录的内容有限，前面说了4G内容。binlog则是无限的。  日志的2PC 举例说明redo log和binlog在update T set c=c+1 where ID=2;时是怎么工作的。\n 【执行器】问【存储引擎】要ID=2的行，如果该行所在数据页已经在内存中，则直接返回，如果不在则从磁盘中加载数据页，然后返回。这里很重要的信息是，更新操作首先是在内存中进行的，之后才会同步到磁盘。 【执行器】更新字段的值，调用【存储引擎】写入新值 【存储引擎】更新内存中的数据，把这个更新记录到redo log中，记录的是一条prepare日志，写到磁盘。 【执行器】生成这个操作的binlog，并写到磁盘。 【执行器】调用事务提交接口，把之前prepare日志改成commit状态。 结束  这个都是为了保证【服务层】和【存储引擎】的数据一致性。\n为何还要binlog？ binlog看似多余落后，为何redo log没有取代呢？\n redo log存储空间有限，binlog则无限。 redo log只有InnoDB可用，其他引擎不能用 历史原因，很多机制比如Master-Slave的数据复制使用的是binlog  数据库备份周期？ 是一天一备还是一周一备？根据什么来选择？\n根据你能承受的系统挂机时间来选择，备份的时间越近就能越快的恢复，反之则时间越长。这个很好理解，距离上次备份到现在所产生的binlog的大小决定了所要恢复的时间。\n","date":"2019-12-18","img":"","permalink":"/post/mysql/redo-log-binlog/","series":null,"tags":["mysql"],"title":"MySQL - Redo Log和binlog"},{"categories":null,"content":"当你执行一条SQL语句的时候，经过的MySQL组件有（未必是先后顺序）：客户端（你）、连接器、查询缓存、分析器、优化器、执行器、存储引擎。它们的职责是：\nServer层：\n 连接器：管理连接，权限验证。 查询缓存：故名思义，如果命中则直接返回结果 分析器：词法分析、语法分析 优化器：生成执行计划，索引选择 执行器：操作引擎，返回结果  存储引擎层：\n 存储引擎：存储数据，提供读写接口。存储引擎有多种选择，比如InnoDB（默认）、MyISAM（旧）、Memory。各有各的特性。   连接器  管理连接：show processlist可以看到当前连接的情况。如果连接长时间没有动静则会断开，默认8小时，由wait_timeout参数控制。 权限验证：客户端连接时先做认证（用户名密码对不对），然后查询出你所拥有的权限，之后这个连接的权限判断逻辑依赖于此时获得的数据。即连接创建之后的权限变更不会影响之前创建的连接。  连接占用内存，MySQL执行过程中临时占用的内存绑定在连接上，只有当连接断开才会释放。解决办法：\n 定时断开连接。 执行完占用大内存的查询后断开连接。 执行完占用大内存的查询后，执行mysql_reset_connection 来初始化连接资源（不会断开）。  查询缓存 在8.0里去掉了这个，因为这个查询缓存基本上没什么用处，理由：\n 缓存失效太平凡，只要对表有更新，就会失效 同时导致缓存命中率太低  分析器 识别你的SQL语句，判断是否符合MySQL语法。做词法分析。也可判断表名、列名是否合法。\n优化器 决定用哪个索引，在Join的时候决定表的连接顺序，最终确定执行方案。\n执行器 判断你对表T的操作权限。根据表定义的存储引擎调用引擎的接口。\n","date":"2019-12-18","img":"","permalink":"/post/mysql/basic-arch/","series":null,"tags":["mysql"],"title":"MySQL - 基础架构"},{"categories":null,"content":"Ingress Nginx默认只支持TLSv1.2，如果想要使其支持更旧版本，则需要修改它的ConfigMap，添加以下KV：\n1ssl-protocols: \u0026#34;TLSv1 TLSv1.1 TLSv1.2\u0026#34; 2ssl-ciphers: \u0026#34;ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA\u0026#34; 注意ssl-ciphers不是随便写的，你可通过Mozilla SSL Configuration Generator 生成。\n验证方法：\n你可用过curl来验证：curl --tlsv1 --tls-max 1.0 \u0026lt;url\u0026gt;，如果成功得到结果则说明服务端启用了TLSv1的支持。\n也可以使用mvance/testssl来验证，它能检查得更多：docker run --rm -it mvance/testssl -p \u0026lt;url\u0026gt;\n参考文档：\n Default TLS Version and Ciphers  SSL Ciphers  ","date":"2019-12-16","img":"","permalink":"/post/k8s/ingress-nginx-tlsv1/","series":null,"tags":["k8s","ingress"],"title":"让Ingress Nginx支持TLSv1的方法"},{"categories":null,"content":"诊断方法 方法一：启动一个诊断工具镜像的Deployment，在Pod上执行诊断脚本（一般都是进入shell）。\n方法二：启动一个诊断工具镜像的DaemonSet，这个方法在你怀疑某个工作节点存在问题时有用，因为DaemonSet会在所有工作节点上启动一个Pod实例，然后你只需要在每个Pod上执行诊断脚本即可。\n诊断工具镜像  busybox ，老牌工具箱，有nslookup、wget、ping、telnet。没有tcpdump、curl，略显不便。 nicolaka/netshoot ，更全面的网络工具箱。 ","date":"2019-12-12","img":"","permalink":"/post/k8s/diagnose-tools/","series":null,"tags":["k8s"],"title":"K8S的一些诊断工具镜像"},{"categories":null,"content":"先说说场景，你有一个StatefulSets，通过volumeClaimTemplate创建了PVC。现在这些PVC所关联的PV对你来说不够用了，你希望能够使用更大的PVC。\n大致步骤如下：\n 先把StatefulSets的Yaml备份下来。 利用busybox复制数据。 使用新PVC。 清理PVC。  下面是详细步骤：\n备份StatefulSets 把StatefulSets的Yaml备份下来，下面是代码片段，注意volumeClaimTemplate和volumeMounts部分：\n1apiVersion:apps/v12kind:StatefulSet3metadata:4name:zookeeper5# ...6spec:7# ...8template:9# ...10spec:11containers:12- image:ranchercharts/confluentinc-cp-zookeeper:5.3.013# ...14volumeMounts:15- mountPath:/var/lib/zookeeper/data16name:datadir17# ...18volumeClaimTemplates:19- metadata:20name:datadir21spec:22accessModes:23- ReadWriteOnce24resources:25requests:26storage:5Gi27volumeMode:Filesystem然后删掉它，删掉StatefulSets不会删除对应的PVC。\n复制数据 StatefulSets的volumeClaimTemplate所生成的PVC的名字是这样的格式：{volume-name}-{statefulsets-name}-数字，比如datadir-zookeeper-0。\n所以我们可以创建一个busybox StatefulSets，名字也是zookeeper，并且它的volumeClaimTemplate和原来的一样，这样它就可以使用旧PVC了。同时它还得创建一个新的volumeClaimTemplate来创建新的PVC。\n注意replicas得和原来的一样。\n下面是例子：\n1apiVersion:apps/v12kind:StatefulSet3metadata:4name:zookeeper5spec:6podManagementPolicy:OrderedReady7# 得和原来的一样8replicas:39selector:10matchLabels:11app:busybox-pvc-migration12serviceName:portal-cp-zookeeper13template:14metadata:15labels:16app:busybox-pvc-migration17spec:18containers:19- image:busybox20imagePullPolicy:Always21name:zookeeper22stdin:true23tty:true24volumeMounts:25# 旧PVC26- mountPath:/datadir-old27name:datadir28# 新PVC29- mountPath:/datadir-new30name:datadir-new31dnsPolicy:ClusterFirst32restartPolicy:Always33updateStrategy:34type:RollingUpdate35volumeClaimTemplates:36# 旧claim37- metadata:38name:datadir39spec:40accessModes:41- ReadWriteOnce42resources:43requests:44storage:5Gi45volumeMode:Filesystem46# 新claim47- metadata:48name:datadir-new49spec:50accessModes:51- ReadWriteOnce52resources:53requests:54storage:10Gi55volumeMode:Filesystem进入每个busybox的shell，复制旧PVC的内容到新的PVC：\n1cp -r /datadir-old/* /datadir-new/ 复制完之后注意检查一下文件的权限和所属用户与用户组。\n最后删除busybox。同理，它所新建的PVC也不会被删除，这些PVC后面要被使用。\n使用新PVC 修改之前备份下来的Yaml，让它使用新的PVC，修改volumeClaimTemplate和volumeMounts部分：\n1apiVersion:apps/v12kind:StatefulSet3metadata:4name:zookeeper5# ...6spec:7# ...8template:9# ...10spec:11containers:12- image:ranchercharts/confluentinc-cp-zookeeper:5.3.013# ...14volumeMounts:15- mountPath:/var/lib/zookeeper/data16# 使用了新的PVC17name:datadir-new18# ...19volumeClaimTemplates:20- metadata:21# 使用了新的PVC22name:datadir-new23spec:24accessModes:25- ReadWriteOnce26resources:27requests:28storage:10Gi29volumeMode:Filesystem清理PVC 确认没有问题后，可以清理掉旧的PVC。\n","date":"2019-12-09","img":"","permalink":"/post/k8s/statefulsets-pv-migration/","series":null,"tags":["k8s"],"title":"StatefulSets迁移PV的方法"},{"categories":null,"content":"场景概述：假设你有个N个服务器，你想要把你的数据均匀的分配到这N个服务器中，并且每次取数据的时候到对应的服务器去取。\n方案一：轮询+字典表 给数据生成一个key，轮询的方式把数据存到这N个服务器中，并且保存一个key-\u0026gt;服务器的字典。\n增加服务器时：老服务器总是会比新服务器存更多数据\n删除服务器时：需要更新字典，因为某些key对应的服务器已经不存在了\n优点：很均匀\n缺点：需要维护字典，这个有额外开销。同时这个字典会变成瓶颈。\n方案二：hash取模分配 给数据生成一个key，取数据和存数据的时候都用serverIndex = hash(key) mod N得到服务器编号。关于hash函数，得使用结果均匀的算法，Java的hashCode不均匀，有以下选择：\n SHA-1 和 MD5 均匀，但他们是密码学算法，比较耗CPU MurmurHash ，开销低一点 还有非密码学算法：xxHash ，MetroHash ，MetroHash   增加服务器时：所有的key都得重新取模\n删除服务器时：所有的key都得重新取模\n优点：没有保存字典的开销\n缺点：增加和删除服务器的时候需要移动所有key\n方案三：一致性hash 一致性hash为了解决前一种方案的缺点，提出了一种可以在增加or删除服务器的时候只移动1/N个key的办法。\n想象有一个环，上面有232个点，每个服务器在这个环上都有一个点，给定一个key怎么找对应的服务器？先hash(key)得到它所在的点，然后顺时针找到第一个服务器：\n当增加or删除服务器的时候，key沿着顺时针找到下一个服务器就行，如果服务器在环上的分布均匀（即间隔均匀），那么也就只有1/N的会产生移动。\n但是随着服务器的增加or删除，总是会不均匀，因此我们可以给服务器增加分身（即虚拟节点）：\n可以看到A、B、C三个服务器在环上的位置不止一个，这样就能解决key分布不均匀的问题。\n参考代码 感谢Tom White - Consistent Hashing ，他给出了一种Java的参考实现：\n1public class ConsistentHash\u0026lt;T\u0026gt; { 2 3 private final HashFunction hashFunction; 4 // 每个服务器有几个分身，即虚拟节点 5 private final int numberOfReplicas; 6 private final SortedMap\u0026lt;Integer, T\u0026gt; circle = 7 new TreeMap\u0026lt;Integer, T\u0026gt;(); 8 9 public ConsistentHash(HashFunction hashFunction, 10 int numberOfReplicas, Collection\u0026lt;T\u0026gt; nodes) { 11 12 this.hashFunction = hashFunction; 13 this.numberOfReplicas = numberOfReplicas; 14 15 for (T node : nodes) { 16 add(node); 17 } 18 } 19 20 public void add(T node) { 21 for (int i = 0; i \u0026lt; numberOfReplicas; i++) { 22 // 给服务器加编号的形式产生虚拟节点 23 circle.put(hashFunction.hash(node.toString() + i), 24 node); 25 } 26 } 27 28 public void remove(T node) { 29 for (int i = 0; i \u0026lt; numberOfReplicas; i++) { 30 // 删除服务器的所有虚拟节点 31 circle.remove(hashFunction.hash(node.toString() + i)); 32 } 33 } 34 35 public T get(Object key) { 36 if (circle.isEmpty()) { 37 return null; 38 } 39 int hash = hashFunction.hash(key); 40 if (!circle.containsKey(hash)) { 41 SortedMap\u0026lt;Integer, T\u0026gt; tailMap = 42 // tailMap方法返回大于等于key的第一个key及其之后的数据，得到当前Map的视图 43 circle.tailMap(hash); 44 // 如果tailMap为空，那么就去环中的第一个节点，否则就去tailMap的第一个节点 45 // 相当于顺时针找服务器 46 hash = tailMap.isEmpty() ? 47 circle.firstKey() : tailMap.firstKey(); 48 } 49 return circle.get(hash); 50 } 51 52} 代价 那么每个服务器多少个虚拟节点才能使得分布均匀呢？\nConsistent Hashing: Algorithmic Tradeoffs 提到：\n 每个服务器100个虚拟节点，负载的标准差为10%，1000个虚拟节点时负载的标准差为~3.2%。这就意味着具有较大的内存开销\n 不过我认为你有100台服务器，每个1,000个虚拟节点，Map中放100,000个entry占用的空间也不大。\n这篇文章里也提到了更多其他的算法，各有利弊。\n参考资料  Tom White - Consistent Hashing ，介绍了基本概念 Consistent Hashing: Algorithmic Tradeoffs ，提到了更多算法实现及利弊 Distributing Content to Open Connect ，提到了服务器本身规格有差别的情况 Consistent Hashing in Cassandra  ","date":"2019-12-04","img":"","permalink":"/post/consistent-hashing/","series":null,"tags":["分布式架构","分布式算法"],"title":"一致性Hash笔记"},{"categories":null,"content":"乐观锁 伪代码如下：\n1do { 2 oldCount = getCount(itemid) 3 if (oldCount \u0026lt;= 0) { 4 return false 5 } 6 newCount = oldCount - 1; 7} while (!compareAndSwap(itemid, newCount, oldCount)) 8return true 主要是解决check-then-act的问题，因此真正更新Redis的时候要检查oldCount是否有变化。\n很遗憾，你无法使用Redis的Optimistic locking using check-and-set 来实现compareAndSet，需要使用LUA脚本来：\n1-- Usage: EVAL \u0026#34;\u0026lt;this script\u0026gt;\u0026#34; 1 \u0026lt;key\u0026gt; \u0026lt;new-value\u0026gt; \u0026lt;old-value\u0026gt; 2local key = KEYS[1] 3local newValue = ARGV[1] 4local expectedOldValue = ARGV[2] 5 6local oldValue = redis.call(\u0026#39;GET\u0026#39;, key) 7 8if oldValue == expectedOldValue then 9 redis.call(\u0026#39;SET\u0026#39;, key, newValue) 10 return \u0026#34;OK\u0026#34; 11end 12return nil 乐观锁的实现比较复杂，每次更新时都得判断数据是否发生变化，且多了几次查询动作，增加了网络开销。\n利用List 有一个讨巧的思路是构建一个Redis List，一个商品有100个，那么List中就有100个元素，增加元素时RPUSH，删除元素时LPOP。当LPOP失败的时候，说明List空了，说明商品卖光了。\n这个方法的优点在于只需要一次LPOP的动作，伪代码：\n1if (nil != redis.lpop(itemid)) { 2 return true 3} 4return false 这个方法的缺陷在于浪费了Redis的空间，事先维护List也是一项工作。\nLUA脚本 还可以更激进一点，把整个秒杀逻辑放在LUA脚本里。因为Redis是单线程的，执行命令是串行的，在Redis里执行LUA脚本能够避免并发环境下的check-then-act错误。下面一个LUA脚本（原始链接 ）的例子：\n1-- Usage: EVAL \u0026#34;\u0026lt;this script\u0026gt;\u0026#34; 1 \u0026lt;good-id\u0026gt; \u0026lt;activity-id\u0026gt; \u0026lt;user-id\u0026gt; 2-- KEYS [good-id] 3-- ARGV [activity-id,user-id] 4-- return -1:库存不足 0:重复购买 1:成功 5 6local good = KEYS[1] 7local activity = ARGV[1] 8local uid = ARGV[2] 9local gooduids = good .. \u0026#39;:\u0026#39; .. activity .. \u0026#39;:uids\u0026#39; 10 11local isin = redis.call(\u0026#39;SISMEMBER\u0026#39;, gooduids, uid) 12 13if isin \u0026gt; 0 then 14 return 0 15end 16 17local goodstock = good .. \u0026#39;:\u0026#39; .. activity .. \u0026#39;:stock\u0026#39; 18local stock = redis.call(\u0026#39;GET\u0026#39;, goodstock) 19 20if not stock or tonumber(stock) \u0026lt;= 0 then 21 return -1 22end 23 24redis.call(\u0026#39;DECR\u0026#39;, goodstock) 25redis.call(\u0026#39;SADD\u0026#39;, gooduids, uid) 26return 1 27-- ———————————————— 28-- 版权声明：本文为CSDN博主「姚仔」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。 LUA脚本来实现业务和用数据库存储过程来实现业务一样，具有灵活性不够、难以维护的问题。如果秒杀业务再复制一点，相信LUA脚本就会变得难以维护。如果秒杀业务需要外部系统的信息，则LUA脚本就不能胜任了。\n","date":"2019-12-03","img":"","permalink":"/post/redis/redis-lua-miaosha/","series":null,"tags":["redis","高并发","微服务"],"title":"Redis解决超卖问题的方案汇总"},{"categories":null,"content":"如果你的应用部署在K8S上，replicas \u0026gt; 1，且你的应用是基于Session的，同时又没有做Session共享or复制，那么你是不能通过NodePort Service来暴露应用的，因为Service只支持一种策略，就是轮询，这样会导致用户的Session丢失。\n默认的Ingress的配置也是轮询的，但是你可以启用基于Cookie的粘滞策略，当用户第一次访问的时候会得到一个Cookie，该Cookie记录了所访问的Pod，再下一次访问的时候Nginx Ingress Controller会将请求转发到同一个Pod上，从而实现Session粘滞。\n关键的三个Annotation：\n nginx.ingress.kubernetes.io/affinity: cookie nginx.ingress.kubernetes.io/affinity-mode: persistent nginx.ingress.kubernetes.io/session-cookie-name: \u0026lt;name\u0026gt;，一定要设置cookie name，避免不同ingress使用相同的cookie name导致冲突。  更多参考Session Affinity 和Sticky Sessions 。\n","date":"2019-12-03","img":"","permalink":"/post/k8s/ingress-nginx-session-cookie-sticky/","series":null,"tags":["k8s","ingress"],"title":"Nginx Ingress的Cookie粘滞策略"},{"categories":null,"content":"语境  微服务架构下，各服务之间的依赖层级关系复杂，甚至成网状 依赖：A调用B，称为A依赖B，也可称A有一个对B对依赖 Client：依赖的形式基本上是A使用B提供的client来调用B，也可以是A使用HttpClient这样的通用client来调用B  能做什么？  避免因一个节点的超时，导致下游节点级联式的请求堆积，崩溃整个系统 避免对一个故障节点发出请求，节省网络资源 快速失败 相对快速的恢复：侦测节点，恢复通信 熔断时的降级 一些报警，监控，运行时控制的功能 hystrix不仅仅局限于网络通信，用在其他地方也是可以的  设计原则  防止单个依赖用尽容器（如Tomcat）的所有线程 使用减载和快速失败，而不是排队 提供fallback 使用隔离技术（隔离舱，泳道，熔断器模式）限制单个依赖所能产生的影响 防止整个客户端的执行失败，而不只是网络流量 支持运行时修改配置  架构  对外部系统调用的包装：HystrixCommand、HystrixObservableCommand 超时阈值：建议稍微低于99.5%线 每个依赖有一个小线程池或者信号量：线程池满了的话则直接拒绝 指标：成功数、失败数（客户端异常数）、超时数、线程拒绝数 熔断：错误数超过比例自动熔断，也可手动熔断 fallback（降级）：请求失败时、超时时、拒绝时、熔断时 近实时修改：监控指标和配置变更  断路器 三个状态：OPEN、CLOSED、HALF-OPEN\nOPEN 意思：断开，请求被直接短路 触发条件：\n 当断路器流量达到基础值 failure比例到达设定阈值  维持时间：通过参数控制，比如1秒\nCLOSED 意思：闭合，请求可以通过\nHALF-OPEN 意思：半开，如果下一个请求成功则闭合，否则断开 触发条件：在OPEN之后过了一段时间变成半开状态，时间可设置 状态迁移：\n 在HALF-OPEN之后第一个请求成功 -\u0026gt; CLOSED 失败 -\u0026gt; OPEN  隔离机制 线程池  为单个Client提供一个线程池（5-20个线程） 将Caller线程（如Tomcat线程）和实际工作线程解耦 不会阻塞Caller线程 开销：任务排队、调度、上下文切换  信号量  为单个Client提供一个Semaphore caller线程和实际工作线程同一个 会阻塞Caller线程 开销：比线程池模式小多了  请求折叠  在一段时间里对同一个依赖的请求折叠起来，变成一个请求，降低对依赖的实际并发数，比如把get 100个id的动作合并成一个 怎么折叠要用户自己实现 代价：会增加一定的延迟，因为要等待一批请求折叠起来  请求缓存  把在同一请求上下文内的重复请求去重，比如在同一请求内，调用了两次getById(1) 在代码复杂的时候，你很难避免重复调用的代码路径存在 ","date":"2019-12-03","img":"","permalink":"/post/hystrix-note/","series":null,"tags":["微服务","分布式架构","hystrix"],"title":"Netflix Hystrix笔记"},{"categories":null,"content":"什么是内存模型 以下因素会阻止一个线程看到变量的最新值，导致在其他线程的内存操作看起来不按顺序发生：\n 编译器生成的指令的顺序可以和源代码的顺序不同 编译器可以把变量存到寄存器而不是内存 处理器可以并行执行指令，或者不按顺序执行指令 cache可能使得对变量的写以不同的顺序提交到main memory 保存在处理器本地cache中的值可能对其他处理器不可见  Java语言规范要求JVM维持“线程内看起来顺序执行的语义”。\n为何会有以上因素：\n CPU的并行度的增加：pipelined superscalar执行单元，动态指令调度，speculative execution（投机执行），成熟的多级缓存。 编译器变得更复杂：充安排指令以优化执行，使用成熟的全局寄存器分配算法。  平台内存模型 多处理器架构，每个处理器有它自己的cache定时和主内存保持一致。\n处理器架构提供了不同程度的cache coherence，缓存一致性。\n确保每个处理器在任何时刻知道其他处理器在干什么代价是很高的。\n一个架构的“内存模型”告诉程序它能够从内存系统得到怎样的保证，并规定了在共享数据时哪些特殊指令（称为内存屏障或者fence）可以得到额外的内存协调保证。\nJava内存模型屏蔽了不同架构的内存模型，提供了一种抽象，它会在何时的地方插入内存屏障。\nJava内存模型也不提供顺序一致性，现代多处理器架构也不支持顺序一致性。\n重排序 下面这段代码从代码顺序来说，可能的结果是：(1, 0)，(0, 1)，(1, 1)。但还有可能是 (0, 0)。\n1public class PossibleReordering { 2 static int x = 0, y = 0; 3 static int a = 0, b = 0; 4 5 public static void main(String[] args) throws InterruptedException { 6 // Thread A 7 Thread one = new Thread(new Runnable() { 8 public void run() { 9 a = 1; 10 x = b; 11 } 12 }); 13 // Thread B 14 Thread other = new Thread(new Runnable() { 15 public void run() { 16 b = 1; 17 y = a; 18 } 19 }); 20 one.start(); 21 other.start(); 22 one.join(); 23 other.join(); 24 System.out.println(\u0026#34;( \u0026#34; + x + \u0026#34;,\u0026#34; + y + \u0026#34;)\u0026#34;); 25 } 26} 前面将了代码重排序的原因，实际上就算代码按顺序执行，因为cache刷新到主内存的时机也可能使B线程看到A是以相反顺序执行的。\n1Thread A ---\u0026gt; x=b(0) ----------------------\u0026gt; a=1 2Thread B --------------\u0026gt; b=1 -----\u0026gt; y=a(0) 同步（synchronization）禁止了编译器、运行时和硬件对内存操作做出能够违反JMM要求的可见性保证的重排序。注意是可以重排序的，支持禁止了哪些会违反可见性保证的重排序。\nhappens-before：要确保操作B能够看到操作A的结果（不论A和B是否在相同线程中），它们必须有happens-before关系。如果没有happens-before，那么JVM可以随意重排序。\nhappens-before规则：\n  程序顺序规则：同一个线程里的操作happens-before程序顺序中的后一个操作。\n  内置锁规则：unlock 内置锁happens-before后续lock这个锁。\n  volatile变量规则：对volatile变量的写happens-before后续对这个变量的读。\n  线程开始规则：线程start happens-before 这个线程里的动作。\n  线程终止：A线程里的动作 happens-before 侦测到这个线程终止的B线程的动作。Thread.join 和 Thread.isAlive 都适用该规则。\n  中断规则：A线程调用B线程的interrupt方法 happens-before B侦测到中断。B无论是收到InterruptedException，调用isInterrupted或者interrupted方法都适用该规则。\n  Finalizer规则：构造函数的结束 happens-before 该对象finalizer的开始。\n  传递性规则：如果A happens-before B，B happens-before C，那么A也happens-before C。\n  扩展规则（接力式同步）：\n put item到线程安全集合happens-before在其他线程里从这个集合里get countDown CountDownLatch happens-before 一个线程从 await 返回 （AQS的release） 释放一个Semaphore的permit happens-before 从这个Semaphore获取permit （AQS的release） Future代表的任务所执行的动作 happens-before 其他线程从Future.get返回 提交Runnable / Callable 到Executor happens-before 任务执行 一个线程到达 CyclicBarrier/Exchanger happens-before 从同一个barrier/exchanger释放到其他线程。如果CyclicBarrier使用barrier action，那么到达CyclicBarrier happens-before barrier action，进而happens-before 从barrier释放到线程。  注意传递性规则，看这个图，线程A的所有操作happens-before 线程B的所有操作：\n1 [Thread A] 2 y=1 3 lock M 4 x=1 [Thread B] 5 unlock M ------------------\u0026gt; lock M 6 i=x 7 unlock M 8 j=y 接力式同步 把一个happens-before规则和另一个happens-before规则结合起来，一般都是volatile变量 或者 内置锁，使得对一个变量的访问有序。不过这个技巧对语句的顺序很敏感，也容易被破坏，所以这个是榨取性能的最后武器，一般不推荐使用。\n下面这段代码看不到什么锁，但是能够保证不被重排序是因为间接的使用了同一个volatile变量：\n1 private final class Sync extends AbstractQueuedSynchronizer { 2 /** State value representing that task is ready to run */ 3 private static final int READY = 0; 4 /** State value representing that task is running */ 5 private static final int RUNNING = 1; 6 /** State value representing that task ran */ 7 private static final int RAN = 2; 8 /** State value representing that task was cancelled */ 9 private static final int CANCELLED = 4; 10 /** The result to return from get() */ 11 private V result; 12 /** The exception to throw from get() */ 13 private Throwable exception; 14 15 V innerGet() throws InterruptedException, ExecutionException { 16 // 间接调用了tryAcquireShared -\u0026gt; 读取 volatile state变量 17 acquireSharedInterruptibly(0); 18 if (getState() == CANCELLED) 19 throw new CancellationException(); 20 if (exception != null) 21 throw new ExecutionException(exception); 22 return result; 23 } 24 25 void innerSet(V v) { 26 for (;;) { 27 int s = getState(); 28 if (s == RAN) 29 return; 30 if (s == CANCELLED) { 31 // 间接调用了tryReleaseShared -\u0026gt; 写 volatile state变量 32 releaseShared(0); 33 return; 34 } 35 if (compareAndSetState(s, RAN)) { 36 result = v; 37 // 间接调用了tryReleaseShared -\u0026gt; 写 volatile state变量 38 releaseShared(0); 39 done(); 40 return; 41 } 42 } 43 } 44 } 发布 不正确发布的风险正是发布共享对象的线程和访问该对象的线程缺少happens-before的结果。\n不安全发布 看下面这段代码，new Resource()里有对Resource内部属性的写，发布这个对象则是对resource变量的写，两者之间缺乏happens-before关系，那么就意味着这些操作可能会重排序，也就意味着其他线程可能会看到一个构造不完全的对象：\n1@NotThreadSafe 2public class UnsafeLazyInitialization { 3 private static Resource resource; 4 5 public static Resource getInstance() { 6 if (resource == null) 7 resource = new Resource(); // unsafe publication 8 return resource; 9 } 10 11 static class Resource { 12 } 13} 安全发布 举个队列的例子，如果A放X到队列的动作happens-before B从队列中取出B，那么不仅B能看到A所留下的X的状态，B也能看到A在传递X之前的所有动作。\n安全法发布惯用法 添加了synchronized（用的是内置锁规则）：\n1@ThreadSafe 2public class SafeLazyInitialization { 3 private static Resource resource; 4 5 public synchronized static Resource getInstance() { 6 if (resource == null) 7 resource = new Resource(); 8 return resource; 9 } 10 11 static class Resource { 12 } 13} 也可以利用JVM初始化类时，初始化其静态变量串行话（使用了锁）的事实：\n1@ThreadSafe 2public class EagerInitialization { 3 private static Resource resource = new Resource(); 4 5 public static Resource getResource() { 6 return resource; 7 } 8 9 static class Resource { 10 } 11} 再Hack一点，弄个懒加载：\n1@ThreadSafe 2public class ResourceFactory { 3 private static class ResourceHolder { 4 public static Resource resource = new Resource(); 5 } 6 7 public static Resource getResource() { 8 return ResourceFactory.ResourceHolder.resource; 9 } 10 11 static class Resource { 12 } 13} Double-checked locking 下面这段代码就是臭名昭著的DCL：\n1@NotThreadSafe 2public class DoubleCheckedLocking { 3 private static Resource resource; 4 5 public static Resource getInstance() { 6 if (resource == null) { // 这行代码并未同步，因此会看到构造不完全的对象 7 synchronized (DoubleCheckedLocking.class) { 8 if (resource == null) 9 resource = new Resource(); 10 } 11 } 12 return resource; 13 } 14 15 static class Resource { 16 17 } 18} JDK 1.5之后，可以把resource变量变成volatile解决这个问题（因为有了Happens-before）\n初始化安全 “初始化安全”的保证，允许正确构建的不可变对象，安全的在线程间共享，而不需要同步，且不用考虑这个对象是如何发布的。也就是说如果上面代码Resource是不可变的，那就没有DCL的问题。\n对于对象的final属性，初始化安全机制禁止对任何构造函数的代码和初始加载该对象引用做重排序。例外：\n 非final属性没有这个保证 在构造期间对象逃逸了，也没有这个保证 这个保证只针对于可以通过final属性得到的值有效，可认为具有传递性  下面代码是安全发布的，可以看到SafeStates是不可变的，states也只不过是HashMap，但SafeStates依然能够以和前面的Resource一样的形式安全发布：\n1@ThreadSafe 2public class SafeStates { 3 private final Map\u0026lt;String, String\u0026gt; states; 4 5 public SafeStates() { 6 states = new HashMap\u0026lt;String, String\u0026gt;(); 7 states.put(\u0026#34;alaska\u0026#34;, \u0026#34;AK\u0026#34;); 8 states.put(\u0026#34;alabama\u0026#34;, \u0026#34;AL\u0026#34;); 9 /*...*/ 10 states.put(\u0026#34;wyoming\u0026#34;, \u0026#34;WY\u0026#34;); 11 } 12 13 public String getAbbreviation(String s) { 14 return states.get(s); 15 } 16} ","date":"2019-11-26","img":"","permalink":"/post/concurrent-programming/jmm/","series":null,"tags":["并发编程"],"title":"The Java Memory Model"},{"categories":null,"content":"非阻塞算法比基于锁的算法设计起来和实现起来更复杂，但是\n 它们能够提供巨大的伸缩性和liveness优势。 它们在一个更细粒度的层级上协作，能够极大降低调度的开销。 对死锁和其他liveness问题免疫。  CAS和锁的优劣 锁的劣势 如果多个线程同时请求锁，JVM会请求操作系统的帮助：\n 一些线程会被挂起（suspended），在后面还不得不恢复（resumed）——上下文切换。 线程恢复的时候，它还得等其他线程把它们的时间片用完，然后才能轮到它——调度。  基于锁的类在细粒度的操作上，如果竞争频繁，那么调度开销对实际工作的比率是非常高的。\n锁的其他劣势：\n 当一个线程在等待锁的时候，它干不了别的事情 优先级倒置（priority inversion），高优先级线程等待一个被低优先线程占用的锁。 锁对于细粒度操作比如++来说，还是太重量级了  锁的优势  用起来方便，语法紧凑 可以方便的组合复杂操作  CAS的优势  在【少量竞争】和【没有竞争】的情况下基于CAS的表现要比基于锁的好，因为：  无竞争锁获取的fast path，包括至少一个CAS操作 大多数情况下CAS能够成功，硬件可以预测分支，降低控制逻辑的开销 锁虽然在语法上紧凑，但实际上包含了相对复杂的JVM代码，并且可能使用操作系统级别的locking、线程挂起、上下文切换。这些CAS没有。    CAS的劣势  把处理竞争的工作交给了调用方：是重试，然是backing off，还是放弃。 对细粒度操作比较友好  硬件对并发的支持 对于细粒度操作来说可以用一种乐观的机制（锁是悲观的），这种机制依赖于“冲突检测”，检查在操作期间是否有其他线程插入进来，如果有则操作失败，然后可以选择重试还是不重试。\n处理器支持的指令：\n test-and-set fetch-and-increment compare-and-swap load-linked/store-conditional  Compare and swap CAS有三个操作数：内存地址V、预期的旧值A、新值B\n语义：如果V中的值等于A，那么就更新为B，否则啥都不做\n返回值：V中的值\nCAS操作失败的线程不会阻塞，它可自行决定是否重试，或者其他措施。\n下面是一个模拟的CAS：\n1@ThreadSafe 2public class SimulatedCAS { 3 @GuardedBy(\u0026#34;this\u0026#34;) private int value; 4 5 public synchronized int get() { 6 return value; 7 } 8 9 public synchronized int compareAndSwap(int expectedValue, 10 int newValue) { 11 int oldValue = value; 12 if (oldValue == expectedValue) 13 value = newValue; 14 return oldValue; 15 } 16 17 public synchronized boolean compareAndSet(int expectedValue, 18 int newValue) { 19 return (expectedValue 20 == compareAndSwap(expectedValue, newValue)); 21 } 22} 一个非阻塞的计数器 下面是一个非阻塞的计数器的例子：\n1@ThreadSafe 2public class CasCounter { 3 private SimulatedCAS value; 4 5 public int getValue() { 6 return value.get(); 7 } 8 9 public int increment() { 10 int v; 11 do { 12 v = value.get(); 13 } while (v != value.compareAndSwap(v, v + 1)); 14 return v + 1; 15 } 16} Atomic Variable classes 更新一个原子变量的\n fast path（无竞争）不比获得锁的fast path慢，并且通常更快。 slow path（有竞争）绝对比获得锁的slow path快，因为没有线程挂起和调度开销。  Atomics vs “better volatiles” 1@ThreadSafe 2public class CasNumberRange { 3 @Immutable 4 private static class IntPair { 5 // INVARIANT: lower \u0026lt;= upper 6 final int lower; 7 final int upper; 8 9 public IntPair(int lower, int upper) { 10 this.lower = lower; 11 this.upper = upper; 12 } 13 } 14 15 private final AtomicReference\u0026lt;IntPair\u0026gt; values = 16 new AtomicReference\u0026lt;IntPair\u0026gt;(new IntPair(0, 0)); 17 18 public int getLower() { 19 return values.get().lower; 20 } 21 22 public int getUpper() { 23 return values.get().upper; 24 } 25 26 // 单改lower，所以用AtomicReference 27 public void setLower(int i) { 28 while (true) { 29 /*see*/ IntPair oldv = values.get(); 30 if (i \u0026gt; oldv.upper) 31 throw new IllegalArgumentException(\u0026#34;Can\u0026#39;t set lower to \u0026#34; + i + \u0026#34; \u0026gt; upper\u0026#34;); 32 /*see*/ IntPair newv = new IntPair(i, oldv.upper); 33 /*see*/ if (values.compareAndSet(oldv, newv)) 34 return; 35 } 36 } 37 38 public void setUpper(int i) { 39 while (true) { 40 IntPair oldv = values.get(); 41 if (i \u0026lt; oldv.lower) 42 throw new IllegalArgumentException(\u0026#34;Can\u0026#39;t set upper to \u0026#34; + i + \u0026#34; \u0026lt; lower\u0026#34;); 43 IntPair newv = new IntPair(oldv.lower, i); 44 if (values.compareAndSet(oldv, newv)) 45 return; 46 } 47 } 48} 锁和原子变量 代码就不贴了，说结论：\n 在高竞争等级下，锁要比原子变量好那么一点点（吞吐量）。为什么？因为原子变量的版本在失败后立马又重试了，反而加剧了竞争。 但是现实中竞争等级没有那么高，所以原子变量比锁要好挺多（吞吐量）。  总结：\n 在低竞争等级下，原子变量提供了更好的伸缩性。 在高竞争等级下，锁提供了更好的竞争规避  非阻塞算法 如果一个算法是“非阻塞”的，那么当一个线程失败或者挂起的时候，都不会导致其他线程的失败或挂起（你可以认为没有死锁）。\n如果一个算法是“无锁”的，那么在每一步上，总有一些线程可以取得进展。\n一个非阻塞栈 注意：compareAndSet同时提供了可见性和原子性。\n1@ThreadSafe 2 public class ConcurrentStack \u0026lt;E\u0026gt; { 3 AtomicReference\u0026lt;Node\u0026lt;E\u0026gt;\u0026gt; top = new AtomicReference\u0026lt;Node\u0026lt;E\u0026gt;\u0026gt;(); 4 5 public void push(E item) { 6 Node\u0026lt;E\u0026gt; newHead = new Node\u0026lt;E\u0026gt;(item); 7 Node\u0026lt;E\u0026gt; oldHead; 8 do { 9 oldHead = top.get(); 10 newHead.next = oldHead; 11 } while (!top.compareAndSet(oldHead, newHead)); 12 } 13 14 public E pop() { 15 Node\u0026lt;E\u0026gt; oldHead; 16 Node\u0026lt;E\u0026gt; newHead; 17 do { 18 oldHead = top.get(); 19 if (oldHead == null) 20 return null; 21 newHead = oldHead.next; 22 } while (!top.compareAndSet(oldHead, newHead)); // 看top是否变更过 23 return oldHead.item; 24 } 25 26 private static class Node \u0026lt;E\u0026gt; { 27 public final E item; 28 public Node\u0026lt;E\u0026gt; next; 29 30 public Node(E item) { 31 this.item = item; 32 } 33 } 34} 一个非阻塞链表 构建非阻塞的算法的关键在于限定原子性变更仅限定在单个变量上，如果有多个变量要原子性更新，那么需要一些技巧：\n第一个技巧，保证数据结构总是处于一致性的状态下，就算在一个多步骤更新的当中也是如此。如果A更新到一半B进来了，B可以知道这个情况，并且不会立即做自己的更新，B可以等待A完成，这样两个就不会互相影响了。\n如果A操作在半当中失败了，那么B操作就永远没法获得进展，这个时候就可以有第二个技巧来确保一个线程的失败不会导致另一个线程无法进展。\n第二，如果B操作发现数据结构处于A操作当中状态时，B有足够的信息帮助A把接下来的事情完成，然后在把自己的事情做掉。当A回来的时候会发现自己没做完的事情已经被B做了。\n下面是一个LinkedQueue的例子，具体讲解要看书，这里点两个关键：\n 当结构处在完整状态时，tail.next是不为null的 当结构处在中间状态时，tail.next是为null的  1@ThreadSafe 2public class LinkedQueue \u0026lt;E\u0026gt; { 3 4 private static class Node \u0026lt;E\u0026gt; { 5 final E item; 6 final AtomicReference\u0026lt;LinkedQueue.Node\u0026lt;E\u0026gt;\u0026gt; next; 7 8 public Node(E item, LinkedQueue.Node\u0026lt;E\u0026gt; next) { 9 this.item = item; 10 this.next = new AtomicReference\u0026lt;LinkedQueue.Node\u0026lt;E\u0026gt;\u0026gt;(next); 11 } 12 } 13 14 private final LinkedQueue.Node\u0026lt;E\u0026gt; dummy = new LinkedQueue.Node\u0026lt;E\u0026gt;(null, null); 15 private final AtomicReference\u0026lt;LinkedQueue.Node\u0026lt;E\u0026gt;\u0026gt; head 16 = new AtomicReference\u0026lt;LinkedQueue.Node\u0026lt;E\u0026gt;\u0026gt;(dummy); 17 private final AtomicReference\u0026lt;LinkedQueue.Node\u0026lt;E\u0026gt;\u0026gt; tail 18 = new AtomicReference\u0026lt;LinkedQueue.Node\u0026lt;E\u0026gt;\u0026gt;(dummy); 19 20 public boolean put(E item) { 21 LinkedQueue.Node\u0026lt;E\u0026gt; newNode = new LinkedQueue.Node\u0026lt;E\u0026gt;(item, null); 22 while (true) { 23 LinkedQueue.Node\u0026lt;E\u0026gt; curTail = tail.get(); 24 LinkedQueue.Node\u0026lt;E\u0026gt; tailNext = curTail.next.get(); 25 if (curTail == tail.get()) { 26 /*A*/ if (tailNext != null) { 27 // Queue in intermediate state, advance tail 28 /*B*/ tail.compareAndSet(curTail, tailNext); 29 } else { 30 // In quiescent state, try inserting new node 31 /*C*/ if (curTail.next.compareAndSet(null, newNode)) { 32 // Insertion succeeded, try advancing tail 33 /*D*/ tail.compareAndSet(curTail, newNode); 34 return true; 35 } 36 } 37 } 38 } 39 } 40} Atomic field updaters AtomicReferenceFieldUpdater：\n1private class Node\u0026lt;E\u0026gt; { 2 private final E item; 3 private volatile Node\u0026lt;E\u0026gt; next; 4} 5private static AtomicReferenceFieldUpdater\u0026lt;Node, Node\u0026gt; nextUpdater 6 = AtomicReferenceFieldUpdater.newUpdater(Node.class, Node.class, \u0026#34;next\u0026#34;); Atomic field updater代表了一个对volatile字段的反射视图，然后你可以利用它使用CAS。\n为何要用Atomic field updater是因为性能原因：\n 对于频繁创建的，短命的对象（比如队列的Node），每次都创建AtomicReference是一笔开销，用Atomic field updater则免去了这个开销。  另外Atomic field updater还可以帮助你保留对象的序列化形式。\nABA问题 CAS解决的是“V的值是否依然是A？”，但如果V的值再很短的时间内变成过B，又变回A，那么这个就是ABA问题。\n在大多数情况下ABA无所谓，但是有些情况下则不行，比如对于链表来说，head依然指向某个node不代表这个链表没有变过。\n解决办法，在更新值的同时更新版本号，对比的时候连值和版本号一起对比。AtomicStampedReference可以干这个，AtomicMarkableReference也差不多。\n","date":"2019-11-24","img":"","permalink":"/post/concurrent-programming/atomic-vars-and-nonblocking-synchronization/","series":null,"tags":["并发编程"],"title":"Atomic Variables and Nonblocking Synchronization"},{"categories":null,"content":"状态依赖的类  某些操作具有基于状态的前置条件的类 比如：FutureTask、Semaphore、BlockingQueue 比如：你不能从空队列中移除item，不能在任务结束前得到结果  构建状态依赖的类最简单的办法就是利用已有的状态依赖的类。比如使用CountDownLatch，或者自己构建同步器。自己构建同步器可以利用：内置条件队列（intrinsic condition queues）、显式Condition对象、AbstractQueuedSynchronizer框架。\n管理状态依赖 使用polling（轮询）和sleeping来出来状态依赖是很痛苦的。所以不推荐。\n阻塞的状态依赖动作的结构：\n1acquire lock on object state 2while (precondition does not hold) { 3 release lock 4 wait until precondition might hold 5 optionally fail if interrupted or timeout expires 6 reacquire lock 7} 8perform action 9release lock 下面是一个有届的Buffer的基类，用的是循环数组，后面有些例子会用它来说明：\n1@ThreadSafe 2public abstract class BaseBoundedBuffer \u0026lt;V\u0026gt; { 3 @GuardedBy(\u0026#34;this\u0026#34;) private final V[] buf; 4 @GuardedBy(\u0026#34;this\u0026#34;) private int tail; 5 @GuardedBy(\u0026#34;this\u0026#34;) private int head; 6 @GuardedBy(\u0026#34;this\u0026#34;) private int count; 7 8 protected BaseBoundedBuffer(int capacity) { 9 this.buf = (V[]) new Object[capacity]; 10 } 11 12 protected synchronized final void doPut(V v) { 13 buf[tail] = v; 14 if (++tail == buf.length) 15 tail = 0; 16 ++count; 17 } 18 19 protected synchronized final V doTake() { 20 V v = buf[head]; 21 buf[head] = null; 22 if (++head == buf.length) 23 head = 0; 24 --count; 25 return v; 26 } 27 28 public synchronized final boolean isFull() { 29 return count == buf.length; 30 } 31 32 public synchronized final boolean isEmpty() { 33 return count == 0; 34 } 35} 例子：传播前置条件失败给调用方（不要） 下面这个例子不要的地方在于：\n Full和Empty是两个正常状态，抛异常不好 调用方得捕获异常，然后还要自己重试，重试的方式有两种  sleep，但是sleep时长很难掌握，会造成响应度不够 不sleep直接重试，这个就是所谓的busy waiting或者spin waiting，浪费CPU   调用方处理前置条件失败  1@ThreadSafe 2public class GrumpyBoundedBuffer \u0026lt;V\u0026gt; extends BaseBoundedBuffer\u0026lt;V\u0026gt; { 3 public GrumpyBoundedBuffer(int size) { 4 super(size); 5 } 6 7 public synchronized void put(V v) throws BufferFullException { 8 if (isFull()) 9 throw new BufferFullException(); 10 doPut(v); 11 } 12 13 public synchronized V take() throws BufferEmptyException { 14 if (isEmpty()) 15 throw new BufferEmptyException(); 16 return doTake(); 17 } 18} 19 20class ExampleUsage { 21 private GrumpyBoundedBuffer\u0026lt;String\u0026gt; buffer; 22 int SLEEP_GRANULARITY = 50; 23 24 void useBuffer() throws InterruptedException { 25 while (true) { 26 try { 27 String item = buffer.take(); 28 // use item 29 break; 30 } catch (BufferEmptyException e) { 31 Thread.sleep(SLEEP_GRANULARITY); 32 } 33 } 34 } 35} 36 37class BufferFullException extends RuntimeException { 38} 39 40class BufferEmptyException extends RuntimeException { 41} 不用异常也可以，比如通过返回一个Error结果，但是问题的本质没有变\n例子：用轮询和睡眠来阻塞 这个例子稍微好点，自己处理前置条件失败：\n1@ThreadSafe 2public class SleepyBoundedBuffer \u0026lt;V\u0026gt; extends BaseBoundedBuffer\u0026lt;V\u0026gt; { 3 int SLEEP_GRANULARITY = 60; 4 5 public SleepyBoundedBuffer() { 6 this(100); 7 } 8 9 public SleepyBoundedBuffer(int size) { 10 super(size); 11 } 12 13 public void put(V v) throws InterruptedException { 14 while (true) { 15 synchronized (this) { 16 if (!isFull()) { 17 doPut(v); 18 return; 19 } 20 } 21 Thread.sleep(SLEEP_GRANULARITY); 22 } 23 } 24 25 public V take() throws InterruptedException { 26 while (true) { 27 synchronized (this) { 28 if (!isEmpty()) 29 return doTake(); 30 } 31 Thread.sleep(SLEEP_GRANULARITY); 32 } 33 } 34} 不过问题也差不多：睡眠的粒度很难把握，短了浪费CPU，长了增加响应度，\n条件队列（Condition queues） 起名为Condition queue是因为它给一组线程——称为wait set——等待特定的条件变为true。这个队列中的元素是等待条件的线程。\n每个对象可以作为condition queue，Object的wait、notify、notifyAll方法构成了内置条件队列的API。\n对象内置锁和内置条件队列是关联的：\n 你要调用条件队列方法必须先获得对象锁。 你不能等待条件除非你能检查状态，你不能把其他线程从条件等待中释放除非你能够修改状态。  下面这个例子更简单，也更高效，响应度更高。\n1@ThreadSafe 2public class BoundedBuffer \u0026lt;V\u0026gt; extends BaseBoundedBuffer\u0026lt;V\u0026gt; { 3 // CONDITION PREDICATE: not-full (!isFull()) 4 // CONDITION PREDICATE: not-empty (!isEmpty()) 5 public BoundedBuffer() { 6 this(100); 7 } 8 9 public BoundedBuffer(int size) { 10 super(size); 11 } 12 13 // BLOCKS-UNTIL: not-full 14 public synchronized void put(V v) throws InterruptedException { 15 while (isFull()) 16 wait(); 17 doPut(v); 18 notifyAll(); 19 } 20 21 // BLOCKS-UNTIL: not-empty 22 public synchronized V take() throws InterruptedException { 23 while (isEmpty()) 24 wait(); 25 V v = doTake(); 26 notifyAll(); 27 return v; 28 } 29 30 // BLOCKS-UNTIL: not-full 31 // Alternate form of put() using conditional notification 32 // 减少notifyAll的次数 33 public synchronized void alternatePut(V v) throws InterruptedException { 34 while (isFull()) 35 wait(); 36 boolean wasEmpty = isEmpty(); 37 doPut(v); 38 if (wasEmpty) 39 notifyAll(); 40 } 41} 使用条件队列 条件判断 The condition predicate  正确使用条件队列的关键是识别对象所等待的condition predicates。 contidition predicates是使得操作依赖于状态的前置条件。 比如take的condition predicate是buffer不为空、put的则是buffer没有满  condition wait牵涉三个：加锁、wait方法、被锁保护的状态变量。测试condition predicate之前要得到锁，锁对象和条件队列对象得是同一个。\nwait方法：释放锁，阻塞当前线程，等待——直到或超过规定时间、或线程被中断、或线程被通知唤醒。线程被唤醒后和其他线程再次争抢锁。\n醒得太快 waking up too soon 从wait中醒来不代表condition predicate变成true了，所以醒过来后一定要判断条件。\n一个内置条件队列可能被多个condition predicate使用，因此如果有人调用了notifyAll不代表你等待的condition predicate变成true了。而且wait还会虚假的醒来，即并没有人调用notify。\n下面是经典用法：\n1void stateDependentMethod() throws InterruptedException { 2 synchronized(lock) { 3 while (!conditionPredicate()) { 4 lock.wait(); 5 } 6 // object is no in desired state 7 } 8} 使用Object.wait或Condition.await要记牢：\n 总是得有一个condition predicate 在wait之前，和从wait唤醒之后要测试condition predicate 总是在循环中调用wait 保证condition predicate所用的状态变量被condition queue的相同锁保护 调用wait、notify、notifyAll之前要持有锁 在检查condition predicate之后但在对其进行操作之前，请勿释放锁  漏掉的信号 漏掉信号发生在：一个线程必须等待一个已经是true的条件，但是在等待之前没能检查condition predicate。\n如果A 先notify，而B在后面wait，那么B是不会得到A发出的信号的，所以在wait之前一定要检查condition predicate。用前面的代码结构就能解决这个问题。\n通知 如果你在等待一个条件，那么确保肯定有其他人会在条件变成true的时候发出通知。\n通知也需要得到锁，所以而且通知线程释放锁越快越好。大部分情况下要用notifyAll而不是notify，因为notify只通知一个线程，如果这个线程等待的condition没有变成true，那么这次通知就浪费了，那么其他线程就没有机会了，也就是这个信号被劫持了。\nnotify可以作为性能优化的手段，但还是那句老话，先做对再做好。\n例子：gate class 下面是一个gate例子，gate关闭的时候线程等待，gate打开的时候线程通过：\n1@ThreadSafe 2public class ThreadGate { 3 // CONDITION-PREDICATE: opened-since(n) (isOpen || generation\u0026gt;n) 4 @GuardedBy(\u0026#34;this\u0026#34;) private boolean isOpen; 5 @GuardedBy(\u0026#34;this\u0026#34;) private int generation; 6 7 public synchronized void close() { 8 isOpen = false; 9 } 10 11 public synchronized void open() { 12 ++generation; 13 isOpen = true; 14 notifyAll(); 15 } 16 17 // BLOCKS-UNTIL: opened-since(generation on entry) 18 public synchronized void await() throws InterruptedException { 19 int arrivalGeneration = generation; 20 while (!isOpen \u0026amp;\u0026amp; arrivalGeneration == generation) 21 wait(); 22 } 23} 解释一下这段：\n1while (!isOpen \u0026amp;\u0026amp; arrivalGeneration == generation) 2 wait(); 如果大门关闭 且 线程进入时的代数和门的代数一样，就要等待。反过来的意思是，如果大门开放，或者线程进入时的代数比门的代数更老，则通过。为什么？\n因为在从wait唤醒到再次进入while之间门可能会被关闭，如果只看open状态，那么有一部分线程就会通不过，这个是有问题的，因为Gate设计的本来意是如果大门打开，那么就同时释放。\n子类安全性问题 一个依赖状态的类应该要么完全暴露（并文档）它的等待和通知协议给子类，要么压根防止子类参与进来。\n封装Condition queues 最好封装条件队列，这样在类层级外部就不会访问到它。\n进入和退出协议 略。\n显式条件对象 Condition对象关联一个Lock对象，一个Lock对象可以有很多Condition对象。Condition对象继承了Lock对象的公平性。\n下面是Condition接口：\n1void await() 2boolean await(long time, TimeUnit unit) 3long awaitNanos(long nanosTimeout) 4void awaitUninterruptibly() 5boolean awaitUntil(Date deadline) 6void signal() 7void signalAll() 下面是一个例子：\n1@ThreadSafe 2public class ConditionBoundedBuffer \u0026lt;T\u0026gt; { 3 protected final Lock lock = new ReentrantLock(); 4 // CONDITION PREDICATE: notFull (count \u0026lt; items.length) 5 private final Condition notFull = lock.newCondition(); 6 // CONDITION PREDICATE: notEmpty (count \u0026gt; 0) 7 private final Condition notEmpty = lock.newCondition(); 8 private static final int BUFFER_SIZE = 100; 9 @GuardedBy(\u0026#34;lock\u0026#34;) private final T[] items = (T[]) new Object[BUFFER_SIZE]; 10 @GuardedBy(\u0026#34;lock\u0026#34;) private int tail, head, count; 11 12 // BLOCKS-UNTIL: notFull 13 public void put(T x) throws InterruptedException { 14 lock.lock(); 15 try { 16 while (count == items.length) 17 notFull.await(); 18 items[tail] = x; 19 if (++tail == items.length) 20 tail = 0; 21 ++count; 22 notEmpty.signal(); 23 } finally { 24 lock.unlock(); 25 } 26 } 27 28 // BLOCKS-UNTIL: notEmpty 29 public T take() throws InterruptedException { 30 lock.lock(); 31 try { 32 while (count == 0) 33 notEmpty.await(); 34 T x = items[head]; 35 items[head] = null; 36 if (++head == items.length) 37 head = 0; 38 --count; 39 notFull.signal(); 40 return x; 41 } finally { 42 lock.unlock(); 43 } 44 } 45} 解剖同步器 像ReentrantLock、Semaphore、CountDownLatch、FutureTask，都是利用了AbstractQueuedSynchronizer (AQS)。\nAbstractQueuedSynchronizer 基于AQS的同步器执行的操作是acquire和release的变种：\n 获取（acquire）是状态依赖的操作，而且总是会阻塞 释放（release）不是一个阻塞操作，一次释放可能会允许阻塞在acquire的线程通过。  AQS管理同步器的状态，通过getState、setState、compareAndSetState方法。比如：\n ReentrantLock使用它来记录拥有锁的线程获得锁的次数（可重入的关系） Semaphore使用它来代表剩余的permits FutureTask用它来表示任务的状态：没开始、运行中、完成、取消。  同步器也可以保存其他状态，比入ReentrantLock保存了lock owner线程，用来确保只有owner可以释放锁。\nacquire可能是独占的（exclusive），比如ReentrantLock。也可以是非独占的（non-exclusive)，比如Sempaphore和CountDownLatch。\n一次acquire的包含两个部分：\n  第一部分\n 判断当前状态是否允许获取 如果允许，线程通过。如果不允许，线程阻塞或者失败。    第二部分：更新同步器状态。\n  acquire和release的经典形式：\n1boolean acquire() throws InterruptedException { 2 while (state does not permit acquire) { 3 if (blocking acquisition requested) { 4 enqueue current thread if not already queued 5 block current thread 6 } 7 else 8 return failure 9 } 10 possibly update synchronization state 11 dequeue thread if it was queued 12 return success 13} 14void release() { 15 update synchronization state 16 if (new state may permit a blocked thread to acquire) 17 unblock one or more queued threads 18} 实现AQS：\n 支持独占式获取的同步器要实现：tryAcquire、 tryRelease、 isheldExclusively方法。 支持非独占获取的同步器要实现：tryAcquireShared、tryReleaseShared。 AQS的acquire、acquireShared、release、releaseShared会调用上面的try*方法。  tryAcquireShared方法返回值说明：\n \u0026lt; 0，获取失败 = 0，独占式获取成功 \u0026gt; 0，非独占式获取成功  tryRelease和tryReleaseShared返回值说明：\n true，可以释放阻塞在获取操作的线程 false，不释放线程  简单的Latch 1@ThreadSafe 2public class OneShotLatch { 3 private final Sync sync = new Sync(); 4 5 public void signal() { 6 sync.releaseShared(0); 7 } 8 9 public void await() throws InterruptedException { 10 sync.acquireSharedInterruptibly(0); 11 } 12 13 private class Sync extends AbstractQueuedSynchronizer { 14 protected int tryAcquireShared(int ignored) { 15 // Succeed if latch is open (state == 1), else fail 16 return (getState() == 1) ? 1 : -1; 17 } 18 19 protected boolean tryReleaseShared(int ignored) { 20 setState(1); // Latch is now open 21 return true; // Other threads may now be able to acquire 22 23 } 24 } 25} 一般来说不会直接继承AQS，而是弄一个私有内部类来继承，这样可以保证封装。\nAQS在JUC同步器中的运用 ReentrantLock 1protected boolean tryAcquire(int ignored) { 2 find Thread current = Thread.currentThread(); 3 int c = getState(); 4 if (c == 0) { 5 if (compareAndSetState(0, 1)) { // 这里的整段代码不是同步的 6 owner = current; // 没成功说明被别的线程抢了，会跑到最后的return false 7 return true; 8 } 9 } else if (current == owner) { 10 setState(c + 1); 11 return true 12 } 13 return false; 14} Semaphore和CountDownLatch 在Semaphore中的运用：\n1protected int tryAcquireShared(int acquires) { 2 while (true) { 3 int available = getState(); 4 int remaining = available - acquires; 5 if (remaining \u0026lt; 0 || compareAndSetState(available, remaining)) 6 /* \u0026gt; 0: 我拿别人也能拿，非独占 7= 0: 我拿别人拿不了，独占 8\u0026lt; 0: 谁都拿不了 9*/ 10 return remaining; 11 } 12} 13protected boolean tryReleaseShared(int releases) { 14 while (true) { 15 int p = getState(); 16 if (compareAndSetState(p, p + releases)) 17 return true; 18 } 19} 在CountDownLatch中的运用：\n无\nFutureTask state保存任务状态：running、completed、cancelled，同时保存计算结果或抛出的异常，还维护了一个运行这个任务的线程（为了能够cancel）\nReentrantReadWriteLock 同时使用了shared和非shared两种方法。\nAQS内部维护了一个等待线程的队列，跟踪每个线程是请求独占还是非独占。在ReentrantReadWriteLock里，当锁可用式，如果队列头的线程请求写锁，它会得到它。如果队列头线程请求读锁，则会释放它和后面的线程，直到碰到一个请求写锁的线程。\n","date":"2019-11-21","img":"","permalink":"/post/concurrent-programming/building-custom-synchronizers/","series":null,"tags":["并发编程"],"title":"Building Custom Synchronizers"},{"categories":null,"content":"相关文档：https://kafka.apache.org/documentation/#semantics\n消息发送保证有三种：\n 最多一次 至少一次 正好一次  Kafka发送消息时，会有一条committed的日志，committed的消息保证不会被丢失。\n当生产者发送消息时遇到网络故障，那么它是没有办法知道这个消息是不是已经被committed。\n生产者角度  至少一次的语义：在0.11.0.0之前，如果生产者没有收到committed的响应，那么它只能再发一遍。 正好一次的语义：在0.11.0.0之后，kafka提供了幂等发送选项，因此重发不会形成重复的日志。实现方法：每个生产者给了一个ID，每个消息都有一个增长的sequence number用来给消息去重。  0.11.0.0之后还引入了事务语义，发送消息给多个topic partition的时候，要么全部成功，要么全部失败。\n消费者角度 消费者会记录自己读到哪里了（offset），不论这个信息存在持久化设备还是内存中，她有这么两种做法：\n 最多一次的语义：读取消息，记录offset，处理消息。如果在处理消息前crash，那么下次从offset恢复的时候就有可能丢失上次未处理的消息。 至少一次的语义：读取消息，处理消息，记录offset。如果记录offset前crash，那么下次从offset恢复的时候就有可能重复处理消息。大多数情况下会在处理消息时保证幂等性。  【正好一次】怎么实现？在从一个Topic A消费消息然后发送消息到另一个Topic B的场景里（Kafka Streams），在消费消息的时候可以同时把offset作为一个消息发送到一个Topic C中，并且这个过程放在事务里，如果事务中断了，那么这个offset消息会回滚，而Topic B也会回滚。再配合Topic B消费者隔离级别设置为read_committed。\n在把消息写到外部系统的场景中（比如写到数据库），可以把offset一起写到数据库里，这样就避免了2PC（特别是如果外部系统不支持2PC）。\n","date":"2019-11-21","img":"","permalink":"/post/message-queue/kafa-message-delivery-semantics/","series":null,"tags":["MQ","消息队列","kafka"],"title":"Kafka的消息发送语义"},{"categories":null,"content":"这是一次排障过程，发现Worker节点磁盘占用高，K8S报告kublet has disk pressure。\nK8S是Rancher管理的，开启了监控（Grafana+Prometheus），在Grafana监控大盘观察，的确发现节点的磁盘可用空间在10%左右，节点磁盘大小为1T，如此占用不正常。\n尝试在Grafana查找哪个Pod占用的磁盘，但是并未提供这样的视图。\n在节点上执行：\n1sudo du -h --max-depth 1 /var/lib/docker/ 得到的确是Docker占用的磁盘。\n在节点上执行：\n1docker system df 得到Container占用磁盘特别高\n在节点上执行：\n1docker ps -a --format \u0026#34;table {{.Size}}\\t{{.Names}}\u0026#34; 得到容器的磁盘占用，发现kubelet占用磁盘特别高，且符合docker system df的结果。\n进入kubelet查看占用情况：\n1docker exec -it kubelet /bin/bash 2du -h --max-depth 1 发现在/v8磁盘占用了大部分空间，进入后查看发现大量应用日志。\n找到相关应用开发人员，原来是他们使用了hostPath来挂载卷，把日志都写到了节点上，且没有开启日志滚动和压缩，导致占用大量节点磁盘。\n后经研究发现，hostPath挂载的卷在Deployment/StatefulSets删除后也依然存在，手动删除后问题解决，并让开发人员不要使用hostPath后解决。\n","date":"2019-11-11","img":"","permalink":"/post/k8s/find-high-disk-usage-pod/","series":null,"tags":["k8s","troubleshooting"],"title":"查找K8S中高磁盘占用Pod"},{"categories":null,"content":"Lock和ReentrantLock Lock接口：\n1public interface Lock { 2 void lock(); 3 void lockInterruptibly() throws InterruptedException; 4 boolean tryLock(); 5 boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException; 6 void unlock(); 7 Condition newCondition(); 8} Lock的典型用法：\n1Lock lock = new ReentrantLock(); 2... 3lock.lock(); 4try { 5 // update object state 6 // catch exceptions and restore invariants if necessary 7} finally { 8 lock.unlock(); 9} 轮询的和定时的获得锁 一个死锁重试的例子：\n1/** 2* DeadlockAvoidance 3* \u0026lt;p/\u0026gt; 4* Avoiding lock-ordering deadlock using tryLock 5* 6* @author Brian Goetz and Tim Peierls 7*/ 8public class DeadlockAvoidance { 9 private static Random rnd = new Random(); 10 11 public boolean transferMoney(Account fromAcct, 12 Account toAcct, 13 DollarAmount amount, 14 long timeout, 15 TimeUnit unit) 16 throws InsufficientFundsException, InterruptedException { 17 long fixedDelay = getFixedDelayComponentNanos(timeout, unit); 18 long randMod = getRandomDelayModulusNanos(timeout, unit); 19 long stopTime = System.nanoTime() + unit.toNanos(timeout); 20 21 while (true) { 22 if (fromAcct.lock.tryLock()) { // 注意这个if，true就是成功获得，false反之 23 try { 24 if (toAcct.lock.tryLock()) { 25 try { 26 if (fromAcct.getBalance().compareTo(amount) \u0026lt; 0) 27 throw new InsufficientFundsException(); 28 else { 29 fromAcct.debit(amount); 30 toAcct.credit(amount); 31 // 成功得到锁在这里会返回 32 return true; 33 } 34 } finally { 35 toAcct.lock.unlock(); 36 } 37 } 38 } finally { 39 fromAcct.lock.unlock(); 40 } 41 } 42 // 到这里说明没有成功 43 if (System.nanoTime() \u0026lt; stopTime) 44 return false; 45 // 随机sleep避免再次冲突 46 NANOSECONDS.sleep(fixedDelay + rnd.nextLong() % randMod); 47 } 48 } 49 50 private static final int DELAY_FIXED = 1; 51 private static final int DELAY_RANDOM = 2; 52 53 static long getFixedDelayComponentNanos(long timeout, TimeUnit unit) { 54 return DELAY_FIXED; 55 } 56 57 static long getRandomDelayModulusNanos(long timeout, TimeUnit unit) { 58 return DELAY_RANDOM; 59 } 60 61 static class DollarAmount implements Comparable\u0026lt;DollarAmount\u0026gt; { 62 public int compareTo(DollarAmount other) { 63 return 0; 64 } 65 66 DollarAmount(int dollars) { 67 } 68 } 69 70 class Account { 71 public Lock lock; 72 73 void debit(DollarAmount d) { 74 } 75 76 void credit(DollarAmount d) { 77 } 78 79 DollarAmount getBalance() { 80 return null; 81 } 82 } 83 84 class InsufficientFundsException extends Exception { 85 } 86} 下面实际上是一个单线程程序，同时为了避免永久等待，引入了超时：\n1/** 2* TimedLocking 3* \u0026lt;p/\u0026gt; 4* Locking with a time budget 5* 6* @author Brian Goetz and Tim Peierls 7*/ 8public class TimedLocking { 9 private Lock lock = new ReentrantLock(); 10 11 public boolean trySendOnSharedLine(String message, 12 long timeout, TimeUnit unit) 13 throws InterruptedException { 14 long nanosToLock = unit.toNanos(timeout) 15 - estimatedNanosToSend(message); // 这个很重要，能让超时时间更准确一些 16 if (!lock.tryLock(nanosToLock, NANOSECONDS)) 17 return false; 18 try { 19 return sendOnSharedLine(message); 20 } finally { 21 lock.unlock(); 22 } 23 } 24 25 private boolean sendOnSharedLine(String message) { 26 /* send something */ 27 return true; 28 } 29 30 long estimatedNanosToSend(String message) { 31 return message.length(); 32 } 33} 读写锁 1public interface ReadWriteLock { 2 Lock readLock(); 3 Lock writeLock(); 4} 例子代码（实际上更推荐ConcurrentHashMap，这里只是一个例子）：\n1/** 2* ReadWriteMap 3* \u0026lt;p/\u0026gt; 4* Wrapping a Map with a read-write lock 5* 6* @author Brian Goetz and Tim Peierls 7*/ 8public class ReadWriteMap \u0026lt;K,V\u0026gt; { 9 private final Map\u0026lt;K, V\u0026gt; map; 10 private final ReadWriteLock lock = new ReentrantReadWriteLock(); 11 private final Lock r = lock.readLock(); 12 private final Lock w = lock.writeLock(); 13 14 public ReadWriteMap(Map\u0026lt;K, V\u0026gt; map) { 15 this.map = map; 16 } 17 18 public V put(K key, V value) { 19 w.lock(); 20 try { 21 return map.put(key, value); 22 } finally { 23 w.unlock(); 24 } 25 } 26 27 public V remove(Object key) { 28 w.lock(); 29 try { 30 return map.remove(key); 31 } finally { 32 w.unlock(); 33 } 34 } 35 36 public void putAll(Map\u0026lt;? extends K, ? extends V\u0026gt; m) { 37 w.lock(); 38 try { 39 map.putAll(m); 40 } finally { 41 w.unlock(); 42 } 43 } 44 45 public void clear() { 46 w.lock(); 47 try { 48 map.clear(); 49 } finally { 50 w.unlock(); 51 } 52 } 53 54 public V get(Object key) { 55 r.lock(); 56 try { 57 return map.get(key); 58 } finally { 59 r.unlock(); 60 } 61 } 62 63 public int size() { 64 r.lock(); 65 try { 66 return map.size(); 67 } finally { 68 r.unlock(); 69 } 70 } 71 72 public boolean isEmpty() { 73 r.lock(); 74 try { 75 return map.isEmpty(); 76 } finally { 77 r.unlock(); 78 } 79 } 80 81 public boolean containsKey(Object key) { 82 r.lock(); 83 try { 84 return map.containsKey(key); 85 } finally { 86 r.unlock(); 87 } 88 } 89 90 public boolean containsValue(Object value) { 91 r.lock(); 92 try { 93 return map.containsValue(value); 94 } finally { 95 r.unlock(); 96 } 97 } 98} ","date":"2019-11-05","img":"","permalink":"/post/concurrent-programming/explicit-locks/","series":null,"tags":["并发编程"],"title":"Explicit Locks"},{"categories":null,"content":"测试正确性 测试阻塞方法 1void testTakeBlocksWhenEmpty() { 2 final BoundedBuffer\u0026lt;Integer\u0026gt; bb = new BoundedBuffer\u0026lt;\u0026gt;(10); 3 Thread taker = new Thread() { 4 public void run() { 5 try { 6 int unused = bb.take(); 7 fail(); // if we get here, it\u0026#39;s an error 8 } catch (InterruptedException success) {} 9 } 10 try { 11 take.start(); 12 Thread.sleep(LOCKUP_DETECT_TIMEOUT); 13 taker.interrupt(); 14 taker.join(LOCKUP_DETECT_TIMEOUT); 15 assertFalse(taker.isAlive()); 16 } catch (Exception unexpected) { 17 fail(); 18 } 19 } 20} 测试安全性 一种简易的中等质量的随机数生成器：\n1// 用hashcode / nanoTime 作为种子可以得到中等质量的随机数 2static int xorShift(int y) { 3 y ^= (y \u0026lt;\u0026lt; 6); 4 y ^= (y \u0026gt;\u0026gt;\u0026gt; 21); 5 y ^= (y \u0026lt;\u0026lt; 7); 6 return y; 7} 下面是测试线程安全的代码：\n1public class PutTakeTest extends TestCase { 2 protected static final ExecutorService pool = Executors.newCachedThreadPool(); 3 protected CyclicBarrier barrier; 4 protected final SemaphoreBoundedBuffer\u0026lt;Integer\u0026gt; bb; 5 protected final int nTrials, nPairs; 6 protected final AtomicInteger putSum = new AtomicInteger(0); 7 protected final AtomicInteger takeSum = new AtomicInteger(0); 8 9 public static void main(String[] args) throws Exception { 10 new PutTakeTest(10, 10, 100000).test(); // sample parameters 11 pool.shutdown(); 12 } 13 14 public PutTakeTest(int capacity, int npairs, int ntrials) { 15 this.bb = new SemaphoreBoundedBuffer\u0026lt;Integer\u0026gt;(capacity); 16 this.nTrials = ntrials; 17 this.nPairs = npairs; 18 // n个producer + n个consumer + 1个main thread 19 this.barrier = new CyclicBarrier(npairs * 2 + 1); main thread 20 } 21 22 void test() { 23 try { 24 for (int i = 0; i \u0026lt; nPairs; i++) { 25 pool.execute(new Producer()); 26 pool.execute(new Consumer()); 27 } 28 barrier.await(); // wait for all threads to be ready 29 barrier.await(); // wait for all threads to finish 30 assertEquals(putSum.get(), takeSum.get()); 31 } catch (Exception e) { 32 throw new RuntimeException(e); 33 } 34 } 35 36 static int xorShift(int y) { 37 y ^= (y \u0026lt;\u0026lt; 6); 38 y ^= (y \u0026gt;\u0026gt;\u0026gt; 21); 39 y ^= (y \u0026lt;\u0026lt; 7); 40 return y; 41 } 42 43 class Producer implements Runnable { 44 public void run() { 45 try { 46 int seed = (this.hashCode() ^ (int) System.nanoTime()); 47 int sum = 0; 48 barrier.await(); 49 for (int i = nTrials; i \u0026gt; 0; --i) { 50 bb.put(seed); 51 sum += seed; 52 seed = xorShift(seed); 53 } 54 // 在最后汇总sum可以减少snc 55 putSum.getAndAdd(sum); 56 barrier.await(); 57 } catch (Exception e) { 58 throw new RuntimeException(e); 59 } 60 } 61 } 62 63 class Consumer implements Runnable { 64 public void run() { 65 try { 66 barrier.await(); 67 int sum = 0; 68 for (int i = nTrials; i \u0026gt; 0; --i) { 69 sum += bb.take(); 70 } 71 takeSum.getAndAdd(sum); 72 barrier.await(); 73 } catch (Exception e) { 74 throw new RuntimeException(e); 75 } 76 } 77 } 78} 被测代码：\n1@ThreadSafe 2public class SemaphoreBoundedBuffer \u0026lt;E\u0026gt; { 3 private final Semaphore availableItems, availableSpaces; 4 @GuardedBy(\u0026#34;this\u0026#34;) private final E[] items; 5 @GuardedBy(\u0026#34;this\u0026#34;) private int putPosition = 0, takePosition = 0; 6 7 public SemaphoreBoundedBuffer(int capacity) { 8 if (capacity \u0026lt;= 0) 9 throw new IllegalArgumentException(); 10 availableItems = new Semaphore(0); 11 availableSpaces = new Semaphore(capacity); 12 items = (E[]) new Object[capacity]; 13 } 14 15 public boolean isEmpty() { 16 return availableItems.availablePermits() == 0; 17 } 18 19 public boolean isFull() { 20 return availableSpaces.availablePermits() == 0; 21 } 22 23 public void put(E x) throws InterruptedException { 24 availableSpaces.acquire(); 25 doInsert(x); 26 availableItems.release(); 27 } 28 29 public E take() throws InterruptedException { 30 availableItems.acquire(); 31 E item = doExtract(); 32 availableSpaces.release(); 33 return item; 34 } 35 // 这里的synchronized很重要，如果没有就线程不安全了 36 private synchronized void doInsert(E x) { 37 int i = putPosition; 38 items[i] = x; 39 putPosition = (++i == items.length) ? 0 : i; 40 } 41 // 这里的synchronized很重要，如果没有就线程不安全了 42 private synchronized E doExtract() { 43 int i = takePosition; 44 E x = items[i]; 45 items[i] = null; 46 takePosition = (++i == items.length) ? 0 : i; 47 return x; 48 } 49} 测试资源管理 测试SemaphoreBoundedBuffer是否正确释放了空间：\n1class Big { 2 double[] data = new double[100000]; 3} 4 5void testLeak() throws InterruptedException { 6 SemaphoreBoundedBuffer\u0026lt;Big\u0026gt; bb = new SemaphoreBoundedBuffer\u0026lt;Big\u0026gt;(CAPACITY); 7 int heapSize1 = snapshotHeap(); 8 for (int i = 0; i \u0026lt; CAPACITY; i++) 9 bb.put(new Big()); 10 for (int i = 0; i \u0026lt; CAPACITY; i++) 11 bb.take(); 12 int heapSize2 = snapshotHeap(); 13 assertTrue(Math.abs(heapSize1 - heapSize2) \u0026lt; THRESHOLD); 14} 15 16private int snapshotHeap() { 17 /* Snapshot heap and return heap size */ 18 return 0; 19} 测试线程池扩展策略：\n1public class TestThreadPool extends TestCase { 2 3 private final TestingThreadFactory threadFactory = new TestingThreadFactory(); 4 5 public void testPoolExpansion() throws InterruptedException { 6 int MAX_SIZE = 10; 7 // newFixedThreadPool 最多创建10个线程 8 ExecutorService exec = Executors.newFixedThreadPool(MAX_SIZE); 9 10 for (int i = 0; i \u0026lt; 10 * MAX_SIZE; i++) 11 exec.execute(new Runnable() { 12 public void run() { 13 try { 14 Thread.sleep(Long.MAX_VALUE); 15 } catch (InterruptedException e) { 16 Thread.currentThread().interrupt(); 17 } 18 } 19 }); 20 // 等待确保创建了至少10个线程 21 for (int i = 0; 22 i \u0026lt; 20 \u0026amp;\u0026amp; threadFactory.numCreated.get() \u0026lt; MAX_SIZE; 23 i++) 24 Thread.sleep(100); 25 assertEquals(threadFactory.numCreated.get(), MAX_SIZE); 26 exec.shutdownNow(); 27 } 28} 29 30class TestingThreadFactory implements ThreadFactory { 31 public final AtomicInteger numCreated = new AtomicInteger(); 32 private final ThreadFactory factory = Executors.defaultThreadFactory(); 33 34 public Thread newThread(Runnable r) { 35 numCreated.incrementAndGet(); 36 return factory.newThread(r); 37 } 38} 测试性能 Barrier-based timer 利用Barrier的callback来做计时：\n1this.timer = new Barrierimer(); 2this.barrier = new CyclicBarrier(nparis * 2 + 1, timer); 3 4// 会在Barrier放行的时候执行 5public class BarrierTimer implements Runnable { 6 private boolean started; 7 private long startTime, endTime; 8 9 public synchronized void run() { 10 long t = System.nanoTime(); 11 if (!started) { 12 started = true; 13 startTime = t; 14 } else 15 endTime = t; 16 } 17 18 public synchronized void clear() { 19 started = false; 20 } 21 22 public synchronized long getTime() { 23 return endTime - startTime; 24 } 25} 利用BarrierTimer测试【不同线程数，不同Buffer capacity】的吞吐量：\n1public class TimedPutTakeTest extends PutTakeTest { 2 private BarrierTimer timer = new BarrierTimer(); 3 4 public TimedPutTakeTest(int cap, int pairs, int trials) { 5 super(cap, pairs, trials); 6 barrier = new CyclicBarrier(nPairs * 2 + 1, timer); 7 } 8 9 public void test() { 10 try { 11 timer.clear(); 12 for (int i = 0; i \u0026lt; nPairs; i++) { 13 pool.execute(new PutTakeTest.Producer()); 14 pool.execute(new PutTakeTest.Consumer()); 15 } 16 barrier.await(); 17 barrier.await(); 18 long nsPerItem = timer.getTime() / (nPairs * (long) nTrials); 19 System.out.print(\u0026#34;Throughput: \u0026#34; + nsPerItem + \u0026#34; ns/item\u0026#34;); 20 assertEquals(putSum.get(), takeSum.get()); 21 } catch (Exception e) { 22 throw new RuntimeException(e); 23 } 24 } 25 26 public static void main(String[] args) throws Exception { 27 int tpt = 100000; // trials per thread 28 for (int cap = 1; cap \u0026lt;= 1000; cap *= 10) { 29 System.out.println(\u0026#34;Capacity: \u0026#34; + cap); 30 for (int pairs = 1; pairs \u0026lt;= 128; pairs *= 2) { 31 TimedPutTakeTest t = new TimedPutTakeTest(cap, pairs, tpt); 32 System.out.print(\u0026#34;Pairs: \u0026#34; + pairs + \u0026#34;\\t\u0026#34;); 33 t.test(); 34 System.out.print(\u0026#34;\\t\u0026#34;); 35 Thread.sleep(1000); 36 t.test(); 37 System.out.println(); 38 Thread.sleep(1000); 39 } 40 } 41 PutTakeTest.pool.shutdown(); 42 } 43} 避免性能测试陷阱 去除死代码 一个避免被编译器当作是死代码的技巧：\n1if (foo.x.hashCode() == System.nanoTime()) { 2 System.out.print(\u0026#34; \u0026#34;); 3} 其他测试方法 ","date":"2019-10-29","img":"","permalink":"/post/concurrent-programming/testing-concurrent-programs/","series":null,"tags":["并发编程"],"title":"Testing Concurrent Programs"},{"categories":null,"content":"部署拓扑  前端一个Nginx服务器做反向代理（4层或7层）到各worker节点。这个服务器的IP记为IP-A。 K8S集群里部署了Ingress Controller K8S集群是由Rancher创建的  问题 在K8S集群中部署了inanimate/echo-server 看到X-Forwarded-For请求头得到的是IP-A，而不是客户端IP。\n七层代理解决办法 如果前端Nginx服务器使用的是http模式（即7层代理），并且在转发的时候添加了X-Real-IP和X-Forwarded-For两个请求头：\n1location / { 2 ... 3 proxy_set_header X-Real-IP $remote_addr; 4 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 5 proxy_http_version 1.1; 6 proxy_pass ....; 7 ... 8} 修改ingress-nginx 命名空间下的nginx-configuration ConfigMap，添加use-forwarded-headers: true\n四层代理解决办法 如果前端Nginx服务器使用的是stream模式（即4层代理）\n  修改ingress-nginx 命名空间下的nginx-configuration ConfigMap，添加use-proxy-protocol: true\n  修改Nginx服务器添加proxy_protocol on;指令：\n1server { 2 listen 80; 3 proxy_pass worker_nodes_http; 4 proxy_protocol on; 5} 6server { 7 listen 443; 8 proxy_pass worker_nodes_https; 9 proxy_protocol on; 10}   重启Nginx服务器\n  坑  前端Nginx和后端Nginx要么同时开启PROXY protocol那么同时关闭，否则会无法访问。 不要修改Rancher自己的Nginx Ingress的配置，一旦修改你就完了，kubectl会无法使用。  参考资料  Passing the Client’s IP Address to the Backend  Configuring NGINX to Accept the PROXY Protocol  Ingress Nginx ConfigMaps - use-proxy-protocol  Ingress Nginx ConfigMaps - use-forwarded-headers  ","date":"2019-10-25","img":"","permalink":"/post/k8s/pass-client-ip-to-backend/","series":null,"tags":["k8s"],"title":"传递Client Ip到Ingress后端"},{"categories":null,"content":"性能 Amdahl\u0026rsquo;s Law 隐藏的serial点：\n queue.take() 代码之外的result handling，要么有地方汇总结果，要么有side effect  side effect，比如写日志、写数据库    1public class WorkerThread extends Thread { 2 private final BlockingQueue\u0026lt;Runnable\u0026gt; queue; 3 public void run() { 4 while (true) { 5 try { 6 Runnable task = queue.take(); // \u0026lt;- serial点 7 task.run(); 8 } catch (InterruptedException e) { 9 break; 10 } 11 } 12 } 13} 线程的代价 优化非竞争性锁 某个锁被证明不会发生竞争，JVM会优化掉它：\n1synchronized (new Object()) { 2 // do something 3} 通过逃逸分析发现对象从未跳出当前线程，JVM会优化掉它：\n1public String getStoogeNames() { 2 List\u0026lt;String\u0026gt; stooges = new Vector\u0026lt;\u0026gt;(); 3 stooges.add(\u0026#34;foo\u0026#34;); 4 stooges.add(\u0026#34;bar\u0026#34;); 5 return stooges.toString(); 6} 上述代码就算不用逃逸分析，编译器也会合并相邻的锁。\n优化竞争性锁 缩小锁的范围 优化前：\n1private HashMap\u0026lt;String, String\u0026gt; attributes; 2public synchronized boolean userLocationMatches(String name, String regexp) { 3 String key = \u0026#34;users.\u0026#34; + name + \u0026#34;.location\u0026#34;; 4 String location = attributes.get(key); 5 return Pattern.matches(regexp, location); 6} 优化后：\n1private HashMap\u0026lt;String, String\u0026gt; attributes; 2public boolean userLocationMatches(String name, String regexp) { 3 String key = \u0026#34;users.\u0026#34; + name + \u0026#34;.location\u0026#34;; 4 String location; 5 synchronized (this) { 6 location = attributes.get(key); 7 } 8 return Pattern.matches(regexp, location); 9} 或者：\n1private Map\u0026lt;String, String\u0026gt; attributes = Collections.synchronizedMap(...); Lock Splitting，锁分割 不要用一把锁保护两个独立的状态变量：\n1public class ServerStatus { 2 private Set\u0026lt;String\u0026gt; users; 3 private Set\u0026lt;String\u0026gt; queries; 4 public synchronized void addUser(...) { 5 users.add(...); 6 } 7 pubilc synchronized void addQuery(...) { 8 queries.add(...); 9 } 10} 可以两把锁来会更好：\n1public class ServerStatus { 2 private Set\u0026lt;String\u0026gt; users; 3 private Set\u0026lt;String\u0026gt; queries; 4 public void addUser(...) { 5 synchronized (users) { 6 users.add(...); 7 } 8 } 9 pubilc void addQuery(...) { 10 synchronized (queries) { 11 queries.add(...); 12 } 13 } 14} ","date":"2019-10-24","img":"","permalink":"/post/concurrent-programming/performance-and-scalability/","series":null,"tags":["并发编程"],"title":"Performance and Scalability"},{"categories":null,"content":"Lock-ordering deadlocks 不同线程，获得获得相同多个锁的顺序不同导致死锁：\n1public class LeftRightDeadlock { 2 private final Object left = new Object(); 3 private final Object right = new Object(); 4 public void leftRight() { 5 synchronized (left) { 6 synchronized (right) { 7 doSomething(); 8 } 9 } 10 } 11 public void rightLeft() { 12 synchronized (right) { 13 synchronized (left) { 14 doSomething(); 15 } 16 } 17 } 18} Dynamic lock order deadlocks 根据参数来决定locking顺序同样有死锁风险：\n1public void transferMoney(Account from, Account to, double amount) { 2 synchronized (from) { 3 synchronized (to) { 4 doSomething(); 5 } 6 } 7} 解决办法：根据参数来推导出固定的locking顺序：\n1priate static final Object tieLock = new Object(); 2 3public void transferMoney(Account from, Account to, double amount) { 4 long fromHash = System.identityHashCode(from); 5 long toHash = System.identityHashCode(to); 6 if (fromHash \u0026lt; toHash) { 7 synchronized (from) { 8 synchronized (to) { 9 doSomething(); 10 } 11 } 12 } else if (toHash \u0026lt; fromHash) { 13 synchronized (to) { 14 synchronized (from) { 15 doSomething(); 16 } 17 } 18 } else { 19 synchronized (tieLock) { 20 // 当出现hash相同的情况时，全部都穿行到tieLock下执行 21 synchronized (from) { 22 synchronized (to) { 23 doSomething(); 24 } 25 } 26 } 27 } 28} Deadlocks between cooperating object 因为多个对象的协作导致的比较隐蔽的死锁：\n1class Taxi { 2 private final Dispatcher dispatcher; 3 public synchronized Point getLocation() { 4 // ... 5 } 6 public synchronized void setLocation(Point location) { 7 this.location = location; 8 // alien method 9 dispatcher.notifyAvailable(this); 10 } 11} 12class Dispatcher { 13 private final Set\u0026lt;Taxi\u0026gt; taxis; 14 public synchronized void notifyAvailable(Taxi taxi) { 15 // ... 16 } 17 public synchronized Image getImage() { 18 Image image = new Image(); 19 for (Taxi taxi : taxis) { 20 // alien method 21 image.drawMarker(taxi.getLocation()); 22 } 23 return image; 24 } 25} Open calls 用Open calls改造，\n1class Taxi { 2 private final Dispatcher dispatcher; 3 public synchronized Point getLocation() { 4 // ... 5 } 6 public void setLocation(Point location) { 7 synchronized (this) { 8 this.location = location; 9 } 10 // alien method 11 dispatcher.notifyAvailable(this); 12 } 13} 14class Dispatcher { 15 private final Set\u0026lt;Taxi\u0026gt; taxis; 16 public synchronized void notifyAvailable(Taxi taxi) { 17 // ... 18 } 19 public Image getImage() { 20\tSet\u0026lt;Taxi\u0026gt; copy; 21 // 限制了在调用alien方法时，本身不持有锁 22 synchronized (this) { 23 copy = new HashSet\u0026lt;\u0026gt;(taxis); 24 } 25 Image image = new Image(); 26 for (Taxi taxi : copy) { 27 // alien method 28 image.drawMarker(taxi.getLocation()); 29 } 30 return image; 31 } 32} ","date":"2019-10-21","img":"","permalink":"/post/concurrent-programming/avoiding-liveness-hazards/","series":null,"tags":["并发编程"],"title":"Avoiding Liveness Hazards"},{"categories":null,"content":"Service在集群内部的DNS全名：\u0026lt;service名字\u0026gt;.\u0026lt;namespace名字\u0026gt;.svc.\u0026lt;zone名字\u0026gt;\nZone名字一般是cluster.local，可以通过kubectl -n kube-system get configmaps coredns -o yaml查看coredns配置来得到：\n1 Corefile: | 2 .:53 { 3 errors 4 health 5 6 kubernetes cluster.local in-addr.arpa ip6.arpa { 7 8 pods insecure 9 upstream 10 fallthrough in-addr.arpa ip6.arpa 11 } 12 prometheus :9153 13 proxy . /etc/resolv.conf 14 cache 30 15 loop 16 reload 17 loadbalance 18 } 相关资料  [Pod 与 Service 的 DNS][doc-1] [Customizing DNS Service][doc-2] Kubernetes DNS-Based Service Discovery  ","date":"2019-10-21","img":"","permalink":"/post/k8s/k8s-service-fqdn/","series":null,"tags":["k8s"],"title":"K8S中Service的FQDN"},{"categories":null,"content":"阿里云上的启用IPVS的K8S集群，无法从Pod经外部访问自己的排障流水账。\n问题描述：\n 阿里云上的托管版K8S集群（下面简称ACK），启用了IPVS 集群中有两个应用Foo和Bar，Bar使用Ingress暴露外网地址，bar.xxx.com Foo应用无法访问 bar.xxx.com ，得到的错误是 Connection refused  初步排障 在集群外部测试 curl http://bar.xx.com 能够返回结果\nping bar.xxx.com，能够ping通：\n1PING xxx.bar.com (\u0026lt;SLB-IP\u0026gt;): 56 data bytes 264 bytes from \u0026lt;SLB-IP\u0026gt;: icmp_seq=0 ttl=91 time=3.091 ms 364 bytes from \u0026lt;SLB-IP\u0026gt;: icmp_seq=1 ttl=91 time=3.212 ms 464 bytes from \u0026lt;SLB-IP\u0026gt;: icmp_seq=2 ttl=91 time=3.267 ms 注意：\n 解析得到的IP是ACK创建时自动创建的SLB实例的公网IP。  在集群内部测试 在K8S集群中启动一个临时Pod，nicolaka/netshoot\ncurl http://bar.xxx.com 得到错误：curl: (7) Failed to connect to bar.xxx.com port 80: Connection refused\nping bar.xxx.com，能够ping通，得到结果\n1PING xxx.bar.com (\u0026lt;SLB-IP\u0026gt;) 56(84) bytes of data. 264 bytes from nginx-ingress-lb.kube-system.svc.cluster.local (\u0026lt;SLB-IP\u0026gt;): icmp_seq=1 ttl=64 time=0.035 ms 364 bytes from nginx-ingress-lb.kube-system.svc.cluster.local (\u0026lt;SLB-IP\u0026gt;): icmp_seq=2 ttl=64 time=0.036 ms 注意：\n 得到的IP同样是SLB实例的公网IP 解析得到名字是Ingress Controller在集群内部的SVC的DNS Name。  用tcpdump抓包：\ntcpdump -nn host bar.xxx.com，得到 port 80 unreachable的结果\n102:23:25.524028 IP 172.20.1.88.57138 \u0026gt; \u0026lt;SLB-IP\u0026gt;.80: Flags [S], seq 1634983746, win 29200, options [mss 1460,sackOK,TS val 3961214492 ecr 0,nop,wscale 9], length 0 202:23:25.525043 IP \u0026lt;SLB-IP\u0026gt; \u0026gt; 172.20.1.88: ICMP 139.224.167.163 tcp port 80 unreachable, length 68 和阿里同学沟通 建了工单描述了情况，得到的反馈如下：\nIngress Controller Service的externalTrafficPolicy这个为Local（ACK初始化的默认值）的时候跨节点访问SVC SLB地址就是不行，这个和Nginx Ingress Controller没有关系。这个行为在ipvs和kube-proxy实现的service集群上行为是一致的，如果之前是好的，现在不行了，只有一种可能，就是之前访问Ingress入口Url的Pod和两个Nginx Ingress Controller Pod在一个节点上。建议把externalTrafficPolicy改成Cluster。\n解决办法 把externalTrafficPolicy改成Cluster之后的确解决了这个问题。\n不过K8S文档 里说到如果这样设置，那么Pod就得不到客户端的源IP了，要得到客户端源IP只能设置为Local，但是Local又有无法访问的问题。\n阿里的同学说到过：\n 如果之前是好的，现在不行了，只有一种可能，就是之前访问Ingress入口Url的Pod和两个Nginx Ingress Controller Pod在一个节点上\n 就是说如果发起请求的Pod和Ingress Controller的Pod在同一个节点上的话，访问是没有问题的。我实验了一下果然如此。\n于是我把Ingress Controller从Deployment改成DaemonSet，让每个节点上都跑一个Ingress Controller Pod，于是问题解决。\n其他资料 关于这个问题又找了一些资料，不过看不太明白：\n 从service的externalTrafficPolicy到podAntiAffinity  访问 externalTrafficPolicy 为 Local 的 Service 对应 LB 有时超时   另外注意到，用Rancher部署的K8S集群的Ingress Controller都是DaemonSet的。\n","date":"2019-10-21","img":"","permalink":"/post/k8s/k8s-ipvs-cannot-access-self-from-cluster/","series":null,"tags":["k8s"],"title":"启用IPVS的K8S集群无法从Pod经外部访问自己的排障"},{"categories":null,"content":"执行策略和任务的隐式耦合 认识基础组件 扩展线程池 配置线程池 递归算法平行化 循环平行化 1void processCollection(List\u0026lt;Element\u0026gt; elements) { 2 for (Element e : elements) { 3 process(e); 4 } 5} 6 7void processCollectionParallel(Executor exec, List\u0026lt;Element\u0026gt; elements) { 8 for (final Element e : elements) { 9 exec.execute(() -\u0026gt; process(e)); 10 } 11} 递归平行化 1public void sequencialRecursive(List\u0026lt;Node\u0026gt; nodes, Collection results) { 2 for (Node n : nodes) { 3 results.add(node.compute()); 4 sequencialRecursive(n.getChildren(), results); 5 } 6} 7 8public void parallelRecursive(final Executor exec, 9 List\u0026lt;Node\u0026gt; nodes, 10 final Collection results) { 11 for (Node n : nodes) { 12 exec.submit(() -\u0026gt; results.add(n.compute())); 13 parallelRecursive(exec, n.getChildren(), results); 14 } 15} 16 17public Collection getParallelResults(List\u0026lt;Node\u0026gt; nodes) throws InterruptedException { 18 ExecutorService exec = Executors.newCachedThreadPool(); 19 Queue resultQueue = new ConcurrentLinkedQueue(); 20 parallelRecursive(exec, nodes, resultQueue); 21 exec.shutdown(); 22 // 等到所有任务执行完毕 23 exec.awaitTermination(Long.MAX_VALUE, TimeUnits.SECONDS); 24 return resultQueue; 25} ","date":"2019-10-16","img":"","permalink":"/post/concurrent-programming/applying-thread-pools/","series":null,"tags":["并发编程"],"title":"Applying Thread Pools"},{"categories":null,"content":"任务取消 一种做法是设置cancel flag，但是存在永远无法响应的风险：\n1public Task { 2 private volatile boolean cancelled = false; 3 public void cancel() { 4 this.cancelled = true; 5 } 6 public void run() { 7 if (!cancelled) { 8 // 如果这个方法阻塞了，那么Task就永远不会cancel 9 someBlockingMethod(); 10 } 11 } 12} 线程中断 1public class Thread { 2 public void interrupt(); // 通知target thread中断 3 public boolean isInterrupted(); // 查询target thread的中断状态 4 public static boolean interrupted(); // 清空当前thread的中断状态，返回前一个中断状态 5} 利用线程中断来取消任务的例子 1public Task implements Runnable { 2 public void run() { 3 try { 4 // 检测中断状态 5 while (!Thread.currentThread().isInterrupted()) { 6 someBlockingMethod(); 7 } 8 } catch (InterruptedException e) { 9 // 在阻塞方法时线程被中断了 10 // 除非你知道自己在做什么，否则你应该rethrow 或者恢复线程的中断状态 11 Thread.currentThread().interrupt(); 12 } 13 } 14} 就算某个任务不可中断也要在它结束后恢复中断状态 1public Task { 2 public void run() { 3 try { 4 while (true) { 5 try { 6 someBlockingMethod() 7 } catch (InterruptedException e) { 8 interrupted = true; 9 } 10 } 11 } finally { 12 if (interrupted) { 13 Thread.currentThread().interrupt(); 14 } 15 } 16 } 17} 阻塞库的方法一旦探知线程中断状态，就会抛出异常，下面代码会造成死循环，他会不停抛出InterruptedException：\n1public Task { 2 public void run() { 3 while (!blockingQueue.isEmpty()) { 4 try { 5 blockingQueue.take(); 6 } catch (InterrupttedException e) { 7 Thread.currentThread().interrupt(); 8 } 9 } 10 } 11} 反面例子，擅自中断  不知道线程拥有者的中断策略就擅自中断 r.run()里面如果抛出了RuntimeException，返回到了caller那里，然后时间到了触发了caller线程的interruption r.run()先结束了，然后和第2点说的一样 如果r.run()不响应中断，那么timedRun方法就不会返回直到r.run()结束  1// 本意是控制timeRun方法的执行时长 2public void timedRun(Runnable r) { 3 final Thread taskThread = Thread.currentThread(); 4 scheduledExecutor.schedule(() -\u0026gt; taskThread.interrupt(), timeout, unit); 5 r.run(); 6} 用Future中断 1public void timedRun(Runnable r) { 2 Future f = executorService.submit(r); 3 try { 4 f.get(timeout, unit); 5 } catch (TimeoutException e) { 6 // 下面会取消这个task的 7 } catch (ExecutionException e) { 8 // 在task里出现异常，rethrow 9 throw e.getCause(); 10 } finally { 11 // 对一个正常结束的future执行cancel是没有伤害的 12 f.cancel(true); // true代表interrupt 13 } 14} 对付不响应中断 有些方法不响应中断，但是我们要中断咋整？下面给了一个思路：\n1public class ReaderThread extends Thread { 2 private final Socket socket; 3 private final InputStream in; 4 @Override 5 public void interrupt() { 6 try { 7 socket.close(); 8 } catch (IOException ignored) {} 9 finally { 10 super.interrupt(); // 注意还是得让上级中断的 11 } 12 } 13 @Override 14 public void run() { 15 in.read(buf); // 这个方法阻塞但是不响应中断 16 } 17} 对付不响应中断2 如果你是用Executor执行，则可以这样做提供自己的ThreadPoolExecutor.newTaskFor实现，并提供自己的Future.cancel(boolean)：\n1public interface CancellableTask\u0026lt;T\u0026gt; extends Callable\u0026lt;T\u0026gt; { 2 void cancel(); 3 RunnableFuture\u0026lt;T\u0026gt; newTask(); 4} 5public class CancellingExecutor extends ThreadPoolExecutor { 6 // 看这个方法 7 @Override 8 protected\u0026lt;T\u0026gt; RunnableFuture\u0026lt;T\u0026gt; newTaskFor(Callable\u0026lt;T\u0026gt; callable) { 9 if (callable instanceof CancellableTask) { 10 return ((CancellableTask\u0026lt;T\u0026gt;) callable).newTask(); 11 } 12 return super.newTaskFor(callable); 13 } 14} 15public abstract class SocketUsingTask\u0026lt;T\u0026gt; implements CancellableTask\u0026lt;T\u0026gt; { 16 private Socket socket; 17 public synchronized void cancel() { 18 try { 19 if (socket != null) { 20 socket.close(); 21 } 22 } catch (IOException ignored) {} 23 } 24 public RunnableFuture\u0026lt;T\u0026gt; newTask() { 25 return new FutureTask\u0026lt;T\u0026gt;(this) { 26 // 看这个方法 27 @Override 28 public boolean cancel(boolean mayInterruptIfRunning) { 29 try { 30 try { 31 SocketUsingTask.this.cancel() 32 } finally { 33 return super.cancel(mayInterruptIfRunning); 34 } 35 } 36 } 37 } 38 } 39} 停止基于线程的Service 利用ExecutorService 1public class LogService { 2 private final ExecutorService exec = ...; 3 public void stop() throws InterruptionException { 4 try { 5 exec.shutdown(); 6 exec.awaitTermination(timeout, unit); 7 } finally { 8 writer.close(); 9 } 10 } 11 public void log(String msg) { 12 try { 13 exec.execute(new WriteTask(msg)); 14 } catch (RejectedExecutionException ignored) {} 15 } 16} 利用Poison Pills 1producer.(POISON_PILL); 2 3if (POISON_PILL == consumer.take()) { 4 doShutdownWork(); 5} 跟踪shutdownNow时开始但未结束的任务 ExecutorService.shutdownNow会返回还未开始的任务，但是不会返回开始了但是没有结束的任务，用类似下面的代码可以得到这些任务：\n1public class TrackingExecutor extends AbstractExecutorService { 2 private final ExecutorService exec; 3 private final Set\u0026lt;Runnable\u0026gt; tasksCancelledAtShutdown = 4 Collections.synchronizedSet(new HashSet\u0026lt;Runnable\u0026gt;()); 5 public List\u0026lt;Runnable\u0026gt; getCancelledTasks() { 6 if (!exec.isTerminated()) { 7 throw new IllegalStateException(...); 8 } 9 return new ArrayList\u0026lt;\u0026gt;(tasksCancelledAtShutdown); 10 } 11 public void execute(final Runnable runnable) { 12 exec.execute(() -\u0026gt; { 13 try { 14 runnable.run(); 15 } finally { 16 if (isShutdown() \u0026amp;\u0026amp; Thread.currentThread.isInterrupted()) { 17 tasksCancelledAtShutdown.add(runnable); 18 } 19 } 20 }) 21 } 22} 线程异常退出 下面的代码在线程异常退出前告知框架它死了：\n1public void run() { 2 Throwable thrown = null; 3 try { 4 while (!isInterrupted()) { 5 runTask(getTaskFromWorkQueue()); 6 } 7 } catch (Throwable e) { 8 thrown = e; 9 } finally { 10 threadExited(this, thrown); 11 } 12} JVM shutdown ","date":"2019-10-13","img":"","permalink":"/post/concurrent-programming/cancellation-and-shutdown/","series":null,"tags":["并发编程"],"title":"Cancellation and Shutdown"},{"categories":null,"content":"本文如何控制Tiller只能操作特定Namespace的方法。\n在Helm的官方文档介绍的安装方法里，会给Tiller的Service Account绑定cluster-admin集群角色，这就意味着只要你的Helm能够和Tiller通信，那么就能通过Tiller控制所有Namespace下的Release。\n在更多情况下，我们希望能够按照Namespace把Tiller的权限分割开来，比如A用户只能通过Tiller来控制Namespace A的Release，B用户只能通过Tiller来控制Namespace B的Release。\nConfiguring minimal RBAC permissions for Helm and Tiller 文章提供了解决办法，原理是给每个Namespace部署一个Tiller，然后给其分配一个只能操作这个Namespace的Service Account。\n 注意：Configuring \u0026hellip; 文章中提到了给CI/CD用的helm账号，本文没有涉及此内容。\n 我在这篇文章的基础上做了一些脚本，并列举一些常用的命令。\n操作步骤 1）使用init-tiller-sa.sh 在Namespace下创建Service Account：\n1./init-tiller-sa.sh \u0026lt;namespace\u0026gt; 2）安装Tiller：\n1helm init --service-account tiller \\ 2 --tiller-namespace \u0026lt;namespace\u0026gt; \\ 如果安装不成功，比如因为Tiller镜像Pull不下来，你可以这样：\n1helm init --service-account tiller \\ 2 --tiller-namespace \u0026lt;namespace\u0026gt; \\ 3 --upgrade \\ 4 --tiller-image=\u0026lt;另外一个tiller的镜像\u0026gt; 3）使用Helm部署Charts，比如这样：\n1helm --tiller-namespace \u0026lt;namespace\u0026gt; \\ 2 install \u0026lt;chart\u0026gt; \\ 3 --name \u0026lt;release\u0026gt; \\ 4 --namespace \u0026lt;namespace\u0026gt; \u0026ndash;namespace`参数可以不提供，如果不提供则和你kubectl的默认namespace相同。\n注意：\n所有的helm指令你都需要加上--tiller-namespace参数。\n如果你要删除Tiller，则：\n1helm --tiller-namespace \u0026lt;namespace\u0026gt; reset 参考资料  Configuring minimal RBAC permissions for Helm and Tiller  Helm - Role-based Access Control  ","date":"2019-10-11","img":"","permalink":"/post/tiller-for-specific-namespace/","series":null,"tags":["k8s","helm","tiller"],"title":"配置Tiller只能操作特定Namespace的方法"},{"categories":null,"content":"Executor框架 1public interface Executor { 2 void execute(Runnable command); 3} 4public interface ExecutorService { 5 \u0026lt;T\u0026gt; List\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt; invokeAll(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks) 6 throws InterruptedException; 7 \u0026lt;T\u0026gt; List\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt; invokeAll(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks 8 long timeout, 9 TimeUnit unit) 10 throws InterruptedException; 11} Shutting down 一种关闭ExecutorServic的方法：\n1ExecutorService exec = ...; 2exec.shutdown(); 3exec.awaitTermination(5, TimeUnit.SECOND); 另一种方法：\n1private ExecutorService exec = ...; 2public void handleRequest() { 3 if (!exec.isShutdown()) { 4 try { 5 exec.submit(...); 6 } catch(RejctedExecutionException e) { 7 if (!exec.isShutdown()) { 8 log(\u0026#34;task submission rejected\u0026#34;, e); 9 } 10 } 11 12 } 13} Callable和Future和FutureTask 1public interface Callable\u0026lt;V\u0026gt; { 2 V call() throws Exception; 3} 4 5public interface Future\u0026lt;V\u0026gt; { 6 boolean cancel(boolean mayInterruptIfRunning); 7 boolean isCanceled(); 8 boolean isDone(); 9 V get() throws InterruptedException, ExecutionException, CancellationException; 10 V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, 11 CancellationException, TimeoutException; 12} 13 14public abstract AbstractExecutorService implements ExecutorService { 15 protected \u0026lt;T\u0026gt; RunnableFuture\u0026lt;T\u0026gt; newTaskFor(Callable\u0026lt;T\u0026gt; task) { 16 return new FutureTask\u0026lt;T\u0026gt;(task); 17 } 18} CompletionService 1void solve(Executor e, Collection\u0026lt;Callable\u0026lt;Result\u0026gt;\u0026gt; solvers) 2 throws InterruptedException, ExecutionException { 3 CompletionService\u0026lt;Result\u0026gt; ecs = new ExecutorCompletionService\u0026lt;Result\u0026gt;(e); 4 for (Callable\u0026lt;Result\u0026gt; s : solvers) 5 ecs.submit(s); 6 int n = solvers.size(); 7 for (int i = 0; i \u0026lt; n; ++i) { 8 Result r = ecs.take().get(); 9 if (r != null) 10 use(r); 11 } 12} 给任务设定超时 1public void someMethod() throws InterruptedException { 2 List\u0026lt;Future\u0026lt;Result\u0026gt;\u0026gt; futures = exec.invokeAll(tasks, time, unit); 3 for (Future\u0026lt;Result\u0026gt; f : futures) { 4 try { 5 Result r = f.get(); 6 } catch (ExecutionException e) { 7 // task failed with throwing exception 8 } catch (CancellationException e) { 9 // task is timeout 10 } 11 } 12} ","date":"2019-10-08","img":"","permalink":"/post/concurrent-programming/task-execution/","series":null,"tags":["并发编程"],"title":"Task Execution"},{"categories":null,"content":"如何将Iphone的短信迁移到华为手机的方法。\n传统的办法是使用isms2droid ，但是在写本文时isms2droid 无法使用，可能与谷歌禁止华为安装谷歌服务有关。因此采用了另一种方法。\n注意：本文中提到的有些网站需要梯子才可以访问。\n第一步 还是按照isms2droid 的方法，提取到3d0d7e5fb2ce288813306e4d4636395e047a3d28文件，一定要注意，在备份Iphone到本机到时候不要加密备份。\n第二步 其实3d0d7e5fb2ce288813306e4d4636395e047a3d28就是一个SQLite3的dump文件，因此可以导入它然后将其输出成“SMS Backup and Restore”的xml格式文件。\n本文采用的是这篇文章 所提供的php脚本，不过它的脚本存在一些bug，导出的短信时间存在问题（这个问题在这篇文章 里也有提到过）。因此我作了一些修改，代码在gist 。\n执行：\n1php iphone-sms-xml.php 3d0d7e5fb2ce288813306e4d4636395e047a3d28 \u0026gt; sms.xml 得到sms.xml文件。\n第三步 在你的华为手机上安装“SMS Backup and Restore”，需要注意的是这个软件在华为应用市场上是找不到的，你需要自行找一个地方下载APK文件安装。我是在这个网站 下载到的。\n第四步 把前面的sms.xml传到你的手机上，然后运行“SMS Backup and Restore”恢复短信，大功告成。\n","date":"2019-10-04","img":"","permalink":"/post/transfer-iphone-sms-to-huawei/","series":null,"tags":["数码"],"title":"迁移Iphone手机短信到华为手机"},{"categories":null,"content":"Synchronized集合 看你怎么用，有可能线程不安全 有时候虽然用了Synchronized集合，也不代表线程安全，比如下面的就是：\n1public static Object getLast(Vector list) { 2 int lastIndex = list.size() - 1; // 1 3 return list.get(lastIndex); // 2 4} 因为在1和2之间可能会有对Vector的其他写操作。正确的做法是：\n1public static Object getLast(Vector list) { 2 synchronized (list) { 3 // ... 4 } 5} Iterators的ConcurrentModificationException 这个问题在迭代集合的同时在删除集合元素时发生。\n隐藏的Iterators 有些时候Iterator不是明显的，比如下面代码：\n1public class HiddentIterator { 2 private final Set\u0026lt;Integer\u0026gt; set = new HashSet\u0026lt;\u0026gt;(); 3 public synchronized void add(Integer v) { ... } 4 public void addTenThings() { 5 for (int i = 0; i \u0026lt; 10; i++) { 6 add(i); 7 } 8 System.out.println(\u0026#34;Set: \u0026#34; + set); 9 } 10} 上面println隐式调用了Set的toString，而toString有隐式做了迭代器。\nConcurrent集合 阻塞及可中断方法 InterruptedException没法往上抛的处理例子：\n1public class TaskRunnable implements Runnable { 2 public void run() { 3 try { 4 someBlockingCall(); 5 } catch (InterruptedException e) { 6 Thread.currentThread().interrupt(); 7 } 8 } 9} 一种Cache的实现 1public interface Computable\u0026lt;A, V\u0026gt; { 2 V compute(A arg) throws InterruptedException; 3} 4public class Memorizer\u0026lt;A, V\u0026gt; implements Computable\u0026lt;A, V\u0026gt; { 5 private final ConcurrentHashMap\u0026lt;A, Future\u0026lt;V\u0026gt;\u0026gt; cache = new ConcurrentHashMap\u0026lt;\u0026gt;(); 6 private final Computable\u0026lt;A, V\u0026gt; c; 7 public Memorizer(Computable\u0026lt;A, V\u0026gt; c) { this.c = c; } 8 9 public V compute(final A arg) throws InterruptedException { 10 while (true) { 11 Future\u0026lt;V\u0026gt; f = cache.get(arg); 12 if (f == null) { 13 Callable\u0026lt;V\u0026gt; eval = new Callable\u0026lt;\u0026gt;() { 14 public V call() throws InterruptedException { 15 return c.compute(arg); 16 } 17 } 18 FutureTask\u0026lt;V\u0026gt; ft = new FutureTask\u0026lt;\u0026gt;(eval); 19 f = cache.putIfAbsent(arg, ft); 20 if (f == null) { 21 f = ft; 22 ft.run(); 23 } 24 } 25 try { 26 return f.get(); 27 } catch (CancellationException e) { 28 cache.remove(arg, f); 29 } catch (ExecutionException e) { 30 throw launderThrowable(e.getCause()); 31 } 32 } 33 } 34} ","date":"2019-09-19","img":"","permalink":"/post/concurrent-programming/building-blocks/","series":null,"tags":["并发编程"],"title":"Building Blocks"},{"categories":null,"content":"对象管制 例子1：\n1@ThreadSafe 2public class PersonSet { 3 private final Set\u0026lt;Person\u0026gt; mySet = new HashSet\u0026lt;\u0026gt;(); 4 public synchronized void addPerson(Person p) { ... } 5 public synchronized boolean containsPerson(Person p) { ... } 6} 例子2：\n1@ThreadSafe 2public class PersonSet { 3 private final Set\u0026lt;Person\u0026gt; mySet = new HashSet\u0026lt;\u0026gt;(); 4 private final Object mylock = new Object(); 5 public void addPerson(Person p) { 6 synchronized(mylock) { 7 ... 8 } 9 } 10} 例子3：\n1@TreadSafe 2public class MonitorVehicleTracker { 3 private final Map\u0026lt;String, MutablePoint\u0026gt; locations; 4 public MonitorVehicleTracker(Map\u0026lt;String, MutablePoint\u0026gt; locations) { 5 // 深copyMap，防止MutablePoint被共享 6 this.locations = deepCopy(locations); 7 } 8 public synchronized Map\u0026lt;String, MutablePoint\u0026gt; getLocations() { 9 // 深copyMap，防止MutablePoint逃逸 10 return deepCopy(this.locations); 11 } 12 // 用monitor lock保护访问 13 public synchronized void setLocation(String id, int x, int y) { ... } 14} 代理线程安全 把线程安全的工作代理给其他能提供线程安全的类：\n例子：\n1@ThreadSafe class DelegatingVehicleTracker { 2 private final ConcurrentMap\u0026lt;String, ImmutablePoint\u0026gt; locations; 3 private final Map\u0026lt;String, ImmutablePoint\u0026gt; unmodifiableMap; 4 public DelegatingVehicleTracker(Map\u0026lt;String, ImmutablePoint\u0026gt; points) { 5 // 把Map浅copy过来 6 locations = new ConcurrentHashMap\u0026lt;\u0026gt;(points); 7 // 这个比较妙，把线程安全代理给了并发Map 8 unmodifiableMap = Collections.unmodifiableMap(locations); 9 } 10 // 就算逃逸出去也无所谓，反正只能只读，而且因为底层是并发Map，所以不用担心可见性、原子性等问题 11 public Map\u0026lt;String, MutablePoint\u0026gt; getLocations() { 12 return unmodifiableMap; 13 } 14 public void setLocation(String id, int x, int y) { 15 locations.put(...) 16 } 17} 给线程安全类添加功能 给线程安全的类添加功能的时候要注意不要破坏线程安全。\n客户方加锁 下面就是个反面例子：\n1public class ListHelper { 2 public List list = Collections.synchronizedList(new ArrayList()); 3 public synchronized boolean putIfAbsent(Object v) { ... } 4} 这是因为putIfAbsent使用的monitor lock和synchronizedList自身使用的monitor lock不是同一个，这就破坏了线程安全。\n正确的做法：\n1public class ListHelper { 2 public List list = Collections.synchronizedList(new ArrayList()); 3 public boolean putIfAbsent(Object v) { 4 synchronized (list) { 5 ... 6 } 7 } 8} 组合 可以这么干：\n1public class ImprovedList implents List { 2 private final List list; 3 public synchronized boolean putIfAbsent(Object v) { 4 ... 5 list.add(v); 6 } 7 public synchronized void clear() { 8 list.clear(); 9 } 10 ... 11} ","date":"2019-09-19","img":"","permalink":"/post/concurrent-programming/composing-objects/","series":null,"tags":["并发编程"],"title":"编写线程安全对象"},{"categories":null,"content":"Amdahl定律讲的是当用多CPU核心来处理一个任务时，这个任务所能获得的最大理论加速。\n先看下面的公式：\n n代表CPU核心数 S(n)，代表采用n个CPU核心时所能获得的理论加速（倍数） T(1)，任务采用单CPU核心时的耗时 T(n)，任务采用n个CPU核心时的耗时 B，任务无法中平行化的代码的比率 1 - B，任务中可以平行化的代码的比率  这个公式等价于下面的公式：\n n代表CPU核心数 S(n)，代表采用n个CPU核心时所能获得的理论加速（倍数） P，任务中可以平行化的代码的比率  其实这个公式告诉我们，随着CPU核心数的增加，你所能获得的加速边际效应是递减的，看下面这张图：\n","date":"2019-09-19","img":"","permalink":"/post/concurrent-programming/amdahls-law/","series":null,"tags":["并发编程"],"title":"Amdahl定律"},{"categories":null,"content":"","date":"2019-09-18","img":"","permalink":"/post/concurrent-programming/sharing-objects/","series":null,"tags":["并发编程"],"title":"共享对象"},{"categories":null,"content":"","date":"2019-09-18","img":"","permalink":"/post/concurrent-programming/thread-safety/","series":null,"tags":["并发编程"],"title":"线程安全"},{"categories":null,"content":"并行与CPU利用率  如何估算吞吐量以及线程池大小  并行、延迟与吞吐量  Amdahl定律   Java并发编程  线程安全  共享对象  编写线程安全对象  Applying Thread Pools  Building Blocks  Task Execution  Cancellation and Shutdown  运用线程池  Avoiding Liveness Hazards  Performance and scalability  Testing Concurrent Programs  Explicit Locks  Building Custom Synchronizers  Atomic Variables and Nonblocking Synchronization  The Java Memory Model   Go并发编程  Scheduling In Go : Part I - OS Scheduler 阅读笔记  Scheduling In Go : Part II - Go Scheduler 阅读笔记  Scheduling In Go : Part III - Concurrency 阅读笔记  Google I/O 2012 - Go Concurrency Patterns, video  Rob Pike - \u0026lsquo;Concurrency Is Not Parallelism\u0026rsquo;, video , slides  ","date":"2019-09-18","img":"","permalink":"/post/concurrent-programming/index-page/","series":null,"tags":["并发编程"],"title":"并发编程系列"},{"categories":null,"content":"Pairs with Sum: Design an algorithm to find all pairs of integers within an array which sum to a specified value.\nHints: #548, #597, #644, #673\n解法1 可以用暴力破解，两个循环来做但是这样不好。\n可以这么西靠，如果给定一个sum，然后取数组中的一个a，那么就是看这个数组中是否存在元素=sum - a。\n我们可以把数组中的元素都放到一个Set里，那么就可以很方便的判断“数组中是否存在元素=sum - a”。\n有一点要注意的是如果数组中存在重复元素，比如：\n1sum: 4 2array: 2, 2, 1, 3 3result: {2, 2}, {1, 3} 4 5如果array是: 2, 1, 3 6result: {1, 3} 7 8如果array是: 1, 3, 1, 3 9result: {1, 3} 还要注意不要出现重复结果，比如上面的{1, 3}和{3, 1}就是属于重复结果。\n我们可以做一个Map，存放的是元素 -\u0026gt; 计数来解决重复元素的问题。同时用如果构成pair，那么就从Map中去掉这两个元素来解决重复结果的问题。\n代码：\n1public void pairSum(int[] array, int sum) { 2 Map\u0026lt;Integer, Integer\u0026gt; numCounts = makeNumCounts(array); 3 for (int i = 0; i \u0026lt; array; i++) { 4 int num = array[i]; 5 int other = sum - num; 6 if (num == other \u0026amp;\u0026amp; numCounts.containsKey(num) \u0026amp;\u0026amp; numCounts.get(num) \u0026gt; 1) { 7 System.out.println(\u0026#34;{\u0026#34; + num + \u0026#34;,\u0026#34; + num \u0026#34;}\u0026#34;); 8 numCounts.remove(num); 9 } 10 if (numCounts.containsKey(other)) { 11 System.out.println(\u0026#34;{\u0026#34; + num + \u0026#34;,\u0026#34; + other \u0026#34;}\u0026#34;); 12 numCounts.remove(num); 13 numCounts.remove(other); 14 } 15 } 16} 17 18private Map\u0026lt;Integer, Integer\u0026gt; makeNumCounts(int[] array) { 19 Map\u0026lt;Integer, Integer\u0026gt; result = new HashMap\u0026lt;\u0026gt;(); 20 for (int i = 0; i \u0026lt; array; i++) { 21 int num = array[i]; 22 Integer count = result.get(num); 23 if (count == null) { 24 count = 0; 25 } 26 count++; 27 result.put(num, count); 28 } 29 return result; 30} 解法2 给数组排序，让从两头开始找，如果array[head] + array[tail] \u0026lt; sum，那么head++，否则tail\u0026ndash;，代码：\n1public void pairSum(int[] array, int sum) { 2 Arrays.sort(array); 3 int head = 0; 4 int tail = array.length - 1; 5 while (head \u0026lt; tail) { 6 int s = array[head] + array[tail]; 7 if (s == sum) { 8 System.out.println(\u0026#34;{\u0026#34; + array[head] + \u0026#34;,\u0026#34; + array[tail] \u0026#34;}\u0026#34;); 9 head++; 10 tail--; 11 } else { 12 if (s \u0026lt; sum) { 13 head++; 14 } else { 15 tail--; 16 } 17 } 18 } 19} ","date":"2019-09-18","img":"","permalink":"/post/cracking-coding-interview/16.24-pairs-with-sum/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.24 Pairs With Sum"},{"categories":null,"content":"Calculator: Given an arithmetic equation consisting of positive integers, +, -, * and / (no paren­theses), compute the result.\nEXAMPLE\n1Input : 2*3+5/6*3+15 2Output: 23.5 Hints: #521, #624, #665, #698\n解法 没有括号，这个比较好做。\n做两个栈，一个操作数栈，一个操作符栈。\n当遇到数字的时候，压入操作数栈。\n遇到符号的时候根据情况：\n 如果当前符号优先级 \u0026lt; 栈顶符号，则先【计算】，然后做第2步 压入符号到操作数栈  计算过程：\n 从操作符取出一个元素，从操作数取出两个元素 将计算结果压入操作数栈中  比如：\n12 + 3 - 5 2 3STEP 1 4Operands : [2] // 尾部代表栈顶 5Operators: [] // 尾部代表栈顶 6 7STEP 2 8Operands : [2] 9Operators: [+] 10 11STEP 3 12Operands : [2, 3] 13Operators: [+] 14 15STEP 4 16Operands : [2, 3, 5] 17Operators: [+, -] 18 19STEP 5 20Operands : [2, -2] 21Operators: [+] 22 23STEP 6 24Operands : [0] 25Operators: [] 比如：\n12 + 3 * 5 2 3STEP 1 4Operands : [2] 5Operators: [] 6 7STEP 2 8Operands : [2] 9Operators: [+] 10 11STEP 3 12Operands : [2, 3] 13Operators: [+] 14 15STEP 4 16Operands : [2, 3, 5] 17Operators: [+, *] 18 19STEP 5 20Operands : [2, 15] 21Operators: [+] 22 23STEP 6 24Operands : [17] 25Operators: [] 比如：\n12 * 3 + 5 2 3STEP 1 4Operands : [2] 5Operators: [] 6 7STEP 2 8Operands : [2] 9Operators: [*] 10 11STEP 3 12Operands : [2, 3] 13Operators: [*] 14 15STEP 4 因为+优先级比*低，所以先把*计算了 16Operands : [6] 17Operators: [+] 18 19STEP 5 20Operands : [6, 5] 21Operators: [+] 22 23STEP 6 24Operands : [11] 25Operators: [] 代码：\n1public double calculate(String expression) { 2 Stack\u0026lt;Double\u0026gt; operands = new Stack\u0026lt;\u0026gt;(); 3 Stack\u0026lt;Char\u0026gt; operators = new Stack\u0026lt;\u0026gt;(); 4 5 boolean nextNum = true; 6 while (expression != \u0026#34;\u0026#34;) { 7 if (nextNum) { 8 String num = nextNum(expression); 9 expression = expression.subString(num.length()); 10 nextNum = false; 11 operands.push(Double.valueOf(num)); 12 } else { 13 char op = getNextOp(expression); 14 expression = expression.subString(1); 15 nextNum = true; 16 17 if (!operators.isEmpty()) { 18 char prevOp = operators.peek(); 19 if (isOpGt(prevOp, op)) { 20 operands.push(calc(operands, operators)); 21 } 22 } 23 operators.push(op); 24 } 25 } 26 // 做最后的计算 27 while (!operators.isEmpty()) { 28 operands.push(calc(operands, operators)); 29 } 30 return operands.pop(); 31} 32 33private char nextOp(String expression) { 34 return expression.charAt(0); 35} 36 37private String nextNum(String expression) { 38 int s = 0; 39 for (int i = 1; i \u0026lt; expression.length(); i++) { 40 char d = expression.charAt(i); 41 if (d \u0026lt; \u0026#39;0\u0026#39; || d \u0026gt; \u0026#39;9\u0026#39;) { 42 break; 43 } 44 } 45 return expression.subString(s, i); 46} 47 48private double calc(Stack\u0026lt;Double\u0026gt; operands, Stack\u0026lt;Char\u0026gt; operators) { 49 double b = operands.pop(); 50 double a = operands.pop(); 51 char op = operators.pop(); 52 switch (op) { 53 case \u0026#39;*\u0026#39;: 54 return a * b; 55 case \u0026#39;-\u0026#39;: 56 return a - b; 57 case \u0026#39;+\u0026#39;: 58 return a + b; 59 case \u0026#39;/\u0026#39;: 60 return a / b; 61 } 62 return 0d; 63} 64 65private boolean isOpGt(char op1, char op2) { 66 if ((op1 == \u0026#39;*\u0026#39; || op1 == \u0026#39;/\u0026#39;) \u0026amp;\u0026amp; (op2 == \u0026#39;+\u0026#39; || op2 == \u0026#39;-\u0026#39;)) { 67 return true; 68 } 69 return false; 70} ","date":"2019-09-18","img":"","permalink":"/post/cracking-coding-interview/16.26-calculator/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.26 Calculator"},{"categories":null,"content":"Rand7 from Rand5: Implement a method rand7() given rand5(). That is, given a method that generates a random number between 0 and 4 (inclusive), write a method that generates a random number between 0 and 6 (inclusive).\nHints: #505, #574, #637, #668, #697, #720\n解法 rand5()的范围是[0, 4]，先看看那么两个rand5()相加是否能够等价rand10()即[0, 9]。\n   结果 组合 概率     0 0 + 0 0.04( 0.2 * 0.2)   1 1 + 0, 0 + 1 2 * 0.04 = 0.08   2 1 + 1, 0 + 2, 2 + 0 3 * 0.04 = 0.12   3 1 + 2, 2 + 1, 0 + 3, 3 + 0 4 * 0.04 = 0.16   4 1 + 3, 3 + 1, 0 + 4, 4 + 0, 2 + 2 5 * 0.04 = 0.20   5 1 + 4, 4 + 1, 2 + 3, 3 + 2 4 * 0.04 = 0.16   6 3 + 3, 2 + 4, 4 + 2 3 * 0.04 = 0.12   7 3 + 4, 4 + 3 2 * 0.04 = 0.08   8 4 + 4 0.2 * 0.2 = 0.04    可以每个结果的概率并不相同，所以不能成立。其实同理，相乘也不能成立。\n如果对结果取模，那么分布就变成了：\n   结果 组合 概率     0,7 (7 % 7 = 0) 0 + 0, 3 + 4, 4 + 3 3 * 0.04 = 0.12   1,8 (8 % 7 = 1) 1 + 0, 0 + 1, 4 + 4 3 * 0.04 = 0.12   2 1 + 1, 0 + 2, 2 + 0 3 * 0.04 = 0.12   3 1 + 2, 2 + 1, 0 + 3, 3 + 0 4 * 0.04 = 0.16   4 1 + 3, 3 + 1, 0 + 4, 4 + 0, 2 + 2 5 * 0.04 = 0.20   5 1 + 4, 4 + 1, 2 + 3, 3 + 2 4 * 0.04 = 0.16   6 3 + 3, 2 + 4, 4 + 2 3 * 0.04 = 0.12    回发现概率分布还是不均匀。\n得想一个办法将各种结果出现的概率弄成一致，如果这样 5 * rand5() + rand5()：\n   因子1 因子2 结果     0 0 0   0 5 5   0 10 10   0 15 15   0 20 20   1 0 1   1 5 6   1 10 11   1 15 16   1 20 21   2 0 2   2 5 7   2 10 12   2 15 17   2 20 22   3 0 3   3 5 8   3 10 13   3 15 18   3 20 23   4 0 4   4 5 9   4 10 14   4 15 19   4 20 24    可以发现，结果出现的次数都是一次，也就是概率相同。那么，我们可以抛弃掉[21, 24]这4个结果，在[0, 20]之间 % 7，代码：\n1public int rand7() { 2 while (true) { 3 int num = rand5() * 5 + rand5(); 4 if (num \u0026lt; 21) { 5 return num % 7; 6 } 7 } 8} 为什么这样做概率是均匀的？我们可以把代码做一个转换，因为已知rand5(5) + rand(5)能够得到一个均匀分布的[0, 24]的区间，那么就等价于rand25()，然后我们把 % 7 这个操作去掉，把代码变成这样：\n1public int rand21() { 2 while (true) { 3 int num = rand(25); 4 if (num \u0026lt; 21) { 5 return num; 6 } 7 } 8} 假设每次调用rand25()的返回结果是0, 1, 2, 3, ..., 24, 0, 1, 2, ..., 24，那么调用rand21()的记录就是：\n   rand21()结果 rand25()调用结果     0 0   1 1   2 2   \u0026hellip; \u0026hellip;   20 20   0 21, 22, 23, 24, 0，结果取0   1 1   2 2   \u0026hellip;     可以看到rand21()的结果的分布都是均匀的，所以解法提到的方法是可行的。\n","date":"2019-09-18","img":"","permalink":"/post/cracking-coding-interview/16.23-rand7-from-rand5/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.23 Rand7 From Rand5"},{"categories":null,"content":"Sum Swap: Given two arrays of integers, find a pair of values (one value from each array) that you can swap to give the two arrays the same sum.\n1EXAMPLE 2Input: {4, 1, 2, 1, 1, 2} and {3, 6, 3, 3} 3Output: {1, 3} Hints: #545, #557, #564, #577, #583, #592, #602, #606, #635\n解法 这个题目的意思是有两个数组，这两个数组的Sum不一样，然后问从这两个数组中各取一个什么数交换一下，能够使得它们的Sum变成一样。\n先来看一个公式：\n1用A、B代表数组，用a、b代表这两个交换的数，用S代表数组的和 2数组A的和可以表示成：(SA - a) + a 3数组B的和可以表示成：(SB - b) + b 4a、b两个数交换就相当于 5(SA - a) + b = (SB - b) + a 6可以求得： 7b - a = (SB - SA) / 2 这样就建立起了a、b两个数字的关系，然后考虑到数组中的都是整数，那么这a和b的差不能为单数\n代码：\n1public void sumSwap(int[] array1, int[] array2) { 2 int sum1 = sum(array1); 3 int sum2 = sum(array2); 4 int doubleDelta = sum1 - sum2; 5 if (doubleDelta % 2 == 1) { 6 // 这个是找不到的 7 return; 8 } 9 int delta = doubleDelta / 2; 10 Set\u0026lt;Integer\u0026gt; set2 = makeSet(array2); 11 for (int i = 0; i \u0026lt; array1.length; i++) { 12 int e1 = array1[i]; 13 int expectedE2 = e1 - delta; 14 if (set2.contains(expectedE2)) { 15 System.out.println(\u0026#34;\u0026#34; + e1 + \u0026#34;,\u0026#34; + e2); 16 return; 17 } 18 } 19} 20 21private int sum(int[] array) { 22 int sum = 0; 23 for (int i = 0; i \u0026lt; array.length; i++) { 24 sum += array[i]; 25 } 26 return sum; 27} 28 29private Set\u0026lt;Integer\u0026gt; makeSet(int[] array) { 30 Set\u0026lt;Integer\u0026gt; set = new HashSet\u0026lt;\u0026gt;(); 31 for (int i = 0; i \u0026lt; array.length; i++) { 32 set.add(array[i]); 33 } 34 return set; 35} 时间复杂度：O(A + B)，M是array1的长度，N是array2的长度\n","date":"2019-09-17","img":"","permalink":"/post/cracking-coding-interview/16.21-sum-swap/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.21 Sum Swap"},{"categories":null,"content":"T9: On old cell phones, users typed on a numeric keypad and the phone would provide a list of words that matched these numbers. Each digit mapped to a set of 0 - 4 letters. Implement an algo­rithm to return a list of matching words, given a sequence of digits. You are provided a list of valid words (provided in whatever data structure you\u0026rsquo;d like). The mapping is shown in the diagram below:\n1|-----|-----|-----| 2| 1 | 2 | 3 | 3| | abc | def | 4|-----|-----|-----| 5| 4 | 5 | 6 | 6| ghi | jkl | mno | 7|-----|-----|-----| 8| 7 | 8 | 9 | 9|pqrs | tuv | wxyz| 10|-----|-----|-----| 11| | 0 | | 12|-----|-----|-----| Example：\n1Input : 8733 2Output : tree, used 3Hints : #477, #487, #654, #703, #726, #744 解法1 把数字所能组成的word统统算出来，然后按个看是否在字典里。\n算法则是：\n1allWords(digits[0~n]) = allChars of digits[0] * allWords(digits[1~n]) 2 3allWords(digits[0~n]): 数字序列所可能组成的所有单词 4allChars of digits[0]: 第一个数字的所有可能字符 5allWords(digits[1~n]): 数字序列（去掉第一个数字）所可能组成的所有单词 代码：\n1Map\u0026lt;Integer, String[]\u0026gt; digitMap = new HashMap\u0026lt;\u0026gt;(); 2digitMap.put(1, new String[] {\u0026#34;\u0026#34;}); 3digitMap.put(2, new String[] {\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;}); 4digitMap.put(3, new String[] {\u0026#34;d\u0026#34;, \u0026#34;e\u0026#34;, \u0026#34;f\u0026#34;}); 5//... 6digitMap.put(0, new String[] {\u0026#34;\u0026#34;}); 7 8Set\u0026lt;String\u0026gt; dictionary = new HashSet\u0026lt;\u0026gt;(); 9/// 初始化字典数据 10 11public List\u0026lt;String\u0026gt; allValidWords(int[] digits) { 12 List\u0026lt;String\u0026gt; allWords = allWords(digits); 13 List\u0026lt;String\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); 14 for (String word : allWords) { 15 if (dictionary.contains(word)) { 16 result.add(word); 17 } 18 } 19 return result; 20} 21 22private List\u0026lt;String\u0026gt; allWords(int[] digits) { 23 if (digits.length == 1) { 24 return digitMap.get(digits[0]); 25 } 26 int[] subDigits = Arrays.subArray(digits, 1); // 截取digits[1~tail] 27 List\u0026lt;String\u0026gt; subAllWords = allWords(subDigits); 28 29 List\u0026lt;String\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); 30 char[] firstChars = digitMap.get(digits[0]); 31 for (int i = 0; i \u0026lt; firstChars.length; i++) { 32 for (String subWord : subAllWords) { 33 result.add(firstChars[i] + subWord); 34 } 35 } 36 return result; 37} 时间复杂度：O(3n)，n代表数字位数，3是因为大部分数字只代表3个字符，所以取3。\n解法2 解法1时间太长了，是否可以在遍历所有可能性的过程中就去掉可能存在的结果呢？比如8733有一种可能是tqdd，那么在q的时候就能够知道不存在以tq开头的单词，那么后面的就不需要再比较了。\n那么我们把Dictionary做成一种树形的结构，比如：\n1 t 2 / \\ 3 r a 4 / \\ | 5 e a i 6 / | | 7 e i l 8 | l | 9 . | . 10 . 11.代表结束 代码：\n1public class WordNode { 2 Map\u0026lt;Char, WordNode\u0026gt; next; 3} 4 5Map\u0026lt;Integer, char[]\u0026gt; digitMap = new HashMap\u0026lt;\u0026gt;(); 6 7public List\u0026lt;String\u0026gt; allValidWords(int[] digits) { 8 List\u0026lt;String\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); 9 WordNode root = ...; 10 searchWord(digits, 0, root, \u0026#34;\u0026#34;, result); 11 return result; 12} 13 14private void searchWord(int[] digit, int index, WordNode node, String word, List\u0026lt;String\u0026gt; result) { 15 if (index == digit.length \u0026amp;\u0026amp; node.isEnd()) { 16 // digit走到底，且单词结束 17 result.add(word); 18 return; 19 } 20 char[] chars = digitMap.get(digit[index]); 21 22 for (int i = 0; i \u0026lt; chars.length; i++) { 23 char c = chars[i]; 24 if (node.containsNext(c)) { 25 searchWord(digit, index + 1, node.next(c), word + c, result); 26 } 27 } 28} 时间复杂度：最坏情况是O(3n)，n是digits的长度，当比如你弄了一个8733，但是字典里的单词长度都大于4，且每个word的前缀都是8733所能构成的字符串。\n解法3 换个角度思考，可以先将字典中的所有word都转成数字形式，然后构建一个digits -\u0026gt; word list的表。\n代码：\n1// 构建 digits -\u0026gt; word list 2public Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; makeDigits2Words(List\u0026lt;String\u0026gt; dictionary) { 3 4 Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; result = new HashMap\u0026lt;\u0026gt;(); 5 6 for (String word : dictionary) { 7 String digits = toDigits(word); 8 List\u0026lt;String\u0026gt; words = result.get(digits); 9 if (words == null) { 10 words = new ArrayList\u0026lt;\u0026gt;(); 11 result.put(digits, words); 12 } 13 words.add(word); 14 } 15 16 return result; 17} 18 19private String toDigits(String word) { 20 StringBuilder sb = new StringBuilder(); 21 for (int i = 0; i \u0026lt; word.length(); i++) { 22 char c = word.charAt(c); 23 char d = toDigit(c); 24 sb.append(d); 25 } 26 return sb.toString(); 27} 28 29private char toDigit(char c) { 30 if (\u0026#39;a\u0026#39; \u0026lt;= c \u0026amp;\u0026amp; c \u0026lt;= \u0026#39;c\u0026#39;) { 31 return \u0026#39;2\u0026#39;; 32 } 33 if (\u0026#39;d\u0026#39; \u0026lt;= c \u0026amp;\u0026amp; c \u0026lt;= \u0026#39;f\u0026#39;) { 34 return \u0026#39;3\u0026#39;; 35 } 36 if (\u0026#39;g\u0026#39; \u0026lt;= c \u0026amp;\u0026amp; c \u0026lt;= \u0026#39;i\u0026#39;) { 37 return \u0026#39;4\u0026#39;; 38 } 39 ... 40} 41 42private Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; digitWords = makeDigits2Words(dictionary); 43 44public List\u0026lt;String\u0026gt; allValidWords(String digits) { 45 return digitWords.get(digits); 46} 时间复杂度：在于makeDigits2Words方法，这个方法实际上遍历了dictionary所有word的所有字符，所以复杂度为O(N)，N为字典中的所有word的长度之和。\n","date":"2019-09-17","img":"","permalink":"/post/cracking-coding-interview/16.20-t9/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.20 T9"},{"categories":null,"content":"","date":"2019-09-17","img":"","permalink":"/post/jvm/lock-optimization/","series":null,"tags":["jvm"],"title":"JVM - 锁优化"},{"categories":null,"content":"","date":"2019-09-17","img":"","permalink":"/post/jvm/thread-safe/","series":null,"tags":["jvm"],"title":"JVM - 线程安全"},{"categories":null,"content":"","date":"2019-09-16","img":"","permalink":"/post/jvm/thread/","series":null,"tags":["jvm"],"title":"JVM - 线程"},{"categories":null,"content":"","date":"2019-09-16","img":"","permalink":"/post/jvm/memory-model/","series":null,"tags":["jvm","kernel"],"title":"JVM - 内存模型"},{"categories":null,"content":"Pond Sizes: You have an integer matrix representing a plot of land, where the value at that loca­ tion represents the height above sea level. A value of zero indicates water. A pond is a region of water connected vertically, horizontally, or diagonally. The size of the pond is the total number of connected water cells. Write a method to compute the sizes of all ponds in the matrix.\nEXAMPLE\n1Input: 2 0 2 1 0 3 0 1 0 1 4 1 1 0 1 5 0 1 0 1 6Output: 2, 4, 1 (in any order) Hints: #674, #687, #706, #723\n解法 一个矩阵，里面有数字，0则代表水，池塘则是相连的水组成（横着连、纵着连、斜着连），池塘大小则是水的数量。\n例子里给出Output则是这么几个池塘：\n1 [0] 2 1 [0] 2 [0] 1 [0] 1 3 1 1 [0] 1 4 [0] 1 [0] 1 解决思路可以是这样的：\n 按照从左到右，从上到下的顺序，来遍历数组，当遇到0的时候则进入池塘搜索模式 池塘搜索模式：  池塘初始大小为1，把当前cell设置为-1（标记为已经记录过） 碰到非0则退出 向右、向左、向下、向左下、向右下搜索，重复1-3步    代码：\n1public void pondSizes(int[][] land) { 2 int rows = land.length; 3 int cols = land[0].length; 4 for (int i = 0; i \u0026lt; rows; i++) { 5 for (int j = 0; j \u0026lt; cols; j++) { 6 if (land[i][j] == 0) { 7 int pondSize = searchPond(land, i, j); 8 if (pondSize != 0) { 9 System.out.println(pondSize); 10 } 11 } 12 } 13 } 14} 15 16private int searchPond(int[][] land, int r, int c) { 17 // 超出边界 18 if (r \u0026gt;= land.length || c \u0026gt;= land[0].length || r \u0026lt; 0 || c \u0026lt; 0) { 19 return 0; 20 } 21 if (land[r][c] != 0) { 22 return 0; 23 } 24 land[r][c] = -1; 25 int pondSize = 1; 26 // 往右边找 27 pondSize += searchPond(land, r, c + 1); 28 // 往左边找 29 pondSize += searchPond(land, r, c - 1); 30 // 往下边找 31 pondSize += searchPond(land, r + 1, c); 32 // 往左下找 33 pondSize += searchPond(land, r + 1, c - 1); 34 // 往右下找 35 pondSize += searchPond(land, r + 1, c + 1); 36 return pondSize; 37} 时间复杂度：O(N2)，N是NxN矩阵的N。思路：pondSizes方法遍历了整个矩阵，因此是N2。searchPond方法看似也遍历了整个矩阵，但是当它真的遍历了整个矩阵就意味着矩阵里都是0，那么下一次它就不会被调用了。也就是每个0 cell只会被touch一次，第二次的时候就跳过了。\n","date":"2019-09-16","img":"","permalink":"/post/cracking-coding-interview/16.19-pond-sizes/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.19 Pond Sizes"},{"categories":null,"content":"Pattern Matching: You are given two strings, pattern and value.The pattern string consists of just the letters a and b, describing a pattern within a string. For example, the string catcatgocatgo matches the pattern aabab (where cat is a and go is b). It also matches patterns like a, ab, and b. Write a method to determine if value matches pattern.\nHints: #631, #643, #653, #663, #685, #718, #727\n解法 理解一下题意：\n1Input : catcatgocatgo 2Pattern 1: aabab, a=cat, b=go 3Pattern 2: a, a=catcatgocatgo 4Pattern 3: ab, a=c, b=atcatgocatgo or a=ca, b=tcatgocatgo or ... 5Pattern 4: b, b=catcatgocatgo 看一下Pattern 3 ab，其实只要在字符串中间切一刀，只要两边不相同就能够匹配ab。所以这个问题不是对单词（word）的模式匹配。\n看Pattern 2 a和Pattern 4 b，这就说明a和b其实是等价的。\n看Pattern 1aabab，前面已经说了这个问题不是对word的模式匹配，那么是如何得到a=cat、b=go的呢？\n我们可以逐步检验Pattern，我们可以先看第一个a，那么Pattern实际上就变成了a|abab。然后我们开始猜测a：\n1c|atcatgocatgo 2ca|tcatgocatgo 3cat|catgocatgo 4catc|atgocatgo 5... 我们可以先用第一个选择，把a=c，然后就看Pattern的第二个a|bab，检验atcatgocatgo，因为已知a=c，这个就很好检验，发现检验结果失败。\n然后以此类推。这个过程可以描述为：\n1matchPattern(catcatgocatgo, aabab) 2 matchPattern(catcatgocatgo, aabab, a=c, b=) 3 matchPattern(atcatgocatgo, abab, a=c, b=) 4 return false 5 matchPattern(catcatgocatgo, aabab, a=ca, b=) 6 matchPattern(tcatgocatgo, abab, a=ca, b=) 7 return false; 8 matchPattern(catcatgocatgo, aabab, a=cat, b=) 9 matchPattern(catgocatgo, abab, a=cat, b=) 10 matchPattern(gocatgo, bab, a=cat, b=) 11 matchPattern(gocatgo, bab, a=cat, b=g) 12 matchPattern(ocatgo, ab, a=cat, b=g) 13 return false 14 matchPattern(gocatgo, bab, a=cat, b=go) 15 matchPattern(catgo, ab, a=cat, b=go) 16 matchPattern(go, b, a=cat, b=go) 17 matchPattern(\u0026#34;\u0026#34;, \u0026#34;\u0026#34;, a=cat, b=go) 18 return true 代码：\n1public boolean matches(String value, String pattern, String prefixA, String prefixB) { 2 if (value == \u0026#34;\u0026#34; \u0026amp;\u0026amp; pattern == \u0026#34;\u0026#34;) { 3 // 匹配完毕，说明成功了 4 return true; 5 } 6 if (value == \u0026#34;\u0026#34; || pattern == \u0026#34;\u0026#34;) { 7 return false; 8 } 9 char patternChar = pattern.charAt(0); 10 if (patternChar == \u0026#39;a\u0026#39;) { 11 // 现在检查的是a 12 if (prefixA != null) { 13 if (!value.startsWith(prefixA)) { 14 return false; 15 } 16 // 去掉value的prefixA，去掉pattern的当前字符，然后继续比较 17 return matches(value.subString(prefixA.length()), pattern.subString(1), prefixA, prefixB); 18 } else { 19 boolean result = false; 20 for (int i = 1; i \u0026lt;= value.length(); i++) { 21 prefixA = value.subString(0, i); 22 result = result || matches(value, pattern, prefixA, prefixB); 23 } 24 return result; 25 } 26 } 27 28 if (patternChar == \u0026#39;b\u0026#39;) { 29 if (prefixB != null) { 30 if (!value.startsWith(prefixB)) { 31 return false; 32 } 33 return matches(value.subString(prefixB.length()), pattern.subString(1), prefixA, prefixB); 34 } else { 35 boolean result = false; 36 for (int i = 1; i \u0026lt;= value.length(); i++) { 37 prefixB = value.subString(0, i); 38 result = result || matches(value, pattern, prefixA, prefixB); 39 } 40 return result; 41 } 42 } 43} 时间复杂度：太复杂，计算不出来。\n解法2（更好） 还是看这个：\n1Value: catcatgocatgo 2Pattern: aabab 我们可以看到a有3个，b有2个，Value的长度为13，那么可以知道a的最长的长度是13 / 3 = 4，因此可以缩小a的取值范围，b的长度则等于(13 - 3 * a) / 2。可以依此猜测a和b的值，然后看是否匹配。\n代码：\n1public boolean patternMatches(String value, String pattern) { 2 // pattern的第一个字符就是mainChar，另一个则是subChar 3 char mainChar = pattern.charAt(0); 4 // mainChar的数量 5 int mainCount = mainChar == \u0026#39;a\u0026#39; ? count(pattern, \u0026#39;a\u0026#39;) : count(pattern, \u0026#39;b\u0026#39;); 6 // subChar的数量 7 int subCount = pattern.length() - mainCount; 8 // mainChar所代表的字符串的最大长度 9 int maxMainSize = mainCount == 0 ? 0 : value.length() / mainCount; 10 11 int firstSubIndex = pattern.indexOf(subChar); 12 13 // 尝试所有mainChar所代表的字符串的长度 14 for (int mainSize = 0; mainSize \u0026lt;= maxMainSize; i++) { 15 // 计算得到subChar所代表字符串的长度 16 int subSize = (value.length() - mainCount * mainSize) / subCount; 17 if (subSize * subCount + mainSize * mainCount != value.length()) { 18 // 这种组合不等于value的长度 19 continue; 20 } 21 22 String main = value.subString(0, mainSize); 23 // 跳过头部的几个mainChar所代表的字符串，得到subChar代表的字符串。 24 String sub = value.subString(mainSize * firstSubIndex, mainSize * firstSubIndex + subSize); 25 // 根据pattern构建预期的字符串 26 String expected = build(pattern, main, mainCount, sub, subCount); 27 if (value.equals(expected)) { 28 return true; 29 } 30 } 31 return false; 32} 33 34private String build(String pattern, String main, String sub) { 35 StringBuilder sb = new StringBuilder(); 36 char mainChar = pattern.charAt(0); 37 for (int i = 0; i \u0026lt; pattern.length(); i++) { 38 char curr = pattern.charAt(i); 39 if (curr == mainChar) { 40 sb.append(main); 41 } else { 42 sb.append(sub); 43 } 44 } 45 return sb.toString(); 46} 时间复杂度：\n 尝试所有main的可能性为n次（n为value的长度），即n个循环。每个循环里：  构建预期字符串的循环为m次（m为pattern的长度） 判断预期字符串和value是否相等的复杂度为O(n)（n为value的长度）   所以时间复杂度为O(n2)，最坏情况下m=n。 ","date":"2019-09-16","img":"","permalink":"/post/cracking-coding-interview/16.18-pattern-matching/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.18 Pattern Matching"},{"categories":null,"content":"Contiguous Sequence: You are given an array of integers (both positive and negative). Find the contiguous sequence with the largest sum. Return the sum.\nEXAMPLE\n1Input: 2, -8, 3, -2, 4, -10 2Output: 5 (i.e, {3, -2, 4}) Hints: #537, #551, #567, #594, #614\n解法1 可以先把数组变成一个累加数列，当前index sum值 = sum(当前元素 + 所有前面元素的)。\n1array: 2, -8, 3, -2, 4, -10 2sumarray: 2, -6, -3, -5, -1, -11 然后我们知道array[n~m]元素之和 = sumarray[m] - sumarray[n - 1]，所以在计算区间之和的时候就能够减少很多循环。\n如果给定一个index m，那么它能够形成的连续数列可以是：\n1array[0...m] -\u0026gt; sumarray[m] 2array[1...m] -\u0026gt; sumarray[m] - sumarray[0] 3array[2...m] -\u0026gt; sumarray[m] - sumarray[1] 4... 5array[m-1...m] -\u0026gt; sumarray[m] - sumarray[m-2] 6array[m...m] -\u0026gt; sumarray[m] - sumarray[m-1] 那么我们可以从第一个元素开始，计算它所有的连续数列所能组成的和，然后是第二个元素，第三个元素。\n代码：\n1public int maxContiguous(int[] array) { 2 int[] sumarray = array.clone(); 3 // 构建累加数列 4 for (int i = 1; i \u0026lt; sumarray.length; i++) { 5 sumarray[i] = sumarray[i] + sumarray[i - 1]; 6 } 7 // 找到最大的连续数列值 8 int maxSum = Integer.MIN_VALUE; 9 for (int i = 0; i \u0026lt; sumarray.length; i++) { 10 for (int j = -1; j \u0026lt; i; j++) { 11 int sum = 0; 12 if (j == -1) { 13 sum = sumarray[i]; 14 } else { 15 sum = sumarray[i] - sumarray[j]; 16 } 17 if (sum \u0026gt; maxSum) { 18 maxSum = sum; 19 } 20 } 21 } 22 return maxSum; 23} 那么时间复杂度是：\n 构建累加数列，O(n)，n是数组长度。 求最大值，1 + 2 + \u0026hellip; + n = O(n2)  解法2 1 换个思路：\n 记录两个数字：maxSum（最大sum值），prevSum（当前下标之前元素里的sum值） 遍历这个数组，如果prevSum + array[curr] \u0026gt; array[curr]，那么prevSum += array[curr]；否则 prevSum = array[curr]。 同时判断，prevSum 和 maxSum的大小。  举例：\n1Round 1 2maxSum = 2, prevSum = 2 3 v 42, -8, 3, -2, 4, -10 5因为 -8 + 2 = -6 \u0026gt; -8，所以 prevSum = -6 6 7Round 2 8maxSum = 2, prevSum = -6 9 v 102, -8, 3, -2, 4, -10 11因为 -6 + 3 = -3 \u0026lt; 3，所以 prevSum = 3，所以 maxSum = 3 12 13Round 3 14maxSum = 3, prevSum = 3 15 v 162, -8, 3, -2, 4, -10 17因为 3 + (-2) = 1 \u0026gt; -2，所以 prevSum = 1 18 19Round 4 20maxSum = 3, prevSum = 1 21 v 222, -8, 3, -2, 4, -10 23因为 1 + 4 = 5 \u0026gt; 4，所以 prevSum = 5，所以 maxSum = 5 24 25Round 5 26maxSum = 5, prevSum = 5 27 v 282, -8, 3, -2, 4, -10 29因为 5 + (-10) = -5 \u0026gt; -10，所以 prevSum = -5 这个方法的意思是，如果之前的sum加上当前数字对当前情况有提升，那么就将其相加。否则的话还不如直接用当前数字。然后在过程中取得最大的sum。\n代码：\n1public int maxContiguous(int[] array) { 2 int maxSum = array[0]; 3 int prevSum = array[0]; 4 for (int i = 1; i \u0026lt; array.length; i++) { 5 if (prevSum + array[i] \u0026gt; array[i]) { 6 prevSum += array[i]; 7 } else { 8 prevSum = array[i]; 9 } 10 if (prevSum \u0026gt; maxSum) { 11 maxSum = prevSum; 12 } 13 } 14 return maxSum; 15} 时间复杂度：O(n)\n","date":"2019-09-15","img":"","permalink":"/post/cracking-coding-interview/16.17-contiguous-sequence/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.17 Contiguous Sequence"},{"categories":null,"content":"Sub Sort: Given an array of integers, write a method to find indices m and n such that if you sorted elements m through n, the entire array would be sorted. Minimize n - m (that is, find the smallest such sequence).\n1EXAMPLE 2Input : 1, 2, 4, 7, 10, 11, 7, 12, 6, 7, 16, 18, 19 3Output: (3, 9) Hints: #482, #553, #667, #708, #735, #746\n解法 先观察例子：\n1 21, 2, 4, [7, 10, 11, 7, 12, 6, 7], 16, 18, 19 3 ^ ^ 4 左侧最大值 右侧最小值 观察发现：\n 区间左边是有序的 区间右边是有序的 区间里的最小值大于左边的最大值 区间里的最大值小于右边的最小值  这个问题肯定不是排序问题，也不可能让你试遍所有可能性来找这个最小区间。\n先来看怎么找m：\n 从左侧开始遍历，只要当前元素比前一个元素大，那么说明在升序中 当碰到当前元素 \u0026lt; 前一个元素小时，意味着遇到了降序，此时就要开始找之后遇到的最小元素是什么 遍历结束之后，再找这个最小元素应该插入到哪个位置，即第一个比它大的数所在的位置，这个位置就是m  1 开始降序 2 v 31, 2, 4, 7, 10, 11, 7, 12, 6, 7, 16, 18, 19 4 5 找到min 6 v 71, 2, 4, 7, 10, 11, 7, 12, 6, 7, 16, 18, 19 8 9 这里就是m 10 v 111, 2, 4, 7, 10, 11, 7, 12, 6, 7, 16, 18, 19 再来看怎么找n：\n 从右侧开始找，只要当前元素比后一个元素小，说明在降序中 当碰到当前元素 \u0026gt; 前一个元素时，意味着遇到了升序，此时就要开始找之后遇到的最大的元素是什么 遍历结束之后，找这个最大元素应该插入到哪个位置，即第一个比它小的数所在的位置，这个位置就是n  1 开始升序 2 v 31, 2, 4, 7, 10, 11, 7, 12, 6, 7, 16, 18, 19 4 5 找到max 6 v 71, 2, 4, 7, 10, 11, 7, 12, 6, 7, 16, 18, 19 8 9 这里就是n 10 v 111, 2, 4, 7, 10, 11, 7, 12, 6, 7, 16, 18, 19 代码：\n1public void subSort(int[] nums) { 2 int m = find_m(nums); 3 if (m == -1) { 4 System.out.println(\u0026#34;already sorted\u0026#34;); 5 return; 6 } 7 int n = find_n(nums); 8 System.out.println(\u0026#34;m: \u0026#34; + m + \u0026#34;, n: \u0026#34; + n); 9} 10 11public int find_m(int[] nums) { 12 Integer min = null; 13 for (int i = 1; i \u0026lt; nums.length, i++) { 14 if (nums[i] \u0026lt; nums[i - 1]) { 15 min = findMin(nums, i, nums.length - 1); 16 break; 17 } 18 } 19 if (min == null) { 20 return -1; 21 } 22 return findFirstGtIndex(nums, min); 23} 24 25private int findMin(int[] nums, int start, int end) { 26 int min = nums[start]; 27 for (int i = start + 1; i \u0026lt;= end; i++) { 28 if (nums[i] \u0026lt; min) { 29 min = nums[i]; 30 } 31 } 32 return min; 33} 34 35private int findFirstGtIndex(int[] nums, int a) { 36 for (int i = 0; i \u0026lt; nums.length; i++) { 37 if (nums[i] \u0026gt; a) { 38 return i; 39 } 40 } 41 return -1; 42} 43 44public int find_n(int[] nums) { 45 Integer max = null; 46 for (int i = nums.length - 2; i \u0026gt;= 0; i--) { 47 if (nums[i] \u0026gt; nums[i + 1]) { 48 max = findMax(nums, i, 0); 49 break; 50 } 51 } 52 if (max == null) { 53 return -1; 54 } 55 return findFirstLt(nums, max); 56} 57 58private int findMax(int[] nums, int end, int start) { 59 int max = nums[end]; 60 for (int i = end - 1; i \u0026gt;= start; i++) { 61 if (nums[i] \u0026gt; max) { 62 max = nums[i]; 63 } 64 } 65 return max; 66} 67 68private int findFirstLt(int[] nums, int a) { 69 for (int i = nums.length - 1; i \u0026gt;= 0; i--) { 70 if (nums[i] \u0026lt; a) { 71 return i; 72 } 73 } 74 return -1; 75} ","date":"2019-09-11","img":"","permalink":"/post/cracking-coding-interview/16.16-sub-sort/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.16 Sub Sort"},{"categories":null,"content":"Master Mind: The Game of Master Mind is played as follows:\nThe computer has four slots, and each slot will contain a ball that is red (R). yellow (Y). green (G) or blue (B). For example, the computer might have RGGB (Slot #1 is red, Slots #2 and #3 are green, Slot #4 is blue).\nYou, the user, are trying to guess the solution. You might, for example, guess YRGB.\nWhen you guess the correct color for the correct slot, you get a \u0026ldquo;hit:' If you guess a color that exists but is in the wrong slot, you get a \u0026ldquo;pseudo-hit:' Note that a slot that is a hit can never count as a pseudo-hit.\nFor example, if the actual solution is RGBY and you guess GGRR, you have one hit and one pseudo-hit. Write a method that, given a guess and a solution, returns the number of hits and pseudo-hits.\nHints: #639, #730\n解法 关键字，4个slot，4种颜色\nhit容易计算，相同位置相同颜色的则+1；\npeseudoHit可以这样计算：\n1 v 2solution: RGBY 3guess : GGRR 4 5上面指向的G的位置跳过，记录solution中RGBY出现的次数： 6R=1, G=0, B=1, Y=1 7通用计算guess中RGBY出现的次数： 8R=2, G=1, B=0, Y=0 9 10那么 11R的pseudoHit = min(1, 2) = 1 12G的pseudoHit = min(0, 1) = 0 13B的pseudoHit = min(1, 0) = 0 14Y的pseudoHit = min(1, 0) = 0 15所以，总pseudoHit = 1 代码：\n1public void check(char[] solution, char[] guess) { 2 int hits = 0; 3 Map\u0026lt;Char, Integer\u0026gt; solutionColor = new HashMap\u0026lt;\u0026gt;(); 4 Map\u0026lt;Char, Integer\u0026gt; guessColor = new HashMap\u0026lt;\u0026gt;(); 5 initialize(solutionColor); // 把R、G、B、Y初始化为0 6 initialize(guessColor); 7 8 for (int i = 0; i \u0026lt; solution.length; i++) { 9 if (solution[i] == guess[i]) { 10 hits++; 11 continue; 12 } 13 countForColor(solutionColor, solution[i]); 14 countForColor(guessColor, guess[i]); 15 } 16 17 int pseudoHit = 0; 18 for (Char c : solutionColor.keySet()) { 19 pseudoHit += Math.min(solutionColor.get(c), guessColor.get(c)); 20 } 21 System.out.println(\u0026#34;Hits: \u0026#34; + hits + \u0026#34;, Pseudo hits: \u0026#34; + pseudoHits); 22} 也可以不用Map：\n1private int index(char c) { 2 switch (c) { 3 case \u0026#39;B\u0026#39;: 4 return 0; 5 case \u0026#39;G\u0026#39;: 6 return 1; 7 case \u0026#39;R\u0026#39;: 8 return 2; 9 case \u0026#39;Y\u0026#39;: 10 return 3; 11 } 12 return -1; 13} 14public void check(char[] solution, char[] guess) { 15 int hits = 0; 16 int[] solutionColor = new int[4]; 17 int[] guessColor = new int[4]; 18 19 for (int i = 0; i \u0026lt; solution.length; i++) { 20 if (solution[i] == guess[i]) { 21 hits++; 22 continue; 23 } 24 solutionColor[index(solution[i])]++; 25 guessColor[index(guess[i])]++; 26 } 27 28 int pseudoHit = 0; 29 for (int i = 0; i \u0026lt; solutionColor.length; i++) { 30 pseudoHit += Math.min(solutionColor[i], guessColor[i]); 31 } 32 System.out.println(\u0026#34;Hits: \u0026#34; + hits + \u0026#34;, Pseudo hits: \u0026#34; + pseudoHits); 33} ","date":"2019-09-11","img":"","permalink":"/post/cracking-coding-interview/16.15-master-mind/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.15 Master Mind"},{"categories":null,"content":"Best Line: Given a two-dimensional graph with points on it, find a line which passes the most number of points.\nHints: #491, #520, #529, #563\n解法 给你很多点，找一条线能够经过最多的点。\n 把点按照x排序 选第1个点  选第2个点和第1个点构成线，看经过多少个点 选第3个点和第1个点构成线，看经过多少个点 。。。 选第N个点   选第2个点  选第3个点和第2个点构成线，看经过多少个点 。。。 选第N个点和第2个点构成线，看经过多少个点   。。。 选第N-1个点  代码：\n1public class Point { 2 private double x; 3 private double y; 4} 5 6public interface Line { 7 boolean isCross(Point point); 8} 9 10public class NormalLine implements Line { 11 private double slope; 12 private double diff; 13 public boolean isCross(Point point) { 14 return point.x * slope + diff == point.y; 15 } 16} 17 18public class VerticalLine implements Line { 19 private double x; 20 public boolean isCross(Point point) { 21 return point.x == x; 22 } 23} 24 25private Line makeLine(Point p1, Point p2) { 26 if (p1.x == p2.x) { 27 return new VerticalLine(p1.x); 28 } 29 double slope = (p1.y - p2.y) / (p1.x - p2.x); 30 double diff = p1.y - p1.x * slope; 31 return new NormalLine(slope, diff); 32} 33 34public Line bestLine(Point[] points) { 35 int maxCross = 0; 36 Line bestLine = null; 37 for (int i = 0; i \u0026lt; points.length - 1; i++) { 38 for (int j = i + 1; j \u0026lt; points.length; j++) { 39 Line line = makeLine(points[i], points[j]); 40 currentCross = 2; 41 for (int k = j + 1; k \u0026lt; points.length; k++) { 42 if (line.isCross(points[k])) { 43 currentCross++; 44 } 45 } 46 if (currentCross \u0026gt; maxCross) { 47 bestLine = line; 48 maxCross = currentCross; 49 } 50 } 51 } 52 return bestLine; 53} 时间复杂度：\n在i层面，总共进行了N - 1次循环\n在j层面，每次循环的次数为：N - 1、N - 2、。。。、2、1\n在k层面，每次循环的次数为：N - 2，N - 3、。。。、2、1\n所以复杂度为O(n3)，n为点的数量\n解法2 弄一个Line的Map，记录每条Line的经过的点的数量。用两个循环只构造构造Line，遇到重复的Line则给这个Line的计数加1。最后选一个计数最大的Line。\n1public Line bestLine(Point[] points) { 2 Map\u0026lt;Line, Integer\u0026gt; lineCount = new HashMap\u0026lt;\u0026gt;(); 3 for (int i = 0; i \u0026lt; points.length - 1; i++) { 4 for (int j = i + 1; j \u0026lt; points.length; j++) { 5 Line line = makeLine(points[i], points[j]); 6 Integer count = lineCount.get(line); 7 if (count == null) { 8 count = 1; 9 } 10 count++; 11 lineCount.put(line, count); 12 } 13 } 14 Line bestLine = null; 15 int max = 0; 16 for (Map.Entry\u0026lt;Line, Integer\u0026gt; entry : lineCount.entrySet()) { 17 Line line = entry.key(); 18 int count = entry.value(); 19 if (count \u0026gt; max) { 20 max = count; 21 bestLine = line; 22 } 23 } 24 return bestLine; 25} 时间复杂度：O(N2)，N为点的数量\n","date":"2019-09-11","img":"","permalink":"/post/cracking-coding-interview/16.14-best-line/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.14 Best Line"},{"categories":null,"content":"Bisect Squares: Given two squares on a two-dimensional plane, find a line that would cut these two squares in half. Assume that the top and the bottom sides of the square run parallel to the x-axis.\nHints: #468, #479, #528, #560\n解法 1^ 2│ ┌──────┐ 3│ │ │ 4│ │ │ 5│ └──────┘ 6│ 7│ ┌────┐ 8│ │ │ 9│ └────┘ 10│ 11└─────────────────────────────────────\u0026gt; 如上图，画一根线能够让两个正方形都被等分地一切为二。\n先看如何把一个正方形等分地一切为二，当然是从它的中心开始切啦，只要一条线经过正方形的中心，那么肯定等分的把正方形一切为二。\n那么把两个正方形一切为二就是把两个正方形的中心点连接起来，得到的延长线就行啦。\n问题变成了两个子问题：\n 如何求得正方形中心点 如何给定两个点，求得线条的几何公式  代码：\n1public class Point { 2 private int x; 3 private int y; 4} 5public class Square { 6 private Point leftTop; 7 private int size; 8 public Point getCenterPoint() { 9 return new Point(leftTop.x + size / 2, leftTop.y - size / 2); 10 } 11} 12public class Line { 13 private double slope; 14 private double c; 15} 16public class VerticalLine { 17 private x; 18} 19public Line findLine(Square s1, Square s2) { 20 Point c1 = s1.getCenterPoint(); 21 Point c2 = s2.getCenterPoint(); 22 return makeLine(c1, c2); 23} 24private Line makeLine(Point p1, Point p2) { 25 if (p1.x == p2.x) { 26 // 垂直线 27 return new VerticalLine(p1.x); 28 } 29 double slope = (double)(p2.y - p1.y) / (p2.x - p1.x); 30 double c = p2.y - slope * p2.x; 31 return new Line(slope, c); 32} ","date":"2019-09-11","img":"","permalink":"/post/cracking-coding-interview/16.13-bisect-squares/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.13 Bisect Squares"},{"categories":null,"content":"XMLEncoding:Since XML is very verbose, you are given a way of encoding it where each tag gets\nmapped to a pre-defined integer value. The language/grammar is as follows:\n1Element --\u0026gt; Tag Attributes END Children END 2Attribute --\u0026gt; Tag Value 3END --\u0026gt; 0 4Tag --\u0026gt; some predefined mapping to int 5Value --\u0026gt; string value For example, the following XML might be converted into the compressed string below (assuming a mapping of family -\u0026gt; 1, person -\u0026gt;2, firstName -\u0026gt; 3, lastName -\u0026gt; 4, state -\u0026gt; 5).\n1\u0026lt;family lastName=\u0026#34;McDowell\u0026#34; state=\u0026#34;CA\u0026#34;\u0026gt; 2 \u0026lt;person firstName=\u0026#34;Gayle\u0026#34;\u0026gt;Some Message\u0026lt;/person\u0026gt; 3\u0026lt;/family\u0026gt; Becomes:\n11 4 McDowell 5 SCA 0 2 3 Gayle 0 Some Message 0 0 Write code to print the encoded version of an XML element (passed in Element and Attribute objects).\nHints: #466\nElement和Attribute类：\n1public class Element { 2 private String tag; 3 private List\u0026lt;Attribute\u0026gt; attributes; 4 private List\u0026lt;Element\u0026gt; children; 5 private String value; 6} 7public class Attribute { 8 private String tag; 9 private String value; 10} 解法 这个问题看起来可以用递归来解决，步骤大致是：\n 处理 Element.tag 处理 Element.attributes 添加 END 处理 Element.children，这里重复1-5步 添加 END  代码：\n1private static final int END = 0; 2public String encodingXml(Element element, Map\u0026lt;String, Integer\u0026gt; tagMap) { 3 StringBuilder sb = new StringBuilder(); 4 encodingXml(element, tagMap, sb); 5 return sb.toString() 6} 7private void encodingXml(Element element, Map\u0026lt;String, Integer\u0026gt; tagMap, StringBuilder sb) { 8 sb.append(tagMap.get(element.tag)).append(\u0026#39; \u0026#39;); 9 for (Attribute attribute : element.attributes) { 10 sb.append(tagMap.get(attribute.tag)) 11 .append(\u0026#39; \u0026#39;) 12 .append(attribute.value); 13 } 14 sb.append(END).append(\u0026#39; \u0026#39;); 15 if (element.value != null) { 16 sb.append(element.valule).append(\u0026#39; \u0026#39;); 17 } 18 for (Element child : element.children) { 19 encodingXml(child, tagMap, sb); 20 } 21 sb.append(END).append(\u0026#39; \u0026#39;); 22} ","date":"2019-09-11","img":"","permalink":"/post/cracking-coding-interview/16.12-xml-encoding/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.12 XML Encoding"},{"categories":null,"content":"大纲 类库：\n javaassist ASM CGLib AOP框架等  javac：用Java写的字节码生成工具\n动态代理：在还不知道原始类和原始接口的时候就写好代理类\n例子 例子代码，在原始逻辑之前打印\u0026quot;welcome\u0026quot;：\n1public class DynamicProxyTest { 2 interface IHello { 3 void sayHello(); 4 } 5 static class Hello implements IHello { 6 @Override 7 public void sayHello() { 8 System.out.println(\u0026#34;hello world\u0026#34;); 9 } 10 } 11 static class DynamicProxy implements InvocationHandler { 12 Object originObj; 13 Object bind(Object originObj) { 14 this.originObj = originObj; 15 return Proxy.newProxyInstance(originObj.getClass().getClassLoader(), 16 originObj.getClass().getInterfaces(), 17 this); 18 } 19 @Override 20 public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { 21 System.out.println(\u0026#34;welcome\u0026#34;); 22 return method.invoke(originObj, args); 23 } 24 } 25 public static void main(String[] args) { 26 IHello hello = (IHello) new DynamicProxy().bind(new Hello()); 27 hello.sayHello(); 28 } 29} Proxy.newProxyInstance会生成含有字节码的byte[]，系统属性-Dsun.misc.ProxyGenerator.saveGeneratedFiles=true可以得到class文件。反编译后结果（摘选）：\n1public class class $Proxy0 extends Proxy implements DynamicProxyTest.IHello { 2 private static Method m3; 3 // method m2, method m1; 4 public $Proxy0(InvocationHandler paramInvocationHandler) { 5 super(paramInvocationHandler); 6 } 7 8 public final void sayHello() { 9 try { 10 // this.h 就是我们自己实现的InvocationHandler 11 this.h.invoke(this, m3, null); 12 return; 13 } catch (...) { 14 // 略 15 } 16 } 17 18 static { 19 try { 20 m3 = Class.forName(\u0026#34;DynamicProxyTest$IHello\u0026#34;).getMethod(\u0026#34;sayHello\u0026#34;, new Class[0]); 21 m1 = Class.forName(\u0026#34;java.lang.Object\u0026#34;).getMethod(\u0026#34;equals\u0026#34;, Class.forName(\u0026#34;java.lang.Object\u0026#34;)); 22 ... 23 } 24 } 25} ","date":"2019-09-10","img":"","permalink":"/post/jvm/classloader-byte-gen-dynamic-proxy/","series":null,"tags":["jvm"],"title":"JVM - 字节码生成及动态代理"},{"categories":null,"content":"","date":"2019-09-10","img":"","permalink":"/post/jvm/classloader-osgi/","series":null,"tags":["jvm"],"title":"JVM - OSGi的类加载器"},{"categories":null,"content":"","date":"2019-09-10","img":"","permalink":"/post/jvm/classloader-tomcat/","series":null,"tags":["jvm"],"title":"JVM - Tomcat的类加载器"},{"categories":null,"content":"Diving Board: You are building a diving board by placing a bunch of planks of wood end-to-end. There are two types of planks, one of length shorter and one of length longer. You must use exactly K planks of wood. Write a method to generate all possible lengths for the diving board.\nHints: #690, #700, #715, #722, #740, #747\nDiving Board：跳水台。\n解法 看上去有点像走楼梯，你可以一次走1步，也可以一次走2步，让你求有几种走法。\n实际上这个问题步一样，你有两种木板，一个长一个短点，要求你使用K块木板连在一起，让你求所有可能的达到的长度。\n所以这个问题有点像组合问题，我们把S(x)代表x个短木板达到的长度，L(x)代表x个长木板所达到的长度。那么所有可能的长度有：\n1S(0) + L(k) 2S(1) + L(k - 1) 3S(2) + L(k - 2) 4... 5S(k - 2) + L(2) 6S(k - 1) + L(1) 7S(k) + L(0) 不过问题似乎没有这么简单，比如，当 L(1) = S(2) 时，即一块长木板等于2块短木板，那么有可能存在两种方案总长度一样吗？来证明一下\n1l = 长木板长度, s = 短木板长度, d = 短木板块数, k = 总块数, sum = 总长度 2可得公式 3sum = d * s + (k - d) * l 4如果 l = n * s 5sum = d * s + (k - d) * n * s 6 7如果存在d1和d2，能够使得sum相等，那就意味着 8 9d1 * s + (k - d1) * n * s = d2 * s + (k - d2) * n * s 10(d1 + k * n - d1 * n) * s = (d2 + k * n - d2 * n) * s 11 d1 - d1 * n = d2 - d2 * n 12 13如果要是上列等式成立，d1必须等于d2 14 15不过要注意的是，如果 l = s，那么得到的结果总是相同的。这样上面的公式就变成了： 16sum = d * s + (k - d) * s 17 = k * s 我们可以用一个Set来消除重复结果：\n1private static final SHORT = 2; 2private static final LONG = 4; 3 4public void divingBoard(int shortLen, int longLen, int k) { 5 Set\u0026lt;Integer\u0026gt; possibleLength = new HashSet\u0026lt;\u0026gt;(); 6 for (int i = 0; i \u0026lt;= k; i++) { 7 possibleLength.put(i * shortLen + (k - i) * longLen); 8 } 9 return possibleLength; 10} ","date":"2019-09-10","img":"","permalink":"/post/cracking-coding-interview/16.11-diving-board/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.11 Diving Board"},{"categories":null,"content":"Living People: Given a list of people with their birth and death years, implement a method to compute the year with the most number of people alive. You may assume that all people were born between 1900 and 2000 (inclusive). If a person was alive during any portion of that year, they should be included in that year\u0026rsquo;s count. For example, Person (birth= 1908, death= 1909) is included in the counts for both 1908 and 1909.\nHints: #476, #490, #507, #514, #523, #532, #541, #549, #576\n1public class Person { 2 private int final birthYear; 3 private int final deathYear; 4 // getters 5} 6 7List\u0026lt;Human\u0026gt; people = ...; 解法 维护一个delta数组代表1900年到2001年，遇到出生的就在slot上+1，遇到死亡的就在slot上-1，然后将其做成累加数列，结果就变成了每年还有多少人活着的数列。最后遍历这个数组找到最大值所在的slot，知道其年份。\n1b=1904, d=1920 2b=1910, d=1918 3 4index: 0 1 2 3 4 ... 10 ... 18 19 20 21 5delta: 0 0 0 0 1 1 0 -1 0 -1 6 7变成累加数列: 8index: 0 1 2 3 4 ... 10 ... 18 19 20 21 9livin: 0 0 0 0 1 2 2 1 1 0 10 11当你求1919年多少人活着，那就是1人 代码：\n1private int static final int START = 1900; 2 3private int[] living = new int[2000 - START + 2]; 4 5public void process(List\u0026lt;Person\u0026gt; people) { 6 for (Person person: people) { 7 living[person.birthYear - START]++; 8 // 死亡计数延后一年，根据题意1980年死的人在1980年还活着 9 living[person.deathYear - START + 1]--; 10 } 11 // 计算每年活着的人数 12 for (int i = 1; i \u0026lt; living.length; i++) { 13 living[i] += living[i - 1]; 14 } 15} 16 17public int maxLivingYear() { 18 int maxLinvingYear = 0; 19 int maxLiving = 0; 20 for (int i = 0; i \u0026lt; living.length; i++) { 21 if (living[i] \u0026gt; maxLiving) { 22 maxLiving = living[i]; 23 maxLinvingYear = i + START; 24 } 25 } 26 return maxLinvingYear; 27} ","date":"2019-09-10","img":"","permalink":"/post/cracking-coding-interview/16.10-living-people/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.10 Living People"},{"categories":null,"content":"","date":"2019-09-09","img":"","permalink":"/post/jvm/class-loading-classloader/","series":null,"tags":["jvm"],"title":"JVM - 类加载器"},{"categories":null,"content":"","date":"2019-09-09","img":"","permalink":"/post/jvm/class-loading-steps/","series":null,"tags":["jvm"],"title":"JVM - 类加载过程"},{"categories":null,"content":"7个阶段发生顺序  加载（Loading） 连接（Linking）  验证（Verfication） 准备（Preparation） 解析（Resolution）   初始化（Initialization） 使用（Using） 卸载（Unloading）  确定的开始顺序  加载、验证、准备、初始化、卸载 类的加载过程必须按这个顺序开始 解析则不一定，为了支持动态绑定，可以在初始化之后再开始 类的加载，这些阶段通常是互相混合交叉的  何时加载（第一阶段）？ 没有规定。\n何时初始化？  遇到new、putstatic、getstatic、invokespecial指令时  new对象、读写静态变量，调用静态方法时 被final修饰，在编译时已经进入常量池的除外   使用反射调用的时候 初始化子类时发现父类还未初始化时，初始化其父类 JVM启动时执行main方法的那个类时 MethodHandle方法时 例子  通过子类访问父类静态变量，只会初始化父类 类的数组不会初始化元素类 static final String字段   ","date":"2019-09-09","img":"","permalink":"/post/jvm/class-loading-chance/","series":null,"tags":["jvm"],"title":"JVM - 类加载时机"},{"categories":null,"content":"Operations: Write methods to implement the multiply, subtract, and divide operations for integers.The results of all of these are integers. Use only the add operator.\nHints: #572, #600, #613, #648\n解法 用加法实现减、乘、除。\n减法 A - B = A + (-B)\n如果B是正数，那么-B = invertBits(B) + 1。\n如果B是负数，那么-B = invertBits(B - 1)。这个是二进制正数负数的表现形式。\n1public int negate(int v) { 2 if (v == 0) { 3 return 0; 4 } 5 if (v \u0026gt; 0) { 6 return (~v) + 1; 7 } 8 return ~(v + negate(1)); 9} 所以减法：\n1public int minus(int a, int b) { 2 return a + negate(b); 3} 乘法 就是连续加几次，要注意负数的问题。\n两个数符号相同结果为正、符号不同结果为负。\n1public int multiply(int a, int b) { 2 if (a == 0 || b == 0) { 3 return 0; 4 } 5 int num1 = a \u0026gt; 0 ? a : negate(a); 6 int count = b \u0026gt; 0 ? b : negate(b); 7 if (num1 \u0026lt; count) { 8 // 乘号右边的数字更小一点会循环更少 9 return multiply(b, a); 10 } 11 int result = 0; 12 for (int i = 0; i \u0026lt; count; i++) { 13 result += num1; 14 } 15 if (a \u0026lt; 0 \u0026amp;\u0026amp; b \u0026gt; 0) { 16 return negate(result); 17 } 18 if (a \u0026gt; 0 \u0026amp;\u0026amp; b \u0026lt; 0) { 19 return negate(result); 20 } 21 return result; 22} 除法 除法：5 / 2 = 2，其实就是5一直减 2，减到余数小于2为止，减了几次就是结果。比如 5 - 2 = 3, 3 - 2 = 1，减了两次，所以 5 / 2 = 2。\n关键是负数的处理，可以先把两边都变成正数，返回时再改变符号。\n1public int divide(int a, int b) { 2 if (b == 0) { 3 throw new Exception(\u0026#34;/ 0 error\u0026#34;); 4 } 5 if (a == 0) { 6 return 0; 7 } 8 int num1 = a \u0026gt; 0 ? a : negate(a); 9 int num2 = b \u0026gt; 0 ? b : negate(b); 10 int result = 0; 11 while (num1 \u0026gt; num2) { 12 num1 = minus(num1, num2); 13 result++; 14 } 15 if (a \u0026lt; 0 \u0026amp;\u0026amp; b \u0026gt; 0) { 16 return negate(result); 17 } 18 if (a \u0026gt; 0 \u0026amp;\u0026amp; b \u0026lt; 0) { 19 return negate(result); 20 } 21 return result; 22} ","date":"2019-09-09","img":"","permalink":"/post/cracking-coding-interview/16.9-operations/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.9 Operations"},{"categories":null,"content":"","date":"2019-09-09","img":"","permalink":"/post/jvm/memory-alloc-and-reclaim/","series":null,"tags":["jvm","gc"],"title":"JVM - 内存分配与回收策略"},{"categories":null,"content":"Java Platform, Standard Edition HotSpot Virtual Machine Garbage Collection Tuning Guide ","date":"2019-09-07","img":"","permalink":"/post/jvm/gc-collectors/","series":null,"tags":["jvm","gc"],"title":"JVM - 垃圾收集器笔记"},{"categories":null,"content":"English Int: Given any integer, print an English phrase that describes the integer (e.g., \u0026ldquo;One Thou­sand, Two Hundred Thirty Four\u0026rdquo;).\nHints: #502, #588, #688\n解法 英文对于数字的单词是：\n11: one, two, three, four, five, six, seven, eight, nine 210: ten, twenty, thirty, fourty, fifty, sixty, seventy, eighty, ninety 3100: one hundred, two hundred, three hundred, ... 41,000: one thousand, two thousand, three thousand, ... 51,000,000: one million, two million, three million, ... 61,000,000,000: one billion, two billion, three billion, ... 其中对于11～19是这样的：\n111 12 13 14 15 16 17 18 19 2eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen 对于10、20、30是这样的：\n110 20 30 40 50 60 70 80 90 2ten, twenty, thirty, fourty, fifty, sixty, seventy, eighty, ninety 在1000以下，是10倍进位，在1000以上则是1000倍进位。\n1private static final int BILLION = 1000000000; 2private static final int MILLION = 1000000; 3private static final int THOUSAND = 1000; 4private static final int HUNDRED = 100; 5private static final int TEN = 10; 6 7 8private static final String[] TENS = new String {\u0026#34;Twenty\u0026#34;, \u0026#34;Thirty\u0026#34;, ...}; 9private static final String[] TEENS = new String {\u0026#34;Ten\u0026#34;, \u0026#34;Eleven\u0026#34;, ...}; 10private static final String[] ONES = new String {\u0026#34;One\u0026#34;, \u0026#34;Two\u0026#34;, ...} 11 12public String toEnglish(int n) { 13 String result = \u0026#34;\u0026#34;; 14 if (n \u0026lt; 0) { 15 result += \u0026#34;Negative \u0026#34;; 16 n = -n; 17 } 18 if (n \u0026gt;= BILLION) { 19 int c = n / BILLION; 20 result += toEnglish(c) + \u0026#34; Billion \u0026#34;; 21 n = n % BILLION; 22 } 23 24 if (n \u0026gt;= MILLION) { 25 int c = n / MILLION; 26 result += toEnglish(c) + \u0026#34; Million \u0026#34;; 27 n = n % MILLION; 28 } 29 30 if (n \u0026gt;= THOUSAND) { 31 int c = n / THOUSAND; 32 result += toEnglish(c) + \u0026#34; Thousand \u0026#34;; 33 n = n % THOUSAND; 34 } 35 36 if (n \u0026gt;= HUNDRED) { 37 int c = n / HUNDRED; 38 result += toEnglishOne(c) + \u0026#34; Hundred \u0026#34;; 39 n = n % HUNDRED; 40 } 41 42 if (n \u0026gt;= TEN) { 43 int c = n / TEN; 44 if (c \u0026gt; 1) { 45 result += toEnglishTen(c); 46 n = n % 10; 47 } else if (c == 1) { 48 result += toEnglishTeen(n); 49 return result; 50 } 51 } 52 53 if (n \u0026gt; 0) { 54 result += toEnglishOne(n); 55 } 56 57 return result; 58} 59 60public String toEnglishTen(int n) { 61 return TENS[n - 2]; 62} 63 64public String toEnglishTeen(int n) { 65 return TEENS[n - 10]; 66} 67 68public String toEnglishOne(int n) { 69 return ONES[n - 1]; 70} ","date":"2019-09-05","img":"","permalink":"/post/cracking-coding-interview/16.8-english-int/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.8 English Int"},{"categories":null,"content":"Number Max: Write a method that finds the maximum of two numbers. You should not use if-else or any other comparison operator.\nHints: #473, #513, #707, #728\n解法 不用任何if-else和比较操作符，给你两个数字，让你返回最大的那一个。换句话说就是禁止使用if-else、三元条件式、大于小于等于。那么剩下的就只有数学运算符和bit运算符。\n如果给你一个k，当a \u0026gt; b时k=1，否则k=0。那么怎么得到a和b中的最大值呢？可以这样：\n1max = b + (a - b) * k 2OR 3max = a * k + b * (not k) 那如何创建k呢？\n如果a \u0026gt; b，那么 a - b \u0026gt; 0，那么它的符号位是0，向右shift 31 bit，和1 XOR一下，得到k = 1\n如果a \u0026lt; b，那么 a - b \u0026lt; 0，那么它的符号位是1，向右shift 31 bit，和1 XOR一下，得到k = 0\n1// n \u0026gt;= 0 return 1, else return 0 2public int sign(int n) { 3 return flip(n \u0026gt;\u0026gt; 31); 4} 5public int flip(int n) { 6 return n ^ 1; 7} 8 9public int max(int a, int b) { 10 int k = sign(a - b); 11 int q = flip(k); 12 return a * k + b * q; 13} 但是要注意a - b可能会造成int的bit溢出，导致符号位变成1。比如a=Integer.MAX_VALUE b=-20，a \u0026lt; 0且b \u0026gt; 0时，a - b虽然会有溢出，但是符号位不会变。\n所以：\n1符号位=1代表整数，符号位=0代表负数 2 3if (a和b的符号位不同) { 4 // a \u0026lt; 0, b \u0026gt; 0时, a - b符号位应该是0，和a相同 5 // a \u0026gt; 0, b \u0026lt; 0时, a - b符号位应该是1，和a相同 6 符号位 = a的符号位 7} else { 8 符号位 = (a - b)的符号位 9} 代码：\n1public int max(int a, int b) { 2 int c = a - b; 3 int sa = sign(a); 4 int sb = sign(b); 5 int sc = sign(c); 6 7 // sign a和sign b符号是否不同，相同得到0，不同得到1 8 int use_sa = sa ^ sb; 9 // sign a和sign b符号是否相同，相同得到1，不同得到0 10 int use_sc = flip(sa ^ sb); 11 12 int k = sa * use_sa + sc * use_sc; 13 int q = flip(k); 14 return a * k + b * q; 15} ","date":"2019-09-05","img":"","permalink":"/post/cracking-coding-interview/16.7-number-max/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.7 Number Max"},{"categories":null,"content":"Smallest Difference: Given two arrays of integers, compute the pair of values (one value in each array) with the smallest (non-negative) difference. Return the difference.\nEXAMPLE\n1Input: {1, 3, 15, 11, 2}, {23, 127,235, 19, 8} 2Output: 3. That is, the pair (11, 8) Hints: #632, #670, #679\n解法1 把两个数组排序：\n1A: 1, 2, 3, 11, 15 2B: 8, 19, 23, 127, 235 大家都先从先从第一个元素开始计算diff。\n如果a \u0026lt; b，那么a得前进一步才有可能缩小diff。\n如果b \u0026lt; a，那么b得前进一步才有可能缩小diff。\n然后在过程中记录最小diff。\n代码：\n1int findSmallestDifference(int[] array1, int[] array2) { 2 Arrays.sort(array1); 3 Arrays.sort(array2); 4 int a = 0; 5 int b = 0; 6 int difference = Integer.MAX_VALUE; 7 while (a \u0026lt; array1.length \u0026amp;\u0026amp; b \u0026lt; array2.length) { 8 if (Math.abs(array1[a] - array2[b]) \u0026lt; difference) { 9 difference = Math.abs(array1[a] - array2[b]); 10 } 11 /* Move smaller value. */ 12 if (array1[a] \u0026lt; array2[b]) { 13 a++; 14 } else { 15 b++; 16 } 17 } 18 return difference; 19} 时间复杂度：O(AlogA + BlogB + A + B) =\u0026gt; O(AlogA + BlogB)，A和B是两个数组的长度。\n","date":"2019-09-05","img":"","permalink":"/post/cracking-coding-interview/16.6-smallest-difference/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.6 Smallest Difference"},{"categories":null,"content":"内存区域  JVM - 运行时数据区  JVM - String interning  JVM - OutOfMemoryError异常分析   GC  Visualizing Garbage Collection Algorithms ，现代垃圾收集算法（语言无关） JVM - 对象已经死了吗？  JVM -强软弱虚引用以及Reachability Fence    JVM - GC算法  JVM - 垃圾收集器  JVM - 内存分配与回收策略  JVM - G1垃圾收集器  JVM - Card Table和Post-Write Barriers  JVM - 并发标记之三色标记法和Pre-Write Barriers  JVM - GC日志参数   ClassLoader  JVM - 类加载时机  JVM - 类加载过程  JVM - 类加载器  JVM - Tomcat类加载器  JVM - OSGi类加载器  JVM - 字节码生成及动态代理   以下是阅读JVM Spec时所整理的笔记，比较细：\n ClassLoader（一）- 介绍  ClassLoader（二）- 加载过程  ClassLoader - 总结及参考   字节码指令  JVM执行方法调用（一）- 重载与重写  JVM执行方法调用（二）- 指令   内存模型与线程  JVM - 内存模型  JVM - 线程  JVM - 线程安全  JVM - 锁优化   其他  JVM - 对象的内存布局  JVM - 指针压缩原理  JVM - String对象在Java 9中的变化   实战  Java应用性能调优套路  JVM参数  观察Java进程的CPU使用情况（火焰图）  ","date":"2019-09-05","img":"","permalink":"/post/jvm/index-page/","series":null,"tags":["jvm"],"title":"JVM系列"},{"categories":null,"content":"","date":"2019-09-04","img":"","permalink":"/post/jvm/gc-algos/","series":null,"tags":["jvm","gc"],"title":"JVM - GC算法"},{"categories":null,"content":"判断垃圾的算法 引用计数法  做法：对象上添加引用计数，有人引用时+1，引用失效时-1，为0时认为可以被回收。 缺陷：两个对象互相引用时那它们就无法被回收了  可达性分析算法  做法：从GC Roots出发往下找，在引用路径（引用链）上出现过的对象是可达的，反之则是不可达的，即可以被回收的 GC Roots对象  栈帧中的本地变量表中引用的对象 方法区中静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI引用的对象    扩展的引用  强引用  就是普通的引用 只要强引用还存在则对象不可回收   软引用  系统将要发生内存溢出前回收这些对象   弱引用  只能存活过一次垃圾回收的引用（存疑？） 下一次垃圾回收发生时肯定会被回收掉   虚引用  对垃圾回收没有任何影响 用于对象被回收时收到一个通知    方法区回收  回收废弃常量  如果这个常量没有被任何地方引用则可以回收 比如String.intern的字面量abc，如果没有任何String是abc，那么它就可以被回收   回收无用的类  该类的所有实例都已经被回收 加载该类的ClassLoader已经被回收 该类的java.lang.Class对象没有在任何地方被引用，且无法在任何地方通过反射访问该类的方法 满足以上3个条件就能被回收    JVM诊断引用情况 1-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintReferenceGC 下面是引用数量的输出：\n10.403: [GC (Allocation Failure) 0.871: [SoftReference, 0 refs, 0.0000393 secs]0.871: [WeakReference, 8 refs, 0.0000138 secs]0.871: [FinalReference, 4 refs, 0.0000094 secs]0.871: [PhantomReference, 0 refs, 0 refs, 0.0000085 secs]0.871: [JNI Weak Reference, 0.0000071 secs][PSYoungGen: 76272K-\u0026gt;10720K(141824K)] 128286K-\u0026gt;128422K(316928K), 0.4683919 secs] [Times: user=1.17 sys=0.03, real=0.47 secs] ","date":"2019-09-04","img":"","permalink":"/post/jvm/is-object-dead/","series":null,"tags":["jvm","gc"],"title":"JVM - 对象已经死了吗？"},{"categories":null,"content":"Java堆溢出 原因：创建大量不可回收的对象\n解决办法：\n 扩大堆大小 检查代码中持有时间过长，生命周期过长的对象  虚拟机栈和本地方法栈溢出 原因：\n 线程请求的栈深度超出最大深度，StackOverflowError 创建栈时内存空间不足，OutOfMemoryError  解决办法：\n 查看是否调用深度过深 因为每个线程都会申请一个虚拟机栈，如果线程过多则会导致内存不够用。因此可以通过减少堆的大小和减少栈的尺寸来让出空间给线程。  方法区和运行时常量池溢出 原因：\n 太多的类，比如动态生成的类 OSGi导致，同一个类文件被不同的ClassLoader加载即被是为不同类  解决办法：\n 扩大方法区 注意类的回收，虽然类的回收条件苛刻  直接内存溢出 原因：分配了没回收\n注意：如果看到OutOfMemoryError，但是heap dump很小，且代码使用了NIO/Netty，则可以怀疑是直接内存溢出\n解决办法：修复程序bug\n脑图 ","date":"2019-09-04","img":"","permalink":"/post/jvm/out-of-memory-errors/","series":null,"tags":["jvm"],"title":"JVM - OutOfMemoryError异常分析"},{"categories":null,"content":"Factorial Zeros: Write an algorithm which computes the number of trailing zeros in n factorial.\nHints: #585, #711, #729, #733, #745\n求n的阶乘里，尾部有多少个0。\n解法1(不好) 算出n!然后看尾部有多少个0。\n1public int zeros(int n) { 2 int f = fractorial(n); 3 int count = 0; 4 while (f % 10 == 0) { 5 count++; 6 f = f / 10; 7 } 8 return count; 9} 这个方法的缺陷在于n的阶乘会很快就变得很大，int类型会溢出。\n解法2 如果一个数字尾部出现0，那么就意味着10是它的因子，而10的因子则是2和5。也就是说如果两个数字，一个是2的倍数，一个是5的倍数，那么它们两个相乘就能得到等到一个10，那就会在尾部出现一个0。\n因为在1～n的连续数字中，2的倍数的数量总是比5的倍数的数量多，因此只要看5的倍数就行。\n而且不光要看这个数是否5的倍数，还要看它的因子里包含了多少个5，比如15的因子是3 * 5，提供了一个5，可以和一个2相乘得到10。25的因子是5 * 5，提供了两个5，可以组成两个10。75的因子是5 * 5 * 3，同样提供了两个5。\n比如下面的阶乘：\n11 * 2 * 3 * 4 * 5 * 6 * 7 * 8 * 9 * 10 * 11 * 12 * ... 实际上贡献10的数字是：\n12 * ... * 5 * ... * 10 * ... * 15 所以代码就变成了在[1, n]的范围内，遍历每个数字，看它们的因子里有多少个5，然后累加起来：\n1public int countFactor5(int i) { 2 int count = 0; 3 while (i % 5 == 0) { 4 count++; 5 i = i / 5; 6 } 7 return count; 8} 9 10public int zeros(int n) { 11 int count = 0; 12 for (int i = 1; i \u0026lt;= n; i++) { 13 count += countFactor5(i); 14 } 15 return count; 16} 解法3 可以比解法2更高效，比如我们可以看[1, n]之间5的倍数有多少个，再看25的倍数有多少个，125的倍数有多少个。\n1public int zeros(int n) { 2 int count = 0; 3 for (int i = 5; i \u0026lt;= n; i = i * 5) { 4 count += n / i; 5 } 6 return count; 7} ","date":"2019-09-04","img":"","permalink":"/post/cracking-coding-interview/16.5-fractorial-zeros/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.5 Factorial Zeros"},{"categories":null,"content":"本文介绍几种在K8S中管理TLS证书的方案。\n证书申请方案 先看如何申请证书。\ncert-manager cert-manager 是一个集成在k8s中的工具，它可以做到自动从Let\u0026rsquo;s encrypt申请证书、自动更新证书、与Ingress无缝结合。\n大多数情况下建议与Ingress集成的方式使用它，后面会讲。如果你仅需要签发功能，不需要和Ingress集成，则可参考Setting up Issuers 和Issuing Certificates 。\n优点：\n 自动签发 自动续期 与K8S集成良好 免费  缺点：\n 只能签发Server Auth证书，不能签发Client Auth证书 证书仅用做认证，没有商业版证书更高级的功能  阿里云平台购买 比如你可以在阿里云上购买SSL证书 ，一个账号的最多申请100个证书 优点：\n 多种类型证书可以供选择，有免费的有收费的 可在平台上管理 申请的证书可用在其他产品上，比如SLB  缺点：\n 与K8S集成不好，需要手动导入到Secret中才能使用 只能签发Server Auth证书，不能签发Client Auth证书  用CFSSL自签发 你可以使用CFSSL自签发证书，有一篇参考文档 。\n优点：\n 可签发Client Auth证书  缺点：\n 手动管理证书 与K8S集成不好，需要手动导入到Secret中才能使用 自签发的Server Auth证书在浏览器端会报警告  总结 对于Server Auth证书：\n 如果只是开发或者演示环境，cert-manager方案更适合你 如果是生产环境或者对证书有更高要求的，可以采用从平台购买的方案  对于Client Auth证书：\n 你只能选择用CFSSL自签发的方式  证书部署方案 下面介绍几种部署方案。\n部署在阿里云SLB上 虽然本小节讲的是部署在阿里云的SLB的产品上，但是它的思路和优缺点在其他云平台上基本是一致的。\n做法是在SLB上配置HTTPS监听 ，ACK（阿里云Kubernetes）在创建集群的时候会自动创建几个SLB实例，不要在这几个实例上配置HTTPS监听，因为在ACK中创建Type=LoadBalancer的Service的时候会把你做的配置刷新掉 。\n支持：\n Server Auth Client Auth  优点：\n 可利用阿里云的SSL证书管理功能 可用在阿里云的其他产品上，比如ECS  缺点：\n  不支持SNI，如果你有多个域名，因为一个SLB只会有一个公网IP，此时你就有两种选择：\n  在一个SLB上配置多个监听端口，这样URL中就会携带端口\n  配置多个SLB，避免前面一个方案的问题\n    要自己手动配置服务器组之类的信息\n  K8S Service类型得是Node Port，意味着在同一VPC子网内部流量不受保护\n  K8S集群内部流量不受保护\n  LoadBalancer Service 创建Type=LoadBalancer的Service 来暴露服务，然后在Deployment/StatefulSets里部署证书。\n支持：\n Server Auth Client Auth  优点：\n 集群内部流量受保护 VPC子网内部流量受保护  缺点：\n 不支持SNI，而且因为你只可能有一个公网IP，因此URL中必定要携带端口 在应用中配置证书，且方式方法与应用所使用架构/类库 有关  Ingress配合cert-manager 前面说过cert-manager支持与Ingress集成，你很少的工作能够配置Server Auth，和一个稍微复杂一点的步骤配置Client Auth，详情可参考这篇文章 。\n支持：\n TLS Server Auth TLS Client Auth SNI，即一个443端口对应多个域名  优点：\n Server Auth证书自动签发、自动续期 Client Auth手动配置 对应用的侵入性为0  缺点：\n 集群内部流量不受保护，这个问题可以通过Network Policy做namespace隔离来缓解  总结 优先考虑Ingress配合cert-manager的方案。\n如果你对安全性有很高的要求，那么考虑LoadBalancer Service。\n","date":"2019-09-04","img":"","permalink":"/post/k8s/k8s-how-to-manage-tls-certs/","series":null,"tags":["k8s","tls"],"title":"K8S中的TLS证书管理方案"},{"categories":null,"content":"Tic Tac Win: Design an algorithm to figure out if someone has won a game of tic-tac-toe.\nHints: #710, #732\n解法 Tic-Tac-Toe就是那种井字棋，上面画圈圈和叉叉的那种。这个问题实际上就是给你一个残局，让你判断圈圈或者叉叉哪个赢了。\n1-|-|- 2-|-|- 3-|-|- 最简单的办法就是检查每行，每列，两个对角线，那么时间复杂度是O(n)，n=棋盘的宽度，实际上是2 * n + 2次，在3x3的棋盘里就是检查8次。\n","date":"2019-09-03","img":"","permalink":"/post/cracking-coding-interview/16.4-tic-tac-win/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.4 Tic Tac Win"},{"categories":null,"content":"Intersection: Given two straight line segments (represented as a start point and an end point), compute the point of intersection, if any.\nHints: #465, #472, #497, #517, #527\n解法1 看下图：\n两个线段，分别是S1（x1, y1) - (x2, y2)，S2 (x3, y3) - (x4, y4)，求两个线段的交点。\n其实可以知道，存在一个交点，那么肯定存在图中S2的一个点(x5, y5)，这个点到交点到距离等于(x3, y3)到交点的距离。\n也如果我们知道(x5, y5)的坐标，那么它与(x3, y3)的中点就是那个交点。\n这个数学题不会做。\n","date":"2019-09-02","img":"","permalink":"/post/cracking-coding-interview/16.3-intersection/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.3 Intersection"},{"categories":null,"content":"Word Frequencies: Design a method to find the frequency of occurrences of any given word in a book. What if we were running this algorithm multiple times?\nHints: #489, #536\n解法 代码：\n1Map\u0026lt;String, Integer\u0026gt; cache = new HashMap\u0026lt;\u0026gt;(); 2 3public void prepare() { 4 File book = ...; 5 while (book not eof) { 6 String line = book.readLine(); 7 String[] words = line.split(\u0026#34;[^\\\\w]\u0026#34;); 8 for (String word : words) { 9 if (!cache.contains(word)) { 10 cache.put(word, 0); 11 } 12 cache.put(word, cache.get(word) + 1); 13 } 14 } 15} 16 17public int wordFreq(String word) { 18 if (!cache.contains(word)) { 19 cache.put(word, 0); 20 } 21 return cache.get(word); 22} ","date":"2019-09-02","img":"","permalink":"/post/cracking-coding-interview/16.2-word-frequencies/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.2 Word Frequencies"},{"categories":null,"content":"Number Swapper: Write a function to swap a number in place (that is, without temporary vari­ables).\nHints: #492, #716, #737\n解法1 用减法，代码：\n1public void swap() { 2 int a = ...; 3 int b = ...; 4 a = a - b; 5 b = b + a; 6 a = b - a; 7} 解法2 用XOR：\n1a : 00 11 01 00 11 2b : 10 01 01 10 00 3c = a ^ b: 10 10 00 10 11 4 ^ b: 00 11 01 00 11 == a 5 ^ a: 10 01 01 10 00 == b 代码：\n1int a = ...; 2int b = ...; 3a = a ^ b; 4b = a ^ b; 5a = a ^ b; 关于XOR：对0XOR的结果和原来一样，对1XOR的结果肯定是翻转bit。\n第一步flag = a ^ b，得到两者的异同flag，0代表相同，1代表不同。\n第二步b = flag ^ b，则是把b中和a相同的部分保留，和a中不同的部分翻转，也就是变成a，最终b彻底变成a。\n第三步a = flag ^ b，因为b已经变成了a，那么做的事情就和第二步一样了，把a（由现在的b持有）中和b相同的部分保留，不同的部分翻转，最终彻底变成b。\n","date":"2019-09-02","img":"","permalink":"/post/cracking-coding-interview/16.1-number-swapper/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 16.1 Number Swapper"},{"categories":null,"content":"","date":"2019-09-02","img":"","permalink":"/post/interview/databases/","series":null,"tags":["interview"],"title":"Interview Skills - Databases"},{"categories":null,"content":"Deadlocks and Deadlock Prevention In order for a deadlock to occur, you must have all four of the following conditions met:\n Mutual Exclusion:Only one process can access a resource at a given time.(Or, more accurately, there is limited access to a resource. A deadlock could also occur if a resource has limited quantity.) Hold and Wait: Processes already holding a resource can request additional resources, without relinquishing their current resources. No Preemption: One process cannot forcibly remove another process' resource. Circular Wait: Two or more processes form a circular chain where each process is waiting on another resource in the chain.  Deadlock prevention entails removing any of the above conditions.\n大部分方法都专注在解决第四点。\n","date":"2019-09-02","img":"","permalink":"/post/interview/thread-and-locks/","series":null,"tags":["interview"],"title":"Interview Skills - Thread and Locks"},{"categories":null,"content":"","date":"2019-09-02","img":"","permalink":"/post/interview/testing/","series":null,"tags":["interview"],"title":"Interview Skills - Testing"},{"categories":null,"content":"","date":"2019-09-02","img":"","permalink":"/post/interview/object-oriental-design/","series":null,"tags":["interview"],"title":"Interview Skills - Object Oriental Design"},{"categories":null,"content":"","date":"2019-09-02","img":"","permalink":"/post/interview/system-design-and-scalability/","series":null,"tags":["interview"],"title":"Interview Skills - System Design and Scalability"},{"categories":null,"content":"Peaks and Valleys: In an array of integers, a \u0026ldquo;peak\u0026rdquo; is an element which is greater than or equal to the adjacent integers and a \u0026ldquo;valley\u0026rdquo; is an element which is less than or equal to the adjacent integers. For example, in the array {5, 8, 6, 2, 3, 4, 6}, {8, 6} are peaks and {5, 2} are valleys. Given an array of integers, sort the array into an alternating sequence of peaks and valleys.\nEXAMPLE\n1Input: {5, 3, 1, 2, 3} 2Output: {5, 1, 3, 2, 3} Hints: #196, #219, #231, #253, #277, #292, #316\n解法1 什么是Peak？ \u0026gt;= 左右两边的数字就是Peak。\n什么是Valley？\u0026lt;= 左右两边的数字就是Valley。\n给你一个数组，对它排序，使得它的Peak和Valley交替。换句话说就是{大、小、大、小}这样。\n现在看一个已经排序好的数组：\n1a1, a2, a3, a4, a5 那么我们可以从左右两边向中间取元素，交替放置：\n1a5, a1 2a5, a1, a4, a2, a3 代码：\n1public int[] peakValleys(int[] array) { 2 int[] result = new int[array.length]; 3 Arrays.sort(array); 4 int head = 0; 5 int tail = array.length - 1; 6 int i = 0; 7 while (head \u0026lt; tail) { 8 result[i] = array[tail]; 9 tail--; 10 i++; 11 result[i] = array[head]; 12 head++; 13 i++; 14 } 15 if (head == tail) { 16 result[i] = array[head]; 17 } 18 return result; 19} 解法2 有没有办法不对数组做排序来弄？可以弄一个指针从index 1开始遍历，在两个检查模式中切换：\n 当前元素比前一个元素小 当前元素比前一个元素大  如果检查结果为false，那么就将当前元素和前一个元素交换\n1mode_lt = check(a[i] \u0026lt; a[i - 1]) == true 2mode_gt = check(a[i] \u0026gt; a[i - 1]) == true 3 4Round 1: mode_lt, check pass 5 v 65, 3, 1, 2, 3 7 8Round 2: mode_gt, check fail, swap 9 v 105, 3, 1, 2, 3 -\u0026gt; 5, 1, 3, 2, 3 11 12Round 3: mode_lt, check pass 13 v 145, 1, 3, 2, 3 15 16Round 4: mode_gt, check pass 17 v 185, 1, 3, 2, 3 代码：\n1public void peakValley(int[] array) { 2 if (array.length \u0026lt;= 1) { 3 return; 4 } 5 int mode = MODE_LT; 6 for (int i = 1; i \u0026lt; array.length; i++) { 7 if (mode == MODE_LT) { 8 if (!(array[i] \u0026lt; array[i - 1])) { 9 swap(array, i, i - 1); 10 } 11 mode = MODE_GT; 12 } else { 13 if (!(array[i] \u0026gt; array[i - 1])) { 14 swap(array, i, i - 1); 15 } 16 mode = MODE_LT; 17 } 18 } 19} 20 21private void swap(int[array], int i, int j) { 22 int tmp = array[i]; 23 array[i] = array[j]; 24 array[j] = tmp; 25} ","date":"2019-08-29","img":"","permalink":"/post/cracking-coding-interview/10.11-peaks-and-valleys/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 10.11 Peaks and Valleys"},{"categories":null,"content":"Rank from Stream: Imagine you are reading in a stream of integers. Periodically, you wish to be able to look up the rank of a number x (the number of values less than or equal to x). lmplement the data structures and algorithms to support these operations. That is, implement the method track(int x), which is called when each number is generated, and the method getRankOfNumber(int x), which returns the number of values less than or equal to x (not including x itself).\nEXAMPLE\n1Stream (in order of appearance): 5, 1, 4, 4, 5, 9, 7, 13, 3 2getRankOfNumber(1) = 0 3getRankOfNumber(3) = 1 4getRankOfNumber(4) = 3 Hints: #301, #376, #392\n解法1(不好) 弄三个：\n map 1记录 \u0026lt; x 的数字的数量。这个map按照key升序排。 map 2 记录x重复的数字的数量。 map 3 记录 \u0026lt;= x的数字的数量 = \u0026lt; x的数字的数量 + x 重复的数字的数量 - 1。  每次track的时候要遍历map 1，找到在x前面的值。\n每次getRankOfNumber的时候直接get map 3就行。\n这个做法不太好，因为每次都牵涉到遍历。\n解法2 比如弄一个二叉搜索树，左节点 \u0026lt;= 当前节点，右节点 \u0026gt; 当前节点：\n1 5 2 / \\ 3 1 9 4 \\ / \\ 5 4 7 13 6 / 7 4 8 \\ 9 5 10 / 11 3 因为有重复数据，所以我们可以把重复的数量记录在里面：\n1 5(d=2) 2 / \\ 31(d=1) 9(d=1) 4 \\ / \\ 5 4(d=2) 7(d=1) 13(d=1) 6 / 73(d=1) 因为rank = 自己重复数量 - 1 + 比自己小的数字的数量，改写成rank = sel.dups - 1 + sum(smaller.dups)。\nsum(smaller.dups)怎么计算的，在二叉搜索树中查找x所经过的路径中的遇到过的比自己小的节点时，sum(其左子树的dups)（含这个节点自身）。\n1public Node { 2 private int value; 3 private Node left; 4 private Node right; 5 private int dups; 6 private int leftSumDups; 7 8 public Node(int value) { 9 this.value = value; 10 this.dups = 1; 11 } 12 13 public void track(int value) { 14 if (value == this.value) { 15 this.dups++; 16 return; 17 } 18 if (value \u0026lt; this.value) { 19 if (this.left == null) { 20 this.left = new Node(value); 21 } else { 22 this.left.track(value); 23 this.leftSumDups++; 24 } 25 return; 26 } 27 if (value \u0026gt; this.value) { 28 if (this.right == null) { 29 this.right = new Node(value); 30 } else { 31 this.right.track(value); 32 } 33 } 34 } 35 36 public int getRankOfNumber(int value) { 37 if (value == this.value) { 38 return this.dups - 1 + this.leftSumDups; 39 } 40 if (value \u0026lt; this.value \u0026amp;\u0026amp; this.left != null) { 41 return this.left.getRankOfNumber(value); 42 } 43 if (value \u0026gt; this.value \u0026amp;\u0026amp; this.right != null) { 44 int rightRank = this.right.getRankOfNumber(value); 45 if (rightRank == -1) { 46 return -1; 47 } 48 return this.dups + this.leftSumDups + rightRank; 49 } 50 return -1; 51 } 52} ","date":"2019-08-29","img":"","permalink":"/post/cracking-coding-interview/10.10-rank-from-stream/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 10.10 Rank From Stream"},{"categories":null,"content":"Sorted Matrix Search: Given an M x N matrix in which each row and each column is sorted in ascending order, write a method to find an element.\nHints: #193, #211, #229, #251, #266, #279, #288, #291, #303, #317, #330\n解法1 一个在行、列两个方向都是升序排列的矩阵，举个例子：\n11, 2, 3, 4 22, 3, 4, 5 33, 4, 5, 6 44, 5, 6, 7 根据定义在任意坐标(r, c)上，成立以下关系：\n (r - 1, c) \u0026lt;= (r, c) (r + 1, c) \u0026gt; (r, c) (r, c - 1) \u0026lt;= (r, c) (r, c + 1) \u0026gt; (r, c)  在有序数组的二分法查找的时候只有左右两个方向，那么在矩阵二分查找的话则有左右、上下两个方向。\n1public RowCol { 2 final int row; 3 final int col; 4 public RowCol(int row, int col) { 5 this.row = row; 6 this.col = col; 7 } 8 public boolean isGreaterThan(Row another) { 9 return this.row \u0026gt; another.row \u0026amp;\u0026amp; this.col \u0026gt; another.col; 10 } 11 public boolean isNotFound() { 12 return row == -1 \u0026amp;\u0026amp; col == -1; 13 } 14 public RowCol minusRow() { 15 return new RowCol(row - 1, col); 16 } 17 public RowCol plusRow() { 18 return new RowCol(row + 1, col); 19 } 20 public RowCol minusCol() { 21 return new RowCol(row, col - 1); 22 } 23 public RowCol plusCol() { 24 return new RowCol(row, col + 1); 25 } 26 public RowCol mid(RowCol another) { 27 return new RowCol((row + another.row) / 2, (col + another.col) / 2); 28 } 29} 30 31public RowCol search(int[][] matrix, int n) { 32 int rows = matrix.length; 33 int cols = matrix[0].length; 34 return search(matrix, n, new RowCol(0, 0), new RowCol(rows - 1, cols - 1)); 35} 36 37private RowCol search(int[][] matrix, int n, RowCol start, RowCol end) { 38 if (start.isGreaterThat(end)) { 39 return RowCol(-1, -1); 40 } 41 RowCol mid = start.mid(end); 42 int midValue = matrix[mid.row][mid.col]; 43 if (n == midValue) { 44 return mid; 45 } 46 if (n \u0026lt; midValue) { 47 RowCol tmp = search(matrix, n, start, mid.minusRow()); 48 if (tmp.isNotFound()) { 49 return search(matrix, n, start, mid.minusCol()); 50 } 51 return tmp; 52 } 53 RowCol tmp = search(matrix, n, mid.plusRow(), end); 54 if (tmp.isNotFound()) { 55 return search(matrix, n, mid.plusCol(), end); 56 } 57 return tmp; 58} 解法2 步骤：\n 从第一行开始，从右到左看列，如果某列大于x（被搜索值），则左移一列，因为左一列可能能找到。 如果某列小于x则下移一行，因为下一行可能能找到。 重复1到2步。  代码：\n1public int[] search(int[][] matrix, int n) { 2 int row = 0; 3 int col = matrix[0].length - 1; 4 while (row \u0026lt;= matrix.length - 1 \u0026amp;\u0026amp; col \u0026gt;= 0) { 5 if (matrix[row][col] == n) { 6 return new int[row, col]; 7 } else if (matrix[row][col] \u0026gt; n) { 8 col--; 9 } else { 10 row++; 11 } 12 } 13 return new int[] {-1, -1}; 14} ","date":"2019-08-29","img":"","permalink":"/post/cracking-coding-interview/10.9-sorted-matrix-search/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 10.9 Sorted Matrix Search"},{"categories":null,"content":"Find Duplicates: You have an array with all the numbers from 1 to N, where N is at most 32,000. The array may have duplicate entries and you do not know what N is. With only 4 kilobytes of memory available, how would you print all duplicate elements in the array?\nHints: #289, #315\n解法 又遇到了有限内存的问题。\n题目中给了4K内存，4K = 4096 bytes = 8 * 4096 bits =\u0026gt; 32,000 。题目中由说了N不会超过32,000，那也就意味着我们可以用bit vector来做这个事情。\n1public int findDuplicates(int[] array) { 2 byte[] bitVector = new byte[4 * 1024]; 3 for (int i = 0; i \u0026lt; array.length; i++) { 4 int byteIndex = i / Byte.SIZE; 5 int bitIndex = i % Byte.SIZE; 6 byte flag = 1 \u0026lt;\u0026lt; bitIndex; 7 if (bitVector[byteIndex] \u0026amp; flag == 0) { 8 bitVector[byteIndex] |= flag; 9 } else { 10 System.out.println(i); 11 } 12 } 13} ","date":"2019-08-29","img":"","permalink":"/post/cracking-coding-interview/10.8-find-duplicates/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 10.8 Find Duplicates"},{"categories":null,"content":"Missing Int: Given an input file with four billion non-negative integers, provide an algorithm to generate an integer that is not contained in the file. Assume you have 1 GB of memory available for this task.\nFOLLOW UP\nWhat if you have only 10 MB of memory? Assume that all the values are distinct and we now have no more than one billion non-negative integers.\nHints: #235, #254, #281\n解法1 一个文件里有40亿个非负整数，同时文件里的数字又没有排序，现在要写一个算法生成一个不在其中的整数。\n1b m t 20, 000, 000, 000 3Gb Mb Kb 4 5b: billion 6m: million 7t: thousand 注意4 billion = 4 * 1 billion = 4 * 230 = 232，而Integer的非负数最多只有231个，那也就意味着这个文件里肯定存在重复的数字。\n如果我们用每个bit对应一个数字，那么需要231个bit，也就是228 bytes = 250Mb，我们现在有1GB内存，所以Hold的住。\n那么算法是：\n 构建一个bit vector，里面包含231 + 1个bit 遍历文件，每读到一个数字在对应的bit上设置1 遍历bit vector，找到第一个是0的bit 把它变成数字  1public int getMissingInt(File file) { 2 long bits = ((long) Integer.MAX_VALUE) + 1; 3 byte[] bitVector = new byte[(int)(bits / Byte.SIZE)]; 4 while (file not eof) { 5 String line = readLine(file); 6 int num = Integer.valueOf(line); 7 bitVector[num / Byte.SIZE] |= 1 \u0026lt;\u0026lt; (num % Byte.SIZE); 8 } 9 for (int i = 0; i \u0026lt; bitVector.length; i++) { 10 int b = (int) bitVector[i]; 11 for (int j = 0; j \u0026lt; Byte.SIZE; j++) { 12 if (b \u0026amp; (1 \u0026lt;\u0026lt; j) == 0) { 13 return i * Byte.SIZE + j; 14 } 15 } 16 } 17 return -1; 18} 解Follow Up 现在有1 Billion个不重复的非负整数，然后有10MB内存。\n如果有前面bit vector的方法，我们需要250MB内存，但我们现在只有10MB，所以方法1不适合。\n因为告诉你了数字不重复，那么你就可以对分段进行计数，比如分为[0, 999]、1000, 1999]，如果一个数字在某个分段范围内，那么就把这个分段的计数+1。然后当某个分段计数不等于1000的时候，就知道它里面缺少某个数字。\n那么分段范围怎么确定？\n每个分段都用一个Integer计数，一个Integer占用4个字节，现在有10MB内存，那么可以分为 (10 * 220) / 4 = 10 * 218 个段。\n然后最多有有231个非负Integer，那么每段的大小是 231 / (10 * 218) = 213 / 10 = 8192 / 10 ~= 820。为了方便起见我们可以把分段大小变大一点，比如1024，这样会占用 \u0026lt; 10MB的内存。\n因为知道某个段里缺少数字，那么我们就可以像前面那样用bit vector找出缺少的数字，不过这个时候的bit vector需要饱含的bit数只需要1024个就行了。\n1private final int SEG_SIZE = 1024; 2 3public int getMissingInt(File file) { 4 int[] blocks = new int[Integer.MAX_VALUE / SEG_SIZE + 1]; 5 while (file not eof) { 6 String line = readLine(file); 7 int n = Integer.valueOf(line); 8 blocks[n / SEG_SIZE]++; 9 } 10 11 int start = 0; 12 int end = 0; 13 for (int i = 0; i \u0026lt; count.length; i++) { 14 if (count[i] != SEG_SIZE) { 15 start = SEG_SIZE * i; 16 end = start + SEG_SIZE - 1; 17 break; 18 } 19 } 20 return findMissingInt(file, start, end); 21} 22 23private int findMissingInt(File file, int start, int end) { 24 byte[] bitVector = new byte[SEG_SIZE / Byte.SIZE]; 25 while (file not eof) { 26 String line = readLine(file); 27 int n = Integer.valueOf(line); 28 if (n \u0026lt; start || n \u0026gt; end) { 29 continue; 30 } 31 bitVector[(n - start) / Byte.SIZE] |= (n - start) % Byte.SIZE; 32 } 33 34 for (int i = 0; i \u0026lt; bitVector.length; i++) { 35 int b = bitVector[i]; 36 for (int j = 0; j \u0026lt; Byte.SIZE; j++) { 37 if (b \u0026amp; (1 \u0026lt;\u0026lt; j) == 0) { 38 return start + i * Byte.SIZE + j; 39 } 40 } 41 } 42 return -1; 43} ","date":"2019-08-28","img":"","permalink":"/post/cracking-coding-interview/10.7-missing-int/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 10.7 Missing Int"},{"categories":null,"content":"Sort Big File: Imagine you have a 20 GB file with one string per line. Explain how you would sort the file.\nHints: #207\n解法 拆成若干小文件，比如每个文件100M，对其做快排，然后把这些小文件合并起来（合并两个有序数组）。\n","date":"2019-08-28","img":"","permalink":"/post/cracking-coding-interview/10.6-sort-big-file/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 10.6 Sort Big File"},{"categories":null,"content":"Sparse Search: Given a sorted array of strings that is interspersed with empty strings, write a method to find the location of a given string.\nExample\n1Input: ball, {\u0026#34;at\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;ball\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;car\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;dad\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;} 2Output: 4 Hints: #256\n解法1 不能直接用二分法，因为mid可能是\u0026quot;\u0026quot;，那么你就不知道下一步应该到左边找还是右边找了。\n能够想到的简单办法是如果mid是空串，那么就往左找非空串作为mid。如果左边找不到那么就往右边找mid。\n1public int sparseSearch(String[] array, String str) { 2 return sparseSearch(array, str, 0, array.length); 3} 4 5private int sparseSearch(String[] array, String str, int start, int end) { 6 if (start \u0026gt; end) { 7 return -1; 8 } 9 int mid = (start + end) / 2; 10 if (array[mid] == \u0026#34;\u0026#34;) { 11 int newMid = leftNonEmpty(array, mid); 12 if (newMid == -1) { 13 newMid = rightNonEmpty(array, mid); 14 } 15 if (newMid == -1) { 16 // 说明左右两边都是空串 17 return -1; 18 } 19 mid = newMid; 20 } 21 22 if (array[mid] == str) { 23 return mid; 24 } 25 if (array[mid] \u0026lt; str) { 26 return sparseSearch(array, str, mid + 1, end); 27 } 28 return sparseSearch(array, str, start, mid - 1); 29} 30 31private int leftNonEmpty(String[] array, int mid, int start) { 32 while (mid \u0026gt;= start) { 33 if (array[mid] != \u0026#34;\u0026#34;) { 34 return mid; 35 } 36 mid--; 37 } 38 return -1; 39} 40 41private int rightNonEmpty(String[] array, int mid, int end) { 42 while (mid \u0026lt;= end) { 43 if (array[mid] != \u0026#34;\u0026#34;) { 44 return mid; 45 } 46 mid++; 47 } 48 return -1; 49} ","date":"2019-08-28","img":"","permalink":"/post/cracking-coding-interview/10.5-sparse-search/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 10.5 Sparse Search"},{"categories":null,"content":"Sorted Search, No Size: You are given an array-like data structure Listy which lacks a sizemethod. It does, however, have an elementAt(i) method that returns the element at index i in O(1) time. If i is beyond the bounds of the data structure, it returns -1. (For this reason, the data structure only supports positive integers.) Given a Listy which contains sorted, positive integers, find the index at which an element x occurs. If x occurs multiple times, you may return any index.\nHints: #320, #337, #348\n解法1 Listy没有提供size方法，所以没有办法用二分查找。那么问题的关键是否在于如何知道它的size，知道之后就可以用二分查找。\n是否可以这样呢，尝试在1、2、4、8、16、……的位置elementAt(i)，如果返回-1，那么就在前一个试探点到当前试探点之间的位置用二分找到elementAt(i) != -1 \u0026amp;\u0026amp; elementAt(i + 1) == -1的点，从而知道它的size。\n1public int getSize(Listy list) { 2 if (list.elementAt(0) == -1) { 3 return 0; 4 } 5 return getSize(list, 1, 1); 6} 7 8public int getSize(Listy list, int curr, int prev) { 9 if (list.elementAt(curr) == -1) { 10 return getSizeBinary(list, prev, curr - 1); 11 } 12 return getSize(list, curr * 2, curr); 13} 14 15public int getSizeBinary(Listy list, int start, int end) { 16 int mid = (start + end) / 2; 17 if (list.elementAt(mid) == 1 \u0026amp;\u0026amp; list.elementAt(mid + 1) == -1) { 18 return mid - 1; 19 } 20 if (list.elementAt(mid) == -1) { 21 return getSizeBinary(list, start, mid - 1;) 22 } 23 return getSizeBinary(list, mid + 1, end); 24} 查找Listy长度的时间复杂度：\n 最坏情况下，我们要试探logn次，并且在最后一段里也就是在n/2的长度里二分查找size。那也就是说复杂度是：O(logn + log(n/2))，也就是O(logn)  解法2（更好） 我们可以不要精确知道size，只需要知道n大概在哪个范围内。比如我们可以在1、2、4、8、……范围内试探，看一旦发现Listy.elementAt(i) \u0026gt; n，那么就知道n可能在[i / 2, i]这个范围内。当然，如果Listy.elementAt(i) == -1，也意味着n可能在[i / 2, i]这个范围内。\n然后对这个返回做二分查找，二分的时候要注意，可以把-1认为是无限大。\n1public int search(Listy list, int n) { 2 int index = 1; 3 while (list.elementAt(index) != -1 \u0026amp;\u0026amp; list.elementAt(index) \u0026lt; n) { 4 index = index * 2; 5 } 6 return binarySearch(list, n, index / 2, index); 7} 8 9private int binarySearch(Listy list, int n, int start, int end) { 10 if (start \u0026gt; end) { 11 return -1; 12 } 13 int mid = (start + end) / 2; 14 int midVal = list.elementAt(mid); 15 if (midVal == n) { 16 return mid; 17 } 18 if (midVal \u0026gt; n || midVal == -1) { 19 return binarySearch(list, n, start, mid - 1); 20 } 21 return binarySearch(list, n mid + 1, end); 22} ","date":"2019-08-28","img":"","permalink":"/post/cracking-coding-interview/10.4-sorted-search-no-size/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 10.4 Sorted Search, No Size"},{"categories":null,"content":"Search in Rotated Array: Given a sorted array of n integers that has been rotated an unknown number of times, write code to find an element in the array. You may assume that the array was originally sorted in increasing order.\nEXAMPLE\n1lnput: find 5 in {l5, 16, 19, 20, 25, 1, 3, 4, 5, 7, 10, 14} 2Output: 8 (the index of 5 in the array) Hints: #298, #310\n解法1 你可以认为在一个循环有序数组里查找。\n把这个数组中间切一刀，那么会发现左右两边至少会有一边是有序的（头 \u0026lt; 尾）。我们在有序的里面二分查找，在无需的那么在另一边里再切一刀找。\n步骤：\n 把数组中间切一刀，会得到L、R两个数组 如果某个数组的头 \u0026lt; 尾，说明它是有序的，启用二分查找 如果某个数组的头 \u0026gt;= 尾，说明它是无序的，对它重复1-3步  1public int search(int[] a, int n, int start, int end) { 2 if (start \u0026gt; end) { 3 return -1; 4 } 5 if (a[start] \u0026gt;= a[end] \u0026amp;\u0026amp; end - start \u0026gt; 0) { 6 // 本段不是有序的 7 int mid = (start + end) / 2; 8 int result = search(a, n, start, mid); 9 if (result != -1) { 10 return result; 11 } 12 return search(a, n, mid + 1, end); 13 } 14 15 if (a[start] \u0026lt;= n \u0026amp;\u0026amp; n \u0026lt;= a[end]) { 16 // 本段是有序的 17 return binarySearch(a, n, start, end); 18 } 19 // 本段有序但是所求值不在我的范围内 20 return -1; 21} 22 23private int binarySearch(int[] a, int n, int start, int end) { 24 if (start \u0026gt; end) { 25 return -1; 26 } 27 int mid = (start + end) / 2; 28 if (a[mid] == n) { 29 return mid; 30 } else if (a[mid] \u0026lt; n) { 31 return binarySearch(a, n, mid + 1, end); 32 } else { 33 return binarySearch(a, n, statt, mid - 1); 34 } 35} 时间复杂度：\n 如果本来就是有序的，复杂度是O(log n)，和二分一样 如果全部都是重复元素，复杂度O(n)，比如在[3,3,3,3]里找2，那么最终会对4个3做二分。 ","date":"2019-08-28","img":"","permalink":"/post/cracking-coding-interview/10.3-search-in-rotated-array/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 10.3 Search in Rotated Array"},{"categories":null,"content":"Group Anagrams: Write a method to sort an array of strings so that all the anagrams are next to each other.\nHints: #177, #182, #263, #342\n解法1 Anagram是字谜的意思，其实并不懂这个Anagram是啥东西的话没有办法做这道题。\n如果说一个word是由另一个word的字母重排列组成，那么它们两个互为Anagram。比如LISTEN和SLIENT就是Anagram。\n那么也就是说互为Anagram的两个字符串有下面特性：\n 长度相同 每个字母的数量相同 如果把字符串内的字母排序，那么它们的结果相同  代码：\n1class Word implements Comparable { 2 String origin; 3 String sorted; 4 int compareTo(Word another) { 5 return this.sorted.compareTo(another.sorted); 6 } 7} 8 9public List\u0026lt;String\u0026gt; groupAnagrams(List\u0026lt;String\u0026gt; strings) { 10 List\u0026lt;Word\u0026gt; words = new ArrayList\u0026lt;\u0026gt;(); 11 for (String string : strings) { 12 words.add(makeWord(string)); 13 } 14 Collections.sort(words); 15 List\u0026lt;String\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); 16 for (Word word : words) { 17 result.add(word.getOrigin()); 18 } 19 return result; 20} 21 22private Word makeWord(String string) { 23 char[] chars = string.charArray(); 24 Arrays.sort(chars); 25 return new Word(string, new String(chars)); 26} 时间复杂度：O(s * log s * a + a * log a + a)，s是平均字符串长度，a是数组长度。\n解法2 解法1对每个字符串做了排序，然后又对整个数组进行了排序。说起来题目只要求互为Anagram的字符串分组，没有要求排序，那么可以用Map对其进行分组，然后再合并一下返回。\n1public List\u0026lt;String\u0026gt; groupAnagrams(List\u0026lt;String\u0026gt; strings) { 2 Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; letterCountMap = new HashMap\u0026lt;\u0026gt;(); 3 for (String string : strings) { 4 String letterCount = countLetter(string); 5 List\u0026lt;String\u0026gt; subResult = letterCountMap.get(letterCount); 6 if (subResult == null) { 7 subResult = new ArrayList\u0026lt;\u0026gt;(); 8 letterCountMap.put(letterCount, subResult); 9 } 10 subResult.add(string); 11 } 12 13 List\u0026lt;String\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); 14 for (List\u0026lt;String\u0026gt; subResult : letterCountMap.values()) { 15 result.addAll(subResult); 16 } 17 return result; 18} 19 20private String countLetter(String string) { 21 int[] count = new int[26]; // 假设26个英文字母，而且都是小写 22 for (int i = 0; i \u0026lt; string.length(); i++) { 23 count[string.charAt(i) - \u0026#39;a\u0026#39;]++; 24 } 25 String result = \u0026#34;\u0026#34;; 26 for (int i = 0; i \u0026lt; count.length; i++) { 27 if (count[i] == 0) { 28 continue; 29 } 30 result += \u0026#34;\u0026#34; + (\u0026#39;a\u0026#39; + i) + count[i]; 31 } 32 return result; 33} 时间复杂度：O(s * a + a)，s是平均字符串的长度，a是数组长度。\n","date":"2019-08-28","img":"","permalink":"/post/cracking-coding-interview/10.2-group-anagrams/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 10.2 Group Anagrams"},{"categories":null,"content":"Sorted Merge: You are given two sorted arrays, A and B, where A has a large enough buffer at the end to hold B. Write a method to merge B into A in sorted order.\nHints: #332\n解法 比如下面两个数组：\n1A: [x1, x2, x3, _ , _ ] 2B: [y1, y2] 两个数组都是有序的，数组A尾部有足够的空间放B数组，要求不利用临时数组，把B数组合并到A里，结果依然有序。\n第一个想到的办法是两个数组从头开始比，如果B[i] \u0026lt; A[j]，把B[i]插入到A[j]前面。不过这个方式有两个问题：\n 每次插入都会牵涉到值copy 每次插入A的遍历下标都要变化  那么反过来，从两个数组的尾部开始比，谁大谁就放在尾部。\n代码\n1public void sortedMerge(int[] a, int aLength, int[] b) { 2 int aEnd = aLength - 1; 3 int bEnd = b.length - 1; 4 int i = a.length - 1; 5 while (aEnd \u0026gt;= 0 \u0026amp;\u0026amp; bEnd \u0026gt;= 0) { 6 if (a[aEnd] \u0026gt; b[bEnd]) { 7 a[i] = a[aEnd]; 8 aEnd--; 9 } else { 10 a[i] = b[bEnd]; 11 bEnd--; 12 } 13 i--; 14 } 15 while (bEnd \u0026gt;= 0) { 16 a[i] = b[bEnd]; 17 bEnd--; 18 i--; 19 } 20} ","date":"2019-08-28","img":"","permalink":"/post/cracking-coding-interview/10.1-sorted-merge/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 10.1 Sorted Merge"},{"categories":null,"content":"Boolean Evaluation: Given a boolean expression consisting of the symbols 0 (false), 1 (true), \u0026amp; (AND), | (OR), and ^ (XOR), and a desired boolean result value result, implement a function to count the number of ways of parenthesizing the expression such that it evaluates to result.\nEXAMPLE\n1countEval(\u0026#34;1^0|0|1\u0026#34;, false) -\u0026gt; 2 2countEval(\u0026#34;0\u0026amp;0\u0026amp;0\u0026amp;1^1|0\u0026#34;, true) -\u0026gt; 10 Hints: #148, #168, #197, #305, #327\n解法1 对于第一个例子的两个做法是：\n11^(0|(0|1)) 21^((0|0)|1) 怎么分析这个问题？\n先看两个简单的例子：\n1表达式: a | b 2加括号: (a) | (b) 3 4表达式: a \u0026amp; b | c 5加括号: (a) \u0026amp; (b | c) 6 (a \u0026amp; b) | (c) 7其中: b | c 可以拆分成 (b) | (c) 8 a \u0026amp; b 可以是 (a) \u0026amp; (b) 所以，可以发现加括号实际上可以是一个递归的过程，将表达式根据操作符分割成左右两边，对左右两边再做分割。直到表达式里没有操作符为止，即达到Base Condition。\n然后再看表达式的左右两边值得是如何的才能得到期望值：\n1Required: a | b == true 2Solution: a == true \u0026amp;\u0026amp; b == true 3 OR a == true \u0026amp;\u0026amp; b == false 4 OR a == false \u0026amp;\u0026amp; b == true 5 6Required: a | b == false 7Solution: a == false \u0026amp;\u0026amp; b == false 8 9Required: a \u0026amp; b == true 10Solution: a == true \u0026amp;\u0026amp; b == true 11 12Required: a \u0026amp; b == false 13Solution: a == true \u0026amp;\u0026amp; b == false 14 OR a == false \u0026amp;\u0026amp; b == true 15 OR a == false \u0026amp;\u0026amp; b == false 16 17Required: a ^ b == true 18Solution: a == true \u0026amp;\u0026amp; b == false 19 OR a == false \u0026amp;\u0026amp; b == true 20 21Required: a ^ b == true 22Solution: a == true \u0026amp;\u0026amp; b == true 23 OR a == false \u0026amp;\u0026amp; b == false 所以：\n1countEval(a | b, true) = countEval(a, true) * countEval(b, false) 2 + countEval(a, false) * countEval(b, true) 3 + countEval(a, true) * countEval(b, true) 4 5countEval(a | b, false) = countEval(a, false) * countEval(b, false) 6 7countEval(a \u0026amp; b, true) = countEval(a, true) * countEval(b, true) 8 9countEval(a \u0026amp; b, false) = countEval(a, true) * countEval(b, false) 10 + countEval(a, false) * countEval(b, true) 11 + countEval(a, false) * countEval(b, false) 12 13countEval(a ^ b, true) = countEval(a, true) * countEval(b, false) 14 + countEval(a, false) * countEval(b, true) 15 16countEval(a ^ b, false) = countEval(a, true) * countEval(b, true) 17 + countEval(a, false) * countEval(b, false) 所以代码：\n1public int countEval(String expression, boolean expected) { 2 if (expression == \u0026#34;\u0026#34;) { 3 return 0; 4 } 5 if (expression == \u0026#34;1\u0026#34;) { 6 return expected ? 1 : 0; 7 } 8 if (expression == \u0026#34;0\u0026#34;) { 9 return expected ? 0 : 1; 10 } 11 int ways = 0; 12 for (int i = 1; i \u0026lt; expression.length; i += 2) { 13 char op = expression.charAt(i); 14 String left = expression.subString(0, i); 15 String right = expression.subString(i + 1); 16 17 int leftTrue = countEval(left, true); 18 int leftFalse = countEval(left, false); 19 int rightTrue = countEval(right, true); 20 int rightFalse = countEval(right, false); 21 22 if (op == \u0026#39;|\u0026#39;) { 23 if (expected) { 24 ways += leftTrue * rightTrue 25 + leftTrue * rightFalse 26 + leftFalse * rightTrue; 27 } else { 28 ways += leftFalse * rightFalse; 29 } 30 } else if (op == \u0026#39;\u0026amp;\u0026#39;) { 31 if (expected) { 32 ways += leftTrue * rightTrue; 33 } else { 34 ways += leftTrue * rightFalse 35 + leftFalse * rightTrue 36 + leftFalse * rightFalse; 37 } 38 } else if (op == \u0026#39;^\u0026#39;) { 39 if (expected) { 40 ways += leftTrue * rightFalse 41 + leftFalse * rightTrue; 42 } else { 43 ways += leftTrue * rightTrue 44 + leftFalse * rightFalse; 45 } 46 } 47 } 48 return ways; 49} 上面的代码有点长，可以这样计算：\n1左右表达式的总数量 = 左边表达式的总数 * 表达式的总数 2 = (左边true + 左边false) * (右边true + 右边false) 3因此: 4totalCount(a | b) = (countEval(a, true) + countEval(a, false)) 5 * (countEval(b, true) + countEval(b, false)) 6 7而countEval(a | b, false) = totalCount(a | b) - countEval(a | b, true); 因此可以简化：\n1public int countEval(String expression, boolean expected) { 2 if (expression == \u0026#34;\u0026#34;) { 3 return 0; 4 } 5 if (expression == \u0026#34;1\u0026#34;) { 6 return expected ? 1 : 0; 7 } 8 if (expression == \u0026#34;0\u0026#34;) { 9 return expected ? 0 : 1; 10 } 11 int ways = 0; 12 for (int i = 1; i \u0026lt; expression.length; i += 2) { 13 char op = expression.charAt(i); 14 String left = expression.subString(0, i); 15 String right = expression.subString(i + 1); 16 17 int leftTrue = countEval(left, true); 18 int leftFalse = countEval(left, false); 19 int rightTrue = countEval(right, true); 20 int rightFalse = countEval(right, false); 21 int total = (leftTrue + leftFalse) * (rightTrue * rightFalse); 22 int totalTrue = 0; 23 if (op == \u0026#39;|\u0026#39;) { 24 totalTrue = leftTrue * rightTrue 25 + leftTrue * rightFalse 26 + leftFalse * rightTrue; 27 } else if (op == \u0026#39;\u0026amp;\u0026#39;) { 28 totalTrue = leftTrue * rightTrue; 29 } else if (op == \u0026#39;^\u0026#39;) { 30 totalTrue = leftTrue * rightFalse 31 + leftFalse * rightTrue; 32 } 33 int subWays = result ? totalTrue : total - totalTrue; 34 ways += subWays; 35 } 36 return ways; 37} 解法2 考虑这个表达式a|b\u0026amp;a|b，当分割成(a|b)*(a|b)时，左边的数量右边的数量是一致的，因此可以缓存起来避免重复计算。\n1public int countEval(String expression, boolean expected, Map\u0026lt;String, Map\u0026lt;Boolean, Integer\u0026gt;\u0026gt; cache) { 2 if (expression == \u0026#34;\u0026#34;) { 3 return 0; 4 } 5 if (expression == \u0026#34;1\u0026#34;) { 6 return expected ? 1 : 0; 7 } 8 if (expression == \u0026#34;0\u0026#34;) { 9 return expected ? 0 : 1; 10 } 11 Map\u0026lt;Boolean, Integer\u0026gt; boolCache = cache.get(expression); 12 if (boolCache != null) { 13 Integer cacheCount = cache.get(expression).get(result); 14 if (cacheCount != null) { 15 return cacheCount; 16 } 17 } 18 19 int ways = 0; 20 for (int i = 1; i \u0026lt; expression.length; i += 2) { 21 char op = expression.charAt(i); 22 String left = expression.subString(0, i); 23 String right = expression.subString(i + 1); 24 25 int leftTrue = countEval(left, true); 26 int leftFalse = countEval(left, false); 27 int rightTrue = countEval(right, true); 28 int rightFalse = countEval(right, false); 29 int total = (leftTrue + leftFalse) * (rightTrue * rightFalse); 30 int totalTrue = 0; 31 if (op == \u0026#39;|\u0026#39;) { 32 totalTrue = leftTrue * rightTrue 33 + leftTrue * rightFalse 34 + leftFalse * rightTrue; 35 } else if (op == \u0026#39;\u0026amp;\u0026#39;) { 36 totalTrue = leftTrue * rightTrue; 37 } else if (op == \u0026#39;^\u0026#39;) { 38 totalTrue = leftTrue * rightFalse 39 + leftFalse * rightTrue; 40 } 41 int subWays = result ? totalTrue : total - totalTrue; 42 ways += subWays; 43 } 44 45 if (boolCache == null) { 46 boolCache = new HashMap\u0026lt;\u0026gt;(); 47 cache.put(expression, boolCache); 48 } 49 boolCache.put(result, ways); 50 return ways; 51} ","date":"2019-08-27","img":"","permalink":"/post/cracking-coding-interview/8.14-boolean-evaluation/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 8.14 Boolean Evaluation"},{"categories":null,"content":"Stack of Boxes: You have a stack of n boxes, with widths wi, heights hi and depths di. The boxes cannot be rotated and can only be stacked on top of one another if each box in the stack is strictly larger than the box above it in width, height, and depth. Implement a method to compute the height of the tallest possible stack. The height of a stack is the sum of the heights of each box.\nHints: #155, #194, #214, #260, #322, #368, #378\n解法 先举个例子来解释这个问题，加入有，Box-A(w=1,h=2,d=3)和Box-B(w=1 h=3,d=2)，按照题目中的定义，这两个Box-A和Box-B谁都不比谁大（题目中要求w、h、d都比对方大才算大），但是h的话是Box-B比较大。\n要注意的是：\n 如果Box1 \u0026gt; Box2，那么Box1.height 必定 \u0026gt; Box2.height 否则，Box1.height 未必 \u0026gt; Box2.height  如果我们把Box排序，那么可能会发现一段连续的Box里的谁都不比谁大，但是它们中肯定存在一个最大的height，比如下面的B1～4都是谁都不比谁大的：\n1 B1(w5,h=5,d=5) B2(w5,h=6,d=5) B3(w5,h=4,d=5) B4(w4,h=7,d=4) 2 B5(w3,h=3,d=3) B6(w2,h=2,d=2) 所以：\n1maxHeight(boxes[0~n]) = max(boxes[0~i].height) + maxHeight(boxes[i+1~n]) 上面的boxes[0~i]指的是在[0, i]范围内的box谁都不比谁大，取这里面的最大height，再加上后面那段里的值。\nBox对象：\n1class Box { 2 int width; 3 int height; 4 int depth; 5 public boolean isLargerThan(Box another) { 6 return this.width \u0026gt; another.width 7 \u0026amp;\u0026amp; this.height \u0026gt; another.height 8 \u0026amp;\u0026amp; this.depth \u0026gt; another.depth; 9 } 10 int compareTo(Box another) { 11 if (this.isLargerThan(another)) { 12 return -1; 13 } 14 if (another.isLargerThan(this)) { 15 return 1; 16 } 17 return another.height - this.height; 18 } 19} 代码：\n1public int maxHeight(Box[] boxes) { 2 Arrays.sort(boxes); 3 return maxHeight(boxes, 0); 4} 5public int maxHeight(Box[] boxes, int index) { 6 if (index == boxes.length) { 7 return 0; 8 } 9 Box curr = boxes[index]; 10 if (index == boxes.length - 1) { 11 return curr.height; 12 } 13 int maxHeight = 0; 14 // 往后找，找到第一个比当前盒子小的盒子下标i，然后从它开始maxHeight(boxes[i...]) 15 // 结果再加上当前盒子到i之间的盒子的最大height 16 maxHeight = curr.height; 17 for (int i = index + 1; i \u0026lt; boxes.length; i++) { 18 if (!curr.isLargerThan(boxes[i])) { 19 maxHeight = Math.max(maxHeight, boxes[i].height); 20 } else { 21 break; 22 } 23 } 24 maxHeight += maxHeight(boxes, i); 25 return maxHeight; 26} ","date":"2019-08-27","img":"","permalink":"/post/cracking-coding-interview/8.13-stack-of-boxes/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 8.13 Stack of Boxes"},{"categories":null,"content":"Eight Queens: Write an algorithm to print all ways of arranging eight queens on an 8x8 chess board so that none of them share the same row, column, or diagonal. In this case, \u0026ldquo;diagonal\u0026rdquo; means all diagonals, not just the two that bisect the board.\nHints: #308, #350, #371\n解法1 在一个8x8的棋盘里，放8个皇后，使得每个皇后都不在其他皇后的同行、同列、同斜线上。其实就是说放8个皇后，这8个皇后谁都没法吃谁，因为国际象棋里皇后可以衡走、竖走、斜走，且每步的长度无限。\n 保证新放的皇后没法被前面的皇后吃掉。 保证不会产生重复结果，也就是知道什么时候可以停止计算了。  根据皇后的吃子规则可知，每行只能有一个皇后，我们可以先在第一行放一个皇后，然后在下一行放一皇后。那么下一行放的皇后的位置必定不能在其左下一格、下方一格、右下一格，其他列都可以放。当放到第8行的时候就知道结束了。\n代码：\n1public List\u0026lt;int[][]\u0026gt; queens8() { 2 List\u0026lt;int[][]\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); 3 int[][] board = new int[8][8]; 4 queens8(board, int row, int col, result) 5 return result; 6} 7 8public void queens8(int[][] board, int row, int col, List\u0026lt;int[][]\u0026gt; result) { 9 if (row \u0026gt; 7) { 10 // 出界 11 return; 12 } 13 if (isConflict(board, row, col)) { 14 // 和其他皇后冲突 15 return; 16 } 17 if (row == 7) { 18 // 不冲突不出界，最后一个 19 board[row][col] = 1; 20 result.add(clone(board)); 21 return; 22 } 23 board[row][col] = 1; // 放皇后 24 for (int i = 0; i \u0026lt; 8; i++) { 25 if (i == col - 1 || i == col || i == col + 1) { 26 // 不在下一行的左下、下、右下放皇后 27 continue; 28 } 29 queens8(board, row + 1, i, result); // 右马步 30 } 31 board[row][col] = 0; // 不论是否成功、失败都把皇后清掉 32} 33 34public boolean isConflict(int[][] board, int row, int col) { 35 for (int i = 0; i \u0026lt; 8; i++) { 36 if (board[row][i] == 1) { 37 // 行冲突 38 return true; 39 } 40 if (board[i][col] == 1) { 41 // 列冲突 42 return true; 43 } 44 } 45 46 for (int i = 1; i \u0026lt;= 8; i++) { 47 int upperRightRow = row - i; 48 int upperRightCol = col + i; 49 int upperLeftRow = row - i; 50 int upperLeftCol = col - i; 51 int lowerRightRow = row + i; 52 int lowerRightCol = col + i; 53 int lowerLeftRow = row + i; 54 int lowerLeftCol = col - i; 55 56 if (upperRightRow \u0026lt; 8 \u0026amp;\u0026amp; upperRightCol \u0026lt; 8 57 \u0026amp;\u0026amp; board[upperRightRow][upperRightCol] == 1) { 58 // 和右上斜线皇后冲突 59 return true; 60 } 61 if (upperLeftRow \u0026lt; 8 \u0026amp;\u0026amp; upperLeftCol \u0026lt; 8 62 \u0026amp;\u0026amp; board[upperLeftRow][upperLeftCol] == 1) { 63 // 和左上斜线皇后冲突 64 return true; 65 } 66 if (lowerRightRow \u0026lt; 8 \u0026amp;\u0026amp; lowerRightCol \u0026lt; 8 67 \u0026amp;\u0026amp; board[lowerRightRow][lowerRightCol] == 1) { 68 // 和右下斜线皇后冲突 69 return true; 70 } 71 if (lowerLeftRow \u0026lt; 8 \u0026amp;\u0026amp; lowerLeftCol \u0026lt; 8 72 \u0026amp;\u0026amp; board[lowerLeftRow][lowerLeftCol] == 1) { 73 // 和左下斜线皇后冲突 74 return true; 75 } 76 } 77 return false; 78} 可能可以做的优化：对于一种8皇后解法来说，它的镜像肯定也是一个解，那么是否是说只第一行只需要尝试1-4列就行了呢？\n解法2（更好） 因为每行放一个皇后，所以不需要int[][] borad来记录位置，只需要int[] cols就行了。比如cols[0]就是第一行皇后所处的列。\n1public List\u0026lt;int[]\u0026gt; queens8() { 2 int[] cols = new int[] {-1, -1, -1, -1, -1, -1, -1, -1}; 3 List\u0026lt;int[]\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); 4 queens8(cols, 0, result); 5 return result; 6} 7public void queens8(int[] cols, int row, List\u0026lt;int[]\u0026gt; result) { 8 if (row == 8) { 9 result.add(cols.clone()); 10 return; 11 } 12 for (int col = 0; col \u0026lt; 8; i++) { 13 if (!isConflict(row, col, cols)) { 14 cols[row] = col; 15 queens8(cols, row + 1, result); 16 } 17 } 18} 19 20// 判断本 21private boolean isConflict(int row, int col, int[] cols) { 22 // 只和前面的行比较 23 for (int i = 0; i \u0026lt; row; i++) { 24 // 判断和前面的皇后是否处于相同列 25 if (col[i] == col) { 26 return true; 27 } 28 // 判断是否处于前面皇后的斜线上 29 int rightDownCol = col[i] + (row - i); // 右下方斜线在本行的列数 30 if (col == rightDownCol) { 31 return true; 32 } 33 int leftDownCol = col[i] - (row - i); // 左下方斜线在本行的列数 34 if (col == leftDownCol) { 35 return true; 36 } 37 } 38 return false; 39} ","date":"2019-08-27","img":"","permalink":"/post/cracking-coding-interview/8.12-eight-queens/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 8.12 Eight Queens"},{"categories":null,"content":"Coins: Given an infinite number of quarters (25 cents), dimes (10 cents), nickels (5 cents), and pennies (1 cent), write code to calculate the number of ways of representing n cents.\nHints: #300, #324, #343, #380, #394\n解法1（审题错误） 你有25分、10分、5分、1分面值的硬币，给一个n让你求有几种能够组合能够变成n。\n举个例子：\nn=34，求Coins(34)（求34的各种组合）。\n先从第一个硬币开始，如果我选择的1分，那么结果就是1分 + C(33)。如果选择的是5分，那么结果就是5分 + C(29)，其他情况以此类推。\n需要注意的是因为是组合问题不是排列问题，因此要避免得到重复结果，比如{1, 1, 1, 1, 5, 25}和{5, 1, 25, 1, 1, 1}是一样的。\n解决办法是选择的硬币的面值必须 \u0026gt;= 上一个硬币的面值\n1public List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; coins(int n) { 2 List\u0026lt;Integer\u0026gt; sofar = new ArrayList\u0026lt;\u0026gt;(); 3 sofar.add(0); 4 List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); 5 coins(sofar, 0, n, result); 6 return result; 7} 8 9public void coins(List\u0026lt;Integer\u0026gt; sofar, int currentSum, int targetSum, List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; result) { 10 if (currentSum == targetSum) { 11 result.add(sofor.subList(1)); 12 return; 13 } 14 if (currentSum \u0026gt; targetSum) { 15 return; 16 } 17 int lastCoin = getLast(sofar); 18 if (1 \u0026gt;= lastCoin) { 19 add(sofar, 1); 20 coins(sofar, currentSum + 1, targetSum, result); 21 removeLast(sofar); 22 } 23 if (5 \u0026gt;= lastCoin) { 24 add(sofar, 1); 25 coins(sofar, currentSum + 5, targetSum, result); 26 removeLast(sofar); 27 } 28 if (10 \u0026gt;= lastCoin) { 29 add(sofar, 1); 30 coins(sofar, currentSum + 5, targetSum, result); 31 removeLast(sofar); 32 } 33 if (25 \u0026gt;= lastCoin) { 34 add(sofar, 1); 35 coins(sofar, currentSum + 5, targetSum, result); 36 removeLast(sofar); 37 } 38} 39 40private add(List\u0026lt;Integer\u0026gt; list, Integer i) { 41 list.add(i); 42} 43 44private getLast(List\u0026lt;Integer\u0026gt; list) { 45 return list.get(list.size() - 1); 46} 47 48private removeLast(List\u0026lt;Integer\u0026gt; list) { 49 return list.remove(list.size() - 1); 50} 解法2 题目要求的计算有多少种方式，而不是求出所有方式。\n选择第一个硬币的数量，我们从大到小选，先选25分面值的硬币，假设目标是100分：\n1F(100) = F(100分, 用0个25分) 2 + F(100分, 用1个25分) 3 + F(100分, 用2个25分) 4 + F(100分, 用3个25分) 5 + F(100分, 用4个25分) 25硬币的使用情况都已经枚举完毕，后面是10分硬币的情况。注意到：\n1F(100分, 用0个25分) = F(100分, 用0..n个10分) 2F(100分, 用1个25分) = F(75分, 用0..n个10分) 3F(100分, 用2个25分) = F(50分, 用0..n个10分) 4F(100分, 用3个25分) = F(25分, 用0..n个10分) 5F(100分, 用4个25分) = F(0分，用0..n个10分) = 1 然后再选5分硬币，比如：\n1F(100分, 用1个10分) = F(90分, 用0..n个5分) 最后选1分硬币，比如：\n1F(90分, 用1个5分) = F(85, 用0..n个1分) = 1 Base Condition有2个：\n 到当选用1分硬币的时候你就只有1种选择，因为你只能全部用1分。 当总金额为0的时候你也就只有1种选择。  代码：\n1public int coins(int amount) { 2 return coins(amount, 25); 3} 4public int coins(int amount, int currentMianzhi) { 5 if (currentMianzhi == 1) { 6 return 1; 7 } 8 if (amount == 0) { 9 return 1; 10 } 11 int ways = 0; 12 for (int i = 0; i * currentMianzhi \u0026lt;= amount; i++) { 13 int remainingAmount = amount - i * currentMianzhi; 14 int nextMianzhi = getNextMianzhi(currentMianzhi); 15 ways += coins(remainingAmount, nextMianzhi); 16 } 17 return ways; 18} 19 20private int getNextMianzhi(int mianzhi) { 21 if (mianzhi == 25) { 22 return 10; 23 } 24 if (mianzhi == 10) { 25 return 5; 26 } 27 if (mianzhi == 5) { 28 return 1; 29 } 30 return 0; 31} 不过上面的做法对于每次取下一个面值代码有点写死，可以这样做：\n1public int coins(int amount) { 2 int[] mianzhi = new int[] {25, 10, 5, 1}; 3 return coins(amount, mianzhis, 0); 4} 5 6public int coins(int amount, int[] mianzhis, int mianzhiIndex) { 7 if (mianzhiIndex == mianzhis.length - 1) { 8 // 已经是最小面值了，在本题中是1 9 return 1; 10 } 11 int ways = 0; 12 int mianzhi = mianzhis[mianzhiIndex]; 13 for (int i = 0; i * mianzhi \u0026lt;= amount; i++) { 14 int remainingAmount = amount - i * mianzhi; 15 ways += coins(remainingAmount, mianzhis, mianzhiIndex + 1); 16 } 17 return ways; 18} 解法3 上面的做法里存在重复计算：\n1F(100) = F(100分, 用0个25分) = F(100, 用0..n个10分) 2 + ... 3 + F(100分, 用2个25分) = F(50, 用0..n个10分) 4 + ... 而：\n1F(100, 用0..n个10分) = F(100, 0个10分) 2 + ... 3 + F(100, 5个10分) = F(50, 0..n个5分) 4F(50, 用0..n个10分) = F(50, 0个10分) = F(50, 0..n个5分) 5 + ... 可以看到存在重复计算。\n也就是说F(总金额,面值)可以作为key来缓存结果。\n1public int coins(int amount) { 2 int[] mianzhi = new int[] {25, 10, 5, 1}; 3 int[][] cache = new int[mianzhi.length][amount + 1]; 4 return coins(amount, mianzhis, 0, cache); 5} 6 7public int coins(int amount, int[] mianzhis, int mianzhiIndex, int[][] cache) { 8 if (cache[mianzhiIndex][amount] != 0) { 9 return cache[mianzhiIndex][amount]; 10 } 11 if (mianzhiIndex == mianzhis.length - 1) { 12 return 1; 13 } 14 int ways = 0; 15 int mianzhi = mianzhis[mianzhiIndex]; 16 for (int i = 0; i * mianzhi \u0026lt;= amount; i++) { 17 int remainingAmount = amount - i * mianzhi; 18 ways += coins(remainingAmount, mianzhis, mianzhiIndex + 1); 19 } 20 cache[mianzhiIndex][amount] = ways; 21 return ways; 22} ","date":"2019-08-27","img":"","permalink":"/post/cracking-coding-interview/8.11-coins/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 8.11 Coins"},{"categories":null,"content":"Paint Fill: Implement the \u0026ldquo;paint fill\u0026rdquo; function that one might see on many image editing programs. That is, given a screen (represented by a two-dimensional array of colors), a point, and a new color, fill in the surrounding area until the color changes from the original color.\nHints: #364, #382\n解法1 举个例子：如果一个画布背景是白色，上面有一个黑色的方块，点中这个方块中的某个坐标，把这个方块变成绿色。\n如果两个方块顶点相碰，那么只会有一个方块变颜色。这也就是体重所说的surrounding区域变色，而surrounding的概念则是上下左右4个方向，不含斜方向。要注意避免重复着色。\n1public void paintFill(byte[][] screen, int r, int c, byte toColor) { 2 byte srcColor = screen[r][c]; 3 paintFill(screen, r, c, srcColor, toColor); 4} 5 6public void paintFill(byte[][] screen, int r, int c, byte srcColor, byte toColor) { 7 if (r \u0026lt; 0 || c \u0026lt; 0 || r \u0026gt;= screen.length || c \u0026gt;= screen[0].length) { 8 // 越过屏幕边界 9 return; 10 } 11 byte meColor = screen[r][c]; 12 if (meColor != srcColor) { 13 return; 14 } 15 screen[x][y] = toColor; 16 paintFill(screen, r + 1, y, srcColor, toColor); // up 17 paintFill(screen, r - 1, y, srcColor, toColor); // down 18 paintFill(screen, x, c + 1, srcColor, toColor); // right 19 paintFill(screen, x, c - 1, srcColor, toColor); // left 20} ","date":"2019-08-26","img":"","permalink":"/post/cracking-coding-interview/8.10-paint-fill/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 8.10 Paint Fill"},{"categories":null,"content":"Parens: Implement an algorithm to print all valid (e.g., properly opened and closed) combinations of n pairs of parentheses.\n1EXAMPLE 2Input: 3 3Output: ((())), (()()), (())(), ()(()), ()()() Hints: #138, #174, #187, #209, #243, #265, #295\n解法1 这个问题的难点在于如果你把所有的可插入点都去插一下，那么会得到重复的结果，比如插入点有这么几个：\n ()的里面 ()的左边 ()点右边  即使我们去掉左边这个插入点，那么依然会存在重复，比如：\n1下面用()代表之前得到的结果，[]代表本步骤新插入的结果： 2 3f(1) = () 4 5f(2) = 在 f(1) 的插入点插入 6 = ()[] 7 ([]) 8 9f(3) = 在 f(2) 的插入点插入 10 = ([])() case 1 插里面 11 ()[]() case 2 插右边 12 ()([]) case 3 插里面 13 ()()[] case 4 插右边 14 15 (([])) case 5 插里面 16 (()[]) case 6 插右边 17 (())[] case 7 插右边 18 19case 1和case 7重复 20case 2和case 4重复 用什么办法做插入才能不产生重复？如果用HashSet来排重的话太复杂了。\n解法2(正确) 把(记为L，把)记为R，这个问题是否可以理解为给定2 * n个空位，让你在里面填上L和R。\n要求一：结果的L和R的数量相等\n如果我们从第一个空格开始填，那么应该填什么？基本上来说你填L肯定是安全的（只要没超数量就行），那么什么时候填R呢？当count(R) \u0026lt; count(L)的时候可以。如果你从左到右读一个合法的结果，在读的时候给L和R计数，那么你会发现R的计数永远不会超过L。所以总结一下：\n 最终结果count(L) == count(R) count(L) == n 当count(R) \u0026lt; count(L) 的时候可以填写R 当count(L) \u0026lt; n的时候可以填写L 当count(R) == count(L) == n的时候构造完成  代码：\n1public List\u0026lt;String\u0026gt; parens(int n) { 2 List\u0026lt;String\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); 3 parens(new StringBuilder(), n, n, result); 4 return result; 5} 6 7// lCount: ( 剩余的数量，这里和上面有点差别，上面说的是迄今为止用了多少个L，这里是还剩多少个 ( 没用。 8// rCount: ) 剩余的数量 9public void parens(StringBuilder sb, int lCount, int rCount, List\u0026lt;String\u0026gt; result) { 10 if (lCount == 0 \u0026amp;\u0026amp; rCount == 0) { 11 result.add(sb.toString()); 12 return; 13 } 14 if (lCount \u0026gt; 0) { 15 sb.append(\u0026#39;(\u0026#39;); 16 parens(sb, lCount - 1, rCount, result); 17 sb.deleteAt(sb.length() - 1); 18 } 19 if (rCount \u0026gt; 0 \u0026amp;\u0026amp; rCount \u0026gt; lCount) { 20 sb.append(\u0026#39;)\u0026#39;); 21 parens(sb, lCount, rCount - 1, result); 22 sb.deleteAt(sb.length() - 1); 23 } 24} ","date":"2019-08-26","img":"","permalink":"/post/cracking-coding-interview/8.9-parens/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 8.9 Parens"},{"categories":null,"content":"Permutations with Dups: Write a method to compute all permutations of a string whose charac­ ters are not necessarily unique. The list of permutations should not have duplicates.\nHints: #161, #190, #222, #255\n解法1 还是用8.7 Permutations without Dups 的prefix法来做，查看prefix是否被用过，如果用过则跳过：\n1P(, aab) 2 P(a, ab) 3 P(aa, b) 4 P(aab, ) \u0026lt;- 最终结果 5 P(ab, a) 6 P(aba, ) \u0026lt;- 最终结果 7 P(a, ab) \u0026lt;- X相同prefix 8 P(b, aa) 9 P(ba, a) 10 P(baa, ) \u0026lt;- 最终结果 11 P(ba, a) \u0026lt;- X相同prefix 代码：\n1public List\u0026lt;String\u0026gt; permute(String str) { 2 List\u0026lt;String\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); 3 permute(new StringBuilder(), new StringBuilder(str), result); 4 return result; 5} 6 7public void permute(StringBuilder prefix, StringBuilder post, List\u0026lt;String\u0026gt; permutations) { 8 if (post.length() == 0) { 9 permutations.add(prefix.toString()); 10 return; 11 } 12 Set\u0026lt;String\u0026gt; prefixes = new HashSet\u0026lt;\u0026gt;(); 13 for (int i = 0; i \u0026lt; post.length(); i++) { 14 char c = post.charAt(i); 15 prefix.append(c); 16 post.deleteAt(i); 17 if (!prefixes.contains(prefix)) { 18 prefixes.add(prefix); 19 permute(prefix, post, permutations); 20 } 21 prefix.deleteAt(prefix.length() - 1); 22 post.insert(c, i); 23 } 24} 空间复杂度：就是计算HashSet中存了多少个字符。以不重复的时候计算，因为之前的调用返回后都归还了空间，我们只看最后一次调用整个两条上用到的空间：\n1P( , abc) 2 P(a, bc) 3 P(b, ac) 4 P(c, ab) 5 P(ca, b) 6 P(cb, a) 7 P(cba, ) 用了：1个3字符，2个2字符，3个1字符 ，总共10个字符。\n换成公式等于：\n1缓存的字符数 = 1 * n + 2 * (n - 1) + 3 * (n - 2) + ... + (n - 2) * 3 + (n - 1) * 2 + n * 1 2 = 2 * (n + 2n + 3n + ... + (n/2) * n) - 2 * (2*1 + 3*2 + 4*3 + 5*4) 3 = 大致上是O(n^3) 解法2 这个解法是答案里看来的，比较难以理解。大致思想是你不管重复的字符，你只需要知道有多少个unique字符，并且它们的计数是多少。\n然后在unique字符中取出\n 取出一个字符，添加到prefix中，将其计数-1。如果这个字符计数为0则跳过。 在剩余字符里，重复第1步 直到prefix长度等于字符串长度，那么prefix就是一个permutation  下面是一个举例：\n1Input : aab 2charCount : a=2, b=1 3P(, aab) 4 P(a, ab) a=1, b=1 5 P(aa, b) a=0, b=1 6 P(aab, ) a=0, b=0 \u0026lt;- 最终结果 7 P(ab, a) a=1, b=0 8 P(aba, ) a=0, b=0 \u0026lt;- 最终结果 9 P(b, aa) a=2, b=0 10 P(ba, a) a=1, b=0 11 P(baa, ) a=0, b=0 \u0026lt;- 最终结果 这个办法的精髓是：每次是取出一个unique字符，所以就不存在同一字符在同一index出现两次的情况。\n可以对比解法1做法：\n1P(, aab) 2 P(a, ab) 3 P(aa, b) 4 P(aab, ) 5 P(ab, a) 6 P(aba, ) 7 P(a, ab) \u0026lt;- a在index=0里再一次出现了 8 P(b, aa) 9 P(ba, a) 10 P(baa, ) 11 P(ba, a) \u0026lt;- X相同prefix 代码：\n1public List\u0026lt;String\u0026gt; permute(String str) { 2 List\u0026lt;String\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); 3 Map\u0026lt;Char, Integer\u0026gt; charCount = makeCharCount(str); 4 permute(charCount, \u0026#34;\u0026#34;, str.length(), result); 5 return result; 6} 7 8private Map\u0026lt;Char, Integer\u0026gt; makeCharCount(String str) { 9 Map\u0026lt;Char, Integer\u0026gt; result = new HashMap\u0026lt;\u0026gt;(); 10 for (int i = 0; i \u0026lt; str.length; i++) { 11 char c = str.charAt(i); 12 Integer count = result.get(c); 13 if (count == null) { 14 result.put(c, 0); 15 count = 0; 16 } 17 result.put(c, count + 1); 18 } 19 return result; 20} 21 22private void permute(Map\u0026lt;Char, Integer\u0026gt; charCount, String prefix, int remaining, List\u0026lt;String\u0026gt; permutations) { 23 if (remaining == 0) { 24 permutations.add(prefix); 25 } 26 for (Char c : charCount.keySet()) { 27 int count = charCount.get(c); 28 if (count \u0026gt; 0) { 29 charCount.put(c, count - 1); 30 permute(charCount, prefix + c, remaining - 1, permutations); 31 // 恢复计数，给当前index的下一次取的是别的字符，自己的计数-1要恢复 32 charCount.put(c, count); 33 } 34 } 35} 空间复杂度：O(n)，n是字符串长度。\n","date":"2019-08-26","img":"","permalink":"/post/cracking-coding-interview/8.8-permutation-with-dups/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 8.8 Permutation Wit Dups"},{"categories":null,"content":"Permutations without Dups: Write a method to compute all permutations of a string of unique characters.\nHints: #150, #185, #200, #267, #278, #309, #335, #356\n解法1 1permute(abcd) = a 插入到 permute(bcd) 结果的各个插入点 2permute(bcd) = b 插入到 permute(cd) 结果的各个插入点 3permute(cd) = c 插入到 permute(d) 结果的各个插入点 4permute(d) = d 代码：\n1public List\u0026lt;String\u0026gt; permute(String str) { 2 List\u0026lt;String\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); 3 if (str.length() == 1) { 4 result.add(str) 5 return result; 6 } 7 char c = str.charAt(0); 8 List\u0026lt;String\u0026gt; permutations = permute(str.subString(1)); 9 for (String permutation : permutations) { 10 for (int i = 0; i \u0026lt;= permutation.length(); i++) { 11 result.add(insert(permutation, i, c)); 12 } 13 } 14} 15 16private String insert(String str, int index, char c) { 17 if (index == 0) { 18 return c + str; 19 } 20 if (index == str.length()) { 21 return str + c; 22 } 23 return str.subString(0, index - 1) 24 + c 25 + str.subString(index, str.length()); 26} 解法2 1permute(abcd) = a + permute(bcd) 2 + b + permute(acd) 3 + c + permute(abd) 4 + d + permute(abc) 5permute(bcd) = b + permute(cd) 6 + c + permute(bd) 7 + d + permute(bc) 8permute(cd) = c + permute(d) 9 + d + permute(c) 10permute(c) = c 代码：\n1public List\u0026lt;String\u0026gt; permute(String str) { 2 List\u0026lt;String\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); 3 if (str.length() == 1) { 4 result.add(str); 5 return result; 6 } 7 for (int i = 0; i \u0026lt; str.length(); i++) { 8 char initial = str.charAt(i); 9 String remaining = deleteChar(str, i); 10 List\u0026lt;String\u0026gt; remainingPermutations = permute(remaining); 11 for (String remainingPermutation : remainingPermutations) { 12 result.add(initial + remainingPermutation); 13 } 14 } 15 return result; 16} 解法3 对于解法2用prefix法：\n1P( , abc) 2 P(a, bc) 3 P(ab, c) 4 P(abc, ) \u0026lt;- 5 P(ac, b) 6 P(acb, ) \u0026lt;- 7 P(b, ac) 8 P(ba, c) 9 P(bac, ) \u0026lt;- 10 P(bc, a) 11 P(bca, ) \u0026lt;- 12 P(c, ab) 13 P(ca, b) 14 P(cab, ) \u0026lt;- 15 P(cb, a) 16 P(cba, ) \u0026lt;- 代码：\n1 2public List\u0026lt;String\u0026gt; permute(String str) { 3 List\u0026lt;String\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); 4 permute(new StringBuilder(), new StringBuilder(str), result); 5 return result; 6} 7 8public void permute(StringBuilder prefix, StringBuilder post, List\u0026lt;String\u0026gt; permutations) { 9 if (post.length() == 0) { 10 permutations.add(prefix.toString()); 11 return; 12 } 13 for (int i = 0; i \u0026lt; post.length(); i++) { 14 char c = post.charAt(i); 15 prefix.append(c); 16 post.delete(i); 17 18 permute(prefix, post, permutations); 19 20 prefix.delete(prefix.length() - 1); 21 post.insert(c, i); 22 } 23} ","date":"2019-08-26","img":"","permalink":"/post/cracking-coding-interview/8.7-permutation-without-dups/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 8.7 Permutation Without Dups"},{"categories":null,"content":"Towers of Hanoi: In the classic problem of the Towers of Hanoi, you have 3 towers and N disks of different sizes which can slide onto any tower. The puzzle starts with disks sorted in ascending order of size from top to bottom (i.e., each disk sits on top of an even larger one).You have the following constraints:\n Only one disk can be moved at a time. A disk is slide off the top of one tower onto another tower. A disk cannot be placed on top of a smaller disk.  Write a program to move the disks from the first tower to the last using stacks.\nHints: #144, #224, #250, #272, #318\n解法 用S1、S2、S3代表3个Stack，S1初始有disks，S2和S3为空。现在我们要把S1的disk移到S3中：\n 当S1=（1）的时候，直接把1移动到S3 当S2=（1，2）的时候，把1移动到S2，把2移动到S3，把S1移动到S3 当S3=（1，2，3）的时候，把（1，2）移动到S2，把3移动到S3，把（1，2）移动到S3  所以可以看到，把S1移动到S3的步骤是：\n 把除了最后一个的disk都移动到S2。在这一步里，S1是src、S2是dest、S3是tmp 把最后一个disk移动到S3。在这一步里，S1是src、S3是dest。 把S2的移动到S3。在这一步里，S2是src、S3是dest、S1是tmp。  在第1步里递归执行1-3，在第2步里也是递归执行1-3。\n1public void hanoi(Stack src, Stack dest, Stack tmp) { 2 // 把除最后一个移动到tmp中 3 hanoi(src.size() - 1, src, tmp, dest); 4 // 把最后一个移动到dest中 5 dest.push(src.pop()); 6 // 把除最后一个移动到dest中 7 hanoi(src.size() - 1, tmp, dest, src); 8} 9 10// amount: 要移动的disk的数量 11public void hanoi(int amount, Stack src, Stack dest, Stack tmp) { 12 if (amount \u0026lt;= 0) { 13 return; 14 } 15 // 把除最后一个移动到tmp中 16 hanoi(amount - 1, src, tmp, dest); 17 // 把最后一个移动到dest中 18 dest.push(src.pop()); 19 // 把除最后一个移动到dest中 20 hanoi(amount - 1, tmp, dest, src); 21} 22 ","date":"2019-08-26","img":"","permalink":"/post/cracking-coding-interview/8.6-towers-of-hanoi/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 8.6 Towers of Hanoi"},{"categories":null,"content":"Recursive Multiply: Write a recursive function to multiply two positive integers without using the * operator.You can use addition, subtraction, and bit shifting, but you should minimize the number of those operations.\nHints: #166, #203, #227, #234, #246, #280\n解法1 用加法：\n1public int multiply(int a, int b) { 2 int num = Math.max(a, b); 3 int factor = Math.min(a, b); 4 int res = 0; 5 for (int i = 0; i \u0026lt; factor; i++) { 6 res += num; 7 } 8 return res; 9} 解法2 用加法，用f(a, b)代表a * b，拿8 * 9举例：\n1f(8, 9) = double(f(4, 9)) 2 = double(f(2, 9)) 3 = double(f(1, 9)) 如果是 7 * 9：\n1f(7, 9) = double(f(3, 9)) + 9 2 = double(f(1, 9)) + 9 每次double实际上就是自己加自己，是一次加法操作，那么f(8, 9)的加法次数是3，f(7, 9)的加法次数是4，比解法1好多了。\n所以f(m, n)的算法复杂度是：O(logm)，m \u0026lt; n。\n1public int multiply(int a, int b) { 2 if (a \u0026gt; b) { 3 return multiplyInternal(b, a);s 4 } 5 return multiplyInternal(a, b); 6} 7 8// a \u0026lt;= b 9public int multiplyInternal(int a, int b) { 10 if (a == 1) { 11 return b; 12 } 13 int res = multiplyInternal(a \u0026gt;\u0026gt; 1, b); 14 res += res; 15 if (a \u0026amp; 1 == 1) { 16 // 如果a是奇数 17 res += b; 18 } 19 return res; 20} ","date":"2019-08-26","img":"","permalink":"/post/cracking-coding-interview/8.5-recursive-multiply/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 8.5 Recurisve Multiply"},{"categories":null,"content":"Power Set: Write a method to return all subsets of a set.\nHints: #273, #290, #338, #354, #373\n解法1 时间复杂度估算**（很重要，这个是答案里说的）**：\n我们返回一个集合的所有子集，比如{1, 2, 3}的子集是{1}, {2}, {3}, {1, 2}, {1, 3}, {2, 3}, {1, 2, 3}，那么所有子集的元素数量之和就是我们的时间复杂度（同时也是空间复杂度）。为什么？因为元素数量就是List.add的调用次数啊。\n那么所有子集的元素数量之和怎么算出来？\n先看会有多少个子集，每个元素要么出现在子集中，要么不出现在子集中，所以每个元素都有两种可能，那么子集的数量等于2 * 2 * 2 ..，也就是2n个（上面的例子是7个是因为去掉了空集）。\n每个元素出现在某个子集里的机会是1/2，也就是说对于每个元素来说，一半的子集里有它。因此所有子集的元素数量之和等于n * 2n - 1个。\n因此时间复杂度：O(n * 2n)\n空间复杂度：O(n * 2n)\n P(N)记为，N个元素的所有子集 P(N) = P(N - 1) + 取出的元素 | P(N - 1)。意思是P(N)的子集等于：P(N - 1)的所有子集，加上，把某个被取出的元素加入到所有P(N - 1)的子集里形成的新的子集。 P(0) = 空集  代码：\n1public List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; powerSets(List\u0026lt;Integer\u0026gt; set, int index) { 2 List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; subsets; 3 if (index == set.size()) { 4 subsets = new ArrayList\u0026lt;\u0026gt;(); 5 subsets.add(new ArrayList\u0026lt;\u0026gt;()); 6 return subsets; 7 } 8 subsets = powerSets(set, index + 1); 9 Integer element = set.get(index); 10 List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; newSubsets = new ArrayList\u0026lt;\u0026gt;(); 11 for (List\u0026lt;Integer\u0026gt; subSubset : subsets) { 12 List\u0026lt;Integer\u0026gt; clonedSubSubset = new ArrayList\u0026lt;\u0026gt;(subSubSet); 13 clonedSubSubset.add(element); 14 newSubsets.add(clonedSubSubset); 15 } 16 subsets.addAll(newSubsets); 17 return subsets; 18} 解法2 前面已经提到了在某个子集中，某个元素要么出现要么不出现，那么这个就能够想到二进制，出现用1表示，不出现用0表示，那么我们可以遍历0～2n（不含）的数字，然后根据其二进制形式来构建子集。\n1public List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; powerSets(List\u0026lt;Integer\u0026gt; set) { 2 int max = Math.power(2, set.size()); 3 List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; results = new ArrayList\u0026lt;\u0026gt;(); 4 for (int i = 0; i \u0026lt; max; i++) { 5 results.add(translateBinary(i, set)); 6 } 7 return results; 8} 9 10public List\u0026lt;Integer\u0026gt; translateBinary(int num, List\u0026lt;Integer\u0026gt; set) { 11 List\u0026lt;Integer\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); 12 int index = 0; 13 while (num != 0) { 14 if (num \u0026amp; 1 == 1) { 15 result.add(set.get(index)); 16 } 17 index++; 18 num \u0026gt;\u0026gt;= 1; 19 } 20 return result; 21} ","date":"2019-08-23","img":"","permalink":"/post/cracking-coding-interview/8.4-power-set/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 8.4 Power Set"},{"categories":null,"content":"Magic Index: A magic index in an array A[0...n - 1] is defined to be an index such that A[i] = i. Given a sorted array of distinct integers, write a method to find a magic index, if one exists, in array A.\nFOLLOW UP\nWhat if the values are not distinct?\nHints: #170, #204, #240, #286, #340\n解法1 看上去就是遍历，和递归没有什么关系。\n不过也不是从头到尾都要检查，当发现a[i] \u0026gt; i的时候，就可以不用再找了。这是因为：\n 如果 a[i] \u0026gt; i，考虑到i是整数，那么a[i] \u0026gt;= i + 1。 从a是一个不重复的排序数组可知，a[i + 1] \u0026gt; a[i]，同理a[i + 1] \u0026gt;= a[i] + 1。 得到a[i + 1] \u0026gt;= i + 1 + 1 \u0026gt;= i + 2 \u0026gt; i + 1 因此，因此a[i]之后的所有数字都不可能是a[i] == i。  时间复杂度：O(n)\n解法2 比O(n)更小的复杂度是O(logn)和O(1)。提到O(logn)那么就想到二分法，考虑到解法1得到的结论：\n 当a[i] \u0026gt; i的时候就不用再往右边找了  如果a[i] \u0026lt; i能推导出什么呢？\n 考虑到i是整数，可得a[i] \u0026lt;= i - 1 因为a[i - 1] \u0026lt; a[i]，可得a[i - 1] \u0026lt;= a[i] - 1 可得a[i - 1] \u0026lt;= i - 2 因此，a[i]之前的都无法满足a[i] == i  所以当a[i] \u0026lt; i的时候就不用往左边找了，因此我们可以用二分法来找：\n1public int findMagicIndex(int[] a, int start, int end) { 2 if (start \u0026gt; end) { 3 return -1; 4 } 5 int mid = (start + end) / 2; 6 if (a[mid] == mid) { 7 return mid; 8 } 9 if (a[mid] \u0026gt; mid) { 10 // 找左边 11 return findMagicIndex(a, start, mid - 1); 12 } 13 // 找右边 14 return findMagicIndex(a, mid + 1, end); 15} 时间复杂度：O(logn)，n是数组长度\n解法3（附加题） 如果存在重复的数字，那么前面的两个推导就要修改了：\n如果a[i] \u0026gt; i即a[i] \u0026gt;= i + 1：\n 因为a[i + 1] \u0026gt;= a[i]，所以a[i + 1] \u0026gt;= i + 1 也就是说右边还有机会  如果a[i] \u0026lt; i即a[i] \u0026lt;= i - 1：\n 因为a[i - 1] \u0026lt;= a[i]，所以a[i - 1] \u0026lt;= i - 1 也就是说左边还有机会  这么看来只能是从头遍历到尾了，时间复杂度O(n)\n","date":"2019-08-23","img":"","permalink":"/post/cracking-coding-interview/8.3-magic-index/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 8.3 Magic Index"},{"categories":null,"content":"Robot in a Grid: Imagine a robot sitting on the upper left corner of grid with r rows and c columns.The robot can only move in two directions, right and down, but certain cells are \u0026ldquo;off limits\u0026rdquo; such that the robot cannot step on them. Design an algorithm to find a path for the robot from the top left to the bottom right.\nHints: #331, #360, #388\n解法1 机器人从(1, 1)开始：\n 右移，在剩下的(2, 1)~(r, c)网格里找路线 下移，在剩下的(1, 2)~(r, c)网格里找路线  然后以此类推。\nBase Condition：\n 当x == r时只能右移 当c == 1时只能下移 当遇到坏掉的cell的时候停止探索，报告失败 当遇到右下角的时候停止探索，报告成功  代码：\n1public String findPath(int row, int col) { 2 StringBulder path = new StringBuilder(); 3 boolean success = findPathInternal(1, 1, col, row, path); 4 if (success) { 5 return path.toString(); 6 } 7 return null; 8} 9 10public boolean findPathInternel(int x1, int y1, int x2, int y2, StringBuilder path) { 11 if (isOffLimit(x1, y1)) { 12 // 某个cell坏掉了 13 return false; 14 } 15 if (x1 == x2 \u0026amp;\u0026amp; y1 == y2) { 16 return true; 17 } 18 int end = path.length(); 19 boolean success = false; 20 if (x1 \u0026lt; x2) { 21 path.add(\u0026#39;R\u0026#39;); 22 success |= findPathInternal(x1 + 1, y1, x2, y2, path); 23 } 24 if (!success) { 25 path.delete(end, path.length()); 26 } 27 28 if (y1 \u0026lt; y2) { 29 path.add(\u0026#39;D\u0026#39;); 30 success |= findPathInternal(x1, y1 + 1, x2, y2, path); 31 } 32 if (!success) { 33 path.delete(end, path.length()); 34 } 35 return success; 36} ","date":"2019-08-23","img":"","permalink":"/post/cracking-coding-interview/8.2-robot-in-a-grid/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 8.2 Robot in a Grid"},{"categories":null,"content":"Triple Step: A child is running up a staircase with n steps and can hop either 1 step, 2 steps, or 3 steps at a time. Implement a method to count how many possible ways the child can run up the stairs.\nHints: #152, #178, #217, #237, #262, #359.\n解法1 如果第一次要走1个台阶，那么就只有一种走法(1)，剩余n - 1个台阶要走。\n如果第一次要走2个台阶，那么有两种走法(1)、(2)，剩余n - 2个台阶要走。\n如果第一次要走3个台阶，那么有4种走法(1,1,1)、(1,2)、(2,1)、(3)，剩余n - 4个台阶要走。\n1f(n) = f(n - 1) + f(2) * f(n - 2) + f(3) * f(n - 3) 2 = f(n - 1) + 2 * f(n - 2) + 4 * f(n - 3) 代码：\n1public int tripleStep(int n) { 2 if (n == 1 || n == 2) { 3 return n; 4 } 5 if (n == 3) { 6 return 4; 7 } 8 int count = 0; 9 if (n - 1 \u0026gt; 0) { 10 count += tripleStep(n - 1); 11 } 12 if (n - 2 \u0026gt; 0) { 13 count += 2 * tripleStep(n - 2); 14 } 15 if (n - 3 \u0026gt; 0) { 16 count += 4 * tripleStep(n - 3); 17 } 18 return count; 19} 时间复杂度：O(3n)\n解法2 解法1存在重复计算，弄一个缓存：\n1public int tripleStep(int n, int[] cache) { 2 if (n == 1 || n == 2) { 3 return n; 4 } 5 if (n == 3) { 6 return 4; 7 } 8 if (cache[n] != 0) { 9 return cache[n]; 10 } 11 int count = 0; 12 if (n - 1 \u0026gt; 0) { 13 count += tripleStep(n - 1); 14 } 15 if (n - 2 \u0026gt; 0) { 16 count += 2 * tripleStep(n - 2); 17 } 18 if (n - 3 \u0026gt; 0) { 19 count += 4 * tripleStep(n - 3); 20 } 21 cache[n] = count; 22 return count; 23} 时间复杂度：O(n)\n空间复杂度：O(n)\n","date":"2019-08-23","img":"","permalink":"/post/cracking-coding-interview/8.1-triple-step/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 8.1 Triple Step"},{"categories":null,"content":"Poison: You have 1000 bottles of soda, and exactly one is poisoned. You have 10 test strips which can be used to detect poison. A single drop of poison will turn the test strip positive permanently. You can put any number of drops on a test strip at once and you can reuse a test strip as many times as you\u0026rsquo;d like (as long as the results are negative). However, you can only run tests once per day and it takes seven days to return a result. How would you figure out the poisoned bottle in as few days as possible?\nFOLLOW UP\nWrite code to simulate your approach.\nHlnts: #146, #163, #183, #191, #205, #221, #230, #241, #249\n解法1 把1000个样本分成10组，每组100个，分别在10根试纸上测试\n 7天后：知道某组里有毒，试纸剩9根 样本100个，分10组，每组11个，最后一组1个 7天后，知道某组里有毒，试纸剩8根 样本11个，分9组，每组1个，最后一组2个 7天后，知道某组里有毒，试纸剩余7根 样本2个，分2组，每组1个 7天后，确定哪个有毒  最差情况28天。\n解法2 如果你有7个样本，一个试纸，那你怎么最快知道哪个样本有毒？\n你可以第1天滴样本1，第2天滴样本2，第3天滴样本3，……，因为已知7天后试纸会发生反应，那么如果第7天发生反应就意味着样本1有毒，第8天发生反应意味着样本2有毒，第13天发生反应意味着样本7有毒。所以最慢第13天就能测出来。\n也就是说1根试纸可以当7根用，那么10根试纸可以当70根用，那么把1000个样本分为70组，每组15个样本，然后同时测，最慢13天之后能够知道哪15个样本有毒。\n此时试纸还剩9根，我们可以取8根，每根第一天点1滴，第二天点1滴。比如这样负责：\n 1号试纸负责样本1、2 2号试纸负责样本3、4 3号试纸负责样本5、6 8号试纸负责样本15  那么最慢8天之后能够知道哪个样本有毒。\n这样就是最差情况13 + 8 = 21天可以测完全部1000个样本。\n不过这个结果还可以优化的，比如第一轮测试1根试纸当4根用，那么最慢10天就能知道哪25个样本有问题。然后第二轮每根试纸当3根用，那么最慢9天就能知道那个样本有问题，最慢19天可以测完。\n解法3(最优) 如果把10根试纸看作10个bit，那么它一共能代表210=1024个数字，因此可以hold住1000个瓶子。\n把1000个瓶子从1～1000编号，然后将其编号的二进制数字对应的1 bit滴到10根试纸里。\n最后看哪3个bit是1，然后就能知道是哪个瓶子有问题了。\n所以只要7天就能知道结果。\n","date":"2019-08-22","img":"","permalink":"/post/cracking-coding-interview/6.10-poison/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 6.10 Poison"},{"categories":null,"content":"100 Lockers: There are 100 closed lockers in a hallway. A man begins by opening all 100 lockers.Next, he closes every second locker. Then, on his third pass, he toggles every third locker (closes it if it is open or opens it if it is closed). This process continues for 100 passes, such that on each pass i, the man toggles every ith locker. After his 100th pass in the hallway, in which he toggles only locker #100, how many lockers are open?\nHints: #139, #172, #264, #306\n解法 换个思路想这个问题：\n 所有锁一开始都是closed状态 编号X的锁会被toggle奇数次还是偶数次？如果是奇数次那么最后就是opened，偶数次那么回归closed  编号X的锁会被toggle几次取决于它有几个能够整除它的因子，这些因子 1 \u0026lt;= 因子 \u0026lt;= X。\n如果X可以被a整除：b = X / a，那么a和b都是X的因子。那么是否意味着X的因子数肯定是偶数呢？\n不是的，比如4的因子是：1、2、4，9的因子是：1、3、9，16的因子是1、2、4、8、16。\n其实也就是说如果a == b，那么X的因子数就是奇数个。什么时候a == b？X能够被完整开根号的时候。\n在1到100里，能够被正好开根号的数字有1 * 1、2 * 2、3 * 3、。。。、10 * 10，一共10个。所以最终会有10个锁会是opened状态。\n","date":"2019-08-22","img":"","permalink":"/post/cracking-coding-interview/6.9-100-lockers/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 6.9 100 Lockers"},{"categories":null,"content":"The Egg Drop Problem: There is a building of 100 floors. If an egg drops from the Nth floor or above, it will break. If it\u0026rsquo;s dropped from any floor below, it will not break. You\u0026rsquo;re given two eggs. Find N, while minimizing the number of drops for the worst case.\nHints: #156, #233, #294, #333, #357, #374, #395\n解法1（错误） 有个楼一共有100层，已知当鸡蛋在\u0026gt;= N层往下丢的时候鸡蛋会破，在 \u0026lt; N层往下丢丢时候鸡蛋不会破。现在给你2鸡蛋，求最少丢几次能够知道这个N是几。\n因为有100层，因此每一层的概率都是相同的：0.01\n   f层 N \u0026lt;= f的概率     1 0.01   2 0.02   3 0.03   \u0026hellip;    50 0.50   51 0.51   \u0026hellip;    99 0.99   100 1    也就是N在[1, 50]的概率是0.5，在[51, 100]的概率也是0.5，我们可以参考二分查找的办法来做：\n所以我们要在(1 + 100) / 2 = 50层丢\n  如果破了，那么我们得从1层开始丢，直到丢破了为止。\n  如果没破\n 那么我们得在(51 + 100) / 2= 75层丢 如果破了就从51层开始丢，知道丢破为止。 如果没破  就在(76 + 100) / 2 = 88层丢 如果破了，则从76层开始丢，直到丢破为止。 如果没破：。。。      1public int findFloor(int start, int end) { 2 int mid = (start + end) / 2; 3 boolean broken = drop(mid); 4 if (broken) { 5 // 鸡蛋破了，则从start开始一层一层找 6 return findFloorOneByOne(start); 7 } 8 // 鸡蛋没破，在下一个区间找 9 return findFloor(mid + 1, end); 10} 11 12// 暴力一层一层往上找 13public int findFloorOneByOne(int start) { 14 int i = start; 15 while (!drop(i)) { 16 i++; 17 } 18 return i; 19} 这个解法最坏情况下要丢几次呢？50次。\n解法2（错误） 如果我们把东西分成长度为10的若干段，那么我们这么找：\n11...10...20...30...40...50...60...70...80...90...100  在10层丢，如果破了，在1～9层丢，总共丢10次 在20层丢，如果破了，在11～19层丢，总共丢11次 在30层丢，如果破了，在21～29层丢，总共丢12次 。。。 在90层丢，如果破了，在81～89层丢，总共丢18次 最后[91, 100]区间里不需要丢10次，我们手里还有两个蛋，可以再分割成小区间，因此肯定少于10次。  所以最坏情况下丢18次。\n公式是：f(n) = (100/n - 1) + (n - 1) = n + 100/n - 2\nf(n)是最坏情况丢的次数，(100/n - 1)是最多丢多少次确定区间，(n - 1)是在区间内最多丢多少次确定楼层，n是区间大小。\n后面解不出来了。\n解法2（正确） 上面的最坏情况是随着丢的次数增加而增加的，可以表现为 丢egg1的次数 + 丢egg2的次数。因为采取的是固定宽度，因此丢egg2的次数是固定的，而丢egg1的次数又是递增的，因此总体丢的次数是递增的。\n想一个办法弄让总丢次数恒定。比如当多丢一次egg1时，能够少丢一次egg2。\n如果我们把楼层间隔设置为X，那么就意味着：\n egg1丢一次，如果破了，egg2丢X - 1次。如果没破看下面： egg1再丢一次，如果破了，egg2丢X - 2次。如果没破看下面： egg1再丢一次，如果破了，egg2丢X - 3次。如果没破看下面：  那么就是说，egg1从X层开始丢、加X-1层、加X - 2层，直到丢到100层。\n1X + (X - 1) + (x - 2) + ... + 1 = 100 2 X(X + 1) / 2 = 100 3 X = 13.65 因为X取整数，可以是14或者13，看选哪一个。\n如果是14，那么是14 + 13 + 12 + 11 + ... + 4=99，看最后一个4，这里一共是11次丢egg1，在加上4-1次丢egg2，总共丢14次。如果答案是100层，那么丢12次就行了。\n如果是13，那么是13 + 12 + 11 + 10 + ... + 1 = 91，如果答案是100，那么要丢13次egg1再加9次egg2，总共丢22次。\n所以X是14，所以总丢次数是14次。\n","date":"2019-08-22","img":"","permalink":"/post/cracking-coding-interview/6.8-the-egg-drop-problem/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 6.8 the Egg Drop Problem"},{"categories":null,"content":"The Apocalypse: In the new post-apocalyptic world, the world queen is desperately concerned about the birth rate. Therefore, she decrees that all families should ensure that they have one girl or else they face massive fines. If all families abide by this policy-that is, they have continue to have children until they have one girl, at which point they immediately stop-what will the gender ratio of the new generation be? (Assume that the odds of someone having a boy or a girl on any given pregnancy is equal.) Solve this out logically and then write a computer simulation of it.\nHints: #154, #160, #171, #188, #201\n解法1 国家命令老百姓生孩子，而且一定要生一个女孩。现在已知生男生女的概率相同，都是50%，那么老百姓一直生，直到生到女孩为止，此时的男女比例是多少（排除掉父母计算）。\n用B代表男孩，G代表女孩，P(B\u0026hellip;G)代表某种生法的概率：\nP(G) = 1/2（每个家庭必定有一个女孩，所以不存在P(B)）\nP(BG) = 1/22，第一个生男的概率是0.5，第二个生女的概率是0.5\nP(BBG) = 1/23\n整理一个表格：\n   男孩数量 概率 男孩数量 * 概率     0 1/21 0   1 1/22 1/22   2 1/23 2/23   3 1/24 3/24   4 1/25 4/25   5 1/26 5/26   6 1/27 6/27    那么平均下来每个家庭有几个男孩呢？把上面Sum（男孩数量 * 概率）：\n1 1 2 3 4 5 6 2-—- + -—- + -—- + -—- + -—- + -—- 3 4 8 16 32 64 128 把分母都变成128然后计算：\n1 32 32 24 16 10 6 120 2-—- + -—- + -—- + -—- + -—- + -—- = --- 3128 128 128 128 128 128 128 接近1，所以平均下来每个家庭有1个男孩，那么因为已知每个家庭有1个女孩，那么男女比例接近1:1。男的1是到不了的，只能无限接近。\n代码：\n1// n: 家庭数量 2public double genderRatio(int n) { 3 int boys = 0; 4 int girls = 0; 5 for (int i = 0; i \u0026lt; n; i++) { 6 int genders = birth(); 7 boys += genders[0]; 8 girls += genders[1]; 9 } 10 return boys / (double) girls; 11} 12 13public int[] birth() { 14 int boys = 0; 15 int girls = 0; 16 Random random = new Random(); 17 while (girls == 0) { 18 if (random.nextBoolean()) { 19 girls++; 20 } else { 21 boys++; 22 } 23 } 24 return new int[] {boys, girls}; 25} ","date":"2019-08-22","img":"","permalink":"/post/cracking-coding-interview/6.7-the-apocalypse/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 6.7 the Apocalypse"},{"categories":null,"content":"Blue-Eyed Island: A bunch of people are living on an island, when a visitor comes with a strange order: all blue-eyed people must leave the island as soon as possible. There will be a flight out at 8:00 pm every evening. Each person can see everyone else\u0026rsquo;s eye color, but they do not know their own (nor is anyone allowed to tell them). Additionally, they do not know how many people have blue eyes, although they do know that at least one person does. How many days will it take the blue-eyed people to leave?\nHints: #218, #282, #341, #370\n解法 这道题的意思是，岛上有一群人，其中有些人是蓝眼睛，现在有一个命令说所有蓝眼睛的都必须离开小岛。现在的情况是：\n 岛上蓝眼睛人数 \u0026gt;= 1 每个人知道其他人是不是蓝眼睛 每个人不知道自己是不是蓝眼睛 每天有一班飞机离开小岛  问多少天之后所有蓝眼睛的会离开小岛？\n问题的关键是，蓝眼睛的人何时会知道自己是蓝眼睛的（没有人会告诉他）？\n下面方便起见把蓝眼睛简称为B，白眼睛简称为W。下面举几个例子来说明：\n如果岛上只有一个蓝眼睛 B1脑中：看到其他人都是W，因为知道岛上至少有一个B，那么B1就知道自己是B。\nW脑中：B1可以走了。\n结果：B1走了\n因此：\nf(1) = 1\n如果岛上有两个蓝眼睛 B1、B2视角：看到1个B\nW视角：看到2个B\nDay 1：\nB1、B2脑中：因为f(1) = 1，所以他应该在Day 1走\nW脑中：你们走吧\n结果：没人走\nDay 2：\nB1、B2脑中：Day 1没人走，那说明这里还有一个B，但是其他人都是W，那么说明自己也是B\nW脑中：。。。。。。\n结果：B1、B2走了\n因此：\nf(2) = 2\n如果岛上有3个蓝眼睛 B1视角：看到2个B\nB2视角：看到2个B\nB3视角：看到2个B\nW视角：看到3个B\nDay 1：\nB1、B2、B3脑中：因为f(2) = 2，所以他应该在Day 2走，我先观察两天再说\nW脑中：。。。。。。\n结果：没人走\nDay 2：\nB1、B2、B3脑中：那两个B今天应该走了\nW脑中：。。。。。。\n结果：没人走\nDay 3：\nB1、B2、B3脑中：说明还有一个B，那个B就是自己\nW脑中：。。。。。。\n结果：B1、B2、B3都走了\n因此：\nf(3) = 3\n总结  任何人看到其他人是B的时候，首先不会认为自己是蓝眼睛。 但是当这个人发现B没有离开小岛的时候，他就会知道B不止一个，而这个人就是自己。 没有B会提前离开，要走都是一起走的，因为它们是同时意识到自己是B的。  所以 f(b) = b （b=蓝眼睛数量）\n","date":"2019-08-21","img":"","permalink":"/post/cracking-coding-interview/6.6-blue-eyed-island/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 6.6 Blue-Eyed Island"},{"categories":null,"content":"Ants on a Triangle: There are three ants on different vertices of a triangle. What is the probability of collision (between any two or all of them) if they start walking on the sides of the triangle? Assume that each ant randomly picks a direction, with either direction being equally likely to be chosen, and that they walk at the same speed.\nSimilarly, find the probability of collision with n ants on an n-vertex polygon.\nHints:#157, #195, #296\n解法 因为所有蚂蚁的速度都是一样的，因此不存在快的追上慢的的情况。\n什么时候不会撞车？就是大家方向都一致的时候\n所以P(撞车) = 1 - P(方向一致)。\n方向一致的情况有两种都向左和都向右，因此P(反向一致) = P(都向左) + P(都向右)。\n而向左或向右的概率都是0.5，因此 P(撞车) = 1 - 0.53 - 0.53 = 0.75\n所以如果有n个蚂蚁，那么P(撞车) = 1 - 2 * 0.5n = 1 - 0.5n - 1（因为0.5 = 1/2）\n","date":"2019-08-21","img":"","permalink":"/post/cracking-coding-interview/6.4-ants-on-a-triangle/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 6.4 Ants on a Triangle"},{"categories":null,"content":"Jugs of Water: You have a 5-quart jug, a 3-quart jug, and an unlimited supply of water (but no measuring cups). How would you come up with exactly 4 quarts of water? Note that the jugs are oddly shaped,such that filling up exactly \u0026ldquo;half\u0026rdquo; of the jug would be impossible.\nHints :#149, #379, #400\n翻译：five-quart jug，五夸脱的水罐。\n解法 一个5单位的罐子，一个3单位的罐子，无限的水，让你弄出4单位的水。\nJ3(x)代表3升桶里有x升水，J5(x)代表5升桶里有x升水\n 把3升桶罐满：J3(3)，J5(0) 倒进5升桶里：J3(0)，J5(3) 把3升桶罐满：J3(3)，J5(3) 倒进5升桶里，3升桶里剩余1升：J3(1)，J5(5) 把5升桶倒掉：J3(1)，J5(0) 把3升桶里的水倒进5升桶里：J3(0)，J5(1) 把3升桶罐满：J3(3)，J5(1) 倒进5升桶里：J3(0)，J5(4)  另一个办法：\n 把5升桶罐满：J5(5)，J3(0) 倒进3升桶里：J5(2)，J3(3) 倒掉3升桶：J5(2)，J3(0) 5升桶倒进3升桶里：J5(0)，J3(2) 把5升桶罐满：J5(5)，J3(2) 5升桶倒进3升桶里：J5(4)，J3(3) 3升桶倒掉：J5(4)，J3(0) ","date":"2019-08-21","img":"","permalink":"/post/cracking-coding-interview/6.5-jugs-of-water/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 6.5 Jugs of Water"},{"categories":null,"content":"Dominos: There is an 8x8 chessboard in which two diagonally opposite corners have been cut off.You are given 31 dominos, and a single domino can cover exactly two squares. Can you use the 31 dominos to cover the entire board? Prove your answer (by providing an example or showing why it\u0026rsquo;s impossible).\nHints: #367, #397\n解法1（不好） 意思是一个8x8的棋盘，选任意一条对角线，把这个对角线两端的方块扣掉，那么剩下的格子就有64 - 2 = 62个。现在有31个骨牌，每个骨牌是1x2，问是否能够用这些骨牌把整个棋盘填满（骨牌不重叠）。实际上是不能的，你要证明。\n注意扣掉的两个格子形成了4条边都是奇数个格子。\n如果我们线不铺4条边，而是先把中间的铺了（6x6），那么最终留下的格子数是26个，也就是最外侧有26个格子。按照上左下右的顺序排列，上边7个，左边6个，下边7个，右边6个。\n可以看到无论怎样都有奇数个格子，因此无法在不重叠骨牌的情况下排满。\n解法2 如果这样描述这个棋盘，第一行7个，第二行8个，第三行8个，。。。，第8行7个。\n我们从第一行来放骨牌，你会发现会有一个骨牌串到第二行去，然后在第二行放骨牌回发现有一个骨牌会串到下一行去。然后总是有一个骨牌串到下一行，所以放不了。\n解法3 把棋盘用间隔地涂上黑白，得到然后再扣掉两个格子：\n会发现原本是32个黑格子，32个白格子，扣掉之后就变成30个黑格子、32个白格子（或者32个黑格子、30个白格子）。一个骨牌必定会占用一个黑格子一个白格子，你有31个骨牌就意味着会占据31个黑格子和31个白格子。所以你没法占满整个格子。\n","date":"2019-08-21","img":"","permalink":"/post/cracking-coding-interview/6.3-dominos/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 6.3 Dominos"},{"categories":null,"content":"Basketball: You have a basketball hoop and someone says that you can play one of two games.\n Game 1: You get one shot to make the hoop. 投篮一次即中。 Game 2: You get three shots and you have to make two of three shots. 投三次中两次。  If p is the probability of making a particular shot, for which values of p should you pick one game or the other?\nHints:#181, #239, #284, #323\n备注：basketball hoop的意思是篮筐。\n解法 Game 1的成功率是p。\nGame 2的成功率 = P(3投2中) + P(3投3中)，P代表概率\nP(3投3中) = p3\nP(3投2中) = P(hit, hit, miss) + P(hit, miss, hit) + P(miss, hit, hit)\n​ = p * p * (1 - p) + p * (1 - p) * p + (1 - p) * p * p\n​ = 3p2 - 3p3\nGame 2的成功率 = 3p2 - 2p3\n当Game 1的成功率 \u0026gt; Game 2的成功率的时候，可以选择Game 1，反之则选择Game 2。\np \u0026gt; 3p2 - 2p3\n1 \u0026gt; 3p - 2p2\n3p - 2p2 \u0026lt; 1\n3p - 2p2 - 1 \u0026lt; 0\n2p2 - 3p + 1 \u0026gt; 0\n(2p - 1) * (p - 1) \u0026gt; 0\n如果要不等式成立，那么必须左右两边都是正数或负数，因为 p \u0026lt; 1，所以 p - 1 肯定 \u0026lt; 0，因此就变成了 2p - 1 \u0026lt; 0，得到 p \u0026lt; 0.5，也就是当 p \u0026lt; 0.5的时候，选择Game 1，否则选择Game 2。\n感想：\n这道题是看答案得到的，关键点有两个：\n 计算连续hit的概率是p的n次方（n=连续的次数） 要把3投2中的各种情况都计算进去 ","date":"2019-08-21","img":"","permalink":"/post/cracking-coding-interview/6.2-basketball/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 6.2 Basketball"},{"categories":null,"content":"The Heavy Pill: You have 20 bottles of pills. 19 bottles have 1.0 gram pills, but one has pills of weight 1.1 grams. Given a scale that provides an exact measurement, how would you find the heavy bottle? You can only use the scale once.\nHints: #186, #252, #319, #387\n备注：scale的意思是磅秤\n解法 1.1 比 1.0 大 0.1，所以要利用这个多出来的0.1来识别是哪个瓶子。我们给瓶子编号从1-20，然后从瓶子中拿出和编号数量一样的药片，那么总重量 = 1 + 2 + 3 + ... + j * 1.1 + ... + 18 + 19 + 20。其中 1 \u0026lt;= j \u0026lt;= 20，j就是第几个药瓶。\n我们知道如果所有药片都是1克，那么总重量 = 1 + 2 + 3 + ... + 18 + 19 + 20 = 210，两者相减得到的就是多出来的 j * 0.1 克。那么只需将结果除以0.1就能得到j，即第几个药瓶。\n","date":"2019-08-21","img":"","permalink":"/post/cracking-coding-interview/6.1-the-heavy-pill/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 6.1 the Heavy Pill"},{"categories":null,"content":"Draw Line: A monochrome screen is stored as a single array of bytes, allowing eight consecutive pixels to be stored in one byte. The screen has width w, where w is divisible by 8 (that is, no byte will be split across rows). The height of the screen, of course, can be derived from the length of the array and the width. Implement a function that draws a horizontal line from (x1, y) to (x2, y).\nThe method signature should look something like:\n1drawline(byte[] screen, int width, int xl, int x2, int y) Hints: #366, #381, #384, #391\n解法 byte[] screen是一个一维数组，里面存放的是一个byte，byte中的1bit代表一个像素点。里面存的是：\n1| byte | byte | byte | byte | 2[00100110,11100000,10100000,00001001, ...] width是8的倍数，单位是bit，height = screen * / width。\n所谓画一条线就是把这条线上的像素点代表的bit设为1。注意这道题目中的画的是水平线，不是斜线，所以比较简单。\n先把byte [] screen变成下面这种形式看看：\n1|\u0026lt;- width -\u0026gt;| 2 00000000 00000000 00000000 00000000 3 00000000 00000000 00000000 00000000 4 (x1, y) (x2, y) 5 v v 6 00000000 00111111 11111111 11111000 7 00000000 00000000 00000000 00000000 8 00000000 00000000 00000000 00000000 9 00000000 00000000 00000000 00000000 给定一个坐标让你求是第几个bit（从左往右数的，从0开始的）：\n1int allBitIndex = (y - 1) * width + x 求位于第几个byte：\n1int byteIndex = allBitIndex / 8 求位于这个byte里的第几个bit：\n1int byteBitIndex = allBitIndex % 8 代码：\n1public void drawline(byte[] screen, int width, int xl, int x2, int y) { 2 Coord c1 = getCoord(width, x1, y); 3 Coord c2 = getCoord(width, x2, y); 4 byte allOne = (byte) (~0); 5 6 // 把x1, x2（不含）之间字节的都设1 7 for (int i = c1.byteIdx + 1; i \u0026lt; c2.byteIdx; i++) { 8 screen[c1.byteIdx] = allOne; 9 } 10 if (c1.byteIdx != c2.byteIdx) { // 两个像素在同一个byte里 11 // 把c1.bitIdx后面（含）都设1 12 screen[c1.byteIdx] |= allOne \u0026gt;\u0026gt; c1.bitIdx; 13 // 把c2.bitIdx前面（含）都设1 14 screen[c2.byteIdx] |= allOne \u0026lt;\u0026lt; (8 - c2.bitIdx - 1); 15 } else { 16 screen[c1.byteIdx] |= (allOne \u0026gt;\u0026gt; c1.bitIdx) \u0026amp; (allOne \u0026lt;\u0026lt; (8 - c2.bitIdx - 1)); 17 } 18} 19 20private Coord getCoord(int width, int x, int y) { 21 int allBitIdx = (y - 1) * width + x; 22 int byteIdx = allBitIdx / 8; // 也可以是 allBitIdx \u0026gt;\u0026gt; 3 23 int bitIdx = allBitIdx % 8; // 也可以是 allBitIdx \u0026amp; 7 ( 0..0 111) 24 return new Coord(byteIdx, bitIdx); 25} ","date":"2019-08-20","img":"","permalink":"/post/cracking-coding-interview/5.8-draw-line/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 5.8 Draw Line"},{"categories":null,"content":"Pairwise Swap: Write a program to swap odd and even bits in an integer with as few instructions as possible (e.g., bit 0 and bit 1 are swapped, bit 2 and bit 3 are swapped, and so on).\nHints:#145, #248, #328, #355\n解法1 意思是把所有奇数位的和偶数位的交换。\n先举几个例子：\n1bit: 3 2 1 0 | 3 2 1 0 | 3 2 1 0 | 3 2 1 0 2 --------|---------|---------|-------- 3num: 0 0 0 1 | 0 0 1 1 | 1 0 1 0 | 0 1 1 0 4swap: 0 0 1 0 | 0 0 1 1 | 0 1 0 1 | 1 0 0 1 如果我们两个bit两个bit看会发现：\n1before swap | after swap | operation 2------------|------------|---------- 3 0 0 | 0 0 | 什么都不做 4 0 1 | 1 0 | 取反 5 1 0 | 0 1 | 取反 6 1 1 | 1 1 | 什么都不做 过程：\n1n: 10 10 00 2mask: 00 11 00 3n \u0026amp; mask: 00 10 00 // tmp 4~tmp: 11 01 11 5tmp \u0026amp; mask: 00 01 00 // a: swapped bits 6n \u0026amp; ~mask: 10 00 00 // b 7a | b: 10 01 00 8 代码：\n1public int pairSwap(int n) { 2 int c = n; 3 int mask = 3; // bit: 0000 ... 0011 4 while (mask != 0) { 5 int tmp = c \u0026amp; mask; 6 if (tmp != 0 \u0026amp;\u0026amp; tmp != mask) { 7 int sbits = ~tmp \u0026amp; mask; // swap bits 8 c \u0026amp;= ~mask; // clear bits 9 c |= sbits; // put swap bits back 10 } 11 mask \u0026lt;\u0026lt;= 2; 12 } 13 return c; 14} 解法2  把所有偶数位的bit挑出来，向右位移1 把所有奇数位的bit挑出来，向左位移1 让后把两者OR  1num: 11 10 01 10 2mask1: 10 10 10 10 3num \u0026amp; mask1: 10 10 00 10 // a 把偶数bit挑出来 4a \u0026gt;\u0026gt; 1 : 01 01 00 01 // a 5 6num: 11 10 01 10 7mask2: 01 01 01 01 8num \u0026amp; mask2: 01 00 01 00 // b 把奇数bit挑出来 9b \u0026lt;\u0026lt; 1 : 10 00 10 00 // b 10 11a : 01 01 00 01 12b : 10 00 10 00 13a | b : 11 01 10 01 14num: 11 10 01 10 代码：\n1public int pairSwap(int n) { 2 int maskEven = 0xaaaaaaaa; 3 int maskOdd = 0x55555555; 4 int a = (n \u0026amp; maskEven) \u0026gt;\u0026gt;\u0026gt; 1; 5 int b = (n \u0026amp; maskOdd) \u0026lt;\u0026lt; 1; 6 return a | b; 7} ","date":"2019-08-20","img":"","permalink":"/post/cracking-coding-interview/5.7-pairwise-swap/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 5.7 Pairwise Swap"},{"categories":null,"content":"Conversion: Write a function to determine the number of bits you would need to flip to convert integer A to integer B.\nEXAMPLE\n1Input: 29 (or: 11101), 15 (or: 01111) 2Output: 2 Hints: #336, #369\n解法1 这个题可以用XOR来做，因为XOR的意思是相异为真，然后再数一下有多少个1。\n1public int converstion(int a, int b) { 2 int xor = a ^ b; 3 int count = 0; 4 while (xor != 0) { 5 if (xor \u0026amp; 1 == 1) { 6 count++; 7 } 8 xor \u0026gt;\u0026gt;\u0026gt;= 1; 9 } 10 return count; 11} 解法2 解法1用位移来计算有多少个1，还可以有更简便的方法。\n如果我们可以每次迭代都可以清除一个数字最右边的1，那么我们只需要计算吧这个数字清零为止共做了几次循环即可。\n用n \u0026amp; (n - 1)可以做到这一点，回顾5.5 - Debugger 里对于减法的描述：\n 当你在给二进制做减法的时候，实际上是把最右边的1变成0，把它右边的0都变成1。\n 实际上就是：\n1 rightmost 1 2 v 3n: xxxx100 4n - 1: xxxx011 5AND: xxxx000 两者AND一下就把最右边的1给去除了。\n代码：\n1public int conversion(int a, int b) { 2 int xor = a ^ b; 3 int count; 4 while (xor != 0) { 5 count++; 6 xor \u0026amp;= xor - 1; 7 } 8 return count; 9} ","date":"2019-08-20","img":"","permalink":"/post/cracking-coding-interview/5.6-conversion/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 5.6 Conversion"},{"categories":null,"content":"Debugger: Explain what the following code does: ((n \u0026amp; (n - 1)) == 0).\nHints: #157, #202, #261, #302, #346, #372, #383, #398\n解法 当以下情况时这段代码返回true：\n n是2的次方，且n \u0026gt; 1的时候 或者，n是0  两个数字AND结果为0代表两个数字没有一个1在相同的位置。\n当你在给二进制做减法的时候，实际上是把最右边的1变成0，把它右边的0都变成1。\n1 rightmost 1 2 v 3n: xxxx100 4n - 1: xxxx011 当(n \u0026amp; (n - 1)) == 0就意味着这个n里最右边的1的左边没有1了，也就是说只有一个1，这就意味着n是2的次方。\n","date":"2019-08-19","img":"","permalink":"/post/cracking-coding-interview/5.5-debugger/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 5.5 Debugger"},{"categories":null,"content":"Flip Bit to Win: You have an integer and you can flip exactly one bit from a 0 to a 1. Write code to find the length of the longest sequence of ls you could create.\nEXAMPLE\n1Input: 11001101111 2 ^ 3Output: 7 Hints: #159, #226, #314,#352\n解法1 暴力解法：\n 从右到左找0在哪个位置 记住这个位置，在数字中数连续1的数量  1public int flipToWin(int num) { 2 int zeroIndex = zeroIndex(num, 0); 3 int maxLength = 0; 4 while (zeroIndex != -1) { 5 int length = maxContinousOne(num, zeroIndex); 6 if (length \u0026gt; maxLength) { 7 maxLength = length; 8 } 9 zeroIndex = zeroIndex(num, zeroIndex + 1); 10 } 11 return maxLength; 12} 13 14// 找0的下标 15private int zeroIndex(int num, int start) { 16 for (int i = start; i \u0026lt; 32; i++) { 17 int bit = 1 \u0026lt;\u0026lt; i; 18 if (num \u0026amp; bit == 0) { 19 return i; 20 } 21 } 22 return -1; 23} 24 25// 返回最大连续1的长度，当碰到zeroIndex的时候，当作是1 26private int maxContinousOne(int num, int zeroIndex) { 27 int length = 0; 28 int maxLength = 0; 29 for (int i = 0; i \u0026lt; 32; i++) { 30 int bit = 1 \u0026lt;\u0026lt; i; 31 if (num \u0026amp; bit != 0) { 32 length++; 33 } else if (i == zeroIndex) { 34 length++; 35 } else { 36 // 遇到0了 37 if (length \u0026gt; maxLength) { 38 maxLength = length; 39 } 40 length = 0; 41 } 42 } 43 return maxLength; 44} 时间复杂度：O(d * b)，d代表0的数量，b代表num的比特数。\n空间复杂度：O(d)，d代表0的数量\n解法2 构建一个数组，里面记录连续0和连续1的长度，数组的构建是从低位到高位的，比如11001101111的数组是[0, 4, 1, 2, 2, 2, 21]，数组的第1个元素总是代表0的数量，后面每增加一个元素则反转代表0或1：\n1[0, 4, 1, 2, 2, 2, 21] 2 ^ ^ ^ ^ ^ ^ ^ 3 0 1111 0 11 00 11 000000000000000000000 因为第一个元素总是代表0，并且下一个元素反转为1，那么就意味着每隔两个元素就又是0。我们只需要看这个0的数量是否 == 1，如果是1则可以把左右两边的元素相加再加1（两边的1可以合并），如果 \u0026gt; 1则要么左边的加1，要么右边的加1（可以借用一个0），如果 == 0则等于右边的数，然后取最大值就行了。\n1public List\u0026lt;Integer\u0026gt; makeCount(int num) { 2 List\u0026lt;Integer\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); 3 int count = 0; 4 int seek = 0; 5 for (int i = 0; i \u0026lt; 32; i++) { 6 if (num \u0026amp; 1 == seek) { 7 count++; 8 } else { 9 result.add(count); 10 seek = num \u0026amp; 1; // 翻转为0或1 11 count = 1; 12 } 13 num = num \u0026gt;\u0026gt;\u0026gt; 1; 14 } 15 result.add(count); 16 return result; 17} 18 19public int flipToWin(int num) { 20 if (~num == 0) { 21 // 已经全都是1了 22 return 32; 23 } 24 List\u0026lt;Integer\u0026gt; result = makeCount(num); 25 int maxLength = 0; 26 for (int i = 0; i \u0026lt; result.size(); i += 2) { 27 int zeros = result.get(i); 28 int leftOnes = i \u0026gt; 0 ? result.get(i - 1) : 0; 29 int rightOnes = i \u0026lt; result.size() - 1 ? result.get(i + 1) : 0; 30 int seq = 0; 31 if (zeros == 1) { 32 seq = leftOnes + 1 + rightOnes; 33 } else if (zeros \u0026gt; 1) { 34 seq = Math.max(leftOnes + 1, rightOnes + 1); 35 } else { 36 seq = rightOnes; 37 } 38 maxLength = Math.max(maxLength, seq); 39 } 40 return maxLength; 41} 时间复杂度：makeCount=O(1)，实际上是循环了32次。flipToWin则是O(b)，b代表了数组的数量。\n空间复杂度：O(b)，b代表数组的数量。\n解法3 1public int flipToWin(int num) { 2 if (~num == 0) { 3 return 32; 4 } 5 int currentLength = 0; // 记录当前连续1的数量 6 int previousLength = 0; // 记录上一次连续1的数量 7 int maxLength = 0; 8 while (a != 0) { 9 if ((a \u0026amp; 1) == 1) { 10 // 当前是1 11 currentLength++; 12 } else { 13 // 当前是0 14 // 看下一个bit是0还是1，如果是0，那么说明可以连接，否则不能连接 15 // 两段连续1可以连接时，previousLength和currentLength都不为0 16 previousLength = (a \u0026amp; 2) == 0 ? 0 : currentLength; 17 currentLength = 0; 18 } 19 maxLength = Math.max(previousLength + currentLength + 1, maxLength); 20 a \u0026gt;\u0026gt;\u0026gt;= 1; 21 } 22} 时间复杂度：O(b)\n空间复杂度：O(1)\n","date":"2019-08-19","img":"","permalink":"/post/cracking-coding-interview/5.3-flip-bit-to-win/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 5.3 Flip Bit to Win"},{"categories":null,"content":"Next Number: Given a positive integer, print the next smallest and the previous largest number that have the same number of 1 bits in their binary representation.\nHints: #147, #175, #242, #312, #339, #358, #375, #390\n解法 问题是，给一个正整数，求下一个最小的和前一个最大的1的数量一样的数字。所谓的最小的和最大的都比给的数字要大。\nNext Smallest：\n1假设整数为8bit 2 v 3Input: 0 0 0 0 0 0 0 1 4Small: 0 0 0 0 0 0 1 0 5 v 6Input: 0 0 0 0 0 0 1 1 7Small: 0 0 0 0 0 1 0 1 8 v 9Input: 0 0 0 0 1 0 1 0 10Small: 0 0 0 0 1 1 0 0 11 v 12Input: 0 0 1 0 1 1 1 0 13Small: 0 0 1 1 0 0 1 1 Next Smallest的规律：\n 找到第一个0，这个非尾部0，它的位置用p表示 把这个0变成1  1index: 7 6 5 4 3 2 1 0 2num: 0 1 0 0 1 1 1 0 p = 4, c0 = 1, c1 = 3 3a: 0 0 0 1 0 0 0 0 a = 1 \u0026lt;\u0026lt; p 4n: 0 1 0 1 1 1 1 0 n = num | a  数一下p右边的1的数量c1，把p右边的都清零  1index: 7 6 5 4 3 2 1 0 2num: 0 1 0 1 1 1 1 0 p = 4 3a: 0 0 0 1 0 0 0 0 a = 1 \u0026lt;\u0026lt; p 4b: 0 0 0 0 1 1 1 1 b = a - 1 5mask: 1 1 1 1 0 0 0 0 mask = ~b 6n: 0 1 0 1 0 0 0 0 n = num \u0026amp; mask  在最右边设置c1 - 1个1  1index: 7 6 5 4 3 2 1 0 2num: 0 1 0 1 0 0 0 0 c1 = 3 3a: 0 0 0 0 0 1 0 0 a = 1 \u0026lt;\u0026lt; (c1 - 1) 4b: 0 0 0 0 0 0 1 1 b = a - 1 5n: 0 1 0 1 0 0 1 1 n = num | b 代码：\n1public int nextSmall(int num) { 2 int c0 = 0; 3 int c1 = 0; 4 int c = num; 5 while (c \u0026amp; 1 == 0 \u0026amp;\u0026amp; c != 0) { 6 c0++; 7 c = c \u0026gt;\u0026gt;\u0026gt; 1; 8 } 9 while (c \u0026amp; 1 == 1 \u0026amp;\u0026amp; c != 0) { 10 c1++; 11 c = c \u0026gt;\u0026gt;\u0026gt; 1; 12 } 13 if (c0 + c1 \u0026gt; 31 || c0 + c1 == 0) { 14 // 是负数了 15 return -1; 16 } 17 int p = c0 + c1; 18 // p位设1 19 num |= 1 \u0026lt;\u0026lt; p; 20 // 把p右边的清零 21 num \u0026amp;= ~((1 \u0026lt;\u0026lt; p) - 1); 22 // 在最右侧设置1 23 num |= 1 \u0026lt;\u0026lt; (c1 - 1) - 1; 24 return num; 25} Previous Biggest，和Next Smallest反过来做：\n 找到第一个非尾部1，它的位置是p  1index: 7 6 5 4 3 2 1 0 2num: 0 1 0 1 0 0 1 1 p = 4, c1 = 2, c0 = 2  把这里的1变成0  1index: 7 6 5 4 3 2 1 0 2num: 0 1 0 1 0 0 1 1 p = 4 3a: 0 0 0 1 0 0 0 0 a = 1 \u0026lt;\u0026lt; p 4b: 1 1 1 0 1 1 1 1 b = ~a 5n: 0 1 0 0 0 0 1 1 n = num \u0026amp; b  把p右边的都清一  1index: 7 6 5 4 3 2 1 0 2num: 0 1 0 0 0 0 1 1 p = 4 3a: 0 0 0 1 0 0 0 0 a = 1 \u0026lt;\u0026lt; p 4b: 0 0 0 0 1 1 1 1 b = a - 1 5n: 0 1 0 0 1 1 1 1 n = num | b  在最右边设置c0 - 1个0  1index: 7 6 5 4 3 2 1 0 2num: 0 1 0 0 1 1 1 1 p = 4, c0 = 2 3a: 0 0 0 0 0 0 1 0 a = 1 \u0026lt;\u0026lt; (c0 - 1) 4b: 0 0 0 0 0 0 0 1 b = a - 1 5c: 1 1 1 1 1 1 1 0 c = ~b 6n: 0 1 0 0 1 1 1 0 n = n \u0026amp; c 代码：\n1public int prevBiggest(int num) { 2 int c = num; 3 int c0 = 0; 4 int c1 = 0; 5 while (c \u0026amp; 1 == 1 \u0026amp;\u0026amp; c != 0) { 6 c1++; 7 c \u0026gt;\u0026gt;\u0026gt;= 1; 8 } 9 while (c \u0026amp; 0 == 0 \u0026amp;\u0026amp; c != 0) { 10 c0++; 11 c \u0026gt;\u0026gt;\u0026gt;= 1; 12 } 13 if (c0 + c1 \u0026gt; 31 || c0 + c1 == -1) { 14 return -1; 15 } 16 int p = c0 + c1; 17 // p位设0 18 num \u0026amp;= ~(1 \u0026lt;\u0026lt; p); 19 // p右边都设1 20 num |= (1 \u0026lt;\u0026lt; p) - 1; 21 // 从最右设c0 - 1个0 22 num \u0026amp;= ~(1 \u0026lt;\u0026lt; (c0 - 1) - 1) 23} ","date":"2019-08-19","img":"","permalink":"/post/cracking-coding-interview/5.4-next-number/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 5.4 Next Number"},{"categories":null,"content":"Binary to String: Given a real number between 0 and 1 (e.g., 0.72) that is passed in as a double, print the binary representation. If the number cannot be represented accurately in binary with at most 32 characters, print \u0026ldquo;ERROR.'\nHints: #143, #167, #173, #269, #297\n解法 这个题是看了答案才知道什么意思的。\n给你一个数字0.72，让你求它的二进制，答案是是0.1001，实际上就是把后面的72算成二进制。\n怎么算出来呢？这个问题可以这么理解，0.72的二进制有一堆01组成，但是我们不知道，我们得挨个找出来。可以这么做，看.小数点后面的第1个数字是0还是1、再看第2个数字、再看第3个数字。但是我们的二进制操作只支持整形不只支持小数点咋整？我们可以把这个数字* 2让它进到整形部分再判断：\n1num = 0.1001000 (0.72) 2num * 2 = 1.001000 结果是否\u0026gt;=1，如果是则该bit为1，否则为0。这里通过 * 2可以进位的原理和十进制通过* 10进位是一样的。比如0.72可以看成是7 * 10-1 + 2 * 10-2，而0.1001可以看成是 1 * 2-1 + 0 * 2-2 + 0 * 2-3 + 1 * 2-4 。通过 * 2可以将第一个小数位进入到整数，从而判断其是否为1。\n代码：\n1public String binToStr(double num) { 2 StringBuilder sb = new StringBuilder(); 3 sb.append(\u0026#39;.\u0026#39;); 4 while (num \u0026gt; 0) { 5 if (sb.length() \u0026gt; 32) { 6 return \u0026#34;ERROR\u0026#34;; 7 } 8 double r = num * 2; 9 if (r \u0026gt;= 1) { 10 sb.append(\u0026#39;1\u0026#39;); 11 num = r - 1; // 减掉1，在下个迭代中处理剩余的小数 12 } else { 13 sb.append(\u0026#39;0\u0026#39;); 14 num = r; 15 } 16 } 17 return sb.toString(); 18} ","date":"2019-08-19","img":"","permalink":"/post/cracking-coding-interview/5.2-binary-to-string/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 5.2 Binary to String"},{"categories":null,"content":"Insertion: You are given two 32-bit numbers, N and M, and two bit positions, i and j. Write a method to insert M into N such that M starts at bit j and ends at bit i. You can assume that the bits j through i have enough space to fit all of M. That is, if M = 10011, you can assume that there are at least 5 bits between j and i. You would not, for example, have j = 3 and i = 2, because M could not fully fit between bit 3 and bit 2.\nEXAMPLE\n1Input: N 10000000000, M = 10011, i = 2, j = 6 2Output: N = 10001001100 Hints: #137, #169, #215\n解法 这个问题其实大致分为两步：\n 把N中从i到j的bit统统设置为0 把M向左移动i个bit 两者OR一下  第一步中需要做一个Mask：\n1N: 10000000000, i=2, j=6 2Mask: 11110000011 Mask可以分为两部分做：\n1Mask1: 11110000000 2Mask2: 00000000011 3Mask : Mask1 | Mask2 4 11111000011 Mask1可以用-1 \u0026lt;\u0026lt; j + 1来得到（-1到bit都是1），Mask2可以用(1 \u0026lt;\u0026lt; i) - 1得到。\n代码：\n1public int insert(int n, int m, int i, int j) { 2 int allOnes = ~0; // 都是1 3 int mask = (allOnes \u0026lt;\u0026lt; (j + 1)) | ((1 \u0026lt;\u0026lt; i) - 1); // mask1 | mask2 4 return (n \u0026amp; mask) | (m \u0026lt;\u0026lt; i); 5} ","date":"2019-08-19","img":"","permalink":"/post/cracking-coding-interview/5.1-insertion/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 5.1 Insertion"},{"categories":null,"content":"Random Node: You are implementing a binary search tree class from scratch which, in addition to insert, find, and delete, has a method getRandomNode() which returns a random node from the tree. All nodes should be equally likely to be chosen. Design and implement an algorithm for getRandomNode, and explain how you would implement the rest of the methods.\nHints: #42, #54, #62, #75, #89, #99, #112, #119\n解法1 如果我们在一个数组里随机取一个元素，那么可以用array[random(0, array.length)]来获取。\n而现在是二叉树，那么我们可以在二叉树里额外存一个node数组来实现这个。\n但是这个数组在insert和delete下会存在额外开销：\n 如果是ArrayList，insert的时候均摊时间复杂度是O(1)（扩容的时候），delete的时候则是O(n)，因为牵涉到移动元素。 如果是LinkedList，insert的时候时间复杂度是O(1)，delete的时候则是O(n)，因为要搜索  而且占用额外的空间。\n解法2 如果我们记录整棵树的节点数量，随机从[1, TREE_SIZE]中取一个数kth，然后通过pre-order来找到kth的节点。\n1public BinaryTree { 2 private Node root; 3 4 public Node getRandomNode() { 5 if (size == 0) { 6 return null; 7 } 8 int kth = random.nextInt(1, root.size); 9 return root.getKth(kth); 10 } 11 12} 13public Node { 14 private int size = 1; 15 private int data; 16 private Node left; 17 private Node right; 18 public void insertPreOrder(int data) { 19 if (this.left == null) { 20 this.left = new Node(data); 21 } else if (this.right == null) { 22 this.right = new Node(data); 23 } 24 this.left.insertPreOrder(data); 25 size++; 26 } 27 public Node getKth(kth) { 28 if (kth == 1) { 29 return this; 30 } 31 if (node.left != null) { 32 return getKth(node.left, --kth); 33 } 34 if (node.right != null) { 35 return getKth(node.right, --kth); 36 } 37 return null; 38 } 39} 时间复杂度：O(n)，虽然kth的随机范围在[1, TREE_SIZE]之间，但是实际上还是O(n)。\n解法3 题目中提到的是BST：\n1public class Node { 2 private int size = 1; 3 private int data; 4 private Node left; 5 private Node right; 6 public Node(int data) { 7 // ... 8 } 9 public void insert(int data) { 10 if (data \u0026lt;= this.data) { 11 if (this.left == null) { 12 this.left = new Node(data); 13 } else { 14 this.left.insert(data); 15 } 16 } else { 17 if (this.right == null) { 18 this.right = new Node(data); 19 } else { 20 this.right.insert(data); 21 } 22 } 23 size++; 24 } 25 public Node find(int data) { 26 if (this.data == data) { 27 return this; 28 } 29 if (data \u0026lt; this.data) { 30 if (this.left != null) { 31 return this.left.find(data); 32 } 33 return null; 34 } 35 if (this.right != null) { 36 return this.right.find(data); 37 } 38 return null; 39 } 40} 看下面这张图：\n每个节点都记录自己+子树的节点数量，root的size就是整棵树的size，我们随机从[1, TREE_SIZE]得到一个kth，作为第k个节点，我们要返回第k个节点。可以利用中序遍历来做。\n1public class Node { 2 public Node getKth(int kth) { 3 int leftSize = this.left == null ? 0 : this.left.size; 4 if (kth \u0026lt;= leftSize) { 5 // 说明在左子树中 6 return this.left.getKth(kth); 7 } else if (kth == leftSize + 1) { 8 // 说明就是自己 9 return this; 10 } else { 11 // 跳过了左子树和自己的节点数量，然后在右子树中找 12 return this.right.getKth(kth - (leftSize + 1)); 13 } 14 } 15} ","date":"2019-08-16","img":"","permalink":"/post/cracking-coding-interview/4.11-random-node/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 4.11 Random Node"},{"categories":null,"content":"Paths with Sum: You are given a binary tree in which each node contains an integer value (which might be positive or negative). Design an algorithm to count the number of paths that sum to a given value. The path does not need to start or end at the root or a leaf, but it must go downwards (traveling only from parent nodes to child nodes).\nHints: #6, #14, #52, #68, #77, #87, #94, #103, #108, #115\n解法1 暴力解决：\n1public int countPathWithSum(Node node, int sum) { 2 if (node == null) { 3 return 0; 4 } 5 int countFromRoot = countPathWithSumFromNode(node, sum); 6 int countLeft = countPathWithSum(node.left, sum); 7 int countRight = countPathWithSum(node.right, sum); 8 return countFromRoot + countLeft + countRight; 9} 10 11private int countPathWithSumFromNode(Node node, int sum) { 12 if (node == null) { 13 return 0; 14 } 15 int count = 0; 16 if (sum == 0) { 17 count++; 18 } 19 count += countPathWithSumFromNode(node.left, sum - this.data); 20 count += countPathWithSumFromNode(node.right, sum - this.data); 21 return count; 22} 两种办法来计算时间复杂度：\n思路一，如果现在位于深度为d的节点，那么意味着前面已经走了d步（看countPathWithSumFromNode）。在一棵平衡的树里，最大深度d = logN（N=节点数），然后我们对多少个节点做了这件事情呢（看countPathWithSum），答案是N。那么就是说总的调用次数不会超过 d * N = N * logN。\n思路二：当在root的时候，我们遍历了N - 1次（看countPathWithSum里对countPathWithSumFromNode的调用），在第二层的时候，我们遍历了 N - 3 次，。。。。，所以：\n1调用次数 = (N - 1) + (N - 3) + (N - 7) + (N - 15) + ... + (N - N) 2 root 第2层 第3层 第4层 第d层 那么有几个子式子呢？在一颗平衡的树里就是深度d个，d = logN，所以\n1调用次数 = logN * N - (1 + 3 + 7 + 15 + ... + N) 后面的1、3、7、15其实就等于 21- 1、22 - 1、23 - 1、24 - 1、\u0026hellip;，忽略掉后面的-1，它们的和等于：\n2 * (2d - 1) / (2 - 1) = 2 * 2d - 2 = 2 * N - 2，见等比数列求和公式 所以：\n1调用次数 = logN * N - 2 * N + 2 2 = logN * N 相关问题 先看类似的问题：给你一个数组，里面数字有正数负数，给一个数字targetSum，让你求出有多少个子串能够累加值等于targetSum。\n1index: 0 1 2 3 4 5 6 7 8 2value: 10 -\u0026gt; 5 -\u0026gt; 1 -\u0026gt; 2 -\u0026gt; -1 -\u0026gt; -1 -\u0026gt; 7 -\u0026gt; 1 -\u0026gt; 2 3runningSum: 10 15 16 18 17 16 23 24 26 如果 targetSum = 8，我们从index=0开始逐一往后，每次都是向前看，是否有子串能够sum == 8。比如我们现在已经跑到index=8了，那么有多少个子串sum == 8 呢？我们可以把 24 - 8 =16 看前面有多少个16。你可以发现array[2] == 16、array[5] == 16 ，这意味着什么呢？这意味着 array[3 ~ 8]和array[6 ~ 8]的和等于8。你可以看看是不是这样？\n所以有了下面这个图解：\n1|\u0026lt;- runningSumY -\u0026gt;| 2|\u0026lt;- runningSumX -\u0026gt;|\u0026lt;- targetSum -\u0026gt;| 3|-----------------|---------------| 4s x y 5 6s: 起点下标 7x: y之前的某个下标 8y: 当前下标 所以这个问题就演变成为：我们找当前下标y前面的，有多少个x，能够使得[x + 1 到 y]之间的和等于targetSum。因为runningSumY和targetSum是已知的，所以就变成找有多少个runningSumX == runningSumY - targetSum。\n那么我们就可以用一个Map来记录runningSum出现的次数。\n1public int countTargetSum(int[] array, int targetSum) { 2 Map\u0026lt;Integer, Integer\u0026gt; runningSumMap = new HashMap\u0026lt;\u0026gt;(); 3 int runningSum = 0; 4 int count = 0; 5 for (int i = 0; i \u0026lt; array.length; i++) { 6 runningSum += array[i]; 7 // 增加runningSum的计数 8 increment(runningSumMap, runningSum); 9 // 如果当前runningSum就等于targetSum，那么它必定是一个合格的子串 10 if (runningSum == targetSum) { 11 count++; 12 } 13 int sum = runningSum - targetSum; 14 // 看前面的runningSumX出现了几次 15 count += runningSumMap.getOrDefault(sum, 0); 16 } 17 return count; 18} 19 20private void increment(Map\u0026lt;Integer, Integer\u0026gt; runningSumMap, int runningSum) { 21 int count = runningSumMap.getOrDefault(runningSum, 0); 22 count++; 23 runningSumMap.put(runningSum, count); 24} 解法2 从上面的这个数组的问题可以获得灵感：\n1public int countPathsWithSum(Node node, int targetSum, int runningSum, Map\u0026lt;Integer, Integer\u0026gt; runningSumMap) { 2 if (node == null) { 3 return 0; 4 } 5 int pathCount = 0; 6 runningSum += node.data; 7 if (targetSum == runningSum) { 8 pathCount++; 9 } 10 int sum = runningSum - targetSum; 11 pathCount += runningSumMap.getOrDefault(sum, 0); 12 13 increment(runningSumMap, runningSum); 14 pathCount += countPathsWithSum(node.left, targetSum, runningSum, runningSumMap); 15 pathCount += countPathsWithSum(node.right, targetSum, runningSum, runningSumMap); 16 // runningSumMap只能记录从根到当前节点的各种runningSum出现的次数 17 // 本调用返回后就回到了上一级，那么就要清除掉当前runningSum的计数 18 // 因为上一级只能看到更上级的runningSum计数 19 decrement(runningSumMap, runningSum); 20 return pathCount; 21} 22 23private void increment(Map\u0026lt;Integer, Integer\u0026gt; runningSumMap, int runningSum) { 24 int count = runningSumMap.getOrDefault(runningSum, 0); 25 count++; 26 runningSumMap.put(runningSum, count); 27} 28 29private void decrement(Map\u0026lt;Integer, Integer\u0026gt; runningSumMap, int runningSum) { 30 int count = runningSumMap.getOrDefault(runningSum); 31 count--; 32 if (count == 0) { 33 runningSumMap.remove(runningSum); 34 } else { 35 runningSumMap.put(runningSum, count); 36 } 37} 时间复杂度：O(n)\n空间复杂度：最高的空间复杂度是O(logN)，就是深度\n","date":"2019-08-16","img":"","permalink":"/post/cracking-coding-interview/4.12-paths-with-sum/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 4.12 Paths With Sum"},{"categories":null,"content":"Check Subtree: T1 and T2 are two very large binary trees, with T1 much bigger than T2. Create an algorithm to determine if T2 is a subtree of T1.\nA tree T2 is a subtree of T1 if there exists a node n in T1 such that the subtree of n is identical to T2. That is, if you cut off the tree at node n, the two trees would be identical.\nHints:#4, #11, #18, #31, #37\n解法 看这个题目意思好像是，不能说T2的root node出现在T1中就能认定T2是T1的子树。而是说两棵树看上去一模一样。\n第一个想到的如果T2是T1的子树，那么是不是说T2的遍历字符串是T1遍历字符串的子串？\n看下面这张图（图中的X代表NULL，如果没有这个的话即使遍历字符串一样也不代表两颗树就一样）：\n它的前、中、后序遍历结果是：\n1pre-order: 2 1 X X 3 X X 2in-order: X 1 X 2 X 3 X 3post-order: X X 1 X X 3 2 其中中序遍历结果不能唯一的用来标示一颗树，看下面这张图的：\n它的前、中、后序遍历结果是：\n1pre-order: 3 2 1 X X X X 2in-order: X 1 X 2 X 3 X 3post-order: X X 1 X 2 X 3 可以发现中序遍历结果是一样的，这是为什么呢？因为中序遍历一般都用在BST中，用它来得到从小到大都有序数组。中序遍历本身只表达了大小关系，并没有办法表达结构关系。\n可以使用前序、后序遍历来判断T2是否T1的子树。这里用前序：\n1public void preOrderString(Node node, StringBuilder sb) { 2 if (node == null) { 3 sb.append(\u0026#39;X\u0026#39;); 4 return; 5 } 6 sb.append(node.value + \u0026#34; \u0026#34;); 7 preOrderString(node.left, sb); 8 preOrderString(node.right, sb); 9} 10 11public boolean checkSubtree(Node t1, Node t2) { 12 StringBuilder s1 = new StringBuilder(); 13 StringBuilder s2 = new StringBuilder(); 14 preOrderString(t1, s1); 15 preOrderString(t2, s2); 16 17 return t1Order.indexOf(t2) != -1; 18} 时间复杂度：O(m + n)，m是T1节点数量，n是T2节点数量\n空间复杂度：O(m + n)\n解法2 解法1空间复杂度比较高，希望能够节省空间。\n解法2采用的方式是，在T1中找到匹配T2根的节点，然后从这个节点开始判断其子树是否和T2相等。\n1public boolean checkSubtree(Node t1, Node t2) { 2 if (t1 == null) { 3 return false; 4 } 5 if (t2 == null) { 6 // 空树肯定是子树 7 return true; 8 } 9 if (t1.data == t2.data \u0026amp;\u0026amp; matchTree(t1, t2)) { 10 return true; 11 } 12 return checkSubtree(t1.left, t2) || checkSubtree(t1.right, t2); 13} 14 15boolean matchTree(Node a, Node b) { 16 if (a == null \u0026amp;\u0026amp; b == null) { 17 return true; 18 } else if (a == null || b == null) { 19 return false; 20 } else if (a.data != b.data) { 21 return false; 22 } 23 return matchTree(a.left, b.left) \u0026amp;\u0026amp; matchTree(a.right, b.right); 24} 时间复杂度：O(m + k * n)，m是T1节点数量，n是T2节点数量，k是T1中data==T2根data的节点数量\n空间复杂度：O(1)\n如果节点里都是数字，取值范围是 [0, p]，那么T1中data==T2根data的节点数量概率是多少？答案是m/p。\n因为T2根data的概率是1/p，而T1有m个节点，那么概率就是m/p。\n假设p=10,000，m=100,000，n=100，那么时间复杂度则是 O(100,000 + 100,000 / 10,000 * 100)=O(101,000)。\n而且k * n中的n不是每次都会用足的，当在检查过程中发现节点不对的话就会中断掉的。\n最坏情况是 O(m + m * n) 也就是 T1中的每个节点都和T2根节点匹配。不过这个是不太可能的。\n补充思考：这个方法用到了递归，如果T1有大量节点，那么递归层次会很深，可以采用BFS（广度优先）的方法来做。\n","date":"2019-08-15","img":"","permalink":"/post/cracking-coding-interview/4.10-check-subtree/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 4.10 Check Subtree"},{"categories":null,"content":"BST Sequences: A binary search tree was created by traversing through an array from left to right and inserting each element. Given a binary search tree with distinct elements, print all possible arrays that could have led to this tree.\nEXAMPLE\n1Input: 2 2 3 / \\ 4 1 3 5Output: {2, 1, 3}, {2, 3, 1} Hints: #39, #48, #66, #82\n解法1 这题不是自己想出来的，具体思路看书。\n1public List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; allSequences(Node root) { 2 List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); 3 4 List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; lefts = allSequences(root.left); 5 List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; rights = allSequences(root.right); 6 7 List\u0026lt;Integer\u0026gt; prefix = new ArrayList\u0026lt;\u0026gt;(); 8 prefix.add(root.value); 9 for (List\u0026lt;Integer\u0026gt; left : lefts) { 10 for (List\u0026lt;Integer\u0026gt; right : rights) { 11 List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; weaveLists = weave(left, right, prefix); 12 for (List\u0026lt;Integer\u0026gt; weaveList : weaveLists) { 13 result.add(weaveList.clone()); 14 } 15 } 16 } 17 result; 18} 19 20public void weave(List\u0026lt;Integer\u0026gt; first, List\u0026lt;Integer\u0026gt; second, List\u0026lt;Integer\u0026gt; prefix, List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; weaved) { 21 if (first.isEmpty() || second.isEmpty()) { 22 List\u0026lt;Integer\u0026gt; result = prefix.clone(); 23 result.addAll(first); 24 result.addAll(second); 25 weaved.add(result); 26 return; 27 } 28 if (second.isEmpty()) { 29 weaved.add(prefix.addAll(first).clone()); 30 prefix.removeAll(first); 31 return; 32 } 33 34 Integer firstTmp = first.removeFist(); 35 prefix.addLast(firstTmp); 36 weave(first, second, prefix, weaved); 37 prefix.removeLast(); 38 first.addFirst(firstTmp); 39 40 Integer secondTmp = second.removeFirst(); 41 prefix.addLast(secondTmp); 42 weave(first, second, prefix, weaved); 43 prefix.removeLast(); 44 second.addFirst(secondTmp); 45 46} ","date":"2019-08-15","img":"","permalink":"/post/cracking-coding-interview/4.9-bst-sequences/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 4.9 BST Sequences"},{"categories":null,"content":"Build Order: You are given a list of projects and a list of dependencies (which is a list of pairs of projects, where the second project is dependent on the first project). All of a project\u0026rsquo;s dependencies must be built before the project is. Find a build order that will allow the projects to be built. If there is no valid build order, return an error.\nEXAMPLE\n1Input: 2projects: a, b, c, d, e, f 3dependencies: (a, d), (f, b), (b, d), (f, a), (d, c) 4Output: f, e, a, b, d, c Hints: #26, #47, #60, #85, #125, #133\n解法1（有bug） 这个题目可以认为是一张有向不循环的图，我们可以利用dependencies信息构建一个图，然后利用BFS（广度优先）的方法遍历这张图。\n这张图的合法性其实在于是否出现循环，我们可以在遍历的时候判断是否某个节点出现两次来判断。\n构建图的难点：\n 如何确定root节点 如何添加边  顺带一提，root节点不只1个，例子中f和e都是root节点\n确定root节点的方式比较简单，如果这个节点没有指向它的边，那么它就是root\n1public class Node { 2 private char project; 3 private boolean referenced; // 是否有边指向它自己 4 private List\u0026lt;Node\u0026gt; adjacents = new ArrayList\u0026lt;\u0026gt;(); 5 private boolean marked; // BFS时用 6} 7 8public class Dependency { 9 private char from; 10 private char to; 11} 12 13public char[] buildOrder(char[] projects, Dependency[] dependencies) { 14 List\u0026lt;Node\u0026gt; nodes = buildNodes(projects); 15 buildGraph(nodes, dependencies); 16 List\u0026lt;Node\u0026gt; roots = findRoots(nodes); 17 if (roots.isEmpty()) { 18 throw new IllegalException(\u0026#34;circular dependencies\u0026#34;); 19 } 20 return bfsTraverse(roots, projects.length); 21} 22 23// O(n) 24private List\u0026lt;Node\u0026gt; buildNodes(char[] projects) { 25 List\u0026lt;Node\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); 26 for (char p : projects) { 27 res.add(new Node(p)); 28 } 29 return res; 30} 31 32// O(n) 33private void buildGraph(List\u0026lt;Node\u0026gt; nodes, Dependency[] dependencies) { 34 Map\u0026lt;Char, Node\u0026gt; nodeMap = buildNodeMap(nodes); 35 for (Dependency dep : dependencies) { 36 Node from = nodeMap.get(dep.from); 37 Node to = nodeMap.get(dep.to); 38 to.referenced = true; 39 from.adjacents.add(to); 40 } 41} 42 43// O(n) 44private List\u0026lt;Node\u0026gt; findRoots(List\u0026lt;Node\u0026gt; nodes) { 45 List\u0026lt;Node\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); 46 for (Node n : nodes) { 47 if (!n.referenced) { 48 res.add(n); 49 } 50 } 51 return res; 52} 53 54// 如果每个节点指向所有其他节点，那么复杂度是O(n^2) 55// 如果图退化为链表，那么复杂度是O(n) 56private char[] bfsTraverse(List\u0026lt;Node\u0026gt; nodes, int total) { 57 List\u0026lt;Node\u0026gt; current = nodes; 58 char[] res = new char[total]; 59 int index = 0; 60 while (!current.isEmpty()) { 61 List\u0026lt;Node\u0026gt; next = new ArrayList\u0026lt;\u0026gt;(); 62 for (Node n : current) { 63 res[index++] = n.project; 64 if (n.marked) { 65 throw new IllegalException(\u0026#34;circular dependency: \u0026#34; + res); 66 } 67 n.marked = true; 68 for (Node a : node.adjacents) { 69 next.add(a); 70 } 71 } 72 current = next; 73 } 74 return res; 75} 如果遇到下面这种情况（都是从上往下的箭头），解法1存在bug：\n1 f 2 /|\\ 3 c | d 4 \\|/| 5 a | 6 |/ 7 e 正确的顺序应该是f、c、d、a、e，但是解法1采用广度优先，因此会变成f、c、a、d、e。造成这个错误的原因是没有判断某个节点的所有父节点是否都构建过了\n解法2 A -\u0026gt; B 的意思是 B 依赖 A\n 找不依赖别人的节点，先构建它们 删掉它们到下级节点对它们的依赖（因为已经构建过了，那么这个依赖可以不需要了） 在它们的下级节点里重复1、2步骤  1public class Graph { 2 private Map\u0026lt;String, Project\u0026gt; projectMap = new HashMap\u0026lt;\u0026gt;(); 3 private List\u0026lt;Project\u0026gt; nodes = new ArrayList\u0026lt;\u0026gt;(); 4 5 public void addProject(String name) { 6 if (!projectMap.containsKey(name)) { 7 Project p = new Project(name); 8 nodes.add(p); 9 nodes.put(name, p); 10 } 11 } 12 public void addEdge(Edge edge) { 13 Project from = nodes.get(edge.from); 14 Project to = nodes.get(edge.to); 15 if (from == null || to == null) { 16 throw new RuntimeException(); 17 } 18 from.addNeighbor(to); 19 } 20 public List\u0026lt;Project\u0026gt; getNodes() { ... }; 21} 22 23public class Project { 24 private Map\u0026lt;String, Project\u0026gt; projectMap = new HashMap\u0026lt;\u0026gt;(); 25 private List\u0026lt;Project\u0026gt; neighbors = new ArrayList\u0026lt;\u0026gt;(); 26 private String name; 27 private int deps = 0; // 自己依赖多少个其他项目 28 public Project(String name) { 29 this.name = name; 30 } 31 public void addNeighbor(Project p) { 32 if (!projectMap.containsKey(p.name)) { 33 projectMap.put(p.name, p); 34 neighbors.add(p); 35 p.incrementDeps(); 36 } 37 } 38 public void incrementDeps() { 39 this.deps++; 40 } 41 public void decrementDeps() { 42 this.deps--; 43 } 44 public List\u0026lt;Project\u0026gt; getNeighbors() { ... } 45} 46 47public class Edge { 48 private String from; 49 private String to; 50} 51 52public Project[] buildOrder(String[] projectNames, Edge[] edges) { 53 Graph graph = buildGraph(projectNames); 54 buildEdges(graph, edges); 55 56 Project[] order = new Project[projects.length]; 57 int end = projectOrder(order, projects, 0); 58 int index = 0; 59 while (index \u0026lt; order.length) { 60 Project current = order[index]; 61 /* We have a circular dependency since there are no remaining projects with 62* zero dependencies. */ 63 if (current == null) { 64 return null; 65 } 66 for (Project c : current.adjacents) { 67 c.decrementDeps(); 68 } 69 end = projectOrder(order, current.adjacents, end); 70 index++; 71 } 72 73 return order; 74} 75 76private int projectOrder(Project[] projectOrder, List\u0026lt;Project\u0026gt; projects, int end) { 77 for (Project p : projects) { 78 if (p.deps == 0) { 79 projectOrder[end++] = p; 80 } 81 } 82 return end; 83} 时间复杂度：O(P+D)，P是项目数，D是依赖数（在构建依赖的时候所用的循环）。\n解法3 解法2只能发现有循环依赖，无法告诉循环到底是什么。\n采用深度优先的方法（DFS）来做。\n 构建链条的是这样的：parent parent -\u0026gt; parent -\u0026gt; leaf（叶子节点，不被别人依赖的项目） 每次构建的时候都是把parent插入到child之前。 在处理这个节点前做一个标记，表示正在处理，当处理一个节点的时候发现它正在处理，那么就说明它处于一个循环中。 当发现这个节点已经处理过了，那么就跳过。  可以从任意节点开始处理，因为第4点保证了不会重复处理，第2点则保证了parent肯定在child之前。\n看这个例子（所有箭头都是从上往下）：\n1 f d 2 /|\\ | 3 c | b g 4 \\|/|\\ 5 a | h 6 |/ 7 e 比如我们先处理b：\n1DFS(b) 2 DFS(h) 3 build order = ..., h 4 DFS(a) 5 DFS(e) 6 build order = ..., e, h 7 build order = ..., a, e, h 8 build order = ..., b, a, e, h 然后我们处理f：\n1build order = ..., b, a, e, h 2DFS(f) 3 DFS(c) 4 DFS(a) skip 5 build order = ..., c, b, a, e, h 6 DFS(a) skip 7 DFS(B) skip 8 build order = ..., f, c, b, a, e, h 代码：\n1public class Project { 2 String name; 3 List\u0026lt;Project\u0026gt; adjacents = new ArrayList\u0026lt;\u0026gt;(); 4} 5 6public void buildOrder(List\u0026lt;Project\u0026gt; projects) { 7 8 LinkedList\u0026lt;Project\u0026gt; order = new LinkedList\u0026lt;\u0026gt;(); 9 for (Project p : projects) { 10 buildOrder(p, order); 11 } 12 return order; 13} 14 15private void buildOrder(Project project, LinkedList\u0026lt;Project\u0026gt; order) { 16 if (project.isVisiting) { 17 // 发现循环依赖 18 order.insertFirst(project); 19 throw new RuntimeException(\u0026#34;Cyclic depedencies: \u0026#34; + order); 20 } 21 if (project.isCompleted) { 22 // 该项目已经处理过了 23 return; 24 } 25 project.isVisiting = true; 26 for (Project c : p.adjacents) { 27 buildOrder(c, order); 28 } 29 order.insertFirst(project); 30 project.isFinished = true; 31} ","date":"2019-08-15","img":"","permalink":"/post/cracking-coding-interview/4.7-build-order/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 4.7 Build Order"},{"categories":null,"content":"First Common Ancestor: Design an algorithm and write code to find the first common ancestor of two nodes in a binary tree. Avoid storing additional nodes in a data structure. NOTE: This is not necessarily a binary search tree.\nHints: #10, #16, #28, #36, #46, #70, #80, #96\n解法1 二叉树任意两节点的第一个共同祖先，假设每个node都有一个parent指针。\n暴力的做法是：\n 从node A出发往下递归找node B，如果找到了则node A就是node B的祖先 没找到，从node A的parent出发往下滴贵找node B，如果找到了则node A的parent是node B的共同祖先 没找到，从node A的parent的parent，。。。 。。。  1public Node findAncestor(Node parent, Node b) { 2 if (parent == null) { 3 // 说明这两个不在一颗树里 4 return null; 5 } 6 if (contains(parent, b)) { 7 return parent; 8 } 9 return findAncestor(parent.parent, b); 10} 11 12// 判断这个node及其所有子孙是否含有target node。 13public boolean contains(Node node, Node target) { 14 if (node == null) { 15 return false; 16 } 17 if (node == target) { 18 return true; 19 } 20 if (node.left == target || node.right == target) { 21 return true; 22 } 23 return contains(node.left, target) || contains(node.right, target); 24} 时间复杂度：O(n^2)，试想a、b两个节点分别在一颗树的最左和最右两端。\n解法2 解法1中有一些重复计算，所以它时O(n^2)，比如下面在2这个子树没有找到的情况下，上升到1时，在从1往下找的时候不需要再到2里找一遍，而应该只找3。\n1 1 2 / \\ 3 2 3 4 / \\ 54 5 代码：\n1findAncestor(a, b, null); 2 3public Node findAncestor(Node parent, Node b, Exclusion exclusion) { 4 if (parent == null) { 5 // 说明这两个不在一颗树里 6 return null; 7 } 8 if (parent == b) { 9 return parent; 10 } 11 if (exclusion == LEFT) { 12 if (contains(parent.right, b)) { 13 return parent; 14 } 15 } else if (exclusion == RIGHT) { 16 if (contains(parent.left, b)) { 17 return parent; 18 } 19 } else { 20 if (contains(parent, b)) { 21 return parent; 22 } 23 } 24 if (parent.parent != null \u0026amp;\u0026amp; parent == parent.parent.left) { 25 return findAncestor(parent.parent, b, Exclusion.LEFT); 26 } 27 if (parent.parent != null \u0026amp;\u0026amp; parent == parent.parent.right) { 28 return findAncestor(parent.parent, b, Exclusion.RIGHT); 29 } 30 return null; 31} 32 33// 判断这个node及其所有子孙是否含有target node。 34public boolean contains(Node node, Node target) { 35 if (node == null) { 36 return false; 37 } 38 if (node == target) { 39 return true; 40 } 41 if (node.left == target || node.right == target) { 42 return true; 43 } 44 return contains(node.left, target) || contains(node.right, target); 45} 时间复杂度：O(n)\n解法3 如果可以拿到parent，那么这个问题就和2.7-intersection 有点像了：从两个节点出发，沿着parent链表一路走到底，找到第一个交叉点，这个交叉点就是共同祖先。\n解法4 在没有parent指针的情况下怎么弄？\n共同祖先有什么特性：\n1 p 2 / \\ 3 x b 4 / \\ 5 a x p是a、b的第一个共同祖先，a、b分别在p的左右两边\n1 a 2 / 3 x 4 / \\ 5 x b a就是a、b的第一个共同祖先，a、b在一边。\n所以共同祖先p有两个特性：\n a、b在p的左右两边 或者p == a || p == b  我们先从root开始，判断上面的两个特性是否成立，如果不成立，那么就下沉到左边or右边继续这个过程。\n1public Node findAncestor(Node root, Node a, Node b) { 2 if (root == a || root == b) { 3 return root; 4 } 5 boolean aLeft = contains(root.left, a); 6 boolean bLeft = contains(root.left, b); 7 if (aLeft xor bLeft) { 8 return root; 9 } 10 if (aleft \u0026amp;\u0026amp; bLeft) { 11 return findAncestor(root.left, a, b); 12 } 13 return findAncestor(root.right, a, b); 14} 15 16// 判断这个node及其所有子孙是否含有target node。 17public boolean contains(Node node, Node target) { 18 if (node == null) { 19 return false; 20 } 21 if (node == target) { 22 return true; 23 } 24 if (node.left == target || node.right == target) { 25 return true; 26 } 27 return contains(node.left, target) || contains(node.right, target); 28} ","date":"2019-08-15","img":"","permalink":"/post/cracking-coding-interview/4.8-first-common-ancestor/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 4.8 First Common Ancestor"},{"categories":null,"content":"Successor: Write an algorithm to find the \u0026ldquo;next\u0026rdquo; node (i.e., in-order successor) of a given node in a binary search tree. You may assume that each node has a link to its parent.\nHints: #79, #91\n解法1 这个题目的意思是，如果我们从一个node开始做中序遍历，那么这个节点的下一个被遍历到的节点是哪个？\n先看中序遍历是啥意思：\n1public void inOrder(Node node) { 2 inOrder(node.left); 3 visit(node); 4 inOrder(node.right); 5} 举个例子：\n1 1 2 / \\ 3 2 3 4 / \\ / \\ 54 5 6 7 6 7中序遍历的结果是：4、2、4、1、6、3、7 81的下一个节点是6 其实这个问题可以发现一个节点的中序遍历的下一个节点就是其右子树的最左边节点。\n如果这个node没有右子树，那么得找上一个节点，举个例子：\n1 1 2 / \\ 3 2 3 4 / / \\ 54 6 7 我们要找2的下一个节点，那么它的下一个节点是1，为什么？因为题目里说了一个Node可以访问parent，从1的角度来说，从它开始的中序遍历顺序是4、2、1、6、3、7，看到没有？2的后面是1。\n举几个例子来看：\n1 1 2 / \\ 3 2 3 4 / 54 6 7找4的下一个 8中序结果是：4、2、1、3 94的下一个是2 10 11 1 12 / \\ 13 2 3 14 / 15 4 16 17找4的下一个 18中序结果：2、1、4、3 194的下一个是3 20 21 1 22 / \\ 23 2 3 24 \\ 25 4 26 27找4的下一个 28中序结果是2、4、1、3 294的下一个是1 30 31 1 32 / \\ 33 2 3 34 \\ 35 4 36 37找4的下一个 38中序结果是：2、1、3、4 394的下一个是null 发现的规律是这样的，比较拗口：\n 不断从4开始找祖先 找到一个祖先是某个节点的左节点 那这个某个节点就是4的下一个节点  1public Node successor(Node node) { 2 if (node.right != null) { 3 return leftMost(node.right); 4 } 5 return nextNode(node); 6} 7 8public Node leftMost(Node node) { 9 if (node.left == null) { 10 return node; 11 } 12 return leftMost(node.left); 13} 14 15public Node nextNode(Node node) { 16 if (node.parent == null) { 17 return null; 18 } 19 if (node == node.parent.left) { 20 return node.parent; 21 } 22 return nextNode(node.parent); 23} 总结 关于这个node没有右子树找它下一个节点的办法：\n根据中序遍历的定义，遍历顺序是 left -\u0026gt; parent -\u0026gt; right，如果【当前节点n】是它parent node的左节点，那么它的下一个就是parent node。\n如果它是parent的右节点，那么parent以及left都在它之前遍历过了。那么它下一个遍历的是什么？肯定不是parent，也不会是parent的parent，也就只能是它的祖先是某个node的左节点的时候，这个node才是它的下一个遍历的node。\n","date":"2019-08-14","img":"","permalink":"/post/cracking-coding-interview/4.6-successor/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 4.6 Successor"},{"categories":null,"content":"Validate BST: Implement a function to check if a binary tree is a binary search tree.\nHints: #35, #57, #86, #113, #128\n解法1 （审题错误） 二叉查找树的规则是，node.left \u0026lt;= node \u0026lt; node.right ，注意对于相等的元素必须选一边放，这里选的是左边。\n用递归的方式判断：\n1public boolean validateBST(Node node) { 2 if (node == null) { 3 return true; 4 } 5 if (node.left != null \u0026amp;\u0026amp; node.left.value \u0026gt; node.value) { 6 return false; 7 } 8 if (node.right != null \u0026amp;\u0026amp; node.value \u0026gt;= node.right.value) { 9 return false; 10 } 11 return validateBST(node.value) \u0026amp;\u0026amp; validateBST(node.value); 12} 解法2 解法1会认为下面这种情况是OK的：\n1 5 2 / \\ 3 2 8 4 / \\ 51 9 其实准确的BST的定义是，all left nodes \u0026lt;= node \u0026lt; all right nodes。\n如果是一个BST，那么这个树的每个节点的取值范围根据层数的递增而逐渐收敛的。看下面：\n1 5 (null, null) 2 / \\ 3 3 7 (null, 5), (5, null) 4 / \\ / \\ 52 4 6 8 (null, 3), (3, 5), (5, 7), (7, null) 所以这样解（这里为了简便采取的假设没有重复元素，all left nodes \u0026lt; node \u0026lt; all right nodes ）：\n1public boolean validateBST(Node node, Integer min, Integer max) { 2 if (node == null) { 3 return true; 4 } 5 if (min != null \u0026amp;\u0026amp; !(min \u0026lt; node.value)) { 6 return false; 7 } 8 if (max != null \u0026amp;\u0026amp; !(node.value \u0026lt; max)) { 9 return false; 10 } 11 return validateBST(node.left, min, node.value) 12 \u0026amp;\u0026amp; valdateBST(node.right, node.value, max); 13} 14validateBST(root, null, null); ","date":"2019-08-14","img":"","permalink":"/post/cracking-coding-interview/4.5-validate-bst/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 4.5 Validate BST"},{"categories":null,"content":"Check Balanced: Implement a function to check if a binary tree is balanced. For the purposes of this question, a balanced tree is defined to be a tree such that the heights of the two subtrees of any node never differ by more than one.\nHints:#21, #33, #49, #105, #124\n解法1 - 深度优先（审题错误） 平衡的定义是一颗树中任意节点的两颗子树高度不的超过1。比如下面就是平衡的：\n1 1 2 / 3 2 4 5 1 6 / \\ 7 2 3 8 9 1 10 / \\ 11 2 3 12 / \\ 134 5 下面是不平衡的：\n1 1 2 / \\ 3 2 3 4 / \\ 5 4 5 6 / 76 可以看到（2）这个子树的高度是3，而（3）这个子树的高度是1，高度相差2，所以不平衡。\n首先想到的是计算左右子树高度，然后判断差是否超过1：\n1public boolean checkBalanced(Node root) { 2 int lHeight = height(root.left); 3 int rHeight = height(root.right); 4 return Math.abs(lHeight - rHeight) \u0026lt;= 1; 5} 6 7private int height(Node node) { 8 if (node == null) { 9 return 0; 10 } 11 int lHeight = height(node.left); 12 int rHeight = height(node.right); 13 return Math.max(lHeight, rHeight) + 1; 14} 解法2 - 广度优先（审题错误） 解法1是深度优先的，他会遍历到所有节点，是否可以用广度优先的算法来解。\n因为广度优先是一层一层遍历的，在遍历过程中记录第一个叶子节点的层数，并且比较当前遍历的层数的差，超过1就说明不平衡：\n1 1 2 / \\ 3 2 3 \u0026lt;- 叶子节点 4 / \\ 5 4 5 6 / 76 \u0026lt;- 当前层 这样就不需要遍历所有节点了。\n要注意以下处理这种情况：\n1 1 2 / 3 2 4 / 5 3 6 / 74 这种情况下可以认为叶子节点的层数为1。\n1public boolean checkBalanced(Node root) { 2 int firstLeafLevel = 0; 3 if (root.left == null || root.right == null) { 4 firstLeafLevel = 1; 5 } 6 int currentLevel = 1; 7 List\u0026lt;Node\u0026gt; current = new ArrayList\u0026lt;\u0026gt;(); 8 current.add(root); 9 while (!current.isEmpty()) { 10 if (currentLevel - firstLeafLevel \u0026gt; 1) { 11 return false; 12 } 13 List\u0026lt;Node\u0026gt; parent = current; 14 current = new ArrayList\u0026lt;\u0026gt;(); 15 for (Node p : parent) { 16 if (p.left != null) { 17 current.add(p.left); 18 } 19 if (p.right != null) { 20 current.add(p.right); 21 } 22 if (firstLeafLevel != 0 \u0026amp;\u0026amp; p.left == null \u0026amp;\u0026amp; p.right == null) { 23 // 第一个叶子节点的深度 24 firstLeafLevel = currentLevel; 25 } 26 } 27 if (!current.isEmpty()) { 28 current.level++; 29 } 30 } 31 return true; 32} 解法3 上面两个解法审题错误，从根节点来看左右子树高度不超过1不代表左子树的左右子树高度不超过1。所以要对每个节点都计算一下：\n1public boolean checkBalanced(Node root) { 2 int lHeight = height(root.left); 3 int rHeight = height(root.right); 4 if (Math.abs(lHeight - rHeight) \u0026lt;= 1) { 5 return true; 6 } 7 return checkBalanced(root.left) \u0026amp;\u0026amp; checkBalanced(root.right); 8} 9 10private int height(Node node) { 11 if (node == null) { 12 return 0; 13 } 14 int lHeight = height(node.left); 15 int rHeight = height(node.right); 16 return Math.max(lHeight, rHeight) + 1; 17} 解法4 但是上面牵涉到很多重复计算，那么可以在计算height的时候就同时判断是否平衡：\n1class Tmp { 2 int height; 3 boolean balanced; 4} 5public Tmp height(Node node) { 6 if (node == null) { 7 return new Tmp(0, true); 8 } 9 Tmp l = height(node.left); 10 if (!l.balanced) { 11 return false; 12 } 13 Tmp r = height(node.right); 14 if (!r.balanced) { 15 return false; 16 } 17 int h = Math.max(l.height, r.height) + 1; 18 if (Math.abs(l.height - r.height) \u0026gt; 1) { 19 return new Tmp(h, false); 20 } 21 return new Tmp(h, true); 22} 其实还可以更简单一点，用异常：\n1public int height(Node node) { 2 if (node == null) { 3 return 0; 4 } 5 int lHeight = height(node.left); 6 int rHeight = height(node.right); 7 if (Math.abs(lHeight - rHeight) \u0026gt; 1) { 8 throw new NotBalanced(); 9 } 10 return Math.max(lHeight, rHeight) + 1; 11} 或者用Integer.MIN_VALUE作为一异常值：\n1public int height(Node node) { 2 if (node == null) { 3 return 0; 4 } 5 int lHeight = height(node.left); 6 if (lHeight == Integer.MIN_VALUE) { 7 return Integer.MIN_VALUE; 8 } 9 int rHeight = height(node.right); 10 if (rHeight == Integer.MIN_VALUE) { 11 return Integer.MIN_VALUE; 12 } 13 if (Math.abs(lHeight - rHeight) \u0026gt; 1) { 14 throw Integer.MIN_VALUE; 15 } 16 return Math.max(lHeight, rHeight) + 1; 17} 18 19public boolean checkBalanced(Node root) { 20 return height(root) != Integer.MIN_VALUE; 21} ","date":"2019-08-14","img":"","permalink":"/post/cracking-coding-interview/4.4-check-balanced/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 4.4 Check Balanced"},{"categories":null,"content":"List of Depths: Given a binary tree, design an algorithm which creates a linked list of all the nodes at each depth (e.g., if you have a tree with depth D, you\u0026rsquo;ll have D linked lists).\nHints: #107, #123, #135\n解法1 DFS（深度优先）：\n1public void collectDepth(Node node, int depth, List\u0026lt;List\u0026gt; depthLists) { 2 if (node == null) { 3 return; 4 } 5 if (depthLists.size() \u0026lt; depth) { 6 depthLists.add(new List()); 7 } 8 List depthList = depthLists.get(depth - 1); 9 depthList.add(node); 10 collectDepth(node.left, depth + 1, depthLists); 11 collectDepth(node.right, depth + 1, depthLists); 12} 解法2 BFS（广度优先）：\n1public List\u0026lt;List\u0026gt; depthLists(Node root) { 2 List\u0026lt;List\u0026gt; depthLists = new ArrayList\u0026lt;\u0026gt;(); 3 Queue\u0026lt;Node\u0026gt; queue = new Queue\u0026lt;\u0026gt;(); 4 root.depth = 1; 5 queue.enqueue(root); 6 while (!queue.isEmpty()) { 7 Node node = queue.dequeue(); 8 List depthList = getOrCreateList(depthLists, node.depth); 9 depthList.add(node); 10 if (node.left != null) { 11 node.left.depth = node.depth + 1; 12 queue.enqueue(node); 13 } 14 if (node.right != null) { 15 node.right.depth = node.depth + 1; 16 queue.enqueue(node); 17 } 18 } 19} 20 21List getOrCreateList(List\u0026lt;List\u0026gt; depthLists, int depth) { 22 if (depthLists.size() \u0026lt; depth) { 23 depthLists.add(new List()); 24 } 25 return depthLists.get(depth - 1); 26} 解法3优化 BFS（广度优先）优化。在解法2中记录了depth，实际上可以不需要。\n在广度优先算法中，本身就是按层遍历的，那么第i层的元素可以从第i - 1层中获得，而每一层都是我们要保存下来，所以可以直接获得。\n1public List\u0026lt;List\u0026gt; depthLists(Node root) { 2 List\u0026lt;List\u0026gt; depthLists = new ArrayList\u0026lt;\u0026gt;(); 3 List nextLevel = new ArrayList\u0026lt;\u0026gt;(); 4 nextLevel.add(root); 5 while (!nextLevel.isEmpty()) { 6 depthLists.add(nextLevel); 7 List current = nextLevel; // current level 8 nextLevel = new List(); // prepare for next level 9 for (Node n : current) { 10 if (n.left != null) { 11 nextLevel.add(n.left); 12 } 13 if (n.right != null) { 14 nextLevel.add(n.right); 15 } 16 } 17 } 18 return depthLists; 19} ","date":"2019-08-14","img":"","permalink":"/post/cracking-coding-interview/4.3-list-of-depths/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 4.3 List of Depths"},{"categories":null,"content":"Minimal Tree: Given a sorted (increasing order) array with unique integer elements, write an algo­rithm to create a binary search tree with minimal height.\nHints: #19, #73, #116\n解法1 二叉查找树具有以下特性：\n 任意node的左边 \u0026lt;= 它 任意node的右边 \u0026gt;= 它 它不是完全二叉树，也不是满二叉树，更不是完美二叉树  具有最小高度的tree要么是完全二叉树，要么是完美二叉树。但是完美二叉树要求节点数量必须是 2^k - 1，k=层数。因为给的数组的数量未必正好，所以应该向完全二叉树靠拢。\n完全二叉树的特性是：\n 除了最后一层，其他层都是满的 最后一层要么是满的，要么从左到右填，能填多少就是多少。  比如：\n1 2 2 / \\ 31 3 4 5 3 6 / \\ 7 2 4 8 / 91 10 11 4 12 / \\ 13 2 5 14 / \\ 151 3 16 17 4 18 / \\ 19 2 6 20 / \\ / 211 3 5 22 23 4 24 / \\ 25 2 6 26 / \\ / \\ 271 3 5 7 28 29 5 30 / \\ 31 3 7 32 / \\ / \\ 33 2 4 6 8 34 / 351 但是这个太难了，很难发现构建完全二叉搜索树的规律。\n解法2 根据提示，一个最小高度的树具有这么一个特性：左边节点的数量和右边节点的数量相同。那么怎么构建呢？\n当我们构建一颗子树的时候要尽量保证左右两边都有节点，如果我们对下面这个数组构建树，从左到右的顺序：\n11 2 3 4 5 6 7 2先用2构建子树： 3 2 4 / \\ 51 3 6然后再拿4构建子树： 7 4 8 / \\ 92 6 10再拿6构建子树： 11 6 12 \\ 13 7 14组合起来就是； 15 4 16 / \\ 17 2 6 18 / \\ / \\ 19 1 3 5 7 发现规律：\n 每个子树都是从第2、4、6。。。个开始的，这是为了尽量保证左右都有节点。 根节点选哪个呢？当然应该选中间的元素作为根咯。  那么问题就可以变成：\n 选一个数组的中间元素作为根节点 对左半部分构建树，加入其左节点 对右半部分构建树，加入其右节点 左右部分的构建方法重复1-3步  所以可以看出这就是一个递归的过程：\n1// 取下标在[start, end]区间内的元素构建树 2public Node minimalTree(int[] array, int start, int end) { 3 if (start \u0026gt; end) { 4 return null; 5 } 6 int mid = (start + end) / 2; 7 Node root = new Node(array[mid]); 8 root.left = minimalTree(array, start, mid - 1); 9 root.right = minimalTree(array, mid + 1, end); 10 return root; 11} ","date":"2019-08-14","img":"","permalink":"/post/cracking-coding-interview/4.2-minimal-tree/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 4.2 Minimal Tree"},{"categories":null,"content":"Route Between Nodes: Given a directed graph, design an algorithm to find out whether there is a route between two nodes.\nHints:#127\n解法1 采用广度优先的算法来做，广度优先的话可以找到最短路径：\n1public class Graph { 2 private Node[] nodes; 3} 4public class Node { 5 private Node[] children; 6} 7 8public boolean hasRoute(Node start, Node dest) { 9 Queue\u0026lt;Node\u0026gt; nodes = new Queue\u0026lt;\u0026gt;(); 10 start.marked = true; 11 nodes.enqueue(start); 12 while (!nodes.isEmpty()) { 13 Node node = nodes.dequeue(); 14 if (node == dest) { 15 return true; 16 } 17\tfor (Node child : node.children) { 18 if (!child.marked) { 19 if (child == dest) { 20 return true; 21 } 22 chid.marked = true; 23 nodes.enqueue(child); 24 } 25 } 26 } 27 return false; 28} 解法2 虽然可以用深度优先的方法来做，但是这个得碰运气：\n1public boolean hasRoute(Node start, Node dest) { 2 if (start.visited) { 3 return false; 4 } 5 start.visited = true; 6 if (start == dest) { 7 return true; 8 } 9 for (Node n : start.children) { 10 if (hasRoute(n, dest)) { 11 return true; 12 } 13 } 14 return false; 15} ","date":"2019-08-14","img":"","permalink":"/post/cracking-coding-interview/4.1-route-between-nodes/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 4.1 Route Between Nodes"},{"categories":null,"content":"Animal Shelter: An animal shelter, which holds only dogs and cats, operates on a strictly\u0026quot;first in, first out\u0026quot; basis. People must adopt either the\u0026quot;oldest\u0026quot; (based on arrival time) of all animals at the shelter, or they can select whether they would prefer a dog or a cat (and will receive the oldest animal of that type). They cannot select which specific animal they would like. Create the data structures to maintain this system and implement operations such as enqueue, dequeueAny, dequeueDog, and dequeueCat. You may use the built-in LinkedList data structure.\nHints: #22, #56, #63\n分析 简单来说这么几个要求：\n Dog / Cat 按照插入的时间顺序排列 如果要求取Dog，则拿最早的Dog 如果要求取Cat，则拿最早的Cat 如果不要求，则拿最早的，拿到啥是啥  解法1 就弄一个链表，里面放了Dog和Cat，链表头是最旧的，链表尾是最新的。\n1public class Animal {} 2public class Dog extends Animal {} 3public class Cat extends Animal {} 4public class AnimalShelter { 5 private LinkedList\u0026lt;Animal\u0026gt; animals = new LinkedList\u0026lt;\u0026gt;(); 6 public void enqueue(Animal animal) { 7 animals.add(animal); 8 } 9 public Animal dequeueAny() { 10 return animals.removeFirst(); 11 } 12 public Dog dequeueDog() { 13 for (Iterator\u0026lt;Animal\u0026gt; iter = animals.iterator(); iter.hasNext();) { 14 Animal animal = iter.next(); 15 if (animal instanceof Dog) { 16 iter.remove(); 17 return animal; 18 } 19 } 20 return null; 21 } 22 public Cat dequeueCat() { 23 // 和上面类似 24 } 25} 时间复杂度：对于dequeueDog和dequeueCat来说复杂度是 O(n)。\n解法2 有没有办法把dequeueDog和dequeueCat的时间复杂度变成 O(1)。\n可以弄两个链表分别存储Dog和Cat，Dog和Cat里都入队时间。\n1public class Animal { 2 private long timestamp = System.currentTimeMillis(); 3} 4public class Dog extends Animal {} 5public class Cat extends Animal {} 6public class AnimalShelter { 7 private LinkedList\u0026lt;Dog\u0026gt; dogs = new LinkedList\u0026lt;\u0026gt;(); 8 private LinkedList\u0026lt;Cat\u0026gt; cats = new LinkedList\u0026lt;\u0026gt;(); 9 public void enqueue(Animal animal) { 10 if (animal instanceof Dog) { 11 dogs.add((Dog)animal); 12 } else { 13 cats.add((Cat)animal); 14 } 15 } 16 public Animal dequeueAny() { 17 if (dogs.isEmpty()) { 18 return dequeueCats(); 19 } 20 if (cats.isEmpty()) { 21 return dequeueDogs(); 22 } 23 if (dogs.first().timestamp \u0026lt; cats.first().timestamp) { 24 return dequeueDogs(); 25 } 26 return dequeueCats(); 27 } 28 public Dog dequeueDog() { 29 if (dogs.isEmpty()) { 30 return null; 31 } 32 return dogs.removeFirst(); 33 } 34 public Cat dequeueCat() { 35 if (cats.isEmpty()) { 36 return null; 37 } 38 return cats.removeFirst(); 39 } 40} ","date":"2019-08-13","img":"","permalink":"/post/cracking-coding-interview/3.6-animal-shelter/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 3.6 Animal Shelter"},{"categories":null,"content":"Sort Stack: Write a program to sort a stack such that the smallest items are on the top. You can use an additional temporary stack, but you may not copy the elements into any other data structure (such as an array). The stack supports the following operations: push, pop, peek, and isEmpty.\nHints: #15, #32, #43\n解法1 就是要把一个Stack排序，最小的元素在top，最大的元素在bottom。\n弄一个临时的Stack，保证Stack的顺序是从大到小，最后再把这个Stack压回原Stack，这样原来Stack就变成从小到大了。\n应该会牵涉到递归。\n1// 保证最小元素压到最下面，即newVal必须 \u0026gt;= top 2public void pushSort(Stack stack, int newVal) { 3 if (stack.isEmpty()) { 4 stack.push(newVal); 5 return; 6 } 7 int oldVal = stack.peek(); 8 if (newVal \u0026lt; oldVal) { 9 // 暂且把top拿掉 10 stack.pop(); 11 // 把newVal push到Stack中 12 pushSort(stack, newVal); 13 // 把top放回来 14 stack.push(oldVal); 15 return; 16 } 17 stack.push(newVal); 18} 19 20public void sortStack(Stack stack) { 21 Stack tmp = new Stack(); 22 while (!stack.isEmpty()) { 23 pushSort(tmp, stack.pop()); 24 } 25 while (!tmp.isEmpty()) { 26 stack.push(tmp.pop()); 27 } 28} 解法2 可以不用递归，比如下面S1是要排序的Stack，S2是一个保持大到小顺序的Stack，现在要把5放到S2怎么弄？\n1| S1 | S2 | 2|------|------| 3| | 12 | 4| 5 | 8 | 5| 10 | 3 | 6| 7 | 1 | 步骤这样的：\nStep 1：先把 5 pop出来；Step 2：把 12、8 pop \u0026amp; push 到S1；Step 3：把 5 push到S2。\n1 Step 1 Step 2 Step 3 2| S1 | S2 | | S1 | S2 | | S1 | S2 | 3|------|------| |------|------| |------|------| 4| | 12 | | 8 | | | 8 | | 5| | 8 | -\u0026gt; | 12 | | -\u0026gt; | 12 | 5 | 6| 10 | 3 | | 10 | 3 | | 10 | 3 | 7| 7 | 1 | | 7 | 1 | | 7 | 1 | 注意：做这个题目之前得先画图，例子不能太简单，否则你很难发现解法：\n1public void sortStack(Stack stack) { 2 Stack s2 = new Stack(); 3 while (!stack.isEmpty()) { 4 int val = stack.pop(); 5 while (!s2.isEmpty() \u0026amp;\u0026amp; s2.peek() \u0026gt; val) { 6 stack.push(s2.pop()); 7 } 8 s2.push(val); 9 } 10 while (!s2.isEmpty()) { 11 stack.push(s2.pop()); 12 } 13} ","date":"2019-08-13","img":"","permalink":"/post/cracking-coding-interview/3.5-sort-stack/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 3.5 Sort Stack"},{"categories":null,"content":"Queue via Stacks: Implement a MyQueue class which implements a queue using two stacks.\n解答 两个Stack，如果把一个Stack的元素pop然后push到另外一个Stack上，那么顺序就会发生颠倒。\nStack是FILO，Queue是FIFO，那么很自然的可以想到利用这两个Stack来实现Queue。\n1 IN OUT 2 4 1 3 3 2 4 2 3 5 1 4 当Queue中添加元素的时候，把OUT都移到IN里，然后在IN的顶部push。\n当Queue中拿出元素的时候，把IN都移到OUT里，然后在OUT的顶部push。\n1public class MyQueue { 2 3 Stack in = new Stack(); 4 Stack out = new Stack(); 5 6 public void add(Object value) { 7 drain(out, in); 8 in.push(value); 9 } 10 11 public T remove() { 12 drain(in, out); 13 return out.pop(); 14 } 15 16 public T peek() { 17 drain(in, out); 18 return out.peek(); 19 } 20 21 private void drain(Stack from, Stack to) { 22 if (from.isEmpty()) { 23 return; 24 } 25 Object v = from.pop(); 26 while (v != null) { 27 to.push(v); 28 v = from.pop(); 29 } 30 } 31 32} ","date":"2019-08-13","img":"","permalink":"/post/cracking-coding-interview/3.4-queue-of-stacks/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 3.4 Queue of Stacks"},{"categories":null,"content":"Stack of Plates: Imagine a (literal) stack of plates. If the stack gets too high, it might topple. Therefore, in real life, we would likely start a new stack when the previous stack exceeds some threshold. Implement a data structure SetOfStacks that mimics this. SetOfStacks should be composed of several stacks and should create a new stack once the previous one exceeds capacity. SetOfStacks.push() and SetOfStacks.pop() should behave identically to a single stack (that is, pop() should return the same values as it would if there were just a single stack).\nFOLLOW UP\nImplement a function popAt(int index) which performs a pop operation on a specific sub-stack.\nHints: #64, #87\n解答 可以用Stack of Stacks来解决，当push超过capacity的时候，追加一个Stack。每次pop都从top Stack中pop。\n1public class SetOfStacks { 2 private Stack\u0026lt;Stack\u0026gt; stackOfStacks = new Stack\u0026lt;\u0026gt;(); 3 private int capacity; 4 public SetOfStacks(int capacity) { 5 this.capacity = capacity; 6 pushNewStack(); 7 } 8 9 private Stack pushNewStack() { 10 Stack top = new Stack\u0026lt;\u0026gt;(capacity) 11 stackOfStacks.push(top); 12 return top; 13 } 14 15 private Stack peekTopStack() { 16 return stackOfStacks.peek(); 17 } 18 19 private Stack popTopStack() { 20 return stackOfStacks.pop(); 21 } 22 23 private Stack peekTopStackUntilNotEmpty() { 24 Stack top = stackOfStacks.peek(); 25 if (top != null \u0026amp;\u0026amp; top.isEmpty()) { 26 stackOfStacks.pop(); 27 top = stackOfStacks.peek(); 28 } 29 return top; 30 } 31 public void push(Object value) { 32 Stack top = peekTopStack(); 33 if (top == null) { 34 top = pushNewStack(); 35 } else if (top.isFull()) { 36 top = pushNewStack(); 37 } 38 top.push(value); 39 } 40 41 public Object pop() { 42 Stack top = peekTopStackUntilNotEmpty(); 43 if (top == null) { 44 return null; 45 } 46 return top.pop(); 47 } 48 49 public Object peek() { 50 Stack top = peekTopStackUntilNotEmpty(); 51 if (top == null) { 52 return null; 53 } 54 return top.peek(); 55 } 56 57 public boolean isEmpty() { 58 Stack top = peekTopStackUntilNotEmpty)(); 59 if (top == null) { 60 return true; 61 } 62 return top.isEmpty(); 63 } 64} 解答FOLLOW UP 如果在Stack 1 pop了一个元素，那么就得把 Stack 2的一个元素弄到Stack 1里去，以此类推把Stack 3、4、5 \u0026hellip;的都挪动一下。\n用一个ArrayList存放Stack，Stack提供一个从Bottom移除元素的方法。\n","date":"2019-08-13","img":"","permalink":"/post/cracking-coding-interview/3.3-stack-of-plates/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 3.3 Stack of Plates"},{"categories":null,"content":"Stack Min: How would you design a stack which, in addition to push and pop, has a function min which returns the minimum element? Push, pop and min should all operate in O(1) time.\nHints:#27, #59, #78\n解答 如果在stack里放一个min属性用来跟踪min，那么push的时候min到还好说，但是pop的时候要把次min的恢复出来就麻烦了。\n弄两个stack，一个正常存储value，另一个只存储min values。\n1public class StackMin { 2 private Stack\u0026lt;Integer\u0026gt; num = new Stack\u0026lt;\u0026gt;(); 3 private Stack\u0026lt;Integer\u0026gt; min = new Stack\u0026lt;\u0026gt;(); 4 public void push(Integer value) { 5 if (num.isEmpty()) { 6 num.push(value); 7 min.push(value); 8 return; 9 } 10 if (value \u0026lt;= min.peek()) { 11 // 只存比当前min更小的数字，这里用\u0026lt;=是为了应对连续push相同数字的情况 12 min.push(value); 13 } 14 num.push(value); 15 } 16 public Integer pop() { 17 Integer val = num.pop(); 18 if (val.equals(min.peek())) { 19 // 如果pop了最小值，那么min也 20 min.pop(); 21 } 22 return val; 23 } 24 public Integer min() { 25 return min.peek(); 26 } 27} ","date":"2019-08-12","img":"","permalink":"/post/cracking-coding-interview/3.2-stack-min/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 3.2 Stack Min"},{"categories":null,"content":"Three in One: Describe how you could use a single array to implement three stacks.\nHints: #2, #12, #38, #58\n解答 如果数组的长度固定，那么可以把数组分割成3份，每份各司其职。不过这个似乎太简单了。\n如果说不固定3个数组的长度，即抢占式的。那么似乎每个stack都记录自己的element的下标。\n1public class Stack { 2 private Object[] array; 3 private int[] elementIndex; 4 private int size; 5 6 public Stack(Object[] array) { 7 this.array = array; 8 this.elementIndex = new int[array.length]; 9 for (int i = 0; i \u0026lt; elementIndex.length; i++) { 10 elementIndex[i] = -1; 11 } 12 } 13 14 public Object peek() { 15 if (isEmpty()) { 16 return null; 17 } 18 int slot = elementIndex[size - 1]; 19 return array[slot]; 20 } 21 22 public boolean push(Object value) { 23 int slot = -1; 24 for (int i = 0; i \u0026lt; array.length; i++) { 25 if (array[i] == null) { 26 slot = i; 27 break; 28 } 29 } 30 if (slot == -1) { 31 return false; 32 } 33 array[slot] = value; 34 elementIndex[size] = slot; 35 size++; 36 return true; 37 } 38 39 public Object pop() { 40 if (isEmpty()) { 41 return null; 42 } 43 int slot = elementIndex[size - 1]; 44 Object data = array[slot]; 45 array[slot] = null; 46 elementIndex[size - 1] = -1; 47 size--; 48 return data; 49 } 50 51 public boolean isEmpty() { 52 return size == 0; 53 } 54} ","date":"2019-08-12","img":"","permalink":"/post/cracking-coding-interview/3.1-three-in-one/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 3.1 Three in One"},{"categories":null,"content":"Loop Detection: Given a circular linked list, implement an algorithm that returns the node at the beginning of the loop.\nDEFINITION\nCircular linked list: A (corrupt) linked list in which a node\u0026rsquo;s next pointer points to an earlier node, so as to make a loop in the linked list.\nEXAMPLE\n1Input: A -\u0026gt; B -\u0026gt; C -\u0026gt; D -\u0026gt; E -\u0026gt; C [the same C as earlier] 2Output: C 解答 这个比较复杂，结论是：\n 弄两指针，slow每次走一步，fast每次走两步。 当slow和fast相遇的时候，这个node距离【循环起点】的距离和【链表头】距离【循环起点】的距离是一样的。 这个时候再从相遇点和链表头同时走，走到相遇的时候就是【循环起点】  1o -\u0026gt; o -\u0026gt; o -\u0026gt; o 2 / \\ 3 o o 4 | | 5 o o 6 \\ / 7 o 来看看是怎么推导出来的：\n 假设【循环起点】到【链表头】的距离为K 当slow走到【循环起点】的时候，说明它走了K，而fast则走了2K，也就是说fast已经进入【循环】走了K 假设循环的长度为L，因为fast走在slow前面，所也可以说fast距离slow有L - K 那么还要走多少步fast才能碰到slow呢（即遇到【交叉点】）？  因为fast每次走2步，slow每次走1步，fast比slow快1步 因此对于slow来说还要走L - K步才能碰到一起，对于fast来说要走2(L - K)步才能碰到一起   【交叉点】的位置在哪里呢？在循环里 L -K 的位置，其实fast也在这个位置。这也就是说此交叉点距离【循环起点】为K 看前面所说的，【链表头】到【循环起点】的距离同样也是K。 那也就是说如果此时同时从【链表头】和【交叉点】开始走，遇到第一个相同的node，这个node就是循环的起点。  1public Node findLoopStart(Node a) { 2 Node head = a; 3 Node slow = a; 4 Node fast = a; 5 while (fast != null) { 6 slow = slow.next; 7 fast = fast.next; 8 if (fast == null) { 9 return null; 10 } 11 fast = fast.next; 12 if (slow == fast) { 13 // 遇到交叉点 14 break; 15 } 16 } 17 if (fast == null) { 18 // 没有交叉 19 return null; 20 } 21 while (head != null \u0026amp;\u0026amp; slow != null) { 22 if (head == slow) { 23 // 找到循环起点 24 return head; 25 } 26 head = head.next; 27 slow = slow.next; 28 } 29 return null; 30} ","date":"2019-08-12","img":"","permalink":"/post/cracking-coding-interview/2.8-loop-detection/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 2.8 Loop Detection"},{"categories":null,"content":"Intersection: Given two (singly) linked lists, determine if the two lists intersect. Return the inter­secting node. Note that the intersection is defined based on reference, not value.That is, if the kth node of the first linked list is the exact same node (by reference) as the jth node of the second linked list, then they are intersecting.\n解法1 判断两个链表是否交叉简单，只需把两链表走到底，看最后一个node是否是同一个就行了。因为两链一旦交叉那肯定殊途同归。\n1A -\u0026gt; B -\u0026gt; C 2 \\ 3 -\u0026gt; D -\u0026gt; E -\u0026gt; F 4 / 5 X -\u0026gt; Y 那么怎么知道交叉点是哪个node？\n我们做一个Set\u0026lt;Node\u0026gt;记录之前出现过的node，分别遍历两个链表，当发现某个node出现了两次，那么它就是交叉点。\n1public Node intersect(Node a, Node b) { 2 Set\u0026lt;Node\u0026gt; nodes = new HashSet\u0026lt;\u0026gt;(); 3 while (a != null) { 4 nodes.add(a); 5 a = a.next; 6 } 7 while (b != null) { 8 if (nodes.contains(b)) { 9 return b; 10 } 11 b = b.next; 12 } 13 return null; 14} 解法2 解法1的空间复杂度比较大，看看能不能O(1)。\n如果两个链表的长度一样，那么我们可以同时从两个链表的头部开始遍历，然后对比一下，就能够找到交叉点。\n如果不一样呢？那我们是否可以先让长的那个指针先走几步，然后再一起走（齐头并进），就能够找到交叉点了。\n1public Node intersect(Node a, Node b) { 2 int lenA = length(a); 3 int lenB = length(b); 4 if (lenA \u0026gt; lenB) { 5 a = skip(a, lenA - lenB); 6 } 7 if (lenB \u0026gt; lenA) { 8 b = skip(b, lenB - lenA); 9 } 10 while (a != null) { 11 if (a == b) { 12 return a; 13 } 14 a = a.next; 15 b = b.next; 16 } 17 return null; 18} 19int length(Node a) { 20 int len = 0; 21 while (a != null) { 22 len++; 23 a = a.next; 24 } 25 return len; 26} 27Node skip(Node a, int step) { 28 for (int i = 0; i \u0026lt; step; i++) { 29 a = a.next; 30 } 31 return a; 32} ","date":"2019-08-12","img":"","permalink":"/post/cracking-coding-interview/2.7-intersection/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 2.7 Intersection"},{"categories":null,"content":"Palindrome: Implement a function to check if a linked list is a palindrome.\n这种题目的话应该是不允许使用类似的数据结构来替代的，比如用ArrayList，但是可以用其他数据结构比如HashMap、Stack。\n解法1 克隆一个反向链表，然后遍历比较：\n1public boolean isPalindrome(Node node) { 2 Node reverse = reverseAndClone(node); 3 return isEqual(node, reverse); 4} 5 6// 反向clone一个链表是通过不断在head插入克隆的元素来做到 7Node reverseAndClone(Node node) { 8 Node head = null; 9 while (node != null) { 10 Node clone = new Node(node.data); 11 clone.next = head; 12 head = clone; 13 node = node.next; 14 } 15 return head; 16} 17 18boolean isEqual(Node a, Node b) { 19 while (a != null \u0026amp;\u0026amp; b != null) { 20 if (a.data != b.data) { 21 return false; 22 } 23 a = a.next; 24 b = b.next; 25 } 26 return true; 27} 解法2 用递归+Stack的方式来判断是否回文。比如在中间节点之前在Stack中push，过了中间节点则开始判断是否对称。已知链表长度：\n1public boolean isPalindrome(Node node, int index, int length, Stack stack) { 2 boolean odd = length % 2 == 1; 3 int mid = length / 2; 4 if (odd) { 5 if (index \u0026lt; mid) { 6 stack.push(node.data); 7 } else if (index \u0026gt; mid) { 8 Object top = stack.pop(); 9 if (!top.equals(node.data)) { 10 return false; 11 } 12 } 13 } else { 14 if (index \u0026lt; mid) { 15 stack.push(node.data); 16 } else if (index \u0026gt;= mid) { 17 Object top = stack.pop(); 18 if (!top.equals(node.data)) { 19 return false; 20 } 21 } 22 } 23 if (node.next != null) { 24 return isPalindrome(node.next, index + 1, length, stack); 25 } 26 return true; 27} 解法3 上面这个用递归似乎多余了，可以用循环来做：\n1public boolean isPalindrome(Node node, int length) { 2 int index = 0; 3 int mid = length / 2; 4 boolean odd = length % 2 == 1; 5 Stack\u0026lt;Integer\u0026gt; stack = new Stack\u0026lt;\u0026gt;(); 6 while (node != null) { 7 if (odd) { 8 if (index \u0026lt; mid) { 9 stack.push(node.data); 10 } else if (index \u0026gt; mid) { 11 Integer top = stack.pop(); 12 if (top.intValue() != node.data) { 13 return false; 14 } 15 } 16 } else { 17 if (index \u0026lt; mid) { 18 stack.push(node.data); 19 } else if (index \u0026gt;= mid) { 20 Integer top = stack.pop(); 21 if (top.intValue() != node.data) { 22 return false; 23 } 24 } 25 } 26 node = node.next; 27 index++; 28 } 29 return true; 30} 解法4 如果不知道链表的长度怎么弄？可以用快慢两个指针，慢指针每次走一步，快指针每次走两步，在快指针走到尾之前往Stack里push，到尾之后Stack里pop，看看是不是一样。\n1public boolean isPalindrome(Node node) { 2 Node slow = node; 3 Node fast = node; 4 Stack stack = new Stack(); 5 boolean odd = false; 6 while (fast != null) { 7 stack.push(slow.data); 8 slow = slow.next; 9 fast = fast.next; 10 if (fast == null) { 11 odd = true; 12 break; 13 } 14 fast = fast.next; 15 } 16 if (odd) { 17 // pop middle element 18 stack.pop(); 19 } 20 while (slow != null) { 21 Object top = stack.pop(); 22 if (!top.equals(slow.data)) { 23 return false; 24 } 25 slow = slow.next; 26 } 27 if (!stack.isEmpty()) { 28 return false; 29 } 30 return true; 31} ","date":"2019-08-12","img":"","permalink":"/post/cracking-coding-interview/2.6-palindrome/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 2.6 Palindrome"},{"categories":null,"content":"Sum Lists: You have two numbers represented by a linked list, where each node contains a single digit.The digits are stored in reverse order, such that the 1\u0026rsquo;s digit is at the head of the list. Write a function that adds the two numbers and returns the sum as a linked list.\nEXAMPLE\n1Input: (7 -\u0026gt; 1 -\u0026gt; 6) + (5 -\u0026gt; 9 -\u0026gt; 2). That is, 617 + 295. 2Output: 2 -\u0026gt; 1 -\u0026gt; 9. That is, 912. FOLLOW UP\nSuppose the digits are stored in forward order. Repeat the above problem.\nEXAMPLE\n1lnput: (6 -\u0026gt; 1 -\u0026gt; 7) + (2 -\u0026gt; 9 -\u0026gt; 5). That is, 617 + 295. 2Output: 9 -\u0026gt; 1 -\u0026gt; 2. That is, 912. 解法 这个问题还挺容易理解的，首先你得遍历这两个链表，然后在各自的位上相加，相加结果 mod 10，根据情况进一。遍历的时候注意一下两个链表长短不一致的问题。\n1public Node solve(Node a, Node b) { 2 3 Node head = new Node(); 4 Node tail = head; 5 boolean plus1 = false; 6 while (a != null \u0026amp;\u0026amp; b != null) { 7 int num = a.data + b.data; 8 num = plus1 ? num + 1 : num; 9 plus1 = num \u0026gt;= 10; 10 tail.next = new Node(num % 10); 11 tail = tail.next; 12 a = a.next; 13 b = b.next; 14 } 15 16 Node zero = new Node(0); 17 Node one = new Node(1); 18 19 if (a != null) { 20 // a比b长 21 tail.next = solve(a, plus1 ? one : zero); 22 } else if (b != null) { 23 // b比a长 24 tail.next = solve(b, plus1 ? one : zero); 25 } else if (plus1) { 26 // a、b一样长，但是有一个进位没有处理 27 tail.next = one; 28 } 29 30 return head.next; 31} 解FOLLOW UP FOLLOW UP是说把链表反过来了，那么第一个想到的就是把链表正过来，然后再用上面的办法解，最后再把结果反过来。不过这个似乎有点麻烦，要做3次反转，那么是不是有办法不需要反转就能计算呢？\n能够想到的就是递归，即：\n 当前节点的结果+后面节点的数字=结果 如果后面节点要进1位，那么当前节点结果+1  还要处理两个链表长度不一致的问题，处理办法就是在前面补0。\n1@Override 2public Node solve(Node a, Node b) { 3 int lengthA = length(a); 4 int lengthB = length(b); 5 if (lengthA \u0026gt; lengthB) { 6 b = leftPadZero(b, lengthA - lengthB); 7 } 8 if (lengthB \u0026gt; lengthA) { 9 a = leftPadZero(a, lengthB - lengthA); 10 } 11 Node result = new Node(); 12 boolean plus1 = sum(result, a, b); 13 if (plus1) { 14 // 处理余下的进位 15 Node one = new Node(1); 16 one.next = result; 17 result = one; 18 } 19 return result; 20} 21 22// 计算长度 23private int length(Node node) { 24 if (node == null) { 25 return 0; 26 } 27 return 1 + length(node.next); 28} 29 30// 左侧补齐0 31private Node leftPadZero(Node node, int amount) { 32 if (amount == 0) { 33 return node; 34 } 35 Node head = node; 36 for (int i = 0; i \u0026lt; amount; i++) { 37 Node zero = new Node(0); 38 zero.next = head; 39 head = zero; 40 } 41 return head; 42} 43 44// a、b的长度都是一样的 45private boolean sum(Node head, Node a, Node b) { 46 boolean plus1 = false; 47 if (a.next != null) { 48 head.next = new Node(); 49 plus1 = sum(head.next, a.next, b.next); 50 } 51 int num = a.data + b.data; 52 num = plus1 ? num + 1 : num; 53 head.data = num % 10; 54 return num \u0026gt;= 10; 55} ","date":"2019-08-12","img":"","permalink":"/post/cracking-coding-interview/2.5-sum-lists/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 2.5 Sum Lists"},{"categories":null,"content":"Partition: Write code to partition a linked list around a value x, such that all nodes less than x come before all nodes greater than or equal to x. If x is contained within the list, the values of x only need to be after the elements less than x (see below). The partition element x can appear anywhere in the \u0026ldquo;right partition\u0026rdquo;; it does not need to appear between the left and right partitions.\nEXAMPLE\n1Input: 3 -\u0026gt; 5 -\u0026gt; 8 -\u0026gt; 5 -\u0026gt; 10 -\u0026gt; 2 -\u0026gt; 1 [partition=5] 2Output: 3 -\u0026gt; 1 -\u0026gt; 2 -\u0026gt; 10 -\u0026gt; 5 -\u0026gt; 5 -\u0026gt; 8 解法1 弄两个链表，一个放小于x的，一个放大于等于x的，最后把两个链表接起来：\n1public Node partition(Node head, int x) { 2 Node small = null; 3 Node smallHead = null; 4 Node large = null; 5 Node largeHead = null; 6 Node p = head; 7 while (p != null) { 8 if (p.data \u0026lt; x) { 9 if (small == null) { 10 small = p; 11 smallHead = p; 12 continue; 13 } 14 small.next = p; 15 small = p; 16 } else { 17 if (large == null) { 18 large = p; 19 largeHead = p; 20 continue; 21 } 22 large.next = p; 23 large = p; 24 } 25 p = p.next; 26 } 27 // 这里的large.next要清null，这个是large的尾巴，有可能指向一个small的 28 if (large != null) { 29 large.next = null; 30 } 31 if (smallHead != null) { 32 small.next = largeHead; 33 return smallHead; 34 } 35 return largeHead; 36} 时间复杂度：O(n)\n空间复杂度：O(1)，实际上没有另开链表，只是存了几个变量而已。\n这个算法保持了元素的稳定性，因为不存在交换。\n解法2 把小于x的元素放在链表头部，把大于等于x的元素放在链表尾部。因为本题也没有说要稳定排序，所以是可以的。\n1public Node partition(Node node, int x) { 2 Node head = head; 3 Node tail = head; 4 Node p = head; 5 while (p != null) { 6 Node next = p.next; 7 if (p.data \u0026lt; x) { 8 // 在头部追加\u0026lt;x的node 9 p.next = head; 10 head = p; 11 } else { 12 // 在屁股后面追加\u0026gt;=x的node 13 tail.next = p; 14 tail = p; 15 } 16 p = next; 17 } 18 tail.next = null; 19 return head; 20} ","date":"2019-08-09","img":"","permalink":"/post/cracking-coding-interview/2.4-partition/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 2.4 Partition"},{"categories":null,"content":"Delete Middle Node: Implement an algorithm to delete a node in the middle (i.e., any node but the first and last node, not necessarily the exact middle) of a singly linked list, given only access to that node.\nEXAMPLE\n1Input: the node c from the linked list a-\u0026gt;b-\u0026gt;c-\u0026gt;d-\u0026gt;e-\u0026gt;f 2Result: nothing is returned, 3but the new linked list looks like a-\u0026gt;b-\u0026gt;d-\u0026gt;e- \u0026gt;f 分析 这个问题是如果你能够访问到某个node，那么怎么删除掉这个node，而且你没有办法访问head node。\n因为没有办法获得前驱指针，那有没有办法把后面的提到前面去？似乎可以通过copy data的方式看上去像把node提前了。\n1 v 2a -\u0026gt; b -\u0026gt; c -\u0026gt; d -\u0026gt; e -\u0026gt;f 3 4把data复制过来： 5 v 6a -\u0026gt; b -\u0026gt; d -\u0026gt; d -\u0026gt; e -\u0026gt;f 7 8指向next.next 9a -\u0026gt; b -\u0026gt; d d -\u0026gt; e -\u0026gt;f 10 \\_______/ 11 12孤立next 13a -\u0026gt; b -\u0026gt; d d e -\u0026gt;f 14 \\_______/ 代码：\n1public void deleteNode(Node node) { 2 if (node == null || node.next == null) { 3 return; 4 } 5 node.data = node.next.data; 6 node.next = node.next.next; 7 node.next.next = null; 8} ","date":"2019-08-09","img":"","permalink":"/post/cracking-coding-interview/2.3-delete-middle-node/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 2.3 Delete Middle Node"},{"categories":null,"content":"Remove Dups: Write code to remove duplicates from an unsorted linked list.\nFOLLOW UP\nHow would you solve this problem if a temporary buffer is not allowed?\n解答1 用一个Set来记录哪些data出现过，用两个指针一前一后来遍历\n1public void removeDups(Node head) { 2 Set\u0026lt;Object\u0026gt; datum = new HashSet\u0026lt;\u0026gt;(); 3 Node p1 = null; 4 Node p2 = head; 5 while(p2 != null) { 6 if (datum.contains(p2.data)) { 7 p1.next = p2.next; 8 } else { 9 datum.add(p2.data); 10 p1 = p2; 11 } 12 p2 = p2.next; 13 } 14} 时间复杂度：O(n)\n空间复杂度：O(n)\n解答2 如果不用Set，直接想到的办法是p1指向在第一个节点，p2则从下一个节点开始跑，如果发现重复，则删除p2。\n1public void removeDups(Node head) { 2 Node p1 = head; 3 while(p1 != null \u0026amp;\u0026amp; p1.next != null) { 4 Node p2 = p1; 5 while(p2.next != null) { 6 if (p1.data == p2.next.data) { 7 // 删除p2.next 8 p2.next = p2.next.next; 9 continue; 10 } 11 p2 = p2.next; 12 } 13 p1 = p1.next; 14 } 15} 时间复杂度：O(n^2)\n空间复杂度：O(1)，因为是in place\n","date":"2019-08-08","img":"","permalink":"/post/cracking-coding-interview/2.1-remove-dups/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 2.1 Remove Dups"},{"categories":null,"content":"Return Kth to Last: Implement an algorithm to find the kth to last element of a singly linked list.\n解答1 两指针p1和p2，p2比p1多k-1步，两个同时走，当p2到底多时候，p1就是倒数第k个元素\n1public Node lastKth(Node head, int k) { 2 Node p2 = head; 3 while (k - 1 \u0026gt; 0) { 4 if (p2 == null) { 5 return null; 6 } 7 p2 = p2.next; 8 k--; 9 } 10 Node p1 = head; 11 while (p2.next != null) { 12 p1 = p1.next; 13 p2 = p2.next; 14 } 15 return p1; 16} 时间复杂度：O(k - 1 + n - k) = O(n)\n空间复杂度：O(1)\n解答2 用递归，这个问题就变成如何计算每个元素位于倒数第几，最后一个元素位于倒数第1，倒数第二个元素等于前一个元素的位数+1……：\n1public int lastKth(Node head, int k) { 2 if (head == null) { 3 return 0; 4 } 5 int index = lastKth(head, k) + 1; 6 if (index == k) { 7 print(head); 8 } 9 return index; 10} 不过上面的办法不好，因为它没有返回Node，而是打印出来。看下面这个方法：\n1public class Index { 2 int value; 3} 4public Node lastKth(Node head, int k, Index index) { 5 if (head == null) { 6 return null; 7 } 8 Node node = lastKth(head.next, k, index); 9 index.value = index.value + 1; 10 if (index.index == k) { 11 return head; 12 } 13 return node; 14} 空间复杂度：O(n)，每层递归都hold住变量了\n时间复杂度：O(n)，肯定会从头递归到底。\n","date":"2019-08-08","img":"","permalink":"/post/cracking-coding-interview/2.2-return-kth-to-last/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 2.2 Return Kth to Last"},{"categories":null,"content":"String Rotation:Assume you have a method isSubstring which checks if one word is a substring of another. Given two strings, s1 and s2, write code to check if s2 is a rotation of sl using only one call to isSubstring (e.g.,\u0026quot;waterbottle\u0026quot; is a rotation of \u0026quot;erbottlewat\u0026quot;).\n分析 注意看题目，rotation不是把字符串反转，而是找一个点，把前后颠倒一下。\n解答1 能最简单的办法是弄个指针p遍历s1，用isSubstring判断s1[0~p]和s1[p+1~s1.length-1]是否都是s2的子串。但是这样的话isSubstring就调用了多次了，而题目要求只调用一次。\n题目中给了暗示，isSubstring一般用在长短两个字符串上，但是这里我们的字符串长度是一样的，所以你可以想想看是不是把s1+s2，或者s1+s1，或者s2+s2。\n如果s1是s2的rotation，那么你可以把s1看成两个部分xy，即s1=xy，则s2=yx。如果把s2 double一下，那么就变成了yxyx，然后你会发现s1就是它的子串。在这道题目中适当的抽象是必要的，比如xy这种。\n1public boolean isRotation(String s1, String s2) { 2 if (s1.length() != s2.length()) { 3 return false; 4 } 5 String s22 = s2 + s2; 6 return isSubString(s1, s22); 7} 时间复杂度：O(n)，假设isSubtstring是O(2n)，字符串串接是O(2n)\n空间复杂度：O(n)，搞了个字符串，所以是O(2n)\n","date":"2019-08-08","img":"","permalink":"/post/cracking-coding-interview/1.9-string-rotation/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 1.9 String Rotation"},{"categories":null,"content":"Zero Matrix: Write an algorithm such that if an element in an MxN matrix is 0, its entire row and column are set to 0.\n分析 看似是遍历整个二维数组，如果发现某个点为0，那么就把X轴和Y轴都清零。\n题目里没有讲清楚两个事情：\n 这个matrix里究竟有几个0 因为遇到第一个0之后把X轴和Y轴都清零了，那么如果继续查找肯定会把整个matrix都清0，这种情况怎么处理  假设这两个问题的答案是：\n 有任意多个0 对清零过的cell跳过，不做处理  解答 从左到右从上到下遍历整个matrix。\n记录那些行，哪些列有0，其实就是坐标，然后遍历这些，把行列清零。\n1public void zeroMatrix(int[][] matrix, int m, int n) { 2 // m: 行数, n: 列数 3 boolean[] zeroRows = new boolean[m] 4 boolean[] zeroCols = new boolean[n]; 5 for(int i = 0; i \u0026lt; m; i++) { 6 for(int j = 0; j \u0026lt; n; j++) { 7 if (matrix[i][j] == 0) { 8 zeroRows[i] = true; 9 zeroCols[j] = true; 10 } 11 } 12 } 13 for(int i = 0; i \u0026lt; m; i++) { 14 if (zeroRows[i]) { 15 zeroRows(matrix[i]); 16 } 17 } 18 for(int i = 0; i \u0026lt; n; i++) { 19 if (zeroCols[i]) { 20 zeroCols(matrix, i); 21 } 22 } 23} 24private void zeroRow(int[] array) { 25 for(int i = 0; i \u0026lt; array.length; i++) { 26 array[i] = 0; 27 } 28} 29private void zeroCol(int[][] matrix, int col) { 30 for(int i = 0; i \u0026lt; matrix.length; i++) { 31 matrix[i][col] = 0; 32 } 33} 时间复杂度：O(n*m)\n空间复杂度：O(n+m)\n","date":"2019-08-08","img":"","permalink":"/post/cracking-coding-interview/1.8-zero-matrix/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 1.8 Zero Matrix"},{"categories":null,"content":"Rotate Matrix: Given an image represented by an NxN matrix, where each pixel in the image is 4 bytes, write a method to rotate the image by 90 degrees. Can you do this in place.\n分析 4 bytes可以用一个int来存储，那就变成了NxN的int二维数组的旋转。\n先弄几个例子看看向右旋转90度是怎么回事，我们从外到里顺时针给元素编号：\n周长 = 4n - 4，步进=周长-n-1\n1x1，周长1，步进0：\n10 -\u0026gt; 0 2x2，周长4，步进3：\n10 1 -\u0026gt; 3 0 23 2 2 1 3x3，周长8，步进6：\n10 1 2 6 7 0 27 8 3 -\u0026gt; 5 8 1 36 5 4 4 3 2 4x4，周长12，步进9：\n10 1 2 3 9 10 11 0 211 12 13 4 -\u0026gt; 8 15 12 1 310 15 14 5 7 14 13 2 49 8 7 6 6 5 4 3 从最外圈到里圈变动，格子里的数字 = (原数字+步进) % 周长\n结果，这个分析失败了，因为缺少坐标关系，后面很难弄，不过给后面带来了思路\n继续分析 这次把坐标填上：\n1(0,0) (0,1) (0,2) 2(1,0) (1,1) (1,2) 3(2,0) (2,2) (2,2) 其实旋转可以看成是从四个顶点开始，都按照顺时针方向，挨个把自己的弄到90度的位置上去比如：\n1 --\u0026gt; 2 o o 3 4^ | 5| v 6 7 o o 8 \u0026lt;-- 如果我们知道了左上角的第一个顶点的位置，那么就能够知道其他3个顶点的位置：\n1 (r, [c]++) （[r]++, c+n-1) 2 3 4 ([r+n-1]--,c) (r+n-1, [c+n-1]--) 上面这个图中r=行，c=列，都是从0开始，边长为n，[]里的代表遍历时变动的维度，++/--代表变动的方式。\n然后怎么把整个替换掉，我们可以从最外圈旋转，然后再旋转里圈的：\n1 第一步 第二步 20 1 2 3 9 10 11 0 9 10 11 0 311 12 13 4 --\u0026gt; 8 12 13 1 --\u0026gt; 8 15 12 1 410 15 14 5 7 15 14 2 7 14 13 2 59 8 7 6 6 5 4 3 6 5 4 3 而且第layer层的周长=n - 2 * layer，layer从0开始。\n解法1 一共有几圈=n/2，第一圈的左上角是(0,0)，第二圈的左上角是(1,1)，以此类推：\n1public void rotateMatrix(int[][] matrix, int n) { 2 for (int i = 0; i \u0026lt; n / 2; i++) { 3 int length = n - 2 * i; 4 int firstRow = i; 5 int firstCol = i; 6 int lastRow = firstRow + length - 1; 7 int lastCol = firstCol + length - 1; 8 for (int j = 0; j \u0026lt; length - 1; j++) { 9 int leftTop = matrix[firstRow][firstCol + j]; 10 // leftBottom -\u0026gt; leftTop 11 matrix[firstRow][firstCol + j] = matrix[lastRow - j][firstCol]; 12 // rightBottom -\u0026gt; leftBottom; 13 matrix[lastRow - j][firstCol] = matrix[lastRow][lastCol - j]; 14 // rightTop -\u0026gt; rightBottom 15 matrix[lastRow][lastCol - j] = matrix[firstRow + j][lastCol]; 16 // leftTop -\u0026gt; rightTop 17 matrix[firstRow + j][lastCol] = leftTop; 18 } 19 } 20} 注意上面的 j \u0026lt; length -1\t，因为一条边的最后一个元素就是另一条边的第一个元素，所以我们不能遍历到它。\n解法2优化 可以发现firstRow==firstCol和lastRow==lastCol，因此可以省去一些变量：\n1for (int i = 0; i \u0026lt; n / 2; i++) { 2 int length = n - 2 * i; 3 int first = i; 4 int last = first + length - 1; 5 for (int j = 0; j \u0026lt; length - 1; j++) { 6 int leftTop = matrix[first][first + j]; 7 // leftBottom -\u0026gt; leftTop 8 matrix[first][first + j] = matrix[last - j][first]; 9 // rightBottom -\u0026gt; leftBottom; 10 matrix[last - j][first] = matrix[last][last - j]; 11 // rightTop -\u0026gt; rightBottom 12 matrix[last][last - j] = matrix[first + j][last]; 13 // leftTop -\u0026gt; rightTop 14 matrix[first + j][last] = leftTop; 15 } 16} ","date":"2019-08-08","img":"","permalink":"/post/cracking-coding-interview/1.7-rotate-matrix/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 1.7 Rotate Matrix"},{"categories":null,"content":"String Compression: Implement a method to perform basic string compression using the counts of repeated characters. For example, the string aabcccccaaa would become a2b1c5a3. If the \u0026ldquo;compressed\u0026rdquo; string would not become smaller than the original string, your method should return the original string. You can assume the string has only uppercase and lowercase letters (a - z).\n分析 连续的字符出现次数多少次才能有压缩收益？应该是\u0026gt;=3次，如果=2次则没有收益，如果=1次则反而会有惩罚。\n所以本题的例子里有个错误，应该是a2bc5a3。\n思路是遍历这个字符串，比较当前和前一个是否相等，如果相等则计数+1，如果不等则看计数是否\u0026gt;=2，根据情况变成【字母数字】这种形式还是保持原样，然后清零。\n解法一 1public String compress(String s) { 2 if (s.length \u0026lt;= 2) { 3 return s; 4 } 5 StringBuilder sb = new StringBuilder(); 6 char prevChar = s.charAt(0); 7 int count = 1; 8 for(int i = 1; i \u0026lt;= s.length; i++) { 9 if (i == s.length) { 10 appendChar(sb, prevChar, count); 11 break; 12 } 13 char currChar = s.charAt(i); 14 if (currChar == prevChar) { 15 count++; 16 } else { 17 appendChar(sb, prevChar, count); 18 prevChar = currChar; 19 count = 1; 20 } 21 } 22 if (sb.length() \u0026gt;= s.length) { 23 return s; 24 } 25 return sb.toString(); 26} 27private void appendChar(StringBuilder sb, char c, int count) { 28 if (count \u0026gt;= 2) { 29 sb.append(c); 30 sb.append(count); 31 } else { 32 sb.append(c); 33 } 34} 时间复杂度：O(n)，n=原始字符串长度\n空间复杂度：O(min(n, c))，c=压缩后的字符串长度\n解法二 StringBuilder内部也是一个array，会有扩容的问题（和ArrayList一样）。如果可以事先计算出压缩字符串长度就能够固定StringBuilder的容量。\n1public String compress(String s) { 2 if (s.length \u0026lt;= 2) { 3 return s; 4 } 5 int compressedLength = compressedLength(s); 6 if (compressedLength \u0026gt;= s.length) { 7 return s; 8 } 9 StringBuilder sb = new StringBuilder(compressedLength); 10 char prevChar = s.charAt(0); 11 int count = 1; 12 for(int i = 1; i \u0026lt;= s.length; i++) { 13 if (i == s.length) { 14 appendChar(sb, prevChar, count); 15 break; 16 } 17 char currChar = s.charAt(i); 18 if (currChar == prevChar) { 19 count++; 20 } else { 21 appendChar(sb, prevChar, count); 22 prevChar = currChar; 23 count = 1; 24 } 25 } 26 return sb.toString(); 27} 28private void appendChar(StringBuilder sb, char c, int count) { 29 if (count \u0026gt;= 2) { 30 sb.append(c); 31 sb.append(count); 32 } else { 33 sb.append(c); 34 } 35} 36private int compressedLength(String s) { 37 int compressedLength = 0; 38 char prevChar = s.charAt(0); 39 int count = 1; 40 for(int i = 1; i \u0026lt;= s.length; i++) { 41 if (i == s.length) { 42 compressedLength += compressedLength(count); 43 break; 44 } 45 char currChar = s.charAt(i); 46 if (currChar == prevChar) { 47 count++; 48 } else { 49 compressedLength += compressedLength(count); 50 prevChar = currChar; 51 count = 1; 52 } 53 } 54\treturn compressedLength; 55} 56private int compressedLength(int count) { 57 if (count \u0026lt;= 2) { 58 return count; 59 } 60 return 1 + String.valueOf(count).length; 61} ","date":"2019-08-08","img":"","permalink":"/post/cracking-coding-interview/1.6-string-compression/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 1.6 String Compression"},{"categories":null,"content":"One Away: There are three types of edits that can be performed on strings: insert a character, remove a character, or replace a character. Given two strings, write a function to check if they are one edit (or zero edits) away.\nEXAMPLE\n1pale, ple -\u0026gt; true 2pales, pale -\u0026gt; true 3pale, bale -\u0026gt; true 4pale, bake -\u0026gt; false 分析 两个字符串a和b，看a距离b是否one edit away。\n先看字符数的差异：\n insert：b比a多一个字符，如果多了大于一个字符，那么就不是one edit away remove：b比a少一个字符，如果少了大于一个字符，那么就无法one edit away replace：b和a的字符数一样多 总结下来就是a和b的字符数的差异必须\u0026lt;=1，只有这样才有可能one edit away  再看字符内容的差异：如果要能够one edit away，那么a和b的字符的大部分都是一样的，且存在的差异最多只能有一处。\n解法1 先看字符数差异是否具有one edit away的条件。如果不具备直接返回false。\n如果两个字符数一样，那么用两个指针遍历a、b，当发现有两处不同时，返回false。\n如果a和b差一个字符，也同时遍历a、b，发现不同时将较长字符串的指针进位，继续比较，发现两处不同是，返回false。因为insert和remove实际上是一样的，所以只看insert就行了。\n比如：\n1Round 1: 2v 3ples 4pales 5^ 6Round 2, diffCount++: 7 v 8ples 9pales 10 ^ 11Round 3: 12 v 13ples 14pales 15 ^ 16Round 4: 17 v 18ples 19pales 20 ^ 21Round 5: 22 v 23ples 24pales 25 ^ 1public boolean isOneAway(String a, String b) { 2 int countDiff = abs(a.length - b.length); 3 if (countDiff \u0026gt; 1) { 4 return false; 5 } 6 if (countDiff == 0) { 7 return isOneReplaceAway(a, b); 8 } 9 if (a.length \u0026lt; b.length) { 10 return isOneInsertAway(a, b); 11 } 12 return isOneInsertAway(b, a); 13} 14public boolean isOneReplaceAway(String a, String b) { 15 int diffCount = 0; 16 for(int i = 0; i \u0026lt; a.length; i++) { 17 if (a.charAt(i) != b.charAt(i)) { 18 diffCount++; 19 } 20 if (diffCount \u0026gt; 1) { 21 return false; 22 } 23 } 24 return true; 25} 26public boolean isOneInsertAway(String a, String b) { 27 int diffCount = 0; 28 int i = 0; 29 int j = 0; 30 while(i \u0026lt; a.length) { 31 if (a.charAt(i) != b.charAt(j)) { 32 diffCount++; 33 j++; 34 } else { 35 i++; 36 j++; 37 } 38 if (diffCount \u0026gt; 1) { 39 return false; 40 } 41 } 42 return true; 43} ","date":"2019-08-07","img":"","permalink":"/post/cracking-coding-interview/1.5-one-away/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 1.5 One Away"},{"categories":null,"content":"Palindrome Permutation: Given a string, write a function to check if it is a permutation of a palin­drome. A palindrome is a word or phrase that is the same forwards and backwards. A permutation is a rearrangement of letters. The palindrome does not need to be limited to just dictionary words.\nEXAMPLE\n1Input: tactcoa 2Output: True (permutations: \u0026#34;tacocat\u0026#34;, \u0026#34;atcocta\u0026#34;, etc.) 回文特征 如果给一堆字符，怎么判断它可以构成回文？回文有这么几个特征：\n \u0026lt;=1 个字符的计数是奇数 \u0026gt;=0 个字符的计数是偶数  在这个题里的空格可以忽略的\n字符计数 假设是ASCII字符集。\n1public boolean isPalPermutation(String s) { 2 int oddCount = 0; 3 int evenCount = 0; 4 int[] charCount = new int[128]; 5 for(int i = 0; i \u0026lt; s.length(); i++) { 6 int pos = s.charAt(i); 7 if (pos == \u0026#39; \u0026#39;) { 8 continue; 9 } 10 charCount[pos]++; 11 if (charCount[pos] % 2 == 0) { 12 evenCount++; 13 oddCount--; 14 } else { 15 oddCount++; 16 if (evenCount \u0026gt; 0) { 17 evenCount--; 18 } 19 } 20 } 21 if (oddCount \u0026gt; 1) { 22 return false; 23 } 24 return true; 25} 时间复杂度：O(n)，n=字符串长度\n空间复杂度：O(c)，c=字符集大小\n改进字符计数* 可以发现我们只关心奇数字符，偶数字符我们不关心，所以可以去掉偶数字符的判断：\n1public boolean isPalPermutation(String s) { 2 int oddCount = 0; 3 int[] charCount = new int[128]; 4 for(int i = 0; i \u0026lt; s.length; i++) { 5 int pos = s.charAt(i); 6 if (pos == \u0026#39; \u0026#39;) { 7 continue; 8 } 9 charCount[pos]++; 10 if (charCount[pos] % 2 == 0) { 11 oddCount--; 12 } else { 13 oddCount++; 14 } 15 } 16 if (oddCount \u0026gt; 1) { 17 return false; 18 } 19 return true; 20} ","date":"2019-08-07","img":"","permalink":"/post/cracking-coding-interview/1.4-palindrome-permutation/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 1.4 Palindrome Permutation"},{"categories":null,"content":"URLify: Write a method to replace all spaces in a string with \u0026lsquo;%20\u0026rsquo;. You may assume that the string has sufficient space at the end to hold the additional characters,and that you are given the \u0026ldquo;true\u0026rdquo; length of the string. (Note: If implementing in Java,please use a character array so that you can perform this operation in place.)\n例子：\n1Input: \u0026#34;Mr John Smith \u0026#34;, 13 2Output: \u0026#34;Mr%20John%20Smith\u0026#34; 基本判断 题目里说了，给的char[]有足够的空间容纳增加的%20，并且还会给出字符串的true length，那么也就是说如果true length == char[]的length，那么就说明没有空格，直接返回就是了。\n弄个新数组 弄个新数组，都是空的，遍历旧数组，遇到空格就追加%20，其他的字符就直接追加。\n1public char[] urlify(char[] url, int trueLength) { 2 if (url.length == trueLength) { 3 return url; 4 } 5 char[] res = new char[url.length]; 6 int j = 0; 7 for(int i = 0; i \u0026lt; trueLength; i++) { 8 if (url[i] != \u0026#39; \u0026#39;) { 9 res[j++] = url[i]; 10 } else { 11 res[j++] = \u0026#39;%\u0026#39;; 12 res[j++] = \u0026#39;2\u0026#39;; 13 res[j++] = \u0026#39;0\u0026#39;; 14 } 15 } 16 return res; 17} 时间复杂度：O(n)，n=true length\n空间复杂度：O(n)\nIn place操作 题目里说了，给的char[]有足够的空间容纳增加的%20，如果这个足够的空间不多不少正正好好，那么我们可以利用这一点直接在char[]里操作，我们从字符串true length的末尾开始，把字符都丢到屁股后面去，遇到空格就丢%20。\n1public void urlify(char[] url, int trueLength) { 2 if (url.length == trueLength) { 3 return url; 4 } 5 int j = url.length - 1; 6 for(int i = trueLength - 1; i \u0026gt;= 0; i--) { 7 char c = url[i]; 8 if (c != \u0026#39; \u0026#39;) { 9 url[j--] = c; 10 } else { 11 url[j--] = \u0026#39;0\u0026#39;; 12 url[j--] = \u0026#39;2\u0026#39;; 13 url[j--] = \u0026#39;%\u0026#39;; 14 } 15 } 16 return url; 17} 时间复杂度：O(n)，n=true length\n空间复杂度：O(1)\n","date":"2019-08-07","img":"","permalink":"/post/cracking-coding-interview/1.3-urlify/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 1.3 URLify"},{"categories":null,"content":"Check Permutation: Given two strings,write a method to decide if one is a permutation of the\nother.\n例子：\n1String a = \u0026#34;bbacacege\u0026#34;; 2String b = \u0026#34;aacbcbeeg\u0026#34;; 基本判断 如果两个a.length != b.length，那么return false\n排序比较 对两个字符串进行排序，然后比较是否相等\n1public boolean isPermuation(String a, String b) { 2 if (a.length() != b.length()) { 3 return false; 4 } 5 String sortedA = quickSort(a); 6 String sortedB = quickSort(b); 7 for(int i = 0; i \u0026lt; a.length(); i++) { 8 if (sortedA.charAt(i) != sortedB.charAt(i)) { 9 return false; 10 } 11 } 12 return true; 13} 时间复杂度：O(2 * nlogn) + O(n) =\u0026gt; O(nlogn)\n空间复杂度：O(2 * n) =\u0026gt; O(n)\n字符计数 如果b是a的permutation，那么b里的各个字符的出现的次数肯定和a一样。如果字符集比较小的话，可以用一个int[]来做记录\n1public boolean isPermutation(String a, String b) { 2 if (a.length() != b.length()) { 3 return false; 4 } 5 int[] charCountA = new int[128]; 6 for(int i = 0; i \u0026lt; a.length(); i++) { 7 int pos = a.charAt(i); 8 charCountA[pos]++; 9 } 10 int[] charCountB = new int[128]; 11 for(int i = 0; i \u0026lt; b.length(); i++) { 12 int pos = b.charAt(i); 13 charCountB[pos]++; 14 } 15 for(int i = 0; i \u0026lt; charCountA.length(); i++) { 16 if (charCountA[i] != charCountB[i]) { 17 return false; 18 } 19 } 20 return true; 21} 时间复杂度：遍历了3次，所以是O(3 * n) =\u0026gt; O(n)\n空间复杂度：两个数组，所以是O(2 * c) \u0026gt; O(c)，c=字符集大小\n字符计数改进1 可以在遍历b字符串的时候不额外记录字符出现次数，而是直接减掉，最后看是不是为0\n1public boolean isPermutation(String a, String b) { 2 if (a.length != b.length) { 3 return false; 4 } 5 int[] charCount = new int[128]; 6 for(int i = 0; i \u0026lt; a.length; i++) { 7 int pos = a.charAt(i); 8 charCount[pos]++; 9 } 10 for(int i = 0; i \u0026lt; b.length; i++) { 11 int pos = b.charAt(i); 12 charCount[pos]--; 13 } 14 for(int i = 0; i \u0026lt; charCount.length; i++) { 15 if (charCount[i] != 0) { 16 return false; 17 } 18 } 19 return true; 20} 时间复杂度：同样是O(n)\n空间复杂度：少了一个数组，但依然是O(c)\n字符计数改进2* 如果a和b的长度一样，但是b不是a的permutation，那么b肯定有一个字符计数比a少，而另一个字符计数比a多，这两个情况是同时出现的，我们只需要看是否b存在一个字符计数比a多。\n1public boolean isPermutation(String a, String b) { 2 if (a.length != b.length) { 3 return false; 4 } 5 int[] charCount = new int[128]; 6 for(int i = 0; i \u0026lt; a.length; i++) { 7 int pos = a.charAt(i); 8 charCount[pos]++; 9 } 10 for(int i = 0; i \u0026lt; b.length; i++) { 11 int pos = b.charAt(i); 12 charCount[pos]--; 13 if (charCount[pos] \u0026lt; 0) { 14 // b比a多了一个字符 15 return false; 16 } 17 } 18 return true; 19} 字符计数改进3 如果字符集比较大，那么我们可以HashMap来做字符计数\n","date":"2019-08-07","img":"","permalink":"/post/cracking-coding-interview/1.2-check-permutation/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 1.2 Check Permutation"},{"categories":null,"content":"Is Unique: Implement an algorithm to determine if a string has all unique characters. What if you cannot use additional data structures?\n例子：\n1String s = \u0026#34;foobarzyx\u0026#34;; // o重复 2String s = \u0026#34;abefzpsln\u0026#34;; // unique Bitmap 如果字符集是26个小写英文字母+26个大些英文字母+10个数字=62个字符，那么可以用bitmap，那可以用int/long作为一个bitmap来记录字母的出现情况。\n1public boolean isUnique(String s) { 2 if (s.length() \u0026lt;= 1) { 3 return true; 4 } 5 long bitmap = 0L; 6 for(int i = 0; i \u0026lt; s.length(); i++) { 7 char c = s.charAt(i); 8 long bit = 1L \u0026lt;\u0026lt; (c - \u0026#39;a\u0026#39;); 9 if (bitmap \u0026amp; bit != 0) { 10 return false; 11 } 12 bitmap |= bit; 13 } 14 return true; 15} 时间复杂度：O(n)\n空间复杂度：O(1)\n先排序再遍历 如果字符集很大，比如说ASCII 256个字符，可以采用先排序再遍历的办法。\n1public boolean isUnique(String s) { 2 if (s.length() \u0026lt;= 1) { 3 return true; 4 } 5 char[] chars = s.charArray(); 6 Arrays.sort(chars); 7 for(int i = 1; i \u0026lt; chars.length; i++) { 8 if (chars[i - 1] == chars[i]) { 9 return false; 10 } 11 } 12 return true; 13} 时间复杂度：排序占用O(nlogn)，遍历O(n)，所以复杂度=O(nlogn)\n空间复杂度：O(n)\n用boolean数组 已知字符集范围（比如128个字符），可以用boolean数组来解决：\n1public boolean isUnique(String s) { 2 if (s.length() \u0026lt;= 1) { 3 return true; 4 } 5 if (s.length() \u0026gt; 128) { 6 // 肯定存在重复 7 return false; 8 } 9 boolean[] flags = new boolean[128]; 10 for(int i = 0; i \u0026lt; s.length(); i++) { 11 int pos = s.charAt(i); 12 if (flags[pos]) { 13 return false; 14 } 15 flags[pos] = true; 16 } 17 return true; 18} 时间复杂度：O(min(c, n))，c=字符集的大小，n=字符串长度，遍历的次数不会超过c\n空间复杂度：O(c)，c=字符集的大小\n","date":"2019-08-07","img":"","permalink":"/post/cracking-coding-interview/1.1-is-unique/","series":null,"tags":["ARTS-A"],"title":"Cracking Coding Interview - 1.1 Is Unique"},{"categories":null,"content":"本人发表在Apache ServiceComb的文章：\nhttp://servicecomb.apache.org/cn/docs/how-to-do-microservice-accept-test/ 同样转载在微服务蜂巢公众号\nhttps://mp.weixin.qq.com/s/jHNmi9z3HIrjVEMhTHXKfw ","date":"2019-07-23","img":"","permalink":"/post/how-to-do-microservice-accept-test/","series":null,"tags":["ci_cd","微服务"],"title":"如何给微服务架构的项目做验收测试？"},{"categories":null,"content":"概览 设计思路探究 用一系列问题和回答来探究Redis Cluster的设计思路，下图中绿色的是问题，蓝色的是回答，实现箭头代表由这个回答引申出新的问题，虚线尖头是两个回答之间存在关联。\n","date":"2019-07-12","img":"","permalink":"/post/redis/redis-cluster-design-summary/","series":null,"tags":["redis","分布式算法"],"title":"Redis Cluster设计学习总结"},{"categories":null,"content":"本笔记是对Redis Cluster Spec - Configuration handling, propagation, and failovers 的归纳总结。\nEpoch 因为Redis Cluster没有中心节点，因此Cluster中的每个Node都存有：1）自己的状态（ClusterNode源码 ）；2）Cluster的状态（ClusterState源码 ）。换句话说每个Node都有一个自己的视角来观察Cluster。\n如果大家眼中看到的是一致的自然没有什么问题，如果不一致怎么办？Redis Cluster用是Epoch来解决。那么Epoch是什么？Epoch翻译过来的意思是时代。Redis Cluster定下了规矩，旧时代的说了不算，要听新时代的，某些情况下旧时代发来的请求不予理会（比如一个死了很久的Master复活）。\n你可以看到Cluster状态中有一个currentEpoch字段，意思是整个集群当前的时代。考虑到这个Cluster状态是Node从自己的视角观察到的，因此也可以认为是这个Node所处的时代。\nNode状态中有一个configEpoch字段，意思并非这个Node所处的时代，而是用来表示Slots由哪个Node掌管的意思——回忆一下有一个Slots-\u0026gt;Node的Map。\n集群状态发生变更就要产生一个新时代，准确点说当发生Slots易主的情况就要产生一个新时代。你可以理解为Cluster就是当今世界，Slots易主就是世界格局发生变更，每一次变更都是一个新时代。\nRedis Cluster中的Node通过Gossip协议传播自己的状态+自己所认为的Cluster的状态，传播过程中都会带上configEpoch和currentEpoch（ClusterMsg源码 ），运用旧时代听新时代的规则，使得Node们达成一致，也就是Cluster状态达成一致。\n下面是一些实现细节的总结：\n Epoch是一个64位无符号整形 每个Master有自己的ConfigEpoch且在整个Cluster中唯一、Slave的ConfigEpoch随其Master CurrentEpoch = max(ConfigEpoch) Master的ConfigEpoch初始值是0，也就是说CurrentEpoch的初始值也是0  Slave Promotion Slave的动作 下面是总结的在发生Slave Promotion时，Slave做的事情。\nMaster的动作 下面是总结的在发生Slave Promotion时，Master做的事情。\n传播Slots的配置 Slave赢得选举之后会在己侧更新Slots上的归属信息，然后在定时的PING/PONG中将这个信息传播出去。\nPING/PONG总是会携带上Slots所属Master的信息（包括ConfigEpoch）\nPING的Reciever如果发现Sender的某个Slot上的Master.ConfigEpoch比自己这里记录的小，那么就会返回UPDATE告诉Sender更新Slots归属信息。\n下面是两个规则：\n 如果一个Slot不属于任何Master，然后有一个Master宣称拥有它，那么就修改己侧的Slots信息把这个Slot关联到这个Master上。 如果一个Slot已经归属一个Master，然后又有一个Master宣称拥有它，那么就看谁的ConfigEpoch大，大的那个赢  Node复活后遇到的问题 Node A有两个Slot，然后它死了，它被顶替了，等它复活时发现两个Slot一个被Node B接管，另一个被Node C接管了，那么它：\n 因为自己的ConfigEpoch已经很旧了，所以它复活后不负责任何Slot 然后它会成为最后一个Slot的Master的Slave  Slave迁移算法 Slave迁移时一个自动过程。\n举个例子，现在有Master A、B，它们对应的Slave有A1、B1、B2。现在A死了，A1顶替上去，不过这个时候A1就是一个光棍Master（它没有Slave），B有富余的Slave（B1和B2），把其中一个匀给A1当Slave。\n这个过程不需要共识，因为只是修改Slave的归属，也不会修改ConfigEpoch。\nSlave迁移有两个规则：\n 当有多个Slave富余时，选择NodeID字典顺最小的那个来迁移 只有当Master的Slave数量\u0026gt;=cluster-migration-barrier时，才会挑选它的Slave做Migration  两个跳过共识修改ConfigEpoch的操作 下面两个操作比较危险，最好确定一个成功后再执行另一个：\n CLUSTER_FAILOVER TAKEOVER（手动Failover）直接将一个Slave提升为Master，不需要大多数Master同意。 Slot Migration同样不需要大多数Master同意。  所以就有可能出现同一个Slot有两个相同ConfigEpoch的Master宣称由自己负责，这种冲突的解决算法是：\n 如果Master A发现Master B也宣称了对Slot X的主权，并且两者的ConfigEpoch一样 如果Master A的NodeID的字典顺比Master B的小 那么Master A就把己侧的CurrentEpoch+1，同时ConfigEpoch改成和CurrentEpoch一样  Node重置 略，见文档 。\n移除Node 略，见文档 。\n一些自问自答 Q：ConfigEpoch何时变化？\nA：Slave Promotion时、手动Failover时、Slot Migration时\nQ：ConfigEpoch怎么变化？\nA：Node-\u0026gt;ConfigEpoch = Cluster-\u0026gt;CurrentEpoch + 1，结果也就是Cluster-\u0026gt;CurrentEpoch加1了。源码见这里 。\nQ：两个Master的ConfigEpoch一样怎么办？\nA：这个会出现在两个Slave同时Promotion时，解决办法是NodeID字典序比较小的那个会再一次Bump ConfigEpoch，源码见这里 。\nQ：ConfigEpoch有什么用？\nA：当有两个Master宣称自己拥有同一个/批Slot时，ConfigEpoch大的那个赢，因为大的那个代表最新信息，其他Node只会采用赢的那方所宣称的信息。\nQ：CurrentEpoch有什么用？\nA：1）用来判定Node所获得的Cluster信息的新旧。2）当Node要变更ConfigEpoch时派用处。\n参考资料 官方文档，有些不是太清楚：\n Redis Cluster Spec - Configuration handling, propagation, and failovers   下面是饿了么工程师写的文章，比较透彻\n Redis Cluster 原理与管理   下面是两篇阿里工程师的，写的没有上面的好\n 深入理解redis cluster的failover机制  深入解析redis cluster gossip机制  ","date":"2019-07-10","img":"","permalink":"/post/redis/redis-cluster-config-propagation/","series":null,"tags":["redis","分布式算法"],"title":"Redis Cluster配置传播及故障恢复笔记"},{"categories":null,"content":"本笔记是对Redis Cluster Spec - Failure Detection 的归纳总结\n状态转换图  每个Node在本地维护了一张其他Node的状态表，并根据Failure Detection算法更新这张表里的Node的状态 修改Node状态表里的Node的状态为GOOD（在文档中称之为Clear Flags）、PFAIL，不需要共识（大多数Master Node同意）。 修改Node状态表里的Node的状态为FAIL则需要共识，一旦设置成功要将这个消息传播给所有能连接的Node，其他Node收到这个信息后也要更新本地Node状态表，将对应Node的状态更新为FAIL。  下面是状态转换图，例举的是Node A观察Node B的例子：\n少数派和多数派 多数派：拥有多数Master的一方，可含有Slave。\n少数派：拥有少数Master的一方，可含有Slave。\n少数派视角 少数派只会看到大多数Master处于PFAIL/FAIL状态，0-所有Slave处于PFAIL/FAIL状态。\n多数派视角 多数派只会看到少数Master处于PFAIL/FAIL状态，0-所有Slave处于PFAIL/FAIL状态。\n不会存在以下情况：多数派看到大多数Master处于FAIL状态，因为大多数Master处于FAIL就意味着活着的Master们变成了少数派，这就矛盾了。\n一些自问自答 Q：为何少数派能够看到Master处于FAIL状态？不是说要大多数Master同意才能变成FAIL状态吗？ A：考虑这个情况，在Partition发生的前一秒某些Master被决定为FAIL，随即Partition发生，那么在少数派眼里这些Master依然是处于FAIL状态的。\nQ：这里的每个Node是Slave还是Master呢？ A：随便，只要是Node就行。\nQ：既然每个Master独占的负责Slots，那么少数派继续工作为啥不可以，反正各自管各自的。 A：因为在多数派方，这个Master有可能会被Slave顶替，如果允许少数派继续工作，那么就会形成两个Master，造成split brain\nQ：少数派节点是如何知道自己应该停止工作的？ A：它发现大多数Master变成了PFAIL / FAIL 状态时，就知道自己不能工作了，Redis源码里是这么写的 。\nQ：多数派节点时如何知道自己应该停止工作的？ A：如果这个Cluster要求所有Slots被覆盖，那么当有一个Master处于FAIL状态时，便停止工作，见源码 。如果不要求，则继续工作，只不过部分Slots的操作会报错。\n","date":"2019-07-09","img":"","permalink":"/post/redis/redis-cluster-node-failure-detection/","series":null,"tags":["redis","分布式算法"],"title":"Redis Cluster节点故障探测算法笔记"},{"categories":null,"content":"本文对应代码：github 用Docker部署基于GTID的MySQL Master-Slave Replication例子。\n启动Master 写一个文件mysql-master.cnf：\n1[mysqld] 2server_id=1 3binlog_format=ROW 4gtid_mode=ON 5enforce-gtid-consistency=true 这个配置文件把Master的server_id设置为1，要注意在同一个Master-Slave集群里，server_id不能重复。\n启动Master：\n1docker run -d --name mysql-master \\ 2 -e MYSQL_USER=my_user \\ 3 -e MYSQL_DATABASE=my_database \\ 4 -e MYSQL_PASSWORD=my_database_password \\ 5 -e MYSQL_ROOT_PASSWORD=my_root_password \\ 6 -p 3307:3306 \\ 7 -v $(pwd)/mysql-master.cnf:/etc/mysql/conf.d/mysql-master.cnf \\ 8 mysql:8.0 \\ 9 --log-bin=my 启动Slave 写一个文件mysql-slave-1.cnf：\n1[mysqld] 2server_id=2 3binlog_format=ROW 4gtid_mode=ON 5enforce-gtid-consistency=true 6read_only=ON 这个文件把Slave的server_id设置为2，如果你有多个Slave，那么得分别设置不同的server_id。此外，将Slave设置为read_only模式（这样就不能在slave上执行写操作了）。\n启动Slave：\n1docker run -d --name mysql-slave-1 \\ 2 -e MYSQL_ROOT_PASSWORD=my_root_password \\ 3 -p 3308:3306 \\ 4 -v $(pwd)/mysql-slave-1.cnf:/etc/mysql/conf.d/mysql-slave-1.cnf \\ 5 mysql:8.0 \\ 6 --skip-log-bin \\ 7 --skip-log-slave-updates \\ 8 --skip-slave-start 创建Replication用户 到Master上创建Replication用户：\n1$ docker exec -it mysql-master mysql -u root -p 2Enter password: my_root_password 3 4mysql\u0026gt; CREATE USER \u0026#39;repl\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;password\u0026#39;; 5mysql\u0026gt; GRANT REPLICATION SLAVE ON *.* TO \u0026#39;repl\u0026#39;@\u0026#39;%\u0026#39;; 将Slave和Master关联 到Slave上把自己和Master关联起来：\n1$ docker exec -it mysql-slave-1 mysql -u root -p 2Enter password: my_root_password 3 4mysql\u0026gt; CHANGE MASTER TO 5 MASTER_HOST=\u0026#39;192.168.101.21\u0026#39;, 6 MASTER_PORT=3307, 7 MASTER_USER=\u0026#39;repl\u0026#39;, 8 MASTER_PASSWORD=\u0026#39;password\u0026#39;, 9 GET_MASTER_PUBLIC_KEY=1, 10 MASTER_AUTO_POSITION=1; 注意MASTER_HOST写的是Master所在的Host的IP，MASTER_PORT写的是Master暴露在Host上的端口，MASTER_USER和MASTER_PASSWORD则是Replication用户的信息。\n最后正式启动Slave：\n1mysql\u0026gt; START SLAVE; 验证 到Slave上看看my_database是否存在：\n1$ docker exec -it mysql-slave-1 mysql -u root -p 2Enter password: my_root_password 3 4mysql\u0026gt; show databases; 5+--------------------+ 6| Database | 7+--------------------+ 8| information_schema | 9| my_database | 10| mysql | 11| performance_schema | 12| sys | 13+--------------------+ 145 rows in set (0.01 sec) 如果有就说明my_database从Master复制到了Slave上。\ndocker-compose版本 在github 上也提供了docker-compose.yaml，操作过程和上述一致，只不过容器名字会有变化。\n1# 拉起Master和Slave 2$ docker-compose -p mysql-repl up 3# 连接Master 4$ docker exec -it mysql-repl_mysql-master_1 mysql -u root -p 5# 连接Slave 6$ docker exec -it mysql-repl_mysql-slave_1 mysql -u root -p 并且CHANGE MASTER TO语句有所不同，使用的是Master的Service Name以及容器内端口3306：\n1CHANGE MASTER TO 2 MASTER_HOST=\u0026#39;mysql-master\u0026#39;, 3 MASTER_PORT=3306, 4 MASTER_USER=\u0026#39;repl\u0026#39;, 5 MASTER_PASSWORD=\u0026#39;password\u0026#39;, 6 GET_MASTER_PUBLIC_KEY=1, 7 MASTER_AUTO_POSITION=1; Troubleshooting docker run版本在Mac上无法工作 这个是因为Slave容器无法访问到Master的host。解决办法我也不知道。\n关于GET_MASTER_PUBLIC_KEY 在做本例子时出现过Slave无法连接到Master的情况：\n12019-06-19T01:34:24.361566Z 8 [System] [MY-010597] [Repl] \u0026#39;CHANGE MASTER TO FOR CHANNEL \u0026#39;\u0026#39; executed\u0026#39;. Previous state master_host=\u0026#39;\u0026#39;, master_port= 3306, master_log_file=\u0026#39;\u0026#39;, master_log_pos= 4, master_bind=\u0026#39;\u0026#39;. New state master_host=\u0026#39;mysql-master\u0026#39;, master_port= 3306, master_log_file=\u0026#39;\u0026#39;, master_log_pos= 4, master_bind=\u0026#39;\u0026#39;. 22019-06-19T01:34:28.274728Z 9 [Warning] [MY-010897] [Repl] Storing MySQL user name or password information in the master info repository is not secure and is therefore not recommended. Please consider using the USER and PASSWORD connection options for START SLAVE; see the \u0026#39;START SLAVE Syntax\u0026#39; in the MySQL Manual for more information. 32019-06-19T01:34:28.330825Z 9 [ERROR] [MY-010584] [Repl] Slave I/O for channel \u0026#39;\u0026#39;: error connecting to master \u0026#39;repl@mysql-master:3306\u0026#39; - retry-time: 60 retries: 1, Error_code: MY-002061 42019-06-19T01:35:28.333735Z 9 [ERROR] [MY-010584] [Repl] Slave I/O for channel \u0026#39;\u0026#39;: error connecting to master \u0026#39;repl@mysql-master:3306\u0026#39; - retry-time: 60 retries: 2, Error_code: MY-002061 52019-06-19T01:36:28.335525Z 9 [ERROR] [MY-010584] [Repl] Slave I/O for channel \u0026#39;\u0026#39;: error connecting to master \u0026#39;repl@mysql-master:3306\u0026#39; - retry-time: 60 retries: 3, Error_code: MY-002061 6... 详细细节可见这个issue ，这是因为MySQL 8默认启用了caching_sha2_password authentication plugin，issue中提到了一个办法：在启动Slave的时候添加--default-auth=mysql_native_password参数。不过我感觉这个不太好，查阅相关文档后发现可以在CHANGE MASTER TO添加GET_MASTER_PUBLIC_KEY=1参数来解决这个问题。\n更多详情参考caching_sha2_password and Replication 和CHANGE MASTER TO Syntax 。\n参考资料   Setting Up Replication Using GTIDs   Binary Logging Options and Variables   Replication Slave Options and Variables   DNS Lookup Optimization and the Host Cache   CHANGE MASTER TO Syntax   caching_sha2_password and Replication   Bitnami MySQL Docker , Bitnami制作的MySQL镜像，支持通过环境变量来配置Master-Slave Replication，不过它不支持GTID，只支持基于Binary Log的Replication。\n ","date":"2019-06-18","img":"","permalink":"/post/mysql-master-slave-docker-example/","series":null,"tags":["docker","mysql"],"title":"MySQL Master Slave Docker部署例子"},{"categories":null,"content":"本文介绍Spring Boot连接Redis Sentinel 的例子。\n本文关联的源码：github 基本信息 拓扑（M代表redis-master，S代表redis-sentinel，R代表redis-slave，C代表Spring Boot Application）：\n1 +---------------------------+ 2 | | 3 +-----+ +-----+ +-----+ 4 | M |-------| S |-------| R | 5 +-----+ +-----+ +-----+ 6 | | 7 | +-----+ 8 +----------| C | 9 +-----+ application.yaml配置：\n1spring:2redis:3# host: redis-master4# port: 63795password:abc6sentinel:7master:springboot8nodes:9- redis-sentinel:26379注意这里不需要配置master的host和port，这些信息会从Redis Sentinel中得到。\n演示步骤 打包并构建镜像：mvn clean install dockerfile:build\n进入docker目录，执行docker-compose up -d\n观察Spring Boot Application的日志：docker logs -f docker_spring-boot_1，会发现每隔3秒执行INCR foo：\n107:53:49.205 INFO hello.Application : INCR foo: 1 207:53:52.212 INFO hello.Application : INCR foo: 2 307:53:55.213 INFO hello.Application : INCR foo: 3 407:53:58.216 INFO hello.Application : INCR foo: 4 507:54:01.217 INFO hello.Application : INCR foo: 5 停止redis-master：docker stop docker_redis-master_1，会看到Spring Boot Application的Redis链接出现了问题：\n107:54:37.206 INFO hello.Application : INCR foo: 17 207:54:40.204 INFO hello.Application : INCR foo: 18 307:54:42.238 INFO i.l.core.protocol.ConnectionWatchdog : Reconnecting, last destination was /10.0.19.4:6379 407:54:52.247 WARN i.l.core.protocol.ConnectionWatchdog : Cannot reconnect: io.netty.channel.ConnectTimeoutException: connection timed out: /10.0.19.4:6379 5... 607:55:22.560 INFO i.l.core.protocol.ConnectionWatchdog : Reconnecting, last destination was 10.0.19.4:6379 707:55:22.842 WARN i.l.core.protocol.ConnectionWatchdog : Cannot reconnect: io.netty.channel.AbstractChannel$AnnotatedNoRouteToHostException: Host is unreachable: /10.0.19.4:6379 8... 907:55:29.582 INFO i.l.core.protocol.ConnectionWatchdog : Reconnecting, last destination was 10.0.19.4:6379 1007:55:32.353 WARN i.l.core.protocol.ConnectionWatchdog : Cannot reconnect: io.netty.channel.AbstractChannel$AnnotatedNoRouteToHostException: Host is unreachable: /10.0.19.4:6379 11... 等待大约60秒，Redis Sentinel介入，将redis-slave提拔为master，链接恢复：\n107:55:43.860 INFO i.l.core.protocol.ConnectionWatchdog : Reconnecting, last destination was 10.0.19.4:6379 207:55:43.882 INFO i.l.core.protocol.ReconnectionHandler : Reconnected to 10.0.19.6:6379 307:55:43.887 INFO hello.Application : INCR foo: 20 407:55:43.889 INFO hello.Application : INCR foo: 21 507:55:43.891 INFO hello.Application : INCR foo: 22 607:55:43.892 INFO hello.Application : INCR foo: 23 此时拓扑变成这样：\n1 +-------------//------------+ 2 | | 3 +-----+ +-----+ +-----+ 4 | M |--//---| S |-------| [M] | 5 +-----+ +-----+ +-----+ 6 | | | 7 | +-----+ | 8 +----//----| C |----------+ 9 +-----+ 清理容器：docker-compose down。\nMaster重启之后的问题 这个问题和Spring Boot没有关系，是Redis本身的。如果我们把前面停掉的master重启，sentinel是不会感知到这个master的，因为这个master的ip变了（见这个comment ）：\n你可以观察重启之以后的master的INFO：\n1$ docker exec docker_redis-master_1 redis-cli -a abc INFO replication 2# Replication 3role:master 4... 可以看到它启动之后还是master，不是slave。这样的话就等于出现了两个master，这就出问题了。\nBTW，redis的配置中可以使用hostname，比如slaveof redis-master。但是redis-sentinel，使用的是ip，即使你配置的是hostname，最终也是ip。执行下面命令可以看见sentinel的配置：\n1$ docker exec docker_redis-sentinel_1 cat /bitnami/redis-sentinel/conf/sentinel.conf | grep springboot 2 3sentinel monitor springboot 10.0.25.2 6379 1 4sentinel down-after-milliseconds springboot 60000 5sentinel auth-pass springboot abc 6sentinel config-epoch springboot 0 7sentinel leader-epoch springboot 0 8sentinel known-slave springboot 10.0.25.5 6379 解决办法1：使用host network 使用host network来部署redis-master、redis-slave，使用\u0026lt;host-ip\u0026gt;:\u0026lt;container-port\u0026gt;来访问它们，因为host的ip是比较固定的，可以缓解这个问题。\n用host network则还有一个限制：不能在同一个host上启动两个相同container-port的容器。\n解决办法2：publish端口 把redis-master、redis-slave的端口publish到host上，redis.config中把slave-announce-ip和slave-announce-port设置为host-ip和host-port，最后使用\u0026lt;host-ip\u0026gt;:\u0026lt;host-port\u0026gt;访问，同样也是利用host的ip固定特性来解决这个问题。\n","date":"2019-06-14","img":"","permalink":"/post/redis/redis-sentinel-spring-boot-example/","series":null,"tags":["redis","spring-boot"],"title":"Spring Boot配置Redis Sentinel的例子"},{"categories":null,"content":"Doc  Introducing CFSSL - CloudFlare\u0026rsquo;s PKI toolkit  cfssl bootstrap ，这个文档里面有错误 cfssl config ，列出了config.json所有的字段 db-config.json ，db-config.json的样子，亲测mysql不行，有bug remote_auth ，bootstrap文档中的一个错误，用remote_auth  CRL   CRL Support ，稍微解释了一下CFSSL怎么支持CRL的，但是并没有什么用\n  cfssl使用十进制而不是十六进制来读取serial number   How Tos  How to build your own public key infrastructure ，可以大致看一看，有些地方有错误 Certificate Authority with CFSSL ，讲了怎么利用Intermediate CA签发 Integration of CFSSL with the Lemur Certificate Manager ，CFSSL和Lemur CM集成的例子，也讲了怎么做Intermediate CA ","date":"2019-05-02","img":"","permalink":"/post/cfssl-notes/","series":null,"tags":["openssl"],"title":"CFSSL笔记"},{"categories":null,"content":"证书链  Get your certificate chain right ，解释了什么是证书链、怎么做证书链、怎么验证证书链  How Tos 格式转换：\n Converting Certificates Using OpenSSL  How to convert a certificate into the appropriate format   校验验证：\n Some list of openssl commands for check and verify your keys  ","date":"2019-05-02","img":"","permalink":"/post/openssl-notes/","series":null,"tags":["openssl"],"title":"OpenSSL笔记"},{"categories":null,"content":"ASN.1 - 数据结构描述语言 引用自Wiki ：\n ASN.1 is a standard interface description language for defining data structures that can be serialized and deserialized in a cross-platform way.\n 也就是说ASN.1是一种用来定义数据结构的接口描述语言，它不是二进制，也不是文件格式，看下面的例子你就会明白了：\n1FooQuestion ::= SEQUENCE { 2 trackingNumber INTEGER, 3 question IA5String 4} 这段代码定义了FooQuestion的数据结构，下面是FooQuestion这个数据接口的某个具体的数据：\n1myQuestion FooQuestion ::= SEQUENCE { 2 trackingNumber 5, 3 question \u0026#34;Anybody there?\u0026#34; 4} ASN.1用在很多地方比如下面要讲的X.509 和PKCS group of cryptography standards 。\n文件编码格式 DER编码格式 引用自Wiki ：\n ASN.1 is closely associated with a set of encoding rules that specify how to represent a data structure as a series of bytes\n 意思是ASN.1有一套关联的编码规则，这些编码规则用来规定如何用二进制来表示数据结构，DER 是其中一种。\n把上面的FooQuestion的例子用DER编码则是（16进制）：\n130 13 02 01 05 16 0e 41 6e 79 62 6f 64 79 20 74 68 65 72 65 3f 翻译过来就是：\n130 — type tag indicating SEQUENCE 213 — length in octets of value that follows 3 02 — type tag indicating INTEGER 4 01 — length in octets of value that follows 5 05 — value (5) 6 16 — type tag indicating IA5String 7 (IA5 means the full 7-bit ISO 646 set, including variants, 8 but is generally US-ASCII) 9 0e — length in octets of value that follows 10 41 6e 79 62 6f 64 79 20 74 68 65 72 65 3f — value (\u0026#34;Anybody there?\u0026#34;) 看到这里你应该对DER编码格式有一个比较好的认识了。\nPEM编码格式 引用自Wiki ：\n Privacy-Enhanced Mail (PEM) is a de facto file format for storing and sending cryptographic keys, certificates, and other data, based on a set of 1993 IETF standards defining \u0026ldquo;privacy-enhanced mail.\u0026rdquo;\n PEM是一个用来存储和发送密码学key、证书和其他数据的文件格式的事实标准。许多使用ASN.1的密码学标准（比如X.509 和PKCS ）都使用DER编码，而DER编码的内容是二进制的，不适合与邮件传输（早期Email不能发送附件），因此使用PEM把二进制内容转换成ASCII码。文件内容的格式像下面这样：\n1-----BEGIN label----- 2BASE64Encoded 3-----END label----- label用来区分内容到底是什么类型，下面会讲。\n和PEM相关的RFC有很多，与本文内容相关的则是RFC7468 ，这里面规定了很多label，不过要注意不是所有label都会有对应的RFC或Specification，这些label只是一种约定俗成。\nPEM实际上就是把DER编码的文件的二进制内容用base64编码一下，然后加上-----BEGIN label-----这样的头和-----END label-----这样的尾，中间则是DER文件的Base64编码。\n我们可以通过下面的方法验证这个结论，先生成一个RSA Private Key，编码格式是PEM格式：\n1openssl genrsa -out key.pem 查看一下文件内容，可以看到label是RSA PRIVATE KEY：\n1-----BEGIN RSA PRIVATE KEY----- 2BASE64Encoded 3-----END RSA PRIVATE KEY----- 然后我们把PEM格式转换成DER格式：\n1openssl rsa -in key.pem -outform der -out key.der 如果你这个时候看一下文件内容会发现都是二进制。然后我们把DER文件的内容Base64一下，会看到内容和PEM文件一样（忽略头尾和换行）：\n1base64 -i key.der -o key.der.base64 证书、密码学Key格式 上面讲到的PEM是对证书、密码学Key文件的一种编码方式，下面举例这些证书、密码学Key文件格式：\nX.509证书 引用自Wiki ：\n In cryptography, X.509 is a standard defining the format of public key certificates. X.509 certificates are used in many Internet protocols, including TLS/SSL, which is the basis for HTTPS, the secure protocol for browsing the web.\n X.509是一个Public Key Certificates 的格式标准，TLS/SSL使用它，TLS/SSL是HTTPS的基础所以HTTPS也使用它。而所谓Public Key Certificates 又被称为Digital Certificate 或 Identity Certificate。\n An X.509 certificate contains a public key and an identity (a hostname, or an organization, or an individual), and is either signed by a certificate authority or self-signed.\n 一个X.509 Certificate包含一个Public Key和一个身份信息，它要么是被CA签发的要么是自签发的。\n下面这种张图就是一个X.509 Certificate：\n事实上X.509 Certificate这个名词通常指代的是IETF的PKIX Certificate和CRL Profile，见RFC5280 。所以当你看到PKIX Certificate字样的时候可以认为就是X.509 Certificate。\nPKCS系列 引用自Wiki ：\n In cryptography, PKCS stands for \u0026ldquo;Public Key Cryptography Standards\u0026rdquo;\n 前面提到的X.509是定义Public Key Certificates的格式的标准，看上去和PKCS有点像，但实际上不同，PKCS是Public Key密码学标准。此外Public-Key Cryptography 虽然名字看上去只涉及Public Key，实际上也涉及Priviate Key，因此PKCS也涉及Private Key。\nPKCS一共有15个标准编号从1到15，这里只挑讲PKCS #1、PKCS #8、PKCS #12。\nPKCS #1 PKCS #1，RSA Cryptography Standard，定义了RSA Public Key和Private Key数学属性和格式，详见RFC8017 。\nPKCS #8 PKCS #8，Private-Key Information Syntax Standard，用于加密或非加密地存储Private Certificate Keypairs（不限于RSA），详见RFC5858 。\nPKCS #12 PKCS #12定义了通常用来存储Private Keys和Public Key Certificates（例如前面提到的X.509）的文件格式，使用基于密码的对称密钥进行保护。注意上述Private Keys和Public Key Certificates是复数形式，这意味着PKCS #12文件实际上是一个Keystore，PKCS #12文件可以被用做Java Key Store （JKS），详见RFC7292 。\n如果你用自己的CA所签发了一个证书，运行下列命令可以生成PKCS #12 keystore：\n1openssl pkcs12 -export \\ 2 -in \u0026lt;cert\u0026gt; \\ 3 -inkey \u0026lt;private-key\u0026gt; \\ 4 -name my-cert \\ 5 -caname my-ca-root \\ 6 -CAfile \u0026lt;ca-cert\u0026gt; \\ 7 -chain 8 -out \u0026lt;pkcs-file\u0026gt; PKCS #12一般不导出PEM编码格式。\nPEM格式速查 当你不知道你的PEM文件内容是什么格式的可以根据下面查询。\nX.509 Certificate RFC7468 - Textual Encoding of Certificates 1-----BEGIN CERTIFICATE----- 2BASE64Encoded 3-----END CERTIFICATE----- X.509 Certificate Subject Public Key Info RFC7468 - Textual Encoding of Subject Public Key Info 1-----BEGIN PUBLIC KEY----- 2BASE64Encoded 3-----END PUBLIC KEY----- PKCS #1 Private Key 没有RFC或权威Specification，该格式有时候被称为traditional format、SSLeay format（见SO ）\n1-----BEGIN RSA PRIVATE KEY----- 2BASE64Encoded 3-----END RSA PRIVATE KEY----- PKCS #1 Public Key 同上没有RFC或权威Specification\n1-----BEGIN RSA PUBLIC KEY----- 2BASE64Encoded 3-----END RSA PUBLIC KEY----- PKCS #8 Unencrypted Private Key RFC7468 - One Asymmetric Key and the Textual Encoding of PKCS #8 Private Key Info 1-----BEGIN PRIVATE KEY----- 2BASE64Encoded 3-----END PRIVATE KEY----- PKCS #8 Encrypted Private Key RFC7468 - Textual Encoding of PKCS #8 Encrypted Private Key Info 1-----BEGIN ENCRYPTED PRIVATE KEY----- 2BASE64Encoded 3-----END ENCRYPTED PRIVATE KEY----- Private Key操作命令 生成 生成PKCS #1格式的RSA Private Key\n1openssl genrsa -out private-key.p1.pem 2048 转换 PKCS #1 -\u0026gt; Unencrypted PKCS #8\n1openssl pkcs8 -topk8 -in private-key.p1.pem -out private-key.p8.pem -nocrypt PKCS #1 -\u0026gt; Encrypted PKCS #8\n1openssl pkcs8 -topk8 -in private-key.p1.pem -out private-key.p8.pem 过程中会让你输入密码，你至少得输入4位，所以PKCS #8相比PKCS #1更安全。\nPKCS #8 -\u0026gt; PKCS #1\n1openssl rsa -in private-key.p8.pem -out private-key.p1.pem 如果这个PKCS #8是加密的，那么你得输入密码。\nPKCS #8 Unencrypted -\u0026gt; PKCS #8 Encrypted\n1openssl pkcs8 -topk8 -in private-key.p8.nocrypt.pem -out private-key.p8.crypt.pem 过程中会让你输入密码，你至少得输入4位。\nPKCS #8 Encrypted -\u0026gt; PKCS #8 Unencrypted\n1openssl pkcs8 -topk8 -in private-key.p8.crypt.pem -out private-key.p8.nocrypt.pem -nocrypt 过程中会要求你输入Private Key密码。\nPublic Key操作命令 从PKCS #1/#8提取 提取指的是从Private Key中提取Public Key，openssl rsa同时支持PKCS #1和PKCS #8的RSA Private Key，唯一的区别是如果PKCS #8是加密的，会要求你输入密码。\n提取X.509格式RSA Public Key\n1openssl rsa -in private-key.pem -pubout -out public-key.x509.pem 提取PKCS #1格式RSA Public Key\n1openssl rsa -in private-key.pem -out public-key.p1.pem -RSAPublicKey_out 从X.509证书提取 1openssl x509 -in cert.pem -pubkey -noout \u0026gt; public-key.x509.pem 转换 X.509 RSA Public Key -\u0026gt; PKCS #1 RSA Public Key\n1openssl rsa -pubin -in public-key.x509.pem -RSAPublicKey_out -out public-key.p1.pem PKCS #1 RSA Public Key -\u0026gt; X.509 RSA Public Key\n1openssl rsa -RSAPublicKey_in -in public-key.p1.pem -pubout -out public-key.x509.pem 参考资料  OpenSSL Cookbook ，一本免费介绍OpenSSL的电子书 PKCS #1, PKCS #8, X.509 ，提供了很多格式转换的例子 ","date":"2019-04-27","img":"","permalink":"/post/tls/x509-pkcs-file-formats/","series":null,"tags":["java","tls","openssl"],"title":"X.509、PKCS文件格式介绍"},{"categories":null,"content":"本文基于Spring Cloud Gateway 2.1.1.RELEASE。\n在讲SCG的Filter的排序问题之前得先比较一下Spring Cloud Gateway在对待Filter的方面与Zuul2有着哪些不同。\nFilter的Scope  SCG采用的是Global Filter和Route Filter相结合的方式 Zuul2则都是Global Filter  SCG所谓Route Filter就是像下面这样的：\n1spring:2cloud:3gateway:4routes:5- id:tomcat_route6uri:http://tomcat:80807predicates:8- Path=/tomcat/docs9filters:10- StripPrefix=111- RemoveRequestHeader=X-Request-Foo上面的StripPrefix和RemoveRequestHeader就是Route Filter，而SCG的Global Filter则是隐式的，无需显式配置，它们会在请求过来的时候被SCG调用。\n也就是说你可以配置不同的Route，然后为每个Route配置不同的Route Filter，这一切都是在配置阶段就决定下来的。\n而Zuul2则都是Global Filter，因此你得运行时在每个Filter内部自己决定是否要干活，除此之外，发送到Origin（被代理的服务）的url也得你自己设置，下面是一个例子（来自Zuul2 Sample ）：\n1public class Routes extends HttpInboundSyncFilter { 2 @Override 3 public boolean shouldFilter(HttpRequestMessage httpRequestMessage) { 4 // ... 5 return true; 6 } 7 @Override 8 public HttpRequestMessage apply(HttpRequestMessage request) { 9 // ... 10 // Route healthchecks to the healthcheck endpoint.; 11 context.setEndpoint(ZuulEndPointRunner.PROXY_ENDPOINT_FILTER_NAME); 12 context.setRouteVIP(\u0026#34;tomcat\u0026#34;); 13 14 return request; 15 } 16} Filter的角色  在SCG概念中只有一种Filter（撇开Global和Route的区别），它用代码来区分Pre Filter、Post Filter。在文档中还提到了Routing Filter，其实也是Pre Filter。 Zuul2在代码中显示得提供了InboundFilter（负责进来的请求）、OutboundFilter（负责出去的响应）、ProxyEndpoint（负责请求到Origin，串起Inbound和Outbound）。  下面是SCG的Pre Filter（裁剪自官方例子12.2 Writing Custom GatewayFilter Factories ）：\n1public class PreGatewayFilterFactory extends AbstractGatewayFilterFactory { 2\t@Override 3\tpublic GatewayFilter apply(Config config) { 4\treturn (exchange, chain) -\u0026gt; { 5 // business logic 6 return chain.filter(); 7\t}; 8\t} 9} Post Filter的例子：\n1public class PostGatewayFilterFactory extends AbstractGatewayFilterFactory { 2\t@Override 3\tpublic GatewayFilter apply(Config config) { 4\treturn (exchange, chain) -\u0026gt; { 5\treturn chain.filter(exchange).then(/* business logic */); 6\t}; 7\t} 8} 在Zuul2里，你则得分别实现HttpInboundSyncFilter和HttpOutboundSyncFilter，ProxyEndpoint不需要你自己实现。\nSCG Filter的问题 SCG的优点很明显，它做了Zuul2不做的事情：\n 替你决定进来的请求转发到哪个Origin。在Zuul2里这个交给你自己来实现。 在配置上就决定了这个Route会应用哪些Filter。在Zuul2里这个交给你自己来判断。  但是随着对SCG的深入了解，发现了关于Filter的执行顺序存在一些坑，如果不了解清楚会容易出错。\nFilter的排序 前面讲了，SCG在执行过程中Global Filter和Route Filter是一起执行的，那么它们的order是怎样的？\n先来看看Global Filter，你可以访问/actuator/gateway/globalfilters（见文档 ）得到Global Filter的排序：\n那么如果你写了一个自定义 Global Filter，那么它的order是什么呢？这个要看情况：\n 如果你的自定义Global Filter实现了Ordered接口或者写了@Order注解，那么它的order就是它自己设定的值 否则，它就没有order  关于这点可以看FilteringWebHandler.java的源代码 。\n再来看看Route Filter，这也分两种情况：\n 如果RouteFilter实现了Ordered接口或者写了@Order注解，那么它的order就是它自己设定的值。 否则，它的order则是从1开始，按照Route中定义的顺序依次排序。  关于这点可以看RouteDefinitionRouteLocator.java的源代码 。\n最后SCG把它们两个结合起来，做一个排序，对于没有order的Filter，它的order则默认为Ordered.LOWEST_PRECEDENCE。关于这点可以看FilteringWebHandler.java的源代码 。\n用一张图做总结：\nFilter的执行顺序 先看SCG文档3. How It Works 中的这张图：\n这张图大概告诉你了SCG的调用过程，可以看到经过了一堆Filters，但是并没有告诉你Filter的执行顺序。然后在SCG的6.1 Combined Global Filter and GatewayFilter Ordering 提到了：\n As Spring Cloud Gateway distinguishes between \u0026ldquo;pre\u0026rdquo; and \u0026ldquo;post\u0026rdquo; phases for filter logic execution (see: How It Works), the filter with the highest precedence will be the first in the \u0026ldquo;pre\u0026rdquo;-phase and the last in the \u0026ldquo;post\u0026rdquo;-phase.\n 也就是说意思如果这个Filter是Pre Filter，那么执行顺序和排序顺序相同，如果这个Filter是Post Filter则执行顺序和排序顺序相反。我整理了一下SCG自带GlobalFilter的执行顺序：\n可以看到GatewayMetricsFilter既是Pre Filter也是Post Filter。\n总结  执行某个Route的时候，SCG会将Global Filter和Route Filter结合起来并排序：  没有给order的Global Filter则保持order为null去排序 没有给order的Route Filter的order则从1开始，根据Route中定义的顺序给值 排序逻辑见AnnotationAwareOrderComparator    对于Pre Filter，执行顺序同排序顺序 对于Post Filter，执行顺序与排序顺序相反 如果你要自定义Global Filter，那么一般来说：  自定义的Global Pre Filter要在Routing Filter之前执行 自定义的Global Post Filter要在Routing Filter之后执行或者NettyWriteResponseFilter之后执行   如果你要自定义Route Filter，那么一般来说：  自定义Route Pre Filter要在ForwardPathFilter和RouteToRequestUrlFilter之间，而且不需要实现Ordered接口或添加@Order注解 自定义的Route Post Filter比较少见，放在Routing Filter或者NettyWriteResponseFilter之后执行   ","date":"2019-04-22","img":"","permalink":"/post/spring-cloud-gateway-filters-ordering/","series":null,"tags":["微服务","java"],"title":"理解Spring Cloud Gateway Filters的执行顺序"},{"categories":null,"content":"在Reactor 编程中有时候我们需要对empty Mono\u0026lt;T\u0026gt;做一些特定业务逻辑。下面看一段非reactor编程的代码：\n1public void oldCheck(Token token) { 2 if (token == null) { 3 // business logic 4 return; 5 } 6 if (token.isExpired) { 7 // business logic 8 return; 9 } 10 // business logic 11 return; 12} 如果让你改成reactor你也许会改成这样：\n1public Mono\u0026lt;Void\u0026gt; badCheck(Mono\u0026lt;Token\u0026gt; tokenMono) { 2 return tokenMono 3 .flatMap(token -\u0026gt; { 4 if (token == null) { 5 // CAUTION: You will never be in here 6 // business logic 7 return Mono.empty(); 8 } 9 if (token.isExpired) { 10 // business logic 11 return Mono.empty(); 12 } 13 // business logic 14 return Mono.empty(); 15 }); 16} 上面的示例代码里的注释已经写了if (token == null) {}的这个条件是永远成立的，这是因为当Mono\u0026lt;Token\u0026gt;是empty时，它是不会触发flatMap的。诸如flatMap的绝大部分Operator都依赖于Publisher（Mono和Flux都是Pubisher）推送数据（详情请看javadoc ），如果Publisher本身无数据可推送，那么就不会触发Operator。换句话说flatMap内部是不可能得到null的。\n那么怎么做才可以？你可以使用Java 8的Optional来作为中间值：\n1public Mono\u0026lt;Void\u0026gt; goodCheck(Mono\u0026lt;Token\u0026gt; tokenMono) { 2 return tokenMono 3 // Transform Mono\u0026lt;Token\u0026gt; to Mono\u0026lt;Optional\u0026lt;Token\u0026gt;\u0026gt;. 4 // If Mono\u0026lt;Token\u0026gt; is empty, flatMap will not be triggered, 5 // then we will get a empty Mono\u0026lt;Optional\u0026lt;Token\u0026gt;\u0026gt; 6 .flatMap(token -\u0026gt; Mono.just(Optional.of(token))) 7 // If Mono\u0026lt;Optional\u0026lt;Token\u0026gt;\u0026gt; is empty, provide an empty Optional\u0026lt;Token\u0026gt;, 8 // then we will get a non-empty Mono\u0026lt;Optional\u0026lt;Token\u0026gt;\u0026gt; anyway 9 .defaultIfEmpty(Optional.empty()) 10 // Since Mono\u0026lt;Optional\u0026lt;Token\u0026gt;\u0026gt; is not empty, flatMap will always be triggered. 11 .flatMap(tokenOptional -\u0026gt; { 12 if (!tokenOptional.isPresent()) { 13 // business logic 14 return Mono.empty(); 15 } 16 Token token = tokenOptional.get(); 17 if (token.isExpired) { 18 // business logic 19 return Mono.empty(); 20 } 21 // business logic 22 return Mono.empty(); 23 }); 24} 除了defaultIfEmpty之外，Reactor还提供了switchIfEmpty、repeatWhenEmpty来处理empty Mono/Flux。\n","date":"2019-04-19","img":"","permalink":"/post/reactor/handle-empty-mono/","series":null,"tags":["reactor"],"title":"处理Empty Mono\u003cT\u003e的方法"},{"categories":null,"content":"Logging  The Log: What every software engineer should know about real-time data\u0026rsquo;s unifying abstraction 讲了Log/Event/Stream与Table是同一件事情的两个面，为流处理应用，分布式存储系统的建设提供了高屋建瓴的指导。 上文中文版   分布式架构 分布式系统\n 左耳听风 | 分布式系统架构的冰与火  左耳听风 | 从亚马逊的实践，谈分布式系统的难点  左耳听风 | 分布式系统的技术栈  左耳听风 | 分布式系统关键技术：全栈监控  左耳听风 | 分布式系统关键技术：服务调度  左耳听风 | 分布式系统关键技术：流量与数据调度  左耳听风 | 分布式系统：洞悉PaaS平台的本质   弹力设计\n 左耳听风 | 弹力设计篇之“认识故障和弹力设计”  左耳听风 | 弹力设计篇之“隔离设计”  左耳听风 | 弹力设计篇之“异步通讯设计”  左耳听风 | 弹力设计篇之“幂等性设计”  左耳听风 | 弹力设计篇之“服务的状态”  左耳听风 | 弹力设计篇之“补偿事务”  左耳听风 | 弹力设计篇之“重试设计”  左耳听风 | 弹力设计篇之“熔断设计”  Netflix Hystrix笔记    左耳听风 | 弹力设计篇之“降级设计”  左耳听风 | 弹力设计篇之“弹力设计总结”   限流设计\n 左耳听风 | 弹力设计篇之“限流设计”  How to Design a Scalable Rate Limiting Algorithm ，Kong的限流文章 An alternative approach to rate limiting ，figma的限流经验 Twitter API Rate Limiting ，Twitter API的Rate Limiting设计，值得参考 Ambassador API Gateway的限流设计系列文章  Part 1: Rate Limiting: A Useful Tool with Distributed Systems  Part 2: Rate Limiting for API gateways  Part 3: Implementing a Java Rate Limiting Service for the Ambassador API Gateway  Part 4: Designing a Rate Limiting Service for Ambassador      管理设计\n 左耳听风 | 管理设计篇之\u0026quot;分布式锁\u0026quot;  左耳听风 | 管理设计篇之\u0026quot;配置中心\u0026quot;  左耳听风 | 管理设计篇之\u0026quot;边车模式\u0026quot;  左耳听风 | 管理设计篇之\u0026quot;服务网格\u0026quot;  左耳听风 | 管理设计篇之\u0026quot;网关模式\u0026quot;  左耳听风 | 管理设计篇之\u0026quot;部署升级策略\u0026quot;   性能设计\n 左耳听风 | 性能设计篇之\u0026quot;缓存\u0026quot;  左耳听风 | 性能设计篇之\u0026quot;异步处理\u0026quot;  左耳听风 | 性能设计篇之\u0026quot;数据库扩展\u0026quot;  左耳听风 | 性能设计篇之\u0026quot;秒杀\u0026quot;  左耳听风 | 性能设计篇之\u0026quot;边缘计算\u0026quot;   分布式架构资料\n 分布式架构入门  分布式架构经典图书和论文  分布式架构工程设计  一致性Hash笔记     缓存  The Three Types of Cache  ","date":"2019-04-15","img":"","permalink":"/post/bookmarks/bookmarks-system-arch/","series":null,"tags":["收藏夹"],"title":"收藏夹 - 系统架构（持续更新）"},{"categories":null,"content":"场景 观察进程的CPU使用情况 观察进程内各个函数的CPU使用情况：\n1sudo perf top -p \u0026lt;pid\u0026gt; 同时显示函数调用链：\n1sudo perf top -g -p \u0026lt;pid\u0026gt; 记录采样结果，以供后续分析，加上-g会记录调用链：\n1sudo perf record -g -p \u0026lt;pid\u0026gt; 读取采样结果：\n1sudo perf report 观察容器内进程CPU使用情况 容器内的进程实际上可以在host machine上看到，ps -ef | grep \u0026lt;text\u0026gt;可以找得到。\n因此同样可以用perf top -p \u0026lt;pid\u0026gt;观察，但是会出现无法显示函数符号的问题，注意观察perf top最下面一行：\n1Failed to open /opt/bitnami/php/lib/php/extensions/opcache.so, continuing without symbols 解决办法是先用perf record记录采样数据，然后将容器内文件系统绑定到host上，然后用perf report --symfs \u0026lt;path\u0026gt;指定符号目录。你得先安装bindfs（下面有安装方法）。\n1mkdir /tmp/foo 2PID=$(docker inspect --format {{.State.Pid}} \u0026lt;container-name\u0026gt;) 3bindfs /proc/$PID/root /tmp/foo 4perf report --symfs /tmp/foo 5 6# 使用完成后不要忘记解除绑定 7umount /tmp/foo/ 把上面的\u0026lt;container-name\u0026gt;改成你要观察的容器名。\n观察Java进程的CPU使用情况 你得要先安装perf-map-agent （下面有安装方法），在启动Java进程的时候添加-XX:+PreserveFramePointer参数，下面是几个用法：\n perf-java-top \u0026lt;pid\u0026gt; \u0026lt;perf-top-options\u0026gt; PERF_RECORD_SECONDS=30 perf-java-record-stack \u0026lt;pid\u0026gt; \u0026lt;perf-record-options\u0026gt; PERF_RECORD_SECONDS=30 perf-java-report-stack \u0026lt;pid\u0026gt; \u0026lt;perf-report-options\u0026gt;  更多用法见官网说明。\n还可以使用PERF_RECORD_SECONDS=30 perf-java-flames \u0026lt;pid\u0026gt; \u0026lt;perf-record-options\u0026gt;生成火焰图，你得先安装FlameGraph （下面有安装方法）。关于火焰图的解读看netflix的这篇博客 。\n观察容器内Java进程CPU使用情况 目前没有办法。\n附录：安装方法 下面讲的都是在Ubuntu 16.04系统上的安装方法。\nperf 安装perf\n1$ sudo apt install -y linux-tools-common 运行perf会出现：\n1$ perf 2WARNING: perf not found for kernel 4.4.0-145 3 4 You may need to install the following packages for this specific kernel: 5 linux-tools-4.4.0-145-generic 6 linux-cloud-tools-4.4.0-145-generic 7 8 You may also want to install one of the following packages to keep up to date: 9 linux-tools-generic 10 linux-cloud-tools-generic 于是安装：\n1sudo apt install linux-tools-4.4.0-145-generic linux-cloud-tools-4.4.0-145-generic linux-cloud-tools-generic bindfs 到bindfs官网 下载源码包（本文写是版本为1.13.11）。\n先安装编译需要的工具：\n1sudo apt install -y cmake pkg-config libfuse-dev libfuse2 autoconf 解压缩源码包，进入bindfs目录，编译：\n1./configure \u0026amp;\u0026amp; make \u0026amp;\u0026amp; sudo make install perf-map-agent 到github clone perf-map-agent的源码仓库。\n安装JDK，你之后要监测的程序都得用这个JDK启动，这个JDK也用来编译perf-map-agent。用apt安装openjdk的方法见下面。\n编译：\n1cmake . 2make 3 4# will create links to run scripts in /usr/local/bin 5sudo bin/create-links-in /usr/local/bin 安装openjdk 1sudo apt-get install -y openjdk-8-jdk 通过这种方式安装是没有JAVA_HOME环境变量的，因此我们要自己设置一个，查找openjdk的安装路径：\n1dpkg-query -L openjdk-8-jdk 将发现结果写到~/.bashrc里：\n1export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 FlameGraph 到github clone FlameGraph的源码仓库。\n到~/.bashrc设置环境变量：\n1export FLAMEGRAPH_DIR=\u0026lt;path-to-flame-graph\u0026gt; BCC 官方安装文档 。\n如果你是Ubuntu 18.04：\n1sudo apt-get install bpfcc-tools linux-headers-$(uname -r) 如果你是Ubuntu 16.40：\n1sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 4052245BD4284CDD 2echo \u0026#34;deb https://repo.iovisor.org/apt/$(lsb_release -cs)$(lsb_release -cs)main\u0026#34; | sudo tee /etc/apt/sources.list.d/iovisor.list 3sudo apt-get update 4sudo apt-get install bcc-tools libbcc-examples linux-headers-$(uname -r) 安装路径在：/usr/share/bcc/tools。\n","date":"2019-04-12","img":"","permalink":"/post/kernel/perf-analyze-cpu-note/","series":null,"tags":["kernel","java","运维","troubleshooting","cheatsheet","debug","jvm"],"title":"Perf分析CPU性能问题笔记"},{"categories":null,"content":"用于实现API网关的技术有很多，大致分为这么几类：\n 通用反向代理：Nginx、Haproxy、…… 网络编程框架：Netty、Servlet、Spring Webflux、Go net/http包、Go fasthttp包、…… API网关框架：Spring Cloud Gateway、Zuul、Zuul2、……  API网关最基本的功能就是反向代理，所以在对API网关做技术选型的时候需要着重考察其性能表现，本文对Nginx、Haproxy、Netty、Spring Cloud Gateway、Zuul2做了性能测试，测试代码可以在github 获得。\n测试方法  准备了三台2CPU 4G内存的服务器，分别运行Tomcat、API Gateway、Gatling（压测工具） 先对Tomcat做压测，取Tomcat充分预热后的压测结果作为基准。压的是Tomcat自带的example：/examples/jsp/jsp2/simpletag/book.jsp 对Haproxy（7层）、Nginx（7层）、Netty（4层）、Netty（7层）、Reactor Netty（4层）、Vert.x（7层）、Spring Cloud Gateway（7层）、Zuul2（7层）、Go net/http（7层）、Go fasthttp（7层）做了测试 在对Netty、Zuul2、Spring Cloud Gateway做压测前先压了几轮做预热。 被测的API网关都没有添加额外业务，只做反向代理  吞吐量 下图是吞吐量的情况，可以看到Haproxy（7层）、Nginx（7层）、Netty（4层）、Netty（7层）、Reactor Netty（4层）、Go fasthttp（7层），只比直压Tomcat低一点点，而Spring Cloud Gateway（7层）、Zuul2（7层）、Go net/http（7层）则要低得多。\n下面这张图可以更明显的看到吞吐量比较，Tomcat为100%因为它是基准值，Haproxy（7层）、Nginx（7层）、Netty（4层）、Netty（7层）、Reactor Netty（4层）、Go fasthttp（7层）的只比基准值低10左右%，而Spring Cloud Gateway（7层）、Zuul2（7层）、Go net/http（7层）则只是基准值的30%多一点（难兄难弟）。\n平均响应时间 下图可以看到Haproxy（7层）、Nginx（7层）、Netty（4层）、Netty（7层）、Reactor Netty（4层）、Go fasthttp（7层）的平均响应时间与Tomcat差不多。但是Spring Cloud Gateway（7层）、Zuul2（7层）、Go net/http（7层）则是Tomcat的3倍左右，不出所料。\n下图同样是以Tomcat作为基准值的比较：\n响应时间分布 光看平均响应时间是不够的，我们还得看P50、P90、P99、P99.9以及Max响应时间（可惜Gatling只能设置4个百分位，否则我还想看看P99.99的响应时间）。\n 为何要观察P99.9的响应时间？光看P90不够吗？理由有两个：\n1）观察P99、P99.9、P99.99的响应时间可以观察系统的在高压情况下的稳定性，如果这三个时间的增长比较平滑那么说明该系统在高压力情况下比较稳定，如果这个曲线非常陡峭则说明不稳定。\n2）观察P99、P99.9、P99.99的响应时间能够帮助你估算用户体验。假设你有一个页面会发出5次请求，那么这5次请求均落在P90以内概率是多少？90%^5=59%，至少会经历一次 \u0026gt; P90响应时间的概率是 100%-59%=41%，如果你的P90=10s，那么就意味着用户有41%的概率会在加载页面的时候超过10s，是不是很惊人？如果你的P99=10s，那么用户只有5%的概率会在访问页面的时候超过10s。如果P99.9=10s，则有0.4%的概率。\n关于如何正确压测系统可以看 “How NOT to Measure Latency” by Gil Tene  下面同样是把结果与Tomcat基准值做对比：\n可以看到几个很有趣的现象：\n Haproxy（7层）、Nginx（7层）、Netty（7层）、Reactor Netty（4层）、Go fasthttp（7层）的P50、P90、P99、P99.9、Max都是逐渐递增的。 Netty（4层）的P50、P90、P99、P99.9是很平坦的，Max则为基准值的207%。 Spring Cloud Gateway（7层）、Zuul2（7层）、Go net/http（7层）则是相反的，它们的平面呈现下降趋势。Spring Cloud Gateway的Max甚至还比基准值低了一点点（94%），我相信这只是一个随机出现的数字，不要太在意。  结论 Haproxy（7层）、Nginx（7层）、Netty（4层）、Netty（7层）、Reactor Netty（4层）、Go fasthttp（7层）的表现均很不错，其对于吞吐量和响应时间的性能损耗很低，可以忽略不计。\n但是目前最为火热的Spring Cloud Gateway和Zuul2则表现得比较糟糕，因我没有写额外的业务逻辑这，可以推测这和它们的内置逻辑有关，那么大致有这么几种可能：\n 内置逻辑存在问题，把Netty的优化抵消掉了（两者都基于Netty） 内置逻辑存在阻塞（可能性不大）  另外，Vert.x则显得很独特，它的各种指标位于前面两派的中间。\n不过话说回来考虑选用那种作为API网关（的基础技术）不光要看性能，还要看：\n 是否易于扩展自己的业务逻辑 API使用的便利性 代码的可维护性 文档是否齐全 \u0026hellip;  性能只是我们手里的一个筹码，当我们知道这个东西性能到底几何后，才可以与上面的这些做交换（trade-off）。比如Nginx和Haproxy的可扩展性很差，那么我们可以使用Netty。如果你觉得Netty的API太底层了太难用了，那么可以考虑Spring Cloud Gateway或Zuul2。前提是你知道你会失去多少性能。\n","date":"2019-04-11","img":"","permalink":"/post/api-gateway-perf-comparison/","series":null,"tags":["微服务","java"],"title":"API网关性能比较"},{"categories":null,"content":"四种IO模型 Boost application performance using asynchronous I/O 把同步阻塞、同步非阻塞、异步阻塞、异步非阻塞的模型讲得很清楚。\n处理大量连接的问题 event-driven模型派（异步模型）：\n Dan Kegal\u0026rsquo;s C10K problem  延伸阅读：如何解决C10M问题 The Secret To 10 Million Concurrent Connections -The Kernel Is The Problem, Not The Solution 这个presentation主要讲了如何消除内核network stack的瓶颈，没有特别提到采用哪种模型。  有人对于event-driven模型有一些批判，认为多线程模型（同步阻塞模型）不比事件模型差：\n Thousands of Threads and Blocking I/O ，讲了C10K提到的多线程模型的性能瓶颈在如今的内核里已经不存在了，而多线程模型开发起来更简单。 Why Events are a Bad Idea(for high concurrency servers) Rob von Behren ，讲了多线程模型的性能瓶颈基本上是因为内核支持的不好、多线程类库有缺陷造成的。认为可以通过编译器的优化、修复内核、修复多线程类库来达到和事件驱动模型相当的结果。且认为事件驱动模型的开发比较复杂。  两种模型也不是说水火不容，SEDA 提出了可以将两种模型结合起来，构建更具弹性的系统。10年之后该作者写了篇回顾文章A Retrospective on SEDA 。\nSEDA提出了几个很具有见地的意见：\n 应用程序的各个stage的压力应该是可观测和可调节的。 应用程序应该是well-conditioned。  什么是Well-conditioned service？\n Intuitively, a service is well-conditioned if it behaves like a simple pipeline, where the depth of the pipeline is determined by the path through the network and the processing stages within the service itself. As the offered load increases, the delivered throughput increases proportionally until the pipeline is full and the throughput saturates; additional load should not degrade throughput. Similarly, the response time exhibited by the service is roughly constant at light load, because it is dominated by the depth of the pipeline. As load approaches saturation, the queueing delay dominates. In the closed-loop scenario typical of many services, where each client waits for a response before delivering the next request, response time should increase linearly with the number of clients.\n  The key property of a well-conditioned service is graceful degradation: as offered load exceeds capacity, the service maintains high throughput with a linear response-time penalty that impacts all clients equally, or at least predictably according to some service-specific policy. Note that this is not the typical Web experience; rather, as load increases, throughput decreases and response time increases dramatically, creating the impression that the service has crashed.\n 简单来说当负载超过一个应用的容量时，其性能表现要满足以下两点：\n 吞吐量依然保持稳定，可以稍有下跌但绝不会断崖式下跌 随着负载的增加其延迟线性增长，绝不会出现尖刺  Reactor pattern 事件驱动模型到最后就变成了Reactor Pattern，下面是几篇文章：\nScalable IO in Java 介绍了如何使用NIO，其中很重要的一点是handler用来处理non-blocking的task，如果task是blocking的，那么要交给其他线程处理。这不就是简化版的SEDA吗？\nReactor Pattern的老祖宗论文：Reactor Pattern ，TL;DR。Understanding Reactor Pattern: Thread-Based and Event-Driven 帮助你快速理解什么是Reactor Pattern，文中提到如果要处理10K个长连接，Tomcat是开不了那么多线程的。对此有一个疑问，Tomcat可以采用NIO/NIO2的Connector，为啥不能算作是Reactor呢？这是因为Tomcat不是事件驱动的，所以算不上。\nThe reactor pattern and non-blocking IO 对比了Tomcat和vert.x的性能差别，不过看下来发现文章的压测方式存在偏心：\n 文中给Tomcat的线程少了（只给了500），只利用了40%左右的CPU，而vert.x的测试的CPU利用率为100%。我把的Tomcat的线程设到2000，测试结果就和vert.x差不多了（验证了多线程模型派的观点）。 vert.x的测试代码和Tomcat的测试代码不等价，没有使用Thread.sleep()。不过当我尝试在vert.x中使用sleep则发生了大量报错，应该是我的使用问题，后面就没有深究了。  我写的测试可以在这里 看到。\n总结 看了前面这么多文章其实总结下来就这么几点：\n 选择事件驱动模型还是多线程模型要根据具体情况来（不过这是一句废话，; ) 推崇、反对某个模型的文章/论文都是在当时的历史情况下写出来的，说白了就是存在历史局限性，因此一定要自己验证，当时正确的论断对现在来讲未必正确，事情是会发生变化的。 看测试报告的时候一定要自己试验，有些测试可能本身设计的就有问题，导致结果存在偏见。对于大多数性能测试来说，我觉得只要抓住一点就行了，就是CPU一定要用足。 我们真正应该关注的是不变的东西。  Jeff Darcy\u0026rsquo;s notes on high-performance server design 提到了高性能服务器的几个性能因素：\n data copy，问题依然存在，需要程序员去优化。 context switch，这个问题已经没有了（见多线程派的几篇文章），现代操作系统不论有多少thread，开销不会有显著增加。 memory allocation，这个要看看，不过在Java里似乎和JVM GC有关。 lock contention，这个问题依然存在，应该尽量使用lock-free/non-blocking的数据结构。 另外补充：在C10M 里提到kernel和内核的network stack也是瓶颈。  仔细看看有些因素不就是事件驱动模型和多线程模型都面临的问题吗？而又有一些因素则是两种模型提出的当时所各自存在的短板吗？而某些短板现在不是就已经解决了吗？\n上面说的有点虚，下面讲点实在的。\n如果你有10K个长连接，每个连接大部分时间不使用CPU（处于Idle状态或者blocking状态），那么为每个连接创建一个单独的线程就显得不划算。因为这样做会占用大量内存，而CPU的利用率却很低，因为大多数时间线程都闲着。\n事件驱动模型解决的是C10K问题，注意C是Connection，解决的是用更少的硬件资源处理更多的连接的问题，它不解决让请求更快速的问题（这是程序员/算法的问题）。\n要不要采用事件驱动模型取决于Task的CPU运算时间与Blocking时间的比例，如果比例很低，那么用事件驱动模型。对于长连接来说，比如websocket，这个比例就很小，甚至可近似认为是0，这个时候用事件驱动模型比较好。如果比例比较高，用多线程模型也可以，它的编程复杂度很低。\n不论是采用哪种模型，都要用足硬件资源，这个资源可以是CPU也可以是网络带宽，如果发生资源闲置那你的吞吐量就上不去。\n对于多线程模型来说开多少线程合适呢？Thousands of Threads and Blocking I/O 里讲得很对，当能够使系统饱和的时候就够了。比如CPU到100%了、网络带宽满了。如果内存用满了但是这两个都没用满，那么一般来说是出现BUG了。\n对于事件驱动模型来说也有CPU用满的问题，现实中总会存在一些阻塞操作会造成CPU闲置，这也就是为什么SEDA 和Scalable IO in Java 都提到了要额外开线程来处理这些阻塞操作。关于如何用满CPU我之前写了一篇文章如何估算吞吐量以及线程池大小 可以看看。\n如何用满网络带宽没有什么经验，这里就不说了。\n","date":"2019-04-04","img":"","permalink":"/post/kernel/sync-async-blocking-non-blocking-io-abstract/","series":null,"tags":["kernel","io","高并发","cheatsheet"],"title":"关于同步/异步、阻塞/非阻塞IO的摘要"},{"categories":null,"content":"常见的https网站做的是服务端认证（server authentication），浏览器通过证书判断你所访问的https://baidu.com是否真的是百度，而不是其他人伪造的网站。同时还对流量加密，防止别人窃听你的流量。\ntls还可以做客户端认证（client authentication），即服务端判断客户端是否为其所信任的客户端。由此可见，客户端认证用于那些需要受控访问服务端。\n在数据中心中，有些服务是非常敏感的，那么我们要做到：\n 客户端和我的流量是加密的，防止别人监听 客户端能够确认所访问的服务端的确是我们提供的服务端，而不是别人伪造的服务端 只有我信任的客户端可以访问我，防止恶意请求  所以很明显，前两个问题可以通过服务端认证解决，最后一个问题可以通过客户端认证解决。顺便一提，如果要使用客户端认证就必须使用服务端认证。\n先来讲讲概念然后举个tomcat的例子讲讲怎么做。\n概念 服务端认证 不论是做Server authentication还是Client authentication都需要证书。证书的来源有两种：\n 由权威CA签发，一般都是去购买。也可以使用let\u0026rsquo;s encrypt申请免费证书。 自己签发  在一切可能的情况下都应该使用权威CA签发的证书，为什么这么建议？因为这里牵涉到一个信任问题，浏览器、编程语言SDK和某些工具都维护了一个信任CA证书清单，只要是由这些CA签发的证书那就信任，否则就不信任。而这个链条是可以多级的，这里就不展开了。你只需要知道由信任CA签发的所有证书都是可信的。比如JDK自带的信任CA证书可以通过下面命令看到：\n1keytool -list -keystore $JAVA_HOME/jre/lib/security/cacerts 2 3verisignclass2g2ca [jdk], 2016-8-25, trustedCertEntry, 4证书指纹 (SHA1): B3:EA:C4:47:76:C9:C8:1C:EA:F2:9D:95:B6:CC:A0:08:1B:67:EC:9D 5digicertassuredidg3 [jdk], 2016-8-25, trustedCertEntry, 6证书指纹 (SHA1): F5:17:A2:4F:9A:48:C6:C9:F8:A2:00:26:9F:DC:0F:48:2C:AB:30:89 7verisignuniversalrootca [jdk], 2016-8-25, trustedCertEntry, 8... 让你输密码的时候输入changeit。\n如果这个证书不是由信任CA签发的（比如自己签发）会发生什么？浏览器、编程语言SDK、你所使用的工具会报告以下错误：\ncurl：\n1curl: (60) SSL certificate problem: self signed certificate in certificate chain Java：\n1Exception in thread \u0026#34;main\u0026#34; javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target 2\tat sun.security.ssl.Alerts.getSSLException(Alerts.java:192) 3\tat sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1964) 4\tat sun.security.ssl.Handshaker.fatalSE(Handshaker.java:328) 5\tat sun.security.ssl.Handshaker.fatalSE(Handshaker.java:322) 6\tat sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1614) 7... 浏览器：\n这个错误实际上就是在告诉你这个证书不可信任，可能是一个伪造站点，让你小心点儿。如果这个证书由权威CA签发，那么就没有这个问题了。但是权威CA签发的证书要求申请人拥有域名，如果你这个服务是内部使用的没有域名，那就只能自己签发了。那么如何解决上面的问题呢？你得把自己签发的证书加入到信任CA证书清单里。\n下图是权威CA签发证书的示例：\n可以看到客户端有一个truststore，这个就是存放信任CA证书的地方，服务端有一个keystore，存放的自己的证书及对应的私钥。\n下图是自签发证书的示例：\n在上面可以看到我们自己成为了一个Root CA，把它放到客户端的truststore里。\n客户端认证 前面讲过客户端认证是服务端来验证客户端是否可信的机制，其实做法和服务端认证类似只不过方向相反。客户端认证大多数情况下只能是自签发的（因为没有域名），虽然不是不可以从权威CA签发但是存在一些问题。下面解释为什么，假设权威CA是let\u0026rsquo;s encrypt，然后服务端信任它签发的所有证书。但是let\u0026rsquo;s encrypt是阿猫阿狗都可以申请的，现在有一个黑客申请了这个证书，然后请求你的服务端，服务端就认可了。\n上面这个问题可以用这个方法解决：比如你用let\u0026rsquo;s encrypt申请了A证书，黑客用let\u0026rsquo;s encrypt申请了B证书，你的服务端的truststore只信任A证书，那么黑客用B证书访问你的时候就会被拒绝。但是这就带来另一个问题，比如你在开发的时候客户端证书有这么几套：生产用、调试用、开发用，那么每次客户端签发一个证书都要更新到你的服务器的truststore里，这也太麻烦了。\n所以结合安全性和便利性，我们把自己变成Root CA，然后服务端信任它，这样一来服务端就可以在开发的时候把Client Root CA内置进去，大大减轻了维护truststore的工作量，看下图：\n用Tomcat举个例子 下面举一个Tomcat做客户端认证的例子，因为是测试用，所以服务端认证也是用的自签发证书。\n我们用了cfssl 这个工具来生成证书。\n服务端 先弄一套目录：\n1# 放自签发的服务端CA根证书 2server-secrets/ca 3# 放自签发的服务端的证书 4server-secrets/cert 5# 放服务端的keystore和truststore 6server-secrets/jks 生成自签名CA证书 新建文件：server-secrets/ca/server-root-ca-csr.json\n内容如下：\n1{ 2 \u0026#34;key\u0026#34;: { 3 \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, 4 \u0026#34;size\u0026#34;: 2048 5 }, 6 \u0026#34;names\u0026#34;: [ 7 { 8 \u0026#34;O\u0026#34;: \u0026#34;Company\u0026#34;, 9 \u0026#34;OU\u0026#34;: \u0026#34;Datacenter\u0026#34;, 10 \u0026#34;L\u0026#34;: \u0026#34;Shanghai\u0026#34;, 11 \u0026#34;ST\u0026#34;: \u0026#34;Shanghai\u0026#34;, 12 \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34; 13 } 14 ], 15 \u0026#34;CN\u0026#34;: \u0026#34;server-root-ca\u0026#34; 16} 运行下面命令生成Server ROOT CA证书：\n1cfssl gencert --initca=true ./server-root-ca-csr.json | cfssljson --bare server-root-ca 会得到下面几个文件：\n1server-secrets/ca/ 2├── server-root-ca-key.pem 3├── server-root-ca.csr 4└── server-root-ca.pem 用下面命令验证证书：\n1openssl x509 -in ./server-root-ca.pem -text -noout 2 3Certificate: 4 Data: 5 Version: 3 (0x2) 6 Serial Number: 7 0c:8a:1a:ca:da:fa:4c:17:6c:1f:42:40:4c:f1:90:f4:fd:1d:fe:58 8 Signature Algorithm: sha256WithRSAEncryption 9 Issuer: C=CN, ST=Shanghai, L=Shanghai, O=Company, OU=Datacenter, CN=server-root-ca 10 Validity 11 Not Before: Mar 27 05:14:00 2019 GMT 12 Not After : Mar 25 05:14:00 2024 GMT 13 Subject: C=CN, ST=Shanghai, L=Shanghai, O=Company, OU=Datacenter, CN=server-root-ca 可以看到签发人和被签发人是同一个。\n生成自签发证书 新建文件 server-secrets/cert/server-gencert.json，内容如下：\n1{ 2 \u0026#34;signing\u0026#34;: { 3 \u0026#34;default\u0026#34;: { 4 \u0026#34;usages\u0026#34;: [ 5 \u0026#34;signing\u0026#34;, 6 \u0026#34;key encipherment\u0026#34;, 7 \u0026#34;server auth\u0026#34; 8 ], 9 \u0026#34;expiry\u0026#34;: \u0026#34;87600h\u0026#34; 10 } 11 } 12} 可以看到我们会生成用来做server auth的证书。\n新建文件 server-secrets/cert/demo-csr.json，内容如下：\n1{ 2 \u0026#34;key\u0026#34;: { 3 \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, 4 \u0026#34;size\u0026#34;: 2048 5 }, 6 \u0026#34;names\u0026#34;: [ 7 { 8 \u0026#34;O\u0026#34;: \u0026#34;Company\u0026#34;, 9 \u0026#34;OU\u0026#34;: \u0026#34;Datacenter\u0026#34;, 10 \u0026#34;L\u0026#34;: \u0026#34;Shanghai\u0026#34;, 11 \u0026#34;ST\u0026#34;: \u0026#34;Shanghai\u0026#34;, 12 \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34; 13 } 14 ], 15 \u0026#34;CN\u0026#34;: \u0026#34;server-demo\u0026#34;, 16 \u0026#34;hosts\u0026#34;: [ 17 \u0026#34;127.0.0.1\u0026#34;, 18 \u0026#34;localhost\u0026#34; 19 ] 20} 看上面的hosts，你可以根据自己的需要填写域名或IP，这里因为是本地演示所以是127.0.0.1和localhost。\n运行下面命令生成证书\n1cfssl gencert \\ 2 --ca ../ca/server-root-ca.pem \\ 3 --ca-key ../ca/server-root-ca-key.pem \\ 4 --config ./server-gencert.json \\ 5 ./demo-csr.json | cfssljson --bare ./demo 得到文件：\n1server-secrets/cert/ 2├── demo-key.pem 3├── demo.csr 4└── demo.pem 验证结果：\n1openssl x509 -in ./demo.pem -text -noout 2 3Certificate: 4 Data: 5 Version: 3 (0x2) 6 Serial Number: 7 1d:d0:51:97:6c:ce:ea:29:2a:f4:3b:3c:48:a3:69:b0:ef:f3:26:7b 8 Signature Algorithm: sha256WithRSAEncryption 9 Issuer: C=CN, ST=Shanghai, L=Shanghai, O=Company, OU=Datacenter, CN=server-root-ca 10 Validity 11 Not Before: Mar 27 05:17:00 2019 GMT 12 Not After : Mar 24 05:17:00 2029 GMT 13 Subject: C=CN, ST=Shanghai, L=Shanghai, O=Company, OU=Datacenter, CN=server-demo 可以看到签发者是server-root-ca，Subject是server-demo。\n将证书导入keystore 到 server-secrets/jks，执行下面命令生成pkcs12格式的keystore（JDK识别这个格式）\n1openssl pkcs12 -export \\ 2 -in ../cert/demo.pem \\ 3 -inkey ../cert/demo-key.pem \\ 4 -out server-demo.keystore \\ 5 -name server-demo \\ 6 -CAfile ../ca/server-root-ca.pem \\ 7 -caname root -chain 过程中会让你输入密码，你就输入：server-demo-ks。\n得到文件：\n1server-secrets/jks/ 2└── server-demo.keystore 用JDK提供的keytool看看里面的内容：\n1keytool -list -keystore server-demo.keystore 2 3server-demo, 2019-3-27, PrivateKeyEntry, 4证书指纹 (SHA1): B2:E5:46:63:BB:00:E7:82:48:A4:2F:EC:01:41:CE:B4:4B:CE:68:7A 让你输入密码的时候就输入：server-demo-ks。\n客户端 先弄一套目录：\n1# 放自签发的客户端CA根证书 2client-secrets/ca 3# 放自签发的客户端的证书 4client-secrets/cert 5# 放客户端的keystore和truststore 6client-secrets/jks 生成自签名CA证书 新建文件 client-secrets/ca/client-root-ca-csr.json：\n1{ 2 \u0026#34;key\u0026#34;: { 3 \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, 4 \u0026#34;size\u0026#34;: 2048 5 }, 6 \u0026#34;names\u0026#34;: [ 7 { 8 \u0026#34;O\u0026#34;: \u0026#34;Company\u0026#34;, 9 \u0026#34;OU\u0026#34;: \u0026#34;Datacenter\u0026#34;, 10 \u0026#34;L\u0026#34;: \u0026#34;Shanghai\u0026#34;, 11 \u0026#34;ST\u0026#34;: \u0026#34;Shanghai\u0026#34;, 12 \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34; 13 } 14 ], 15 \u0026#34;CN\u0026#34;: \u0026#34;client-root-ca\u0026#34; 16} 运行下面命令生成Client ROOT CA证书：\n1cfssl gencert --initca=true ./client-root-ca-csr.json | cfssljson --bare client-root-ca 会得到下面几个文件：\n1client-secrets/ca/ 2├── client-root-ca-key.pem 3├── client-root-ca.csr 4└── client-root-ca.pem 用下面命令验证证书：\n1openssl x509 -in ./client-root-ca.pem -text -noout 2 3Certificate: 4 Data: 5 Version: 3 (0x2) 6 Serial Number: 7 7e:fc:f3:53:07:1a:17:ae:24:34:d5:1d:00:02:d6:e4:24:09:92:12 8 Signature Algorithm: sha256WithRSAEncryption 9 Issuer: C=CN, ST=Shanghai, L=Shanghai, O=Company, OU=Datacenter, CN=client-root-ca 10 Validity 11 Not Before: Mar 27 05:20:00 2019 GMT 12 Not After : Mar 25 05:20:00 2024 GMT 13 Subject: C=CN, ST=Shanghai, L=Shanghai, O=Company, OU=Datacenter, CN=client-root-ca 可以看到签发人和被签发人是同一个。\n生成自签发证书 新建文件 client-secrets/cert/client-gencert.json，内容如下：\n1{ 2 \u0026#34;signing\u0026#34;: { 3 \u0026#34;default\u0026#34;: { 4 \u0026#34;usages\u0026#34;: [ 5 \u0026#34;signing\u0026#34;, 6 \u0026#34;key encipherment\u0026#34;, 7 \u0026#34;client auth\u0026#34; 8 ], 9 \u0026#34;expiry\u0026#34;: \u0026#34;87600h\u0026#34; 10 } 11 } 12} 可以看到我们会生成用来做client auth的证书。\n新建文件 client-secrets/cert/demo-csr.json，内容如下：\n1{ 2 \u0026#34;key\u0026#34;: { 3 \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, 4 \u0026#34;size\u0026#34;: 2048 5 }, 6 \u0026#34;names\u0026#34;: [ 7 { 8 \u0026#34;O\u0026#34;: \u0026#34;Company\u0026#34;, 9 \u0026#34;OU\u0026#34;: \u0026#34;Datacenter\u0026#34;, 10 \u0026#34;L\u0026#34;: \u0026#34;Shanghai\u0026#34;, 11 \u0026#34;ST\u0026#34;: \u0026#34;Shanghai\u0026#34;, 12 \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34; 13 } 14 ], 15 \u0026#34;CN\u0026#34;: \u0026#34;client-demo\u0026#34; 16} 这里没有hosts，这是因为我们不需要用这个证书来做服务端认证。\n运行下面命令生成证书\n1cfssl gencert \\ 2 --ca ../ca/client-root-ca.pem \\ 3 --ca-key ../ca/client-root-ca-key.pem \\ 4 --config ./client-gencert.json \\ 5 ./demo-csr.json | cfssljson --bare ./demo 得到文件：\n1client-secrets/cert/ 2├── demo-key.pem 3├── demo.csr 4└── demo.pem 验证结果：\n1openssl x509 -in ./demo.pem -text -noout 2 3Certificate: 4 Data: 5 Version: 3 (0x2) 6 Serial Number: 7 6e:50:e2:2c:02:bb:ef:fd:03:d9:2c:0a:8f:ba:90:65:fb:c4:b5:75 8 Signature Algorithm: sha256WithRSAEncryption 9 Issuer: C=CN, ST=Shanghai, L=Shanghai, O=Company, OU=Datacenter, CN=client-root-ca 10 Validity 11 Not Before: Mar 27 05:21:00 2019 GMT 12 Not After : Mar 24 05:21:00 2029 GMT 13 Subject: C=CN, ST=Shanghai, L=Shanghai, O=Company, OU=Datacenter, CN=client-demo 可以看到签发者是client-root-ca，Subject是client-demo。\n将证书导入keystore 到 client-secrets/jks，执行下面命令生成pkcs12格式的keystore（JDK识别这个格式）\n1openssl pkcs12 -export \\ 2 -in ../cert/demo.pem \\ 3 -inkey ../cert/demo-key.pem \\ 4 -out client-demo.keystore \\ 5 -name client-demo \\ 6 -CAfile ../ca/client-root-ca.pem \\ 7 -caname root -chain 过程中会让你输入密码，你就输入：client-demo-ks。\n得到文件：\n1client-secrets/jks/ 2└── client-demo.keystore 用JDK提供的keytool看看里面的内容：\n1keytool -list -keystore client-demo.keystore 2 3client-demo, 2019-3-27, PrivateKeyEntry, 4证书指纹 (SHA1): 83:AE:0E:5E:0C:CE:86:C9:D1:84:D7:6F:87:F3:76:1F:B4:3E:46:31 让你输入密码的时候就输入：client-demo-ks。\n两端互信 好了，到此为止server和client的证书都已经生成了，接下来只需要将各自的root-ca添加到彼此都truststore中。\n把server-root-ca导入到client的truststore中 1cd client-secrets/jks 2 3keytool -importcert \\ 4 -alias server-root-ca \\ 5 -storetype pkcs12 \\ 6 -keystore client.truststore \\ 7 -storepass client-ts \\ 8 -file ../../server-secrets/ca/server-root-ca.pem -noprompt 注意上面的-storepass参数，这个是trustore的密码：client-ts。\n得到文件：\n1client-secrets/jks/ 2└── client.truststore 用JDK提供的keytool看看里面的内容：\n1keytool -list -keystore client.truststore 2 3server-root-ca, 2019-3-27, trustedCertEntry, 4证书指纹 (SHA1): 75:E3:78:97:85:B2:29:38:25:3C:FD:EC:68:97:9B:78:A0:5F:BB:9D 让你输入密码的时候就输入：client-ts。\n把client-root-ca导入到server的truststore中 1cd server-secrets/jks 2 3keytool -importcert \\ 4 -alias client-root-ca \\ 5 -storetype pkcs12 \\ 6 -keystore server.truststore \\ 7 -storepass server-ts \\ 8 -file ../../client-secrets/ca/client-root-ca.pem -noprompt 注意上面的-storepass参数，这个是trustore的密码：server-ts。\n得到文件：\n1server-secrets/jks/ 2└── server.truststore 用JDK提供的keytool看看里面的内容：\n1keytool -list -keystore server.truststore 2 3client-root-ca, 2019-3-27, trustedCertEntry, 4证书指纹 (SHA1): 1E:95:2C:12:AA:7E:6D:E7:74:F1:83:C2:B8:73:6F:EE:57:FB:CA:46 让你输入密码的时候就输入：server-ts。\n配置Tomcat 好了，我们现在client和server都有了自己证书放在了自己的keystore中，而且把彼此的root-ca证书放到了自己的truststore里。现在我们弄一个tomcat作为server，然后为他配置SSL。\n修改tomcat/conf/server.xml，添加如下Connector：\n1\u0026lt;Connector port=\u0026#34;8443\u0026#34; protocol=\u0026#34;org.apache.coyote.http11.Http11NioProtocol\u0026#34; 2 maxThreads=\u0026#34;150\u0026#34; SSLEnabled=\u0026#34;true\u0026#34;\u0026gt; 3 \u0026lt;SSLHostConfig 4 certificateVerification=\u0026#34;required\u0026#34; 5 truststoreFile=\u0026#34;/path/to/server-secrets/jks/server.truststore\u0026#34; 6 truststorePassword=\u0026#34;server-ts\u0026#34; 7 truststoreType=\u0026#34;PKCS12\u0026#34;\u0026gt; 8 \u0026lt;Certificate 9 certificateKeyAlias=\u0026#34;server-demo\u0026#34; 10 certificateKeystoreFile=\u0026#34;/path/to/server-secrets/demo-jks/server-demo.keystore\u0026#34; 11 certificateKeystoreType=\u0026#34;PKCS12\u0026#34; 12 certificateKeystorePassword=\u0026#34;server-demo-ks\u0026#34; 13 type=\u0026#34;RSA\u0026#34; /\u0026gt; 14 \u0026lt;/SSLHostConfig\u0026gt; 15\u0026lt;/Connector\u0026gt; 可以看到我们开启了客户端认证certificateVerification=\u0026quot;required\u0026quot;，也开启了服务端认证\u0026lt;Certificate\u0026gt;。记得修改上面的keystore和truststore的路径。\n修改tomcat/conf/web.xml，添加如下元素：\n1\u0026lt;security-constraint\u0026gt; 2 \u0026lt;web-resource-collection\u0026gt; 3 \u0026lt;web-resource-name\u0026gt;Automatic Forward to HTTPS/SSL\u0026lt;/web-resource-name\u0026gt; 4 \u0026lt;url-pattern\u0026gt;/*\u0026lt;/url-pattern\u0026gt; 5 \u0026lt;/web-resource-collection\u0026gt; 6 \u0026lt;user-data-constraint\u0026gt; 7 \u0026lt;transport-guarantee\u0026gt;CONFIDENTIAL\u0026lt;/transport-guarantee\u0026gt; 8 \u0026lt;/user-data-constraint\u0026gt; 9\u0026lt;/security-constraint\u0026gt; 这个作用是当访问8080端口时，都跳转到8443端口，强制走HTTPS。\n启动tomcat：\n1tomcat/bin/catalina.sh run 用curl测试 好了，我们现在用curl来测试访问一下：\n1curl https://localhost:8443/ 2 3curl: (60) SSL certificate problem: self signed certificate in certificate chain 4... 看到curl说服务端用的是一个自签发的证书，不可信，也就是说服务端认证失败。添加--insecure试试：\n1curl --insecure https://localhost:8443/ 2 3curl: (35) error:1401E412:SSL routines:CONNECT_CR_FINISHED:sslv3 alert bad certificate 这里就说明客户端认证失败。\n所以如果要正确访问得像下面这样，指定server-root-ca证书，以及客户端自己签发的证书及private key：\n1curl --cacert server-secrets/ca/server-root-ca.pem \\ 2 --key client-secrets/cert/demo-key.pem \\ 3 --cert client-secrets/cert/demo.pem \\ 4 https://localhost:8443/ 5 6\u0026lt;!DOCTYPE html\u0026gt; 7\u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; 8... Httpclient测试 我们现在用Httpclient来访问看看。pom.xml中添加依赖：\n1\u0026lt;dependency\u0026gt; 2 \u0026lt;groupId\u0026gt;org.apache.httpcomponents\u0026lt;/groupId\u0026gt; 3 \u0026lt;artifactId\u0026gt;httpclient\u0026lt;/artifactId\u0026gt; 4 \u0026lt;version\u0026gt;4.5.7\u0026lt;/version\u0026gt; 5\u0026lt;/dependency\u0026gt; Java代码，记得把文件路径改掉：\n1import org.apache.http.HttpEntity; 2import org.apache.http.HttpException; 3import org.apache.http.client.methods.CloseableHttpResponse; 4import org.apache.http.client.methods.HttpGet; 5import org.apache.http.conn.ssl.SSLConnectionSocketFactory; 6import org.apache.http.impl.client.CloseableHttpClient; 7import org.apache.http.impl.client.HttpClients; 8import org.apache.http.ssl.SSLContexts; 9import org.apache.http.util.EntityUtils; 10 11import javax.net.ssl.SSLContext; 12import java.io.File; 13import java.io.IOException; 14 15public class Client { 16 17 public static void main(String[] args) throws Exception { 18 19 SSLContext sslcontext = SSLContexts.custom() 20 .loadTrustMaterial( 21 new File(\u0026#34;/path/to/client-secrets/demo-jks/client.truststore\u0026#34;), 22 \u0026#34;client-ts\u0026#34;.toCharArray() 23 ) 24 .loadKeyMaterial( 25 new File(\u0026#34;/path/to/client-secrets/demo-jks/client-demo.keystore\u0026#34;), 26 \u0026#34;client-demo-ks\u0026#34;.toCharArray(), 27 \u0026#34;client-demo-ks\u0026#34;.toCharArray()) 28 .build(); 29 30 SSLConnectionSocketFactory sslsf = new SSLConnectionSocketFactory( 31 sslcontext, 32 SSLConnectionSocketFactory.getDefaultHostnameVerifier()); 33 34 CloseableHttpClient httpclient = HttpClients.custom() 35 .setSSLSocketFactory(sslsf) 36 .build(); 37 38 HttpGet httpGet = new HttpGet(\u0026#34;https://localhost:8443\u0026#34;); 39 CloseableHttpResponse response = httpclient.execute(httpGet); 40 try { 41 System.out.println(response.getStatusLine()); 42 HttpEntity entity = response.getEntity(); 43 System.out.println(EntityUtils.toString(entity)); 44 } finally { 45 response.close(); 46 } 47 48 } 49} 安全性考虑  所有private key都很重要！如果它被泄漏了，就要回收它所对应都证书。如果CA的private key泄漏了，那么用它签发的所有证书都要被回收。 keystore和truststore的密码设置的要复杂一些。  关于反向代理 因为服务端认证所需要的证书直接配置在Tomcat上的，因此在做反向代理的时候不能使用SSL Termination模式，而是得使用SSL Passthrough模式。\n其他语言、SDK、工具 上面讲的方法不是只适用于Tomcat和Httpclient的，TLS的服务端认证与客户端认证应该在绝大部分的语言、SDK、类库都有支持，请自行参阅文档实践。文中的keystore和truststore是Java特有的，不过不必迷惑，因为它们仅仅起到一个存放证书和private key的保险箱，有些语言或工具则是直接使用证书和private key，比如前面提到的curl。\n参考资料  cfssl  SSL/TLS Configuration HOW-TO  SSL Support  CONFIGURING TOMCAT SSL CLIENT/SERVER AUTHENTICATION ，这篇文章有点古老了，server.xml的配置方式已经不一样了，仅供参考。 ClientCustomSSL.java  JSSE Reference Guide   一些基础概念：\n Basics of Digital Certificates and Certificate Authority ，基础概念，挺重要 Create Your Own Certificate and CA ，这篇文章挺重要的，主要讲了如何使用keytool和openssl来生成证书的过程 Introducing TLS with Client Authentication  The magic of TLS, X509 and mutual authentication explained   其他运用客户端认证的软件的相关文档，很有启发：\n Etcd - Play etcd TLS部分 Etcd - Example 2: Client-to-server authentication with HTTPS client certificates  Coreos - Generate self-signed certificates  ","date":"2019-03-27","img":"","permalink":"/post/tls/how-to-tls-client-authentication-in-tomcat/","series":null,"tags":["java","tls","openssl"],"title":"如何在Tomcat中做TLS客户端认证"},{"categories":null,"content":"在实践中我们可以将任务拆分成多个子任务并行执行来提高程序的性能。\n“性能”这个词过于含糊，更准确的说应该是：延迟（latency）和吞吐量（throughput）。本文举几个简单的例子来解释在固定线程池大小的情况下，不同的并行程度与延迟和吞吐量的关系。\n场景 假设我们现在有一个task，其执行时长需要2秒。这个task可以被无限拆分，并且执行时长等比例缩减,比如拆分成2个task，那么执行时长变成1秒。同时我们有一个容量为6的线程池，这意味着同一时间范围内最多只能有6个线程工作，同时每个线程可以独占一个CPU核心。\n然后给出不同尺寸的工作集——一个尺寸为4的工作集代表意味着有4个task待执行——来观察当task被各种拆分时的吞吐量和延迟：\n task不被拆分时 task被拆分成2个sub-task的情况 task被拆分成4个sub-task的情况 task被拆分成8个sub-task的情况  先来看看task不被拆分时的执行情况：\n图中例举的当工作集尺寸=10时，每个task的执行时间情况。每一条线都是一个task，橘黄色部分是真正的执行时间，蓝色虚线是等待所花费的时间。这些task被同时提交到线程池中，所以起点相同。因为线程池大小为6，因此前6个task没有等待时间，从第7个task则必须等前面的task执行结束后才能开始执行，它需要等待2秒（单个task的执行时长为2秒）。\n下面是task被拆分成2个subtask的执行情况：\n可以看到task被拆分成2个subtask，每个task所需要的线程也变成了2，总的时间减半变成1秒。和前一个图一样当线程池用满的时候，新的task/subtask必须等待。\n下面是task被拆分成4个subtask的执行情况：\n下面是task被拆分成6个subtask的执行情况（注意时间单位不同了），图里的1根线条代表2个subtask：\n这个是task被拆分成8个subtask的执行情况（注意时间单位不同了），图里的1根线条代表2个subtask：\n吞吐量对比 吞吐量的计算公式：吞吐量 = task数量 / 最慢的task所花费的时间。\n下面是吞吐量对比图：\n图中吞吐量线条的锯齿不用在意，因为这和是否用足了线程池中的线程有关。拿不拆分task举例，当工作集=1时，吞吐量 = 1 / 2 = 0.5 tasks/sec，当工作集=6时 吞吐量 = 6 / 2 = 3 tasks/sec。当工作集=7时 吞吐量 = 7 / 4 = 1.75 tasks/sec，下降了，这是因为有5个线程空闲着没有工作，第7个task拖了后腿。所以我们只需要看吞吐量峰值就行了。而且不出意外可以看到，当subtask数量为6是，吞吐量稳定在3 tasks/sec，这是因为总是会用足线程池中的线程。\n可以看到不论是task如何拆分，吞吐量的峰值都是3 task/sec。在如何估算吞吐量以及线程池大小 提到计算吞吐量的公式：\n在我们这个场景中，Tw=0，所以公式就变成了 C / Tc，我们的C=6，而Tc=2s，所以吞吐量就是3 tasks/sec。\n同时可以看到，当6个CPU用满的情况下，无论任务如何做并行化处理，其吞吐量峰值维持不变。\n当然你也不可能通过扩大线程池来提高吞吐量，因为CPU的数量是固定的。\n延迟对比 下面是延迟平均数、延迟中位数、延迟95%位数、延迟99%位数、延迟100%位数（最大延迟数）的对比图。\n不出所料，当并行程度越高的时候延迟就越低，但是要注意的是，并行程度的增高所带来的延迟降低的边际效益是递减的。\n当subtask  6时 那么当subtask数量 \u0026gt; 6 时会发生什么？下面是subtask分别为8、10时候的吞吐量、延迟数据。\n可以看到吞吐量峰值保持不变，依然是3 tasks/sec。延迟比subtask=6时略有增加。上图只是理论值，实际情况中考虑到线程频繁调度等开销，结果会更糟。\n数据excel可以在这里 下载。\n","date":"2019-03-21","img":"","permalink":"/post/concurrent-programming/parallel-latency-throughput/","series":null,"tags":["并发编程"],"title":"并行、延迟与吞吐量"},{"categories":null,"content":"估算吞吐量 现在有一个task，它的执行时间分为2部分，第一部分做数学运算，第二部分等待IO。这两部分就是所谓的计算操作与等待操作。\n那么现在要求估算在CPU火力全开的情况下，执行这个task能够达到的吞吐量峰值是多少？\n那么我们要先知道执行这个task总共需要多少时间，计算部分花费多少时间，等待部分花费多少时间。\n假设这个task的计算部分花费1秒，等待部分花费9秒，并且开了10个线程执行10个task，在单核CPU的情况下可以得到下面的执行图：\n图中的蓝色线条是等待调度，橙色线条是执行计算任务，绿色线条是CPU等待花费的时间。\n可以得益于开了10个线程，每个task可以利用其他task的等待时间里执行自己的计算操作，同时使得CPU始终处于忙碌状态，即利用率100%。这也告诉你，就算你开11个线程也不会得到更多好处。\n上面这个图的计算任务是按顺序执行的，这只是一个假想情况，实际中操作系统会将这10个线程交替运行，见图中的红色线，操作系统可以在这个范围内对这10个task的计算任务做任意调度。如果去除线程调度的开销，花费的总时间其实还是等于10秒的。\n这个图的吞吐量就显而易见了：\n1throughput = 10 tasks / (10 * computing time + wait time) 2 = 10 tasks / (10 * 1s + 9s) 3 = 10 / 19s = 0.526 tasks/s 如果我们现在有一个双核CPU，那么会怎样呢？\n可以看到因为有了2个CPU核心，计算任务可以重叠，进而花费的时间减半，吞吐量为：\n1throughput = 10 tasks / (10 * computing time / 2 + wait time) 2 = 10 tasks / (10 * 1s / 2 + 9s) 3 = 10 / 14s = 0.7142 tasks/s 那么总结一下吞吐量计算公式：\n Throughput：吞吐量。 Tn：task数量。 C：CPU数量。可以有小数，比如0.5，代表只提供一半的算力。 Tc：task计算所花费的时间。 Tw：task等待花费的时间。 E：最后一个task完成所消耗的时间。  公式中C=1的意思是CPU 100%的全速工作，如果C=0.5那么意思就是CPU有50%的空闲时间，如果C=2则代表启动了两颗CPU全速运行。\n可以看到想要提升吞吐量有：\n 提高C，这个下面会讲。 降低Tc 降低Tw  总的来说就是使用更多的CPU核，让task运行时间更短。\n也许你觉得还可以通过提升Tn来提高吞吐量，比如下面这个图：\n可以看到吞吐量随着任务数量的上升而上升，那么是不是会一直长呢？答案是不会的，当Tn越来越大的时候，Tn * Tc / C 也会越来越大，那么可以忽略掉Tw，公式就变成了 C / Tc，这值就是理论上的吞吐量上界，增加Tn只会无限趋近于这个值。\n估算线程池大小 那么问题来了，如何知道要开多少个线程能够让CPU达到目标利用率？\n这个要看下面的公式：\n N：CPU数量。 U：CPU利用率，0.1代表10%，1代表100%。 C：用到CPU的时间。 W：等待时间。  注：本公式里的 N * U = 吞吐量公式中的C。\n如果U=1（利用率100%），决定线程数量的是W与C的比，当W越高时则需要越多的线程，当W=0时，只需要与N同样的线程即可。\n这个公式也告诉我们开启更多的线程不会带来额外的好处，还会造成反效果（增加的线程调度开销），所以在实践中都会使用具有上界的线程池。\n而且在实际做性能调优的时候，会在计算得到的数字左右调整线程池大小，以达到最好效果。\n参考资料  How to decide pool size for Thread Pools?  ","date":"2019-03-21","img":"","permalink":"/post/concurrent-programming/throughput-and-thread-pool-size/","series":null,"tags":["并发编程"],"title":"如何估算吞吐量以及线程池大小"},{"categories":null,"content":"github 在上一篇文章 中我们介绍了本地事务，随着软件复杂度的上升，我们会需要一种可以在多个数据库之间完成事务（分布式事务 ）的方法，而这个方法也必须能够保证ACID。于是就出现了2PC - Two phase commit protocol 。事实上2PC不仅仅适用于多数据库事务场景下使用，也适用于所有支持2PC的参与方（Participants)。\n算法介绍 2PC的参与方有：\n 一个作为Coordinator的节点 多个作为Cohort的网络节点  2PC假设：\n 所有节点都有一个稳定存储用以保存WAL（write-ahead log ） 没有一个节点会永远崩溃（即会最终恢复） write-ahead log中存储的数据永远不会丢失，不会因崩溃而损坏 任意两个节点都能够互相通信  第四个假设太过严格，实际上有不是所有的2PC实现都满足。第一、二个假设则大多数2PC实现都能满足。\nPS. 如果某个节点完全损坏（比如服务器物理损毁），那么数据就直接丢失了。\n2PC的执行步骤：\n Commit request phase /Voting phase。这个阶段做： Coordinator发送一个查询是否同意commit的请求到所有Cohort，并且等待所有Cohort给出应答。 Cohort收到请求，开始执行事务，执行到就差commit为止（不commit）。 每个Cohort根据操作结果返回Yes或No Commit phase / Completion phase。这个阶段分两种情况： 成功。所有Cohort应答Yes 1. Coordinator发送commit指令到所有Cohort 2. 每个Cohort执行commit，并发送ack到Coordinator 3. 当Coordinator收到每个Cohort的ack之后则事务完成 失败。任意Cohort应答No，或者在commit request阶段超时 1. Coordinator发送rollback指令到所有Cohort 2. 每个Cohort执行rollback，并发送ack到Coordinator 3. 当Coordinator收到每个Cohort的ack之后则事务撤销  消息流（摘自wiki）：\n1Coordinator Cohort 2 QUERY TO COMMIT 3 --------------------------------\u0026gt; 4 VOTE YES/NO prepare*/abort* 5 \u0026lt;------------------------------- 6commit*/abort* COMMIT/ROLLBACK 7 --------------------------------\u0026gt; 8 ACKNOWLEDGMENT commit*/abort* 9 \u0026lt;-------------------------------- 10end 2PC的通信次数是：\n 如果实现没有要求任意两个Cohort可以通信，那么是2n（n=Cohort数量） 如果实现要求任意两个Cohort可以通信，那么是n^2  异常处理 我们把上面的流程简化以便说明异常处理：\n Coordinator发送query to commit Cohort执行prepare Cohort返回ack Coordinator发送commit/rollback Cohort执行commit/rollback Cohort返回ack  从Coordinate角度来看出现异常要怎么处理：\n step 1发生异常，Coordinator需要执行rollback step 2、3发生异常，意味着Coordinator没有收到Cohort的响应，这个时候因认定为失败，执行rollback step 4发生异常，Coordinator重试commit/rollback step 5、6发生异常，意味着Coordinator没有收到Cohort的响应，这个时候因认定为失败，重试commit/rollback  从Cohort角度来看看看出现异常怎么处理：\n step 1，意味着Cohort没有收到请求，什么都不需要做 step 2，意味着Cohort没有执行成功，什么都不需要做 step 3，意味着Coordinator没有收到结果，什么都不需要做，等待Coordinator重试即可。Cohort要保证prepare是幂等的。 step 4，等待Coordinator重试即可，这里有点tricky，如果Coordinator迟迟不retry，那么Cohort要自行rollback，否则就会造成资源死锁。 step 5，等待Coordinator重试即可 step 6，意味着Coordinator没有收到结果，什么都不需要做，等待Coordinator重试即可，Cohort要保证commit/rollback是幂等的。  观察一下你就会发现依然存在漏洞——会出现违反一致性的情况：\n 若Coordinator/Cohort因崩溃遗失了信息，有的Cohort已commit，有的Cohort则恢复到commit之前的状态。 若Coordinator在step 4发送commit，而Cohort在rollback（因timeout导致的rollback）。  出现上面的情况就需要人工介入了。\n更多2PC的异常处理推理详见这篇slides 。\n缺点 根据上面的算法介绍可以看出2PC是一个阻塞协议：\n 如果两个事务针对同一个数据，那么后面的要等待前面完成，这是由于Cohort采用的是本地事务所决定的 Cohort在commit request phase之后会阻塞，直到进入Coordinator告之Cohort进入commit phase  对于ACID的保证 2PC所保证的ACID和本地事务所提到的ACID不太一样——事实上对于所有分布式事务来说都不太一样：\n A，正常情况下保证 C，在某个时间点，会出现A库和B库的数据违反一致性要求的情况 I，在某个时间点，A事务能够读到B事务部分提交的结果 D，和本地事务一样，只要commit则数据被持久  XA XA 是一个针对分布式事务 的spec，它实现了2PC协议。在XA中定义了两种参与方：Transaction Manager（TM）和Resource Manager（RM），其中TM=2PC中的Coordinator，RM=2PC中的Cohort。\nJava规范中的JTA（Java Transaction API）定义了XA的Java接口，JTA的实现有Bitronix、Atomikos等等。\n参考资料  wiki - 2PC  wiki - XA  wiki - Distributed Transaction  wiki - Write-ahead log  For 2 phase commit, why is the worst-case communication complexity of a failed transaction O(n^2)?  slides - Distributed Commit Protocols  ","date":"2019-03-18","img":"","permalink":"/post/d-transactions/2pc/","series":null,"tags":["分布式事务"],"title":"事务 - 2PC"},{"categories":null,"content":"原文：What every programmer should know about memory, Part 4: NUMA support 5 NUMA Support 先回顾一下Section 2。\n5.1 NUMA Hardware Figure 2.3是最简单的NUMA形式，处理器可以有自己的本地内存，访问本地内存和其他处理器的本地内存的开销区别不大，即NUMA factor比较低。\nFigure 2.3: Integrated Memory Controller\n对于商业机器来说，所有处理器共享访问相同的内存，即所有处理器共享同一个北桥，导致所有流量都从北桥走，导致北桥成为瓶颈。虽然可以用定制化硬件代替北桥，但是内存芯片必须得支持多port才行，但是Multiport RAM很复杂很贵，所以几乎没有人会使用。\nFigure 5.1: Hypercubes\n一个高效的节点（处理器）拓扑是超立方体，它限定了节点数量为2C，C为每个节点的interconnect接口数量。超立方体拥有2n处理器系统的最小直径（两节点之间的最大距离）。看Figure 5.1，每个处理器的直径为C，这个是最小值。\n后面是已知的几种NUMA的硬件实现，这里就不写了。\n5.2 OS Support for NUMA 操作系统在分配内存的时候必须将NUMA考虑进去。比如一个进程运行在一个处理器上，那么为其所分配的内存应该来自于本地内存，否则所有的code和data都必须访问远程内存才可以。有一些特殊情况只有在NUMA下才需要考虑。text segment of DSOs通常情况下在物理内存中只存有一份，但如果DSOs被所有CPU的线程或进程所使用（比如libc），这就意味着少数处理器之外的所有处理器都要发生远程访问。理想情况下，操作系统会将DSO在每个处理器的本地物理RAM里做mirror，这是一种优化策略，不是一个要求，通常也很难实现。\n操作系统不应该将一个进程或线程迁移到另一个处理器上。不过操作系统应该已经做了相关防范，因为迁移发生就意味着cache就要重新抓。如果为了负载的均衡，一定要把进程或线程从一个处理器迁移到另一个处理器，操作系统通常会随便选一个还剩有容量的处理器。不过在NUMA环境下，操作系统的选择有一点限制：被选择的新处理器内存访问开销不能比旧处理器大。如果找不到合适的处理器，那么只能使用开销更大的处理器。\n针对上面的情况有两个可能的方法。第一个方法，我们可以期望这个情况是暂时的，之后进程可以被迁移回开销更小的处理器。另一个方法，可以把进程的内存页迁移到距离新处理器更近的地方。第二个方法的开销很大，因为要把大量内存从一个地方迁移到另一个地方，而且迁移期间旧的内存区域是不能修改的，此外还有诸多限制。操作系统应该尽量避免使用这种策略，只有当没办法的时候才能采用。\n为了解决上述进程或线程迁移的情况，默认情况下，内存不是独占地分配到本地节点上的。会在所有节点上分配内存，这样一来进程或迁移就不会产生额外的内存访问开销。对于较小的NUMA factor（NUMA所带来的额外开销）这个策略是可接受的，但仍然不是最优的（见 Section 5.4），而且它实际上降低了性能。所以，Linux允许每个进程自己设定内存分配规则。\n5.3 Published Information 内核通过sys伪文件系统提供处理器的cache信息：/sys/devices/system/cpu/cpu*/cache\n在Section 6.2.1会介绍查询各个cache尺寸的接口。在这里我们关注cache的拓扑结构。上述每个目录都有一堆index*子目录对应不同的cache，里面有type、level、shared_cpu_map这些文件。下面是Intel Core 2 QX6700的信息：\nTable 5.1: sysfs Information for Core 2 CPU Caches\n从上面的数据可以看出：\n 每个核（为啥cpu0到cpu3都是核是从另一个地方知道的）拥有三个cache：L1d、L1i、L2 L1d和L1i是每个核独占的，This is indicated by the bitmap in shared_cpu_map having only one set bit. cpu0和cpu1共享L1、cpu2和cpu3共享L2。  下面是一个four-socket, dual-core Opteron机器的cache信息：\nTable 5.2: sysfs Information for Opteron CPU Caches\n从下面这个路径可以看到处理器的拓扑结构：/sys/devices/system/cpu/cpu*/topology\n可以看到每个核拥有自己的L1d、L1i、L2。\n下表是SMP Opteron的处理器拓扑结构：\nTable 5.3: sysfs Information for Opteron CPU Topology\n结合Table 5.2和Table 5.3，可以看到没有hyper-thread（the thread_siblings bitmaps have one bit set）。而且实际上是4个处理器（physical_package_id0-3），每个处理器有两个核。\n任何SMP Opteron机器都是一个NUMA机器，我们来看看NUMA信息/sys/devices/system/node。每个NUMA节点都有对应的子目录，子目录里有一些文件。下面是前面提到的机器的结果：\nTable 5.4: sysfs Information for Opteron Nodes\n所以我们可以看到这个机器的全貌：\n 这个机器有4个处理器。 每个处理器自成一个node，可以从cpumap文件里的bit看出来。 distance文件描述了访问每个node的开销。本地开销为10，远程开销都是20。（不过这里的信息并不准确，至少有一个处理器要连接到南桥，所以至少有一对处理器的开销比20大） 所有处理器构成一个二维超立方体（Figure 5.1）  5.4 Remote Access Costs AMD文档里写了4插口机器的NUMA开销：\nFigure 5.3: Read/Write Performance with Multiple Nodes\n可以0 Hop、两个1 Hop、2 Hop的读写性能差异。不过这个信息不太容易使用，Section 6.5 会将更简单好用的方法。\n我们有可能知道memory-mapped files, Copy-On-Write (COW) pages and anonymous memory是如何分配在各个节点上的。每个进程有自己的NUMA相关的文件/proc/\u0026lt;PID\u0026gt;/numa_maps，看Figure 5.2：\n100400000 default file=/bin/cat mapped=3 N3=3 200504000 default file=/bin/cat anon=1 dirty=1 mapped=2 N3=2 300506000 default heap anon=3 dirty=3 active=0 N3=3 438a9000000 default file=/lib64/ld-2.4.so mapped=22 mapmax=47 N1=22 538a9119000 default file=/lib64/ld-2.4.so anon=1 dirty=1 N3=1 638a911a000 default file=/lib64/ld-2.4.so anon=1 dirty=1 N3=1 738a9200000 default file=/lib64/libc-2.4.so mapped=53 mapmax=52 N1=51 N2=2 838a933f000 default file=/lib64/libc-2.4.so 938a943f000 default file=/lib64/libc-2.4.so anon=1 dirty=1 mapped=3 mapmax=32 N1=2 N3=1 1038a9443000 default file=/lib64/libc-2.4.so anon=1 dirty=1 N3=1 1138a9444000 default anon=4 dirty=4 active=0 N3=4 122b2bbcdce000 default anon=1 dirty=1 N3=1 132b2bbcde4000 default anon=2 dirty=2 N3=2 142b2bbcde6000 default file=/usr/lib/locale/locale-archive mapped=11 mapmax=8 N0=11 157fffedcc7000 default stack anon=2 dirty=2 N3=2 Figure 5.2: Content of /proc/PID/numa_maps\n主要看N0和N3的值，这个是分配到node 0和3的页的数量。所以可以大概猜到进程执行在node 3的核心上。read-only mapping，比如第一个ld-2.4.so和libc-2.4.so和locale-archive则分配在别的node上。\n下面是真实的测试，和Figure 5.3的数据做比较，不过测试的是1 hop远程访问：\nFigure 5.4: Operating on Remote Memory\n可以看到read总是比本地访问慢20%，这个和Figure 5.3的数据不符合，到底为啥只有AMD自己知道了。图里的几个尖刺可以忽略，这是因为测量多线程代码本身的问题。\n看write的比较，当working set size能够放进cache的时候，也是慢20%。当working set size超出cache的的时候，write和local访问差不多，这是因为此时会直接访问RAM，访问RAM的开销占大头，interconnect开销占小头。\n","date":"2019-03-12","img":"","permalink":"/post/kernel/know-memory-cpu-numa-support/","series":null,"tags":["kernel"],"title":"What Every Programmer Should Know About Memory, Part 4: NUMA Support"},{"categories":null,"content":"原文：What every programmer should know about memory, Part 3: Virtual Memory 4 Virtual Memory 虚拟内存（virtual memory）是处理器的一个子系统，它给每个进程提供虚拟地址空间（virtual address space）。这让每个进程以为自己在系统中是独自一人。\nwiki词条 ：\n 虚拟内存的作用在于为进程提供“看上去”连续的地址空间，这么做的好处在于程序不需要处理内存碎片的问题了。\n 虚拟地址空间由CPU的Memory Management Unit（MMU）实现，操作系统必须填写页表数据结构（page table data structures，见wiki词条 ），大多数CPU自己完成余下的工作。\n把虚拟地址（virtual address）作为输入交给MMU做翻译。在32位系统中虚拟地址是32位的，在64位系统中是64位的。\n4.1 Simplest Address Translation MMU可以逐页（page）的将虚拟地址翻译成物理地址的，和cache line一样，虚拟地址被分割成多个部分，这些部分则被索引到不同的表（table）里，这些表用来构造最终的物理地址。最简单的模型则只拥有一个级别的表（only one level of tables）。\nFigure 4.1: 1-Level Address Translation\n虚拟地址的结构：\n 虚拟地址的头部被用来在一个页目录（Page Directory）中选择条目（entry）， 页目录中存储的是条目（entry），每个条目可由操作系统单独设置。 条目决定了物理内存页的地址，即页的物理地址 虚拟地址的尾部是页内的偏移量 所以页的物理地址+偏移量=物理地址 页目录的条目还包含一些辅助信息，比如访问权限  页目录的存储：\n 页目录是存在内存里的， 操纵系统为其分配一段连续的物理内存空间，并将基地址（base address）存在一个特殊的寄存器里 而条目在目录里就是一个数组（记住这是数组，这对于理解下面多级目录，多级索引很重要）  先弄个速算表，下面会用得着：\n 29=512 210=512 * 2=1024=1K 220=1024 * 1024=1MB  拿x86系统，4MB页举例：\n 虚拟地址的偏移量部分占用22位（可以覆盖4MB的空间） 目录部分则还剩10位，即可以存放1024个条目 每个条目存了10位的物理页内存的基地址 10位+22位=32位，形成了完整的物理内存地址  4.2 Multi-Level Page Tables 多级页表（page table），注意原文写到这里用页表（page table）而不是页目录（page directory），这两个实际上是一个东西。\n上面的例子拿4MB页来举例的，不过4MB页表不常见，这是因为操作系统执行的很多操作是按照页来对齐的，意思是每个页的基地址之间都差4MB的倍数，就算你要用1k内存也要申请了一个4MB的页，这造成了大量的浪费。\n真实世界里32位机器大多用4kB页，同样多见于64位机器。\n为啥4kB页，单级页表不行：\n 虚拟地址偏移量占12位 虚拟地址页目录部分占20位（64位机器就是52位） 页表条目数=220，就算每个条目只占4 bytes（32位）那整个页表页要占4MB 然后每个进程会拥有自己的页表，那么大量的物理内存就会被用在页表上。 实际上不光是物理内存用量太大的问题，因页表就是一个数组，需要连续的内存空间，到时候很难分配。  解决办法是使用多级页表。它们能够代表一个稀疏的巨大的页表，可以做到对没有被使用的区域（原文没有讲区域是啥）不需要分配内存。这种形式跟为紧凑，可以为许多进程提供页表，同时又不对性能产生太大影响。\nFigure 4.2: 4-Level Address Translation\n上面是一个4级页表：\n 虚拟地址被分割成5个部分，其中4个部分是不同页表的索引 第4级页表通过CPU里的一个特殊目的的register来引用 第4级-第2级的页表的内容是对下一级页表引用（我觉得应该就是物理内存地址，因为前面讲过页表存在物理内存中的） 第1级页表存储的物理地址的一部分（应该就是去掉偏移量的那一部分）和辅助数据，比如访问权限 所以整个形成了一个页表树（page table tree），稀疏又紧凑（sparse and compact）  得到物理地址的步骤，Page tree walking：\n 先从register中得到第4级页表的地址， 拿到第4级页表  拿虚拟地址中Level 4 Index取得页表中的条目，这个条目里存的是第3级页表的地址   拿到第3级页表  拿虚拟地址中Level 3 Index取得页表中的条目，这个条目里存的是第2级页表的地址   如此反复直到拿到第1级页表里的条目，这个条目里存的是物理地址的高位部分 结合虚拟地址中的偏移量，得到最终的物理地址 Page tree walking在x86、x86-64处理器里是发生在硬件层面的  Page table tree尺寸对性能的影响：\n 每个进程可能需要自己的page table tree，几个进程共享树的一部分是存在的，但这只是特例。 如果页表树所需内存越小，那就越有利于性能和扩展性（performance and scalability） 理想情况下，把使用的内存在虚拟地址空间里紧密的放在一起，就能够让page table tree占用的空间小（单独看这句没有办法明白，结合后面的内容看 举例，4kB/页，512条目/页表，1页表/每级，那么可以寻址2MB连续的地址空间（512*4kB=2MB） 举例，4kB/页，512条目/页表，4-2级只有1个页表，1级有512个页表，那么可以寻址1GB连续的地址空间（512 * 512 * 4KB=1G）  Page table tree布局：\n 假设所有内存都能够连续的被分配太过简单了 比如，出于灵活性的考虑（flexibility），stack和heap分占地址空间的两端，所以极有可能有2个2级页表，每个二级页表有一个1级页表。 显示中比上面这个更复杂，处于安全性考虑，不同的可执行部分（code、data、heap、stack、DSOs又称共享库）是被影射到随机地址上的。所以进程所使用的不同内存区域是遍布整个虚拟地址空间的。所以一个进程不可能只有一两个2级3级页表的。  个人总结，前面讲的对于多少连续的寻址空间，各级别页表需要多少个是这么计算的：\n 首先得知道前提，对于4-2级页表，在同一页表内，不同页表条目不会指向同一个下一级页表 对于1级页表，不同页表条目不会指向相同的物理地址（准确的说是物理地址去掉offset的部分） 对于4-2级页表，每个页表条目指向一个下级页表，即上级页表条目数目=下级页表数 假设现在是32位系统，每个页表至多保存29=512个页表项  下面举连续的2MB寻址空间（页大小为4kB）：\n 2MB=210 * 210 * 2=221 bytes 所以需要：2MB / 4kB = 221 / 212 = 29个1级页表条目 所以需要：29 / 29=1个一级页表=1个2级页表条目 所以前面说，4kB/页，512条目/页表，1页表/每级，那么可以寻址2MB连续的地址空间  下面举例连续的1GB寻址空间（页大小为4kB）：\n 1GB=210 * 210 * 210=230 bytes 所以需要1级页表条目：1GB / 4kB = 230 / 212=218个1级页表条目 所以需要：218 / 29=29个1级页表=29个2级页表条目 所以需要：29 / 29=1个2级页表 所以前面说，4kB/页，512条目/页表，4-2级只有1个页表，1级有512个页表，那么可以寻址1GB连续的地址空间（512 * 512 * 4KB=1G）  同理如果是连续的2GB寻址空间（页大小为4kB）：\n 1GB=210 * 210 * 210 * 2=231 bytes 所以需要：1GB / 4kB = 231 / 212=219个1级页表条目 所以需要：219 / 29=210个1级页表=210个2级页表条目 所以需要：210 / 29=2个二级页表=2个3级页表条目  4.3 Optimizing Page Table Access  所有页表是存在main memory中的，操作系统负责构建和更新页表 创建进程或更新页表时CPU会收到通知 页表被用来每一次解析虚拟地址到物理地址的工作，采用的方式是page tree walking 当解析虚拟地址的时候，每级都至少有一个页表在page tree walking中被使用 所以每次解析虚拟地址要访问4次内存，这很慢  TLB：\n 现代CPU将虚拟地址的计算结果保存在一个叫做TLB（Tranlsation Look-Aside Buffer）的cache中。 TLB是一个很小的cache，而且速度极快 现代CPU提供多级TLB，级别越高尺寸越大同时越慢。也分为数据和指令两种，ITLB和DTLB。高层级TLB比如2LTLB通常是统一的。（和前一篇文章讲的cache结构类似） 因为虚拟地址的offset不参与page tree walking，所以使用其余部分作为cache的tag 通过软件或硬件prefetch code/data会隐式的prefetch TLB条目，如果地址是在另一个page上时  4.3.1 Caveats Of Using A TLB 讲了几种优化TLB cache flush的手段，不过没有讲现代CPU使用的是哪一种。\n个人认为这段不用太仔细读，只需要知道存在一种手段可以最少范围的flush TLB cache entry就行了。\n4.3.2 Influencing TLB Performance 使用大页：\n 页尺寸越大，则页表需要存储的条目就越少，则需要做的虚拟地址-\u0026gt;物理地址翻译工作就越少，则需要TLB的条目就越少。有些x86/x86-64支持4kB、2MB、4MB的页尺寸。 不过大页存在问题，给大页使用的内存区域必须是连续的。 如果物理内存的管理基本单位和虚拟内存页一样大的话，浪费的内存就会变多（因为内存申请是以页为单位的，不管你用多少，都会占用1页）。 2MB的页对于x86-64系统来说也还是太大了，如果要实现则必须用几个小页组成大页来实现。如果小页是4kB，那么就意味着要在物理内存中连续地分配512个小页。要做到这个比较困难，而且系统运行一段时间物理内存就会变得碎片化。 Linux系统在操作系统启动时遇险分配了一块内存区域存放大页（hugetlbs文件系统），固定数量的物理页被保留给虚拟大页使用。 所以大页适合在以下场景：性能优先、资源充足、不怕配置繁琐，比如数据库应用。  提高虚拟页最小尺寸（前面讲的大页是可选的）也会产生问题：\n 内存影射操作（比如加载应用程序）必须能够适配页尺寸。比页尺寸更小的映射是不允许的。 一个可执行程序的各个部分，在大多数架构中，的关系是固定的。 如果页尺寸变得太大，以至于超出了可执行程序所适配的大小，那么就无法加载了。看下图：  1$ eu-readelf -l /bin/ls 2Program Headers: 3 Type Offset VirtAddr PhysAddr FileSiz MemSiz Flg Align 4... 5 LOAD 0x000000 0x0000000000400000 0x0000000000400000 0x0132ac 0x0132ac R E 0x200000 6 LOAD 0x0132b0 0x00000000006132b0 0x00000000006132b0 0x001a71 0x001a71 RW 0x200000 7... Figure 4.3: ELF Program Header Indicating Alignment Requirements\n这是一个x86-64可执行二进制的头，里面规定了内存对齐单位是0x200000 = 2,097,152 = 2MB，如果页尺寸比这个大就不行了。\n另一个使用大页的影响是减少page table tree的层级，因为offset变大了，那么剩下的留给页表的部分就变少了，那么page tree walking就更快了，那么TLB missing所要产生的工作就变少了。\n下面这段没有看懂：\n Beyond using large page sizes, it is possible to reduce the number of TLB entries needed by moving data which is used at the same time to fewer pages. This is similar to some optimizations for cache use we talked about above. Only now the alignment required is large. Given that the number of TLB entries is quite small this can be an important optimization.\n 4.4 Impact Of Virtualization 大致意思是现代虚拟化技术能够消解大部分因虚拟化导致的TLB性能损失，但是这个开销不会完全消失。\n","date":"2019-03-10","img":"","permalink":"/post/kernel/know-memory-cpu-virtual-memory/","series":null,"tags":["kernel"],"title":"What Every Programmer Should Know About Memory, Part 3: Virtual Memory"},{"categories":null,"content":"原文：What every programmer should know about memory, Part 2: CPU caches 关键词：Cache prefetching、TLB cache missing、MESI protocol、Cache types（L1d、L1i、L2、L3）\n3.1 CPU Caches in the Big Picture 内存很慢，这就是为何CPU cache存在的原因，CPU cache内置在CPU内部，SRAM。 CPU cache尺寸不大。\nCPU cache处于CPU和内存之间，默认情况下CPU所读写的数据都存在cache中。\nIntel将CPU cache分为data cache和code cache，这样会有性能提升。\n随着CPU cache和内存的速度差异增大，在两者之间增加了更大但是更慢的CPU cache，为何不扩大原CPU cache的尺寸？答案是不经济。\n现代CPU core拥有三级缓存。\nL1d是data cache，L1i是instruction cache（code cache）。上图只是概要，现实中从CPU core到内存的数据流一路上可以通过、也可以不通过各个高层cache，这取决于CPU的设计者，这部分对于程序员是不可见的。\n每个处理器拥有多个core，每个core几乎拥有所有硬件资源的copy，每个core可以独立运行，除非它们用到了相同的资源。 每个core有用多个thread，每个thread共享其所属处理器的所有资源，Intel的thread仅对reigster做分离，甚至这个也是有限制的，有些register依然是共享的。\n上面这张图：\n 两个处理器，processors，大的灰色矩形 每个处理器有一个L3 cache和L2 cache（从上往下看第一个深绿色L3 cache，第二个较浅绿色L2 cache） 每个处理器有两个core（小的灰色矩形） 每个core有一个L1d cache和L1i cache（两个浅绿色矩形） 每个core有两个thread，红色矩形，同一个processor的所有core都共享相同的L2/L3 cache  3.2 Cache Operation at High Level 插播概念word ：\n Word，数据的自然单位，CPU指令集所能处理的数据单位。在x86-64架构中，word size=64 bits=8 bytes。\n CPU cache中存储的条目（entry）不是word，而是cache line，如今一条cache line大小为64 bytes。每次从RAM中抓取数据的时候不仅会将目标数据抓过来，还会将其附近的数据一并抓过来，构成64 bytes大小的cache line。\n当一个cache line被修改了，但是还没有被写到内存（main memory），则这个cache line被标记为dirty。一旦被写到内存，则dirty标记被清除。\n对于多处理器系统，处理器之间会互相监视写动作，并维持以下规则：\n A dirty cache line is not present in any other processor\u0026rsquo;s cache. Clean copies of the same cache line can reside in arbitrarily many caches.  Cache eviction类型：\n exclusive，当要加载新数据的时候，如果L1d已满，则需要将cache line推到L2，L2转而推到L3，最终推到main memory。优点：加载新数据的时候只需要碰L1d。缺点：eviction发生时代价逐级增高。 inclusive，L1d中的所有cache line同样存在于L2中。优点：L1d eviction快，因为只需要碰L2。缺点：浪费了一些L2的空间。  下表是Intel奔腾M处理访问不同组件所需的CPU周期：\n   To Where Cycles     Register \u0026lt;= 1   L1d ~3   L2 ~14   Main Memory ~240    下图是写不同尺寸数据下的性能表现：\n根据经验可以推测出L1d size=2^12=4K，L2 size=2^20=1M。当数据\u0026lt;=4K时，正好能够放进L1d中，操作的CPU周期\u0026lt;10个。当数据\u0026gt;4K and \u0026lt;=1M时，会利用到L2，操作的CPU周期\u0026lt;75。当数据\u0026gt;1M时，CPU操作周期\u0026gt;400，则说明没有L3，此时是直接访问内存了。\n非常重要：下面的例子里CPU访问数据是按照以下逻辑：\n CPU只能从L1d cache访问数据 如果L1d没有数据，则得先从L2把数据加载到L1d 如果L2没有数据，则得先从main memory（RAM）加载数据  也就是说如果这个数据一开始在L1d、L2都不存在，那么就得先从main memory加载到L2，然后从L2加载到L1d，最后CPU才可以访问。\n3.3 CPU Cache Implementation Details 3.3.1 Associativity 没看懂。略。\n3.3.2 Measurements of Cache Effects keyword：cache prefetching、TLB cache miss\n测试方法是顺序读一个l的数组：\n1struct l { 2 struct l *n; 3 long int pad[NPAD]; 4}; 根据NPAD不同，元素的大小也不同：\n NPAD=0，element size=8 bytes，element间隔 0 bytes NAPD=7，element size=64 bytes，element间隔 56 bytes NPAD=15，element size=128 bytes，element间隔 120 bytes NPAD=31，element size=256 bytes，element间隔 248 bytes  被测CPU L1d cache=16K、L2 cache=1M、cache line=64 bytes。\nSingle Threaded Sequential Access case 1: element size=8 bytes 下面是NPAD=0（element size=8 bytes，element间隔0 bytes），read 单个 element的平均时钟周期：\nFigure 3.10: Sequential Read Access, NPAD=0\n上面的Working set size是指数组的总尺寸（bytes）。\n可以看到就算数据尺寸超过了16K（L1d size），对每个元素的读的CPU周期也没有到达14，甚至当数据尺寸超过1M（L2 size）时也是这样，这就是因为cache prefetching的功劳：\n 当你在读L1d cache line的时候，处理器预先从L2 cache抓取到L1d cache，当你读L1d next cache line的时候这条cache line已经准备好了。 而L2也会做prefetching动作  Cache prefetching是一项重要的优化手段，在使用连续的内存区域的时候，处理器会将后续数据预先加载到cache line中，也就是说当在访问当前cache line的时候，下一个cache line的数据已经在半路上了。\nPrefetching发生既会发生在L1中也会发生在L2中。\ncase 2: element size = cache line, 总尺寸  各个尺寸element的情况：\n NPAD=7（element size=64 bytes，element间隔56 bytes） NPAD=15，element size=128 bytes，element间隔 120 bytes NPAD=31，element size=256 bytes，element间隔 248 bytes  Figure 3.11: Sequential Read for Several Sizes\n观察working set size \u0026lt;= L2，看（210～219区段）：\n 当working set size \u0026lt;= L1d的时候，时钟周期和NPAD=0持平。 当working set size \u0026gt; L1d \u0026lt;= L2的时候，时钟周期和L2本身的周期吻合，在28左右  这是为什么呢？此时prefetching没有起到作用了吗？这是因为：\n prefetching本身需要时钟周期 顺序read array实际上就是在顺序read cache line 当NPAD=0时，element size=8，就意味着你要read多次才会用光cache line，那么prefetching可以穿插在read之间进行，将next cache line准备好 当NPAD=7,15,31时，element size\u0026gt;=cache line，那么就意味着每次read都把一条cache line用完，没有留给prefetching的时钟周期了，下一次read的时候就只能老实从L2加载，所以时钟周期在28左右。  case 3: selement size = cache line, 总尺寸  L2 还是看各个尺寸element的情况：\n NPAD=7（element size=64 bytes，element间隔56 bytes） NPAD=15，element size=128 bytes，element间隔 120 bytes NPAD=31，element size=256 bytes，element间隔 248 bytes  Figure 3.11: Sequential Read for Several Sizes\n观察working set size \u0026gt; L2，看（219之后的区段）：\n NPAD=7（element size=64），依然有prefetching的迹象 NPAD=15（element size=128）、NPAD=31（element size=256）则没有prefetching的迹象  这是因为处理器从size of the strides 判断NPAD=15和31，小于prefetching window（具体后面会讲），因此没有启用prefetching。而元素大小妨碍prefetching的硬件上的原因是：prefetching无法跨过page boundaries。\n而NPAD=15与31的差别很大则是因为TLB cache miss。\n测量TLB效果 TLB是用来存放virtual memory address到physical memory address的计算结果的（虚拟内存地址和物理内存地址在后面会讲）。\n测试NPAD=7（element size=64），每个元素按照下列两种方式排列的性能表现：\n On cache line，数组中的每个元素连续。也就是每次迭代需要新的cache line，每64个元素需要一个新page。 On page，数组中的每个元素在独立的Page中。每次迭代需要新的cache line。  Figure 3.12: TLB Influence for Sequential Read\n 蓝色曲线看到，当数据量超过212 bytes（4K），曲线开始飙升。因此可以推测TLB的大小为4K。 因为每个元素大小为64 bytes，因此可以推测TLB的entry数目为64. 从虚拟内存地址计算物理内存地址，并将结果放到TLB cache中是很耗时的。 main memory读取或从L2读取数据到cache line之前，必须先计算物理内存地址。 可以看到越大的NPAD就越会降低TLB cache的效率。换句话说，越大的元素尺寸就越会降低TLB cache的效率。 所以address translation（地址翻译）的惩罚会叠加到内存访问上，所以Figure 3.11的NPAD=31（element size=256）周期数会比其他更高，而且也比理论上访问RAM的周期高。  case 4: Sequential Read and Write, NPAD=1 测试NPAD=1，element size=16 bytes，顺序读与写：\n Follow，和之前一样是顺序读的测试结果，作为baseline Inc，每次迭代对pad[0]++ Addnext0，每次迭代读取下一个元素的pad[0]，把值加到自己的pad[0]上  Figure 3.13: Sequential Read and Write, NPAD=1\n按照常理来说，Addnext0应该比较慢因为它做的工组比较多，然而在某些working set size下反而比Inc要好，这是因为：\n Addnext0的读取下一个元素的pad[0]这个动作实际上是force prefetch。当程序读取下一个元素的pad[0]的时候，数据已经存在于cache line之中了。 所以只要working set size符合能够放到L2中，Addnext0的表现和Follow一样好  下面这段没看懂，也许这不重要。\n The “Addnext0” test runs out of L2 faster than the “Inc” test, though. It needs more data loaded from main memory. This is why the “Addnext0” test reaches the 28 cycles level for a working set size of 221 bytes. The 28 cycles level is twice as high as the 14 cycles level the “Follow” test reaches. This is easy to explain, too. Since the other two tests modify memory an L2 cache eviction to make room for new cache lines cannot simply discard the data. Instead it has to be written to memory. This means the available bandwidth on the FSB is cut in half, hence doubling the time it takes to transfer the data from main memory to L2.\n case 4: Sequential Read on larger L2/L3 测试NPAD=15，element size=128 bytes。\nFigure 3.14: Advantage of Larger L2/L3 Caches\n 最后一级cache越大，则曲线逗留于L2访问开销对应的低等级的时间越长 第二个处理器在220时比第一个处理快一倍，是因为它的L3 第三个处理器表现的更好则是因为它的4M L2  所以缓存越大越能得到性能上的提升。\nSingle Threaded Random Access Measurements 之前已经看到处理器通过prefetching cache line到L2和L1d的方法，可以隐藏main memory的访问开销，甚至L2的访问开销。但是，只有在内存访问可预测的情况下，这才能工作良好。\n下图是顺序访问和随机访问的对比：\nFigure 3.15: Sequential vs Random Read, NPAD=0\n后面的没有看懂。\n3.3.3 Write behavior cache应该是coherent的，cache的coherency对于userlevel 代码应该是完全透明的，内核代码除外。\n如果一个cache line被修改了，那么自此时间点之后的系统的结果和压根没有cache并且main memory被修改的结果是一样。有两个实现策略：\nWrite-through：\n 一旦cache line被写，则马上将cache line写到main memory 总是保证main memory和cache保持一致，无论什么时候cache line被替换，所cache的内容可以随时丢弃 优点：实现起来最简单 缺点：虽然简单但是不快。如果一个程序不停的修改一个本地变量，会占用FSB带宽。  Write-back：\n cache line被写不马上写到main memory，仅标记为dirty。 当cache line在之后的某个时间点被drop，dirty标记会指导处理器把内容写到main memory 绝大多数系统采用的是这个策略 处理器甚至可以在驱散cache line之前，利用FSB的空闲空间存储cache line的内容。这样一来就允许清除dirty标记，当需要新空间的时候，处理器就能够直接丢弃cache line。  还有另外两个策略，它们都用于地址空间的特殊区域，这些区域不由实际的RAM支持。\nWrite-combining：\n Write-combining是一种首先的cache优化策略，更多的用于设备的RAM上，比如显卡。 传输数据到设备的开销比访问本地RAM要大得多，所以要尽可能避免传输次数太多。 如果仅因为cache line的一个word 的修改而要把整个cache line都传输太浪费。 因此，write-combining把多个写访问合并在一起，然后再把cache line写出去。 这可以加速访问设备RAM的速度。  个人插播：\n 这个策略牺牲了一定的latency，但是提高了throughput，类似于批处理。\n Uncacheable：\n 内存地址压根就不存在RAM里，这些地址一般都是硬编码的。 在商业机器上，一般来说这些地址会被翻译成访问card和连接到某个总线的设备（PCIe）。 这些内存不应该被缓存。  3.3.4 Multi-processor support 在多处理器系统和多核处理器中，对于所有不共享的cache，都会存在cache内容不一致的问题。两个处理器之间不会共享L1d、L1i、L2、L3，同一处理器的两个核之间至少不会共享L1d。\n提供一条能从A处理器直接访问B处理器的cache的通道是不切实际的，因为速度不够快。所以比较实际的做法是将cache内容传输到其他处理器以备不时之需。对于多核处理器也采用这种做法。\n那什么时候传输呢？当一个处理器需要一条cache line做读/写，但是它在其他处理器里是dirty时。\n那么一个处理器是如何决定一条cache line在另外一个处理器里是否dirty呢？通常来说内存访问是读，而读不会把一个cache line变成dirty。处理器每次对cache line的写访问之后都把cache line信息广播出去是不切实际的。\nMESI cache coherency protocol 开发了MESI缓存协同协议（MESI cache coherency protocol），规定了一条cache line的状态有四种：Modified、Exclusive、Shared、Invalid。\n Modified: 本地处理器刚修改cache line，也意味着它是所有cache中的唯一copy。 Exclusive: cache line没有被修改，但已知没有被加载到任何其他处理的cache中。 Shared: cache line没有被修改，可能存在于其他处理器的cache中。 Invalid: cache line无效，比如还未被使用。   MESI所解决的问题和分布式缓存中数据同步的问题是一致的，好好看看，这能够带来一些启发\n 使用这四个状态有可能有效率地实现write-back策略，同时支持多处理器并发使用read-only数据。\nFigure 3.18: MESI Protocol Transitions\n下面是四种状态变化的解读：\nInvalid：\n 最开始所有的cache line都是空的，也即Invalid 如果数据加载到cache line的目的是为了写，变成Modified 如果数据加载到cache line的目的是为了读，  若其他处理器是否也加载了相同的cache line，变成Shared 如果没有，变成Exclusive    Modified\n 如果一条Modified cache line被本地处理器读or写，状态不变。 如果B处理器要读A处理器的Modified cache line，则A处理器必须将内容发送给B处理器，然后状态变成Shared。  发送给B处理器的数据同样也被memory controller接收和处理，然后存到main memory里。 如果这一步没有做，那么状态就不能变成Shared。   如果B处理器要写A处理器的Modified cache line，则A处理器要把数据传给B，然后标记为Invalid。  这就是臭名昭著的Request For Ownership（RFO）（通过address bus）。在最后一级缓存执行这个操作和I-\u0026gt;M一样，代价相对来说是比较高的 对于write-through cache，则必须加上在高一级cache写新的cache line，或者写到main memory的时间，进一步增加了代价    Shared\n 如果本地处理器读一条Shared cache line，状态不变。 如果本地写一条Shared cache line，则变成Modified。  所有其他处理器的cache line copy变成Invalid。 所以写操作必须通过RFO广播到其他处理器。   如果B处理器要读A处理器的Shared cache line，状态不变。 如果B处理器要写A处理器的Shared cache line，则变成Invalid，不牵涉到bus operation。  Exclusive\n Exlusive和Shared一样除了一个区别：本地写不需要RFO。 所以处理器会尽可能把多的cache line维持在Exclusive状态，而不是Shared状态。  当信息不足的时候，Shared状态作为一种fallback——原文没有说明白是什么信息，猜测应该是当无法知道其他处理器是否拥有相同cache line的时候，就把它设为Shared，这样做会比较安全。 E-\u0026gt;M 比 S-\u0026gt;M 快得多     所以在多处理器系统中，除了填充cache line之外，我们还得关注RFO消息对性能的影响。只要出现了RFO消息，就会变慢。\n 有两种场景RFO消息是必须的：\n 一个线程从一个处理器迁移到另一个处理器，所有的cache line都必须一次性移动到新处理器 同一条cache line是真的被两个处理器需要。   在稍小一点的尺度上，多核处理器内部就存在这样的情况，只是代价小一点而已，RFO可能会被发送很多次。  影响Coherency protocol速度的因素：\n  RFO出现的频率，应该越低越好\n  一次MESI状态变化必须等所有处理器都应答之后才能成功，所以最长的可能应答时间决定了coherency protocol的速度。\n  FSB是共享资源，大多数系统所有处理器通过同一条bus连到memory controller。如果一个处理器饱和了FSB，则共享同一bus的两个或四个处理器将进一步限制每个处理器可用的带宽。\n  就算每个处理器有自己的bus连接memory controller（Figure 2.2），那么处理器到memory module的bus还是会被共享的。\n  在多线程/多进程程序里，总有一些synchronization的需求，这些synchronization则是使用memory实现的，所以就会有一些RFO消息。\n  所以concurrency严重地受限于可供synchronization的有限带宽。\n  程序应该最小化从不同处理器、不同核访问同一块内存区域的操作。\n  Multi Threaded Measurements 用之前相同的程序测试多线程的表现，采用用例中最快的线程的数据。所有的处理器共享同一个bus到memory controller，并且只有一条到memory modules的bus。\ncase 1: Sequential Read Access, Multiple Threads Figure 3.19: Sequential Read Access, Multiple Threads\n这个测试里没有修改数据，所有cache line都是shared，没有发生RFO。但是即便如此2线程的时候有18%的性能损失，在4线程的时候则是34%。那么可能的原因就只可能是一个或两个瓶颈所造成的：处理器到memory controller的bus、memory controller到memory modules的bus。一旦working set超过L3尺寸之后，就要从main memory prefetch数据了，带宽就不够用了\ncase 2: Sequential Increment, Multiple Threads 这个测试用的是 “Sequential Read and Write, NPAD=1，Inc”，会修改内存。\nFigure 3.20: Sequential Increment, Multiple Threads\n注意图中的Y轴不是线性增加的，所以看上去很小的差异实际上差别很大。\n2线程依然有18%的性能损失，而4线程则有93%的性能损失，这意味4线程的时候prefetch流量核write-back流量饱和了bus。\n图中也可以发现只要有多个线程，L1d基本上就很低效了。\nL2倒不像L1d，似乎没有什么影响。这个测试修改了内存，我们预期会有很多RFO消息，但是并没有看见2、4线程相比单线程有什么性能损失。这是因为测试程序的关系。\ncase 3: Random Addnextlast, Multiple Threads 下面这张图主要是为了展现令人吃惊的高数字，在极端情况下处理list中的单个元素居然要花费1500个周期。\nFigure 3.21: Random Addnextlast, Multiple Threads\n总结case 1、2、3 把case 1、2、3中的最大working set size的值总结出多线程效率：\n   #Threads Seq Read Seq Inc Rand Add     2 1.69 1.69 1.54   4 2.98 2.07 1.65    Table 3.3: Efficiency for Multiple Threads\n这个表显示了在最大working set size，使用多线程能获得的可能的最好的加速。理论上2线程应该加速2，4线程应该加速4。好好观察这个表里的数字和理论值的差异。\n下面这张图显示了Rand Add测试，在不同working set size下，多线程的加速效果：\nFigure 3.22: Speed-Up Through Parallelism\nL1d尺寸的测试结果，在L2和L3范围内，加速效果基本上是线性的，一旦当尺寸超过L3时，数字开始下坠，并且2线程和4线程的数字下坠到同一点上。这也就是为什么很难看到大于4个处理器的系统使用同一个memory controller，这些系统必须采用不同的构造。\n不同情况下上图的数字是不一样的，这个取决于程序到底是怎么写的。在某些情况下，就算working set size能套进最后一级cache，也无法获得线性加速。但是另一方面依然有可能在大于两个线程、更大working set size的情况下获得线性加速。这个需要程序员做一些考量，后面会讲。\nspecial case: hyper-threads Hyper-Threads(有时候也被称为Symmetric Multi-Threading, SMT)，是CPU实现的一项技术，同时也是一个特殊情况，因为各个线程并不能够真正的同时运行。超线程共享了CPU的所有资源除了register。各个core和CPU依然是并行运行的，但是hyper-threads不是。CPU负责hyper-threads的分时复用（time-multiplexing），当当前运行的hyper-thread发生延迟的时候，就调度令一个hyper-thread运行，而发生延迟的原因大部分都是因内存访问导致的。\n当程序的运行2线程在一个hyper-thread核的时候，只有在以下情况才会比单线程更有效率：2个线程的运行时间之和低于单线程版本的运行时间。这是因为当一个线程在等待内存的时候可以安排另一个线程工作，而原本这个是串形的。\n一个程序的运行时间大致可以用下面这个简单模型+单级cache来计算：\nTexe = N[(1-Fmem)Tproc + Fmem(GhitTcache + (1-Ghit)Tmiss)]\n N = Number of instructions. 指令数 Fmem = Fraction of N that access memory. N的几分之几访问内存 Ghit = Fraction of loads that hit the cache. 加载次数的几分之几命中cache Tproc = Number of cycles per instruction. 每条指令的周期数 Tcache = Number of cycles for cache hit. 命中cache的周期数 Tmiss = Number of cycles for cache miss. 没命中cache的周期数 Texe = Execution time for program. 程序的执行时间  为了使用两个线程有​​意义，两个线程中每个线程的执行时间必须至多是单线程代码的一半。如果把单线程和双线程放到等式的两遍，那么唯一的变量就是cache命中率。不使线程执行速度降低50%或更多（降低超过50%就比单线程慢了），然后计算所需的最小cache命中率，得到下面这张图：\nFigure 3.23: Minimum Cache Hit Rate For Speed-Up\nX轴代表了单线程代码的Ghit，Y代表了双线程代码所需的Ghit，双线程的值永远不能比单线程高，否则的话就意味着单线程可以用同样的方法改进代码了。单线程Ghit \u0026lt; 55%的时候，程序总是能够从多线程得到好处。\n绿色代表的是目标区域，如果一个线程的降速低于50%且每个线程的工作量减半，那么运行时间是有可能低于单线程的运行时间的。看上图，单线程Ghit=60%时，如果要得到好处，双线程程序必须在10%以上。如果单线程Ghit=95%，多线程则必须在80%以上，这就难了。特别地，这个问题是关于hyper-threads本身的，实际上给每个hyper-thread的cache尺寸是减半的（L1d、L2、L3都是）。两个hyper-thread使用相同的cache来加载数据。如果两个线程的工作集不重叠，那么原95%也可能减半，那么就远低于要求的80%。\n所以Hyper-threads只在有限范围的场景下有用。单线程下的cache命中率必须足够低，而且就算减半cache大小新的cache命中率在等式中依然能够达到目标。也只有这样使用Hyper-thread才有意义。在实践中是否能够更快取决于处理器是否能够充分交叠一个线程的等待和另一个线程的执行。而代码为了并行处理所引入的其他开销也是要考虑进去的。\n所以很明白的就是，如果两个hyper-threads运行的是两个完全不同的代码，那么肯定不会带来什么好处的，除非cache足够大到能够抵消因cache减半导致的cache miss率的提高。除非操作系统的工作负载由一堆在设计上真正能够从hyper-thread获益的进程组成，可能还是在BIOS里关掉hyper-thread比较好。\n3.3.5 Other Details 现代处理器提供给进程的虚拟地址空间（virtual address space），也就是说有两种地址：虚拟的和物理的。\n虚拟地址不是唯一的：\n 一个虚拟地址在不同时间可以指向不同的物理地址。 不同进程的相同的地址也可能指向不同的物理地址。  处理器使用虚拟地址，虚拟地址必须在Memory Management Unit（MMU）的帮助下才能翻译成物理地址。不过这个步骤是很耗时的（注：前面提到的TLB cache缓存的是虚拟-\u0026gt;物理地址的翻译结果）。\n现代处理器被设计成为L1d、L1i使用虚拟地址，更高层的cache则使用物理地址。\n通常来说不必关心cache地址处理的细节，因为这些是不能改变的。\nOverflowing the cache capacity是一件坏事情；如果大多数使用的cache line都属于同一个set，则所有缓存都会提前遇到问题。第二个问题可以通过virtual address来解决，但是无法避免user-level进程使用物理地址来缓存。唯一需要记住的事情是，要尽一切可能，不要在同一个进程里把相同的物理地址位置映射到两个或更多虚拟地址。\nCache replacement策略，目前使用的是LRU策略。关于cache replacement程序员没有什么事情可做。程序员能做的事情是：\n 完全使用逻辑内存页（logical memory pages） 使用尽可能大的页面大小来尽可能多样化物理地址  3.4 Instruction Cache 指令cache比数据cache问题更少，原因是：\n 被执行的代码量取决于所需代码的大小，而代码大小通常取决于问题复杂度，而问题复杂度是固定的。 程序的指令是由编译器生成的，编译器知道怎么生成好代码。 程序流程比数据访问内存更容易预测，现代处理器非常擅长预测模式，这有助于prefetching 代码总是具有良好的空间、时间局部性。  CPU核心和cache（甚至第一级cache）的速度差异在增加。CPU已被流水线化，所谓流水线指一条指令的执行是分阶段的。首先指令被解码，参数被准备，最后被执行。有时候这个pipeline会很长，长pipeline就意味着如果pipeline停止（比如一条指令的执行被中断了），那它得花一些时间才能重新找回速度。pipeline停止总是会发生的，比如无法正确预测下一条指令，或者花太长时间加载下一条指令（比如从内存里加载）。\n现代CPU设计师花费了大量时间和芯片资产在分支预测上，为了尽可能不频繁的发生pipeline停止。\n3.4.1 Self Modifying Code 早些时候为了降低内存使用（内存那个时候很贵），人们使用一种叫做Self Modifing Code（SMC）的技术来减少程序数据的尺寸。\n不过现在应该避免SMC，因为如果处理器加载一条指令到流水线中，而这条指令在却又被修改了，那么整个工作就要从头来过。\n所以现在到处理器假设code pages是不可变的，所以L1i没有使用MESI，而是使用更简单的SI\n3.5 Cache Miss Factors 我们已经看到内存访问cache miss导致的开销极具增大，但是有时候这个问题是无法避免的，所以理解实际的开销以及如何缓解这个问题是很重要的。\n3.5.1 Cache and Memory Bandwidth 测试程序使用x86和x86-64处理器的SSE指令每次加载16 bytes，working set size从1K到512M，测试的是每个周期能够加载/存储多少个bytes。\nFigure 3.24: Pentium 4 Bandwidth\n这个图是64-bit Intel Netburst处理器的测试结果。\n先看读的测试可以看到：\n 当working set size在L1d以内的时候，16 bytes/cycle 当L1d不够用的时候，性能下降很快，6 bytes/cycle 到218的时候又下降了一小段是因为DTLB耗尽了，意思是对每个新page需要额外工作。 这个测试是顺序读的，很利于prefetching，而在任何working set size下都能够达到5.3/cycle，记住这些数字，它们是上限，因为真实程序永远无法达到这个值。  在看写和copy的测试：\n 就算是最小的working set size，也不超过4 bytes/cycle。这说明Netburst处理器使用的Write-through策略，L1d的速度显然受制于L2的速度。 copy测试是把一块内存区域copy到另一个不重叠的内存区域，因为上述原因它的结果也没有显著变差。 当L2不够用的时候，下降到0.5 bytes/cycle。  下面是两个线程分别钉在同一核心的两个Hyper-thread上的测试情况：\nFigure 3.25: P4 Bandwidth with 2 Hyper-Threads\n这个结果符合预期，因为Hyper-thread除了不共享register之外，其他资源都是共享的，cache和带宽都被减半了。这意味着就算一个线程在在等待内存的时候可以让另一个线程执行，但是另一个线程实际上也在等待，所以并没有什么区别。\n下图是Intel Core2处理器的测试结果（对比Figure 3.24）：\nFigure 3.26: Core 2 Bandwidth\nCore 2 L2是P4 L2的四倍。这延迟了write和copy测试的性能下跌。read测试在所有的working set size里都维持在16 bytes/cycle左右，在220处下跌了一点点是因为DTLB放不下working set。能够有这么好的性能表现不仅意味着处理器能够及时地prefetching和传输数据，也意味着数据是被prefetch到L1d的。\n看write和copy的表现，Core 2处理器的L1d cache没有采用Write-through策略，只有当必要的时候L1d才会evict，所以能够获得和read接近的表现。当L1d不够用的时候，性能开始下降。当L2不够用的时候再下跌很多。\n下图是Intel Core2处理器双线程跑在两个核心上：\nFigure 3.27: Core 2 Bandwidth with 2 Threads\n这个测试两个线程分别跑在两个核心上，两个线程访问相同的内存，没有完美地同步。read性能和Figure 3.26没有什么差别。\n看write和copy的表现，有意思的是在working set能够放进L1d的表现和直接从main memory读取的表现一样。两个线程访问相同的内存区域，针对cache line的RFO消息肯定会被发出。这里可以看到一个问题，RFO的处理速度没有L2快。当L1d不够用的时候，会将修改的cache line flush到共享的L2，这是性能有显著提升是因为L1d中的数据被flush到L2，那就没有RFO了。而且因为两个核心共享FSB，每个核心只拥有一半的FSB带宽，意味着每个线程的性能大约是单线程的一半。\n厂商的不同版本CPU和不同厂商的CPU的表现都是不同的。原文里后面比较了AMD Opteron处理器，这里就不写了。\n3.2.5 Critical Word Load 数据是一block为单位从main memory传输到cache line的，一个block大小为64 bits（记得前面说的word也是64 bits），一条cache line的大小是64/128 bytes，所以填满一个cache line要传输8/16次。\n后面没有看懂，大致意思是Critical word是cache line中的关键word，程序要读到它之后才能继续运行，但是如果critical word不是cache line的第一个，那么就得等前面的word都加载完了之后才行。blah blah blah，不过这个理解可能也是不对的。\n3.5.3 Cache Placement cache和hyper-thread、core、处理器的关系是程序员无法控制的，但是程序员可以决定线程在哪里执行，所以cache和CPU是如何关联的就显得重要了。\n后面没仔细看，大致讲了由于不同的CPU架构，决定如何调度线程是比较复杂的。\n3.5.4 FSB Influence 不细讲了，对比了667MHz DDR2和800 MHz DDR2（20%的提升），测试下来性能有18%的提升接近理论值（20%）。\nFigure 3.32: Influence of FSB Speed\n所以更快的FSB的确能够带来好处。要注意CPU可能支持更高的FSB，但是主板/北桥可能不支持的情况。\n","date":"2019-03-05","img":"","permalink":"/post/kernel/know-memory-cpu-cache/","series":null,"tags":["kernel"],"title":"What Every Programmer Should Know About Memory, Part 2: CPU Caches"},{"categories":null,"content":"原文：What every programmer should know about memory, Part 1, RAM 1 Introduction 如今的计算机架构中CPU和main memory的访问速度的差异是很大的，解决这一瓶颈有这么几种形式：\n RAM硬件设计的改善（速度和并行） Memory controller设计 CPU caches 给设备用的Direct memory access（DMA）  2 Commodity Hardware Today 大众架构 Figure 2.1: Structure with Northbridge and Southbridge\n 所有CPU通过FSB 连接到北桥，北桥包含内存控制器（memory controller），连接到RAM。不同的内存类型如SRAM、DRAM有不同的内存控制器。 南桥又称I/O桥，如果要访问其他系统设备，北桥必须和南桥通信。南桥连接着各种不同的bus  这个架构要注意：\n CPU之间的所有数据通信必须经过FSB，而这个FSB也是CPU和北桥通信的bus。 所有和RAM的通信都必须经过北桥 RAM只有一个端口（port） CPU和挂接到南桥设备的通信则有北桥路由  可以发现瓶颈：\n 为设备去访问RAM的瓶颈。解决办法是DMA，让设备直接通过北桥访问RAM，而不需要CPU的介入。如今挂到任一bus的所有高性能设备都能利用DMA。虽然DMA减少了CPU的工作量，但是争用了北桥的带宽 北桥到RAM的瓶颈。老的系统里只有一条通往所有RAM芯片的bus。现在的RAM类型要求有两条独立的bus，所以倍增了带宽（DDR2里称为channel）。北桥通过多个channel交替访问内存。  多内存控制器 比较贵的系统北桥自己不包含内存控制器，而是外接内存控制器：\nFigure 2.2: Northbridge with External Controllers\n在这种架构里有多个内存bus，大大增加了带宽。在并发内存访问的时候，可以同时访问不同的memory bank（我理解为就是内存条）。而这个架构的瓶颈则是北桥内部的带宽。\nNUMA 除了使用多个内存控制器，还可以采用下面的架构增加内存带宽。做法就是把内存控制器内置在CPU里。每个CPU访问自己的本地RAM。\nFigure 2.3: Integrated Memory Controller\n这个架构同样也有缺点：因为这种系统里的所有CPU还是要能够访问所有的RAM，所以the memory is not uniform anymore (hence the name NUMA - Non-Uniform Memory Architecture - for such an architecture)。访问本地内存速度是正常的，访问别的CPU的内存就不一样了，CPU之间必须interconnect才行。在上图中CPU1访问CPU4的时候就要用到两条interconnect。\n2.1 RAM Types 2.1.1 Static RAM  访问SRAM没有延迟，但SRAM贵，容量小。  Figure 2.4: 6-T Static RAM\n电路图就不解释了。\n2.2.1 Dynamic RAM Figure 2.5: 1-T Dynamic RAM\n电路图就不解释了。\n DRAM物理结构：若干RAM chip，RAM chip下有若干RAM cell，每个RAM cell的状态代表1 bit。 访问DRAM有延迟（等待电容充放电），但DRAM便宜，容量大。商业机器普遍使用DRAM，DDR之类的就是DRAM。  2.1.3 DRAM Access Figure 2.7: Dynamic RAM Schematic\n访问DRAM的步骤：\n RAS（Row address selection） CAS（Column address selection） 传输数据  RAS和CAS都需要消耗时钟频率，如果每次都需要重新RAS-CAS则性能会低。如果一次性把一行的数据都传输，则速度很快。\n2.1.4 Conclusions  不是所有内存都是SRAM是有原因的（成本原因） memory cell必须被单独选择才能够使用 address line的数目直接影响到内存控制器、主板、DRAM module、DRAM chip的成本 需要等待一段时间才能得到读、写操作的结果  2.2 DRAM Access Technical Details 略。\n2.2.4 Memory Types  现代DRAM内置I/O buffer增加每次传输的数据量。  Figure 2.14: DDR3 SDRAM Operation\n2.2.5 Conclusions  假如DRAM的时钟频率为200MHz，I/O buffer每次传送4份数据（商业宣传其FSB为800MHz），你的CPU是2GHz，那么两者时钟频率则是1:10，意味着内存延迟1个时钟频率，那么CPU就要等待10个时钟频率。  2.3 Other Main Memory Users  网络控制器、大存储控制器，使用DMA访问内存。 PCI-E卡也能通过南桥-北桥访问内存。 USB也用到FSB。 高DMA流量会占用FSB，导致CPU访问内存的时候等待时间变长。 在NUMA架构中，可以CPU使用的内存不被DMA影响。在Section 6会详细讨论。 没有独立显存的系统（会使用内存作为显寸），这种系统对于RAM的访问会很频繁，造成占用FSB带宽，影响系统性能。 ","date":"2019-03-03","img":"","permalink":"/post/kernel/know-memory-ram/","series":null,"tags":["kernel"],"title":"What Every Programmer Should Know About Memory, Part 1, RAM"},{"categories":null,"content":"CPU modes 又称process modes, CPU states, CPU privilege levels，CPU modes是为了能够让某些计算机架构的CPU限制正在被CPU运行的进程所能执行的操作的类型和范围。得益于它操作系统才能够以比应用程序更高的privilege（特权）来运行。\nCPU modes分为两类：\n kernel mode，不受任何限制的做任何事情 user modes，受限模式，注意user modes可以有多个模式  Protection ring Protection ring又称hierarchical protection domains，是一种保护数据和功能免于遭受错误和恶意行为的机制。\n一个Protection ring由一个或多个分级式levels or layers of privilege组成。 通常来说protection ring是硬件强制的，是由一些CPU架构在硬件或微代码层面提供不同的CPU modes来达成的。Protection ring本身也是层级的，由最具特权开始（编号0）到具有最少特权的（编号更大）。在大多数操作系统中，Ring 0是最具特权的，能够直接物理硬件（如CPU、内存）交互。\nx86架构的protection ring：Ring 0（kernel）、Ring 1-2（Device drivers）、Ring 3（Applications）。下图：\n各个CPU的架构提供的ring数不同，有的多达8个。操作系统为了适配更多的CPU架构，不会使用所有的ring，即使硬件支持更多的CPU modes。比如Windows Server 2008系统只用了Ring 0和Ring 3。\n当处理器在某个ring发生错误时，会影响到所有低权限ring。所以当错误发生在ring 0时，整个系统都会崩溃。\nSystem call（系统调用） Linux、macOS、Windows之类的单体内核（monolithic kernel）操作系统，操作系统运行在kernel mode（supervisor mode），应用程序运行在user mode。\n运行在user mode的代码必须使用system call才能够使用到操作系统内核kernel所提供的服务。\n因为针对不同CPU架构，system call的汇编码是不同的，因此操作系统会提供库（如glibc）将system call包一层，方便应用程序使用。System call发生时会将控制权交给kernel，调用结束时则将控制权交还给user mode的进程。\nSystem call一般不要求context switch，因为system call发生在同一进程里。\n参考资料  CPU modes  Protection rings  System call  ","date":"2019-02-27","img":"","permalink":"/post/kernel/cpu-kernel-mode-user-mode/","series":null,"tags":["kernel"],"title":"操作系统Kernel Mode和User Mode"},{"categories":null,"content":"TODO\n","date":"2019-02-27","img":"","permalink":"/post/kernel/virtual-memory-kernel-space-user-space/","series":null,"tags":["kernel"],"title":"Virtual Memory Kernel Space User Space"},{"categories":null,"content":"Image tag是不稳定的 Docker image的tag是不稳定的，这句话的意思是就算tag不变，其所代表的image并非一成不变，例如openjdk:8在去年代表jdk 8u161今年则代表jdk 8u191。就算你使用openjdk:8u181也不能保证这个image是不变的，为什么这么说？\n一个Docker image大致是由4部分组成的：\n 其依赖的基础镜像，由Dockerfile的FROM指令所指定 其所包含的软件，在这个例子里就是 openjdk 8u181 Dockerfile的其他脚本 启动入口，比如docker-entrypoint.sh  就算软件不发生变化，另外3个也是有可能发生变化的，而构建的新image的tag依然是openjdk:8u181。而且要注意到一般采用的是软件的版本号作为tag，而不是commit、构建日期作为tag。如果你是Java程序员，可以类比docker image tag为maven的SNAPSHOT 。\n那这意味着什么？\n 从docker image使用方角度，每次启动之前都需要pull一下，确保使用了新的image 从docker image提供方角度，就算你的软件版本已经冻结，你仍然需要定期构建image并发布仓库上  针对稳定与非稳定版本的构建策略 和Maven的版本定义一样，你的软件应该分为两种：\n stable版，即一旦发布其版本号对应的代码不会再做修改 snapshot版，又称nightly-build版，即该版本号对应的代码是不稳定的  对于stable版，你应该定期对其构建image。比如你有版本1.0、1.1、1.2，那你应该定期从软件仓库中下载这三个版本的构建物，然后对为它们构建image。以Maven举例，定期从Maven仓库下载它们的Jar，然后为它们构建image。记得确保docker build添加了--pull选项。\n对于snapshot版，你应该将构建image的过程融入到软件的构建过程中。以Maven为例，使用spotify-dockerfile-plugin ，mvn clean install dockerfile:build dockerfile:push。\n不论是stable版还是snapshot版，都应该利用CI/CD工具（如Jenkins）将image构建工作自动化。\n","date":"2019-02-27","img":"","permalink":"/post/docker-image-build-strategy-for-different-version-type/","series":null,"tags":["docker","CI_CD"],"title":"稳定与非稳定版本软件的Docker Image构建策略"},{"categories":null,"content":"本文只是拿Java代码做说明的例子，不代表Java的vtable是这样实现的\n虚函数表，又称 virtual method table (VMT), virtual function table, virtual call table, dispatch table, vtable, or vftable。是一种用于支持dynamic dispatch （或称为run-time method binding）的机制。而动态转发则是实现多态中重要一环——方法重写——的重要机制。\n考虑下面代码：\n1class Super { 2 void test() {} 3} 4class Derived extends Super { 5 void test() { 6 } 7} 8 9Super s = ...; 10s.test(); s.test()所调用的是Super#test()还是Derived#test()在编译期是无法知道，因为s指向的真正类型可能是Super也可能是Derived，那么s.test()到底调用那个类的test方法只能在运行时知道，那么是如何知道的呢？答案是依靠vtable。\n每个类都有一张vtable，vtable里记录了每个虚方法（PS. 在Java中除static、\u0026lt;init\u0026gt;、\u0026lt;clinit\u0026gt;、final method之外的都是虚方法）的偏移量及内存地址。父类的vtable的内容会在子类vtable中复制一份，并且保持相同的偏移量，方法的内存地址则要看子类是否覆盖了父类方法而定。下面是vtable布局大致概念：\nObject vtable\n   offset method addr     0 toString() addr-1   1 hashcode() addr-2    Super vtable\n   offset method addr     0 toString() addr-1   1 hashcode() addr-2   2 test() addr-3    Derived vtable\n   offset method addr     0 toString() addr-1   1 hashcode() addr-2   2 test() addr-4    可以看到Super虽然没有覆盖Object类的toString()、hashcode()，但是其vtable中依然有这两个函数，且偏移量和地址与Object vtable一样。Derived的test()方法偏移量与Super的test()方法偏移量一样，但是地址不同，因为Derived覆盖了test()方法。\n当s.test()时做了这么几件事情：\n 获得s所指向的类的vtable 在vtable中找到test()方法条目里所记载的地址 调用该地址的函数  所以虚方法的调用要比直接调用多了几个步骤，对于性能是有损失的。\n那么能够想到的优化方法是记录Derived#test()方法的偏移量，那么当下一次调用的时候就变成了：\n 获得s所指向的类的vtable 发现本次是找Derived#test()，上次记录了该方法在vtable中的偏移量是2 调用偏移量2的条目的内存地址上的函数  参考资料  Virtual method table  12.5 — The virtual table  ","date":"2019-02-25","img":"","permalink":"/post/vtable/","series":null,"tags":["vtable","jvm","kernel"],"title":"虚函数表（vtable/Virtual Table/Virtual Method Table）"},{"categories":null,"content":" 极客时间 - 数据结构与算法之美 - 12 | 排序（下）   问题描述：现在你有 10 个接口访问日志文件，每个日志文件大小约 300MB，每个文件里的日志都是按照时间戳从小到大排序的。你希望将这 10 个较小的日志文件，合并为 1 个日志文件，合并之后的日志仍然按照时间戳从小到大排列。如果处理上述排序任务的机器内存只有 1GB，你有什么好的解决思路，能“快速”地将这 10 个日志文件合并吗？\n思路：其实就是归并排序的里的归并步骤，只不过从归并两个数组变成了归并多个数组。PS. 看这类问题的时候一定仔细看看空间限制条件，不要被吓到也不要随意做判断。\n代码：\n1public class MergeSortedFiles { 2 public static void merge(List\u0026lt;FileIterator\u0026gt; fileIteratorList) { 3 4 FileWriter fileWriter = null; 5 6 // 记录还没有遍历结束的文件 7 List\u0026lt;FileIterator\u0026gt; notEndingFileIterators = new ArrayList\u0026lt;\u0026gt;(fileIteratorList); 8 9 while (!notEndingFileIterators.isEmpty()) { 10 11 FileIterator min = getMin(notEndingFileIterators); 12 fileWriter.writeLine(min.getLine()); 13 14 if (!min.nextLine()) { 15 // 该文件已经遍历到尾了，将其移除 16 notEndingFileIterators.remove(min); 17 } 18 19 } 20 } 21 22 private static FileIterator getMin(List\u0026lt;FileIterator\u0026gt; notEndingFileIterators) { 23 24 FileIterator min = null; 25 26 for (FileIterator fi : notEndingFileIterators) { 27 if (min == null) { 28 min = fi; 29 continue; 30 } 31 32 if (fi.getLine().compareTo(min.getLine()) \u0026lt; 0) { 33 min = fi; 34 } 35 } 36 return min; 37 } 38} 39 40/** 41* 这里不做实现，只表达意思 42*/ 43interface FileIterator { 44 /** 45* 返回当前行 46* 47* @return 48*/ 49 String getLine(); 50 51 /** 52* 前进到下一行 53* 54* @return 如果已经是最后一行了，返回false。否则返回true。 55*/ 56 boolean nextLine(); 57} 58 59/** 60* 这里不做实现，只表达意思 61*/ 62interface FileWriter { 63 /** 64* 写一行到文件中 65* 66* @param line 67*/ 68 void writeLine(String line); 69} 算法复杂度分析：\n 不存在最好最坏情况，因为遍历次数是固定的。 总行数n、文件数k、每个文件行数m，如果数据特征正好能够达成每次把一个文件遍历完再遍历其余的，那么遍历次数是 m*k + m*(k-1) + m*(k-2) + ... + m*1 = m*(k*(k+1)/2)，把m=n/k代入得到，n(k+1)/2，为O(n)。 ","date":"2019-02-25","img":"","permalink":"/post/algo/14-merge-sorted-files/","series":null,"tags":["ARTS-A"],"title":"算法 - 合并若干有序文件"},{"categories":null,"content":" 极客时间 - 数据结构与算法之美 - 12 | 排序（下）   本题目借助快排思想，算法描述：\n a为待排序数组，n为数组长度   问题转换：把第k大数字转换成第l小数字，比如：n=5，k=1，那么l=n-k+1=5，也就是第5小的数字，其下标l_i=5-1=4。 取a[n-1] 作为 pivot 用快排的思路，把 \u0026lt; pivot 的元素放到 pivot 左边，把 \u0026gt;= pivot 的元素放到 pivot 右边，得到pivot的下标：pivot_i 如果 pivot_i \u0026lt; l_i，则说明被查找的数字可能在右边，对右边重复2-5步骤 如果 pivot_i \u0026gt; l_i，则说明被查找的数字可能在左边，对左边重复2-5步骤  代码：\n1public static int findKthBigNumber(int[] a, int kthBig) { 2 int n = a.length; 3 if (kthBig \u0026gt; n) { 4 return -1; 5 } 6 int lthSmall = n - kthBig; 7 8 return quickFind(a, 0, a.length - 1, lthSmall); 9} 10 11private static int quickFind(int[] a, int start, int end, int lthSmall) { 12 if (start \u0026gt; end) { 13 return -1; 14 } 15 int pivot_i = partition(a, start, end); 16 17 if (pivot_i == lthSmall) { 18 return a[pivot_i]; 19 } 20 21 if (pivot_i \u0026lt; lthSmall) { 22 return quickFind(a, pivot_i + 1, end, lthSmall); 23 } 24 25 return quickFind(a, start, pivot_i - 1, lthSmall); 26 27} 28 29/** 30* 快排的分区算法 31* 32* @param a 33* @param start 34* @param end 35* @return 分区点 36*/ 37private static int partition(int[] a, int start, int end) { 38 int pivot = a[end]; 39 40 int pivot_i = start; 41 for (int j = start; j \u0026lt;= end - 1; j++) { 42 if (a[j] \u0026lt; pivot) { 43 if (pivot_i != j) { 44 int tmp = a[j]; 45 a[j] = a[pivot_i]; 46 a[pivot_i] = tmp; 47 } 48 pivot_i++; 49 } 50 } 51 52 a[end] = a[pivot_i]; 53 a[pivot_i] = pivot; 54 return pivot_i; 55} 算法复杂度分析：\n最好情况：\n k \u0026gt; n，即要找的数字超出了数组所能给出的范围，复杂度O(1)。 第一次分区的pivot就是要找的数字，遍历n-1次，复杂度O(n)。  最坏情况：\n 每次pivot分区极不均匀——pivot的左分区元素数量为原始分区数量-1，或者pivot的右分区数量为原始分区数量-1——且分区大小要变成1之后，才能够找到要找的元素。 比如 k=n，且这个数组已经是有序了。那么每次遍历的次数是 (n-1)+(n-2)+(n-3)+...+1=n(n-1)/2，即O(n^2)。  平均情况：\n 不知怎么分析 ","date":"2019-02-25","img":"","permalink":"/post/algo/13-find-kth-big-number/","series":null,"tags":["ARTS-A"],"title":"算法 - 查找第K大数字"},{"categories":null,"content":"String interning （字符串拘留？），是一项把相同字符串值只保存一份copy的方法，比如 \u0026quot;abc\u0026quot;和\u0026quot;abc\u0026quot;虽然是两个字符串，但是因为其值相同，所以只存留一份copy。String interning能够使得处理字符串的任务在时间上或空间上更有效率。不同字符串值保存在所谓string intern pool里。\nJava语言规定所有字符串字面量（string literals）和所有结果为字符串的常量表达式（string-valued constant expression）都被自动interned。或者也可以通过调用String#intern()方法来手动interned。而interened字符串具有这个特性：当且仅当a.equals(b)==true，那么a.intern() == b.intern()。\n下面是一个例子来说明：\n1package testPackage; 2class Test { 3 public static void main(String[] args) { 4 String hello = \u0026#34;Hello\u0026#34;, lo = \u0026#34;lo\u0026#34;; 5 System.out.print((hello == \u0026#34;Hello\u0026#34;) + \u0026#34; \u0026#34;); 6 System.out.print((Other.hello == hello) + \u0026#34; \u0026#34;); 7 System.out.print((other.Other.hello == hello) + \u0026#34; \u0026#34;); 8 System.out.print((hello == (\u0026#34;Hel\u0026#34;+\u0026#34;lo\u0026#34;)) + \u0026#34; \u0026#34;); 9 System.out.print((hello == (\u0026#34;Hel\u0026#34;+lo)) + \u0026#34; \u0026#34;); 10 System.out.println(hello == (\u0026#34;Hel\u0026#34;+lo).intern()); 11 } 12} 13class Other { static String hello = \u0026#34;Hello\u0026#34;; } 1package other; 2public class Other { public static String hello = \u0026#34;Hello\u0026#34;; } 运行结果是：\n1true true true true false true  同类、同包的string literals引用相同的String对象。 不同类、同包的string literals指向相同的String对象。 不同类、不同包的string literals指向相同的String对象。 由constant expression计算得到的字符串是在编译期被计算出来的，被视同为string literal处理。 在运行期通过串接计算得到的字符串则是新创建的，所以不是同一个对象。 显式得intern一个计算得到的字符串的结果，和已经存在的具有相同内容的string literal一样。  参考资料  String interning  Java Language Spec - 3.10.5. String Literals  Java Language Spec - 15.28. Constant Expressions  String#intern()  ","date":"2019-02-24","img":"","permalink":"/post/jvm/string-interning/","series":null,"tags":["jvm"],"title":"JVM - String Interning"},{"categories":null,"content":"原文：Container isolation gone wrong 。\n这篇文章讲了如何分析定位容器运行性能问题的案例。\n现象很简单：有两个容器worker和trasher，当worker独自运行的时候一切OK，当worker和trasher在同一个host上运行的时候，worker性能衰减的很厉害。\n了解这两个容器干什么的：\n worker定期扫描某个目录下文件是否有变化 trasher则是异步处理文件  重现问题：\n 在host上只启动worker，cgroup设定为10% CPU/512M 内存，通过StatsD指标发现任务延迟耗时稳定在~250ms 启动trasher之后，cgroup设定为10% CPU/512M 内存，观察一个小时内的变化，延迟逐步攀升到~550ms 把trasher关掉之后，worker立即回到~250ms  先期排查：\n 怀疑容器的内存/cpu cgroups没有设置正确，结果发现设置正确 怀疑容器的内存/cpu cgroups没有生效，发现的确生效了。且两个容器的CPU/内存使用都远远没有达到cgroup设置的上限。  继续观察：发现host的内存使用量在持续上升，高达~25G，如果trasher关掉，则内存使用量立马下降到正常值，数百M。这提供了一个重要信息，就是内存是被内核所使用的 。\n尝试从系统调用（system call）来观察两个容器干了什么，用sudo sysdig container.name=\u0026lt;container-name\u0026gt;观察两个容器的系统调用：\n worker递归扫描某个目录下的文件 trasher尝试打开大量/tmp/UUID（比如，/tmp/356eb968-88e8-43bf-ba29-d4523577d48e）文件，而这些文件并不存在。  看不出什么，然后找到那个系统调用导致了任务延迟从~250ms到500-600ms\n 用sysdig -r worker1.scap -r worker2.scap -c topscalls_time分别查看单启worker和同时启worker和trasher的时候，worker的系统调用的累积时间。发现lstat的调用增长符合观察到的预期。 用sysdig -r worker1.scap -c spectrogram evt.type=lstat和sysdig -r worker2.scap -c spectrogram evt.type=lstat做的频谱图证实，大部分的lstat的调用从1.x us增长到10.x us  用perf工具进一步观察：\n sudo perf top -p \u0026lt;worker-pid\u0026gt; -d 60 --stdio，观察到__d_lookup的调用占了50%以上的时间。__d_lookup是内核函数，也就意味着大部分时间被内核占用了。 __d_lookup是一个从缓存中查找文件metadata的函数。linux内核会将之前查找过的文件的metadata（dentry）存到一个缓存中，这个缓存就是一个hash table，这样可以加快执行速度。这个hash table是一个固定长度的数组，数组元素是链表。当hash冲突时将同hash值元素追加到链表里。  观察dentry cache：\n $ dmesg | grep Dentry，可以观察到系统启动时这个数组的大小以及尺寸：Dentry cache hash table entries: 4194304 (order: 13, 33554432 bytes) 于是怀疑是否这个cache在trasher运行期间增长过大，导致内核内存使用飙升呢？sudo slabtop -o观察到果然占用了~26G内存，存了5百万个dentry。 但是host上根本没有那么多文件，是怎么产生5百万个dentry呢？  了解dentry的创建机制：不论你查找的目录是否存在，linux内核都会为查询文件创建一个dentry。而trasher则会大量的查询不存在的文件，导致dentry数量持续上升。这解释了为何trasher启动期间内存使用率持续攀升。\n linux内核的这个机制和互联网架构中的缓存穿透一模一样，所谓缓存穿透就是查询数据库中不存在的key，导致每次查询都hit到数据库，避免方式就是对每次查询的key的结果都做缓存。看来很多事情老前辈们早就解决了。\n 那么如何解释__d_lookup慢呢？这是因为大量的dentry产生了大量的hash冲突，导致单个hash槽里的链表变长，增加了查询时间。文章里用了一堆神奇的方法观察到了这一点：\n观察 __d_lookup 函数：\n1$ sudo perf probe -L __d_lookup 2 0 struct dentry * __d_lookup(struct dentry * parent, struct qstr * name) 3 1 { 4 2 unsigned int len = name-\u0026gt;len; 5 3 unsigned int hash = name-\u0026gt;hash; 6 4 const unsigned char *str = name-\u0026gt;name; 7 5 struct hlist_head *head = d_hash(parent,hash); 8 struct dentry *found = NULL; 9 struct hlist_node *node; 10 struct dentry *dentry; 11 12 rcu_read_lock(); 13 14 12 hlist_for_each_entry_rcu(dentry, node, head, d_hash) { 15 struct qstr *qstr; 16 17 15 if (dentry-\u0026gt;d_name.hash != hash) 18 continue; 19 17 if (dentry-\u0026gt;d_parent != parent) 20 Continue; 21... 分别在函数调用处和函数第15行打入probe：\n1$ sudo perf probe --add __d_lookup 2Added new event: 3 probe:__d_lookup (on __d_lookup) 4 5$ sudo perf probe --add __d_lookup_loop=__d_lookup:15 6Added new events: 7 probe:__d_lookup_loop (on __d_lookup:15) 分别观察trasher启动时和trasher没有启动时调用次数：\n1$ sudo perf stat -p 18189 -e \u0026#34;probe:__d_lookup\u0026#34; -e \u0026#34;probe:__d_lookup_loop\u0026#34; -- sleep 60 2 Performance counter stats for process id \u0026#39;18189\u0026#39;: 3 4 2,763,816 probe:__d_lookup 5 75,503,432 probe:__d_lookup_loop 6 7 60.001285559 seconds time elapsed 8 9$ sudo perf stat -p 18189 -e \u0026#34;probe:__d_lookup\u0026#34; -e \u0026#34;probe:__d_lookup_loop\u0026#34; -- sleep 60 10 Performance counter stats for process id \u0026#39;18189\u0026#39;: 11 12 3,800,247 probe:__d_lookup 13 3,811,830 probe:__d_lookup_loop 14 15 60.002976808 seconds time elapsed 发现trasher启动时第二个probe有~30倍于第一个probe的调用次数。\n总结  kill trasher container会释放dentry，在trasher container内部kill 进程则不会。 看似不相关的两个容器会在内核层面产生相互影响。 一切以观测结果为依据，而不是胡乱猜测。 对container的关键指标做好测算打好baseline，在线上观测到结果于预期不符的时候就可以报警，提前知道问题。  PS. linux新内核将kernel object pools和cgroup内存限制绑定在一起了，所以到时候trasher会被内核干掉。\n","date":"2019-02-23","img":"","permalink":"/post/article-review/container-isolation-gone-wrong/","series":null,"tags":["linux","docker","troubleshooting"],"title":"Container Isolation Gone Wrong"},{"categories":null,"content":"原文：Another Reason Why Your Docker Containers May Be Slow 本文讲述了容器在运行过程中，不光会竞争CPU、内存、磁盘、网络，还会竞争内核资源。并提到了使用perf来debug问题。\n文章里提到一个应用，它需要 5 CPU / 30G Memory。\n 当单实例跑在一个虚拟机上的时候，某个调用的测试结果是 a few milliseconds per query 。 但是当多实例，也就3-4个，容器化跑在一个服务器上（72 CPU / 512G Memory）时，响应居然开始变慢了，可高达数秒。  按照理论上讲，跑4个实例才用了 20 CPU / 120G Memory，远远没有用足服务器上的资源。\n然后他们用Sysbench 测试服务器的CPU、内存、磁盘均没有发现瓶颈。\n直到他们用perf工具调试应用进程。结果发现有一个内核资源的调用非常频繁，次数高达70%以上。然后顺藤摸瓜找到使用的第三方库的参数优化方案，问题解决。\n","date":"2019-02-23","img":"","permalink":"/post/article-review/another-reason-why-your-docker-containers-may-be-slow/","series":null,"tags":["docker","linux"],"title":"Another Reason Why Your Docker Containers May Be Slow"},{"categories":null,"content":"在容器打印日志到控制台阻塞的排障 的时候看到一个观点：\n 把日志打印到控制台要比打印到文件慢，而且是非常慢。\n log4j2和logback的两个issue官方也提到了这一点（见LOG4J2-2239 、LOGBACK-1422 ）。\n那么为何输出到控制台慢？有何办法加速呢？问题要从三个角度来分别回答：\n linux的stdout角度 Java程序角度 docker容器角度  stdout角度 写到控制台其实就是写到stdout，更严格的说应该是fd/1。Linux操作系统将fd/0、fd/1和fd/2分别对应stdin、stdout和stdout。\n那么问题就变成为何写到stdout慢，有何优化办法？\n造成stdout慢的原因有两个：\n 你使用的终端会拖累stdout的输出效率 stdout的缓冲机制  在SO的这个问题中：Why is printing to stdout so slow? Can it be sped up? ，这回答提到打印到stdout慢是因为终端的关系，换一个快速的终端就能提升 。这解释了第一个原因。\nstdout本身的缓冲机制是怎样的？Stdout Buffering 介绍了glibc对于stdout缓冲的做法：\n 当stdout指向的是终端的时候，那么它的缓冲行为是line-buffered，意思是如果缓冲满了或者遇到了newline字符，那么就flush。 当stdout没有指向终端的时候，那么它的缓冲行为是fully-buffered，意思是只有当缓冲满了的时候，才会flush。  其中缓冲区大小是4k。下面是一个总结的表格“ GNU libc (glibc) uses the following rules for buffering”:\n   Stream Type Behavior     stdin input line-buffered   stdout (TTY) output line-buffered   stdout (not a TTY) output fully-buffered   stderr output unbuffered    那也就是说当stdout指向一个终端的时候，它采用的是line-buffered策略，而终端的处理速度直接影响到了性能。\n同时也给了我们另一个思路，不将stdout指向终端，那么就能够用到fully-buffered，比起line-buffered能够带来更大提速效果（想想极端情况下每行只有一个字符）。\n我写了一段小代码来做测试（gist ）。先试一下stdout指向终端的情况：\n1$ javac ConsolePrint.java 2$ java ConsolePrint 100000 3... 4lines: 100,000 5System.out.println: 1,270 ms 6file: 72 ms 7/dev/stdout: 1,153 ms 代码测试了三种用法：\n System.out.println 指的是使用System.out.println所花费的时间 file 指的是用4k BufferedOutputStream 写到一个文件所花费的时间 /dev/stdout 则是同样适用4k BufferedOutputStream 直接写到/dev/stdout所花费的时间  发现写到文件花费速度最快，用System.out.println和写到/dev/stdout所花时间在一个数量级上。\n如果我们将输出重定向到文件：\n1$ java ConsolePrint 100000 \u0026gt; a 2$ tail -n 5 a 3... 4System.out.println: 920 ms 5file: 76 ms 6/dev/stdout: 31 ms 则会发现/dev/stdout速度提升到file一个档次，而System.out.println并没有提升多少。之前不是说stdout不指向终端能够带来性能提升吗，为何System.out.println没有变化呢？这就要Java对于System.out的实现说起了。\nJava程序角度 下面是System的源码：\n1public final static PrintStream out = null; 2... 3private static void initializeSystemClass() { 4 FileOutputStream fdOut = new FileOutputStream(FileDescriptor.out); 5 setOut0(newPrintStream(fdOut, props.getProperty(\u0026#34;sun.stdout.encoding\u0026#34;))); 6} 7... 8private static native void setOut0(PrintStream out); 9... 10private static PrintStream newPrintStream(FileOutputStream fos, String enc) { 11 ... 12 return new PrintStream(new BufferedOutputStream(fos, 128), true); 13} 可以看到System.out是PrintStream类型，下面是PrintStream的源码：\n1private void write(String s) { 2 try { 3 synchronized (this) { 4 ensureOpen(); 5 textOut.write(s); 6 textOut.flushBuffer(); 7 charOut.flushBuffer(); 8 if (autoFlush \u0026amp;\u0026amp; (s.indexOf(\u0026#39;\\n\u0026#39;) \u0026gt;= 0)) 9 out.flush(); 10 } 11 } catch (InterruptedIOException x) { 12 Thread.currentThread().interrupt(); 13 } catch (IOException x) { 14 trouble = true; 15 } 16} 可以看到：\n System.out使用的缓冲大小仅为128字节。大部分情况下够用。 System.out开启了autoFlush，即每次write都会立即flush。这保证了输出的及时性。 PrintStream的所有方法加了同步块。这避免了多线程打印内容重叠的问题。 PrintStream如果遇到了newline符，也会立即flush（相当于line-buffered）。同样保证了输出的及时性。  这解释了为何System.out慢的原因，同时也告诉了我们就算把System.out包到BufferedOutputStream里也不会有性能提升。\nDocker容器角度 那么把测试代码放到Docker容器内运行会怎样呢？把gist里的Dockerfile和ConsolePrint.java放到同一个目录里然后这样运行：\n1$ docker build -t console-print . 2$ docker run -d --name console-print console-print 100000 3$ docker logs --tail 5 console-print 4... 5lines: 100,000 6System.out.println: 2,563 ms 7file: 27 ms 8/dev/stdout: 2,685 ms 可以发现System.out.println和/dev/stdout的速度又变回一样慢了。因此可以怀疑stdout使用的是line-buffered模式。\n为何容器内的stdout不使用fully-buffered模式呢？下面是我的两个猜测:\n 不论你是docker run -t分配tty启动，还是docker run -d不非配tty启动，docker都会给容器内的stdout分配一个tty。 因为docker的logging driver都是以“行”为单位收集日志的，那么这个tty必须是line-buffered。  虽然System.out.println很慢，但是其吞吐量也能够达到~40,000 lines/sec，对于大多数程序来说这不会造成瓶颈。\n参考文档  Standard output (stdout)  Stdout Buffering  ","date":"2019-02-22","img":"","permalink":"/post/is-logging-to-console-slow/","series":null,"tags":["linux","java","日志","docker"],"title":"为何把日志打印到控制台很慢？"},{"categories":null,"content":"原文：\n Observability 3 ways: Logging, Metrics \u0026amp; Tracing  Logging vs Tracing vs Monitoring  Metrics, tracing, and logging  Logging,Metrics 和 Tracing   所谓“日志”分为三种：\n logging，通常意义上的日志，比如程序打印到文件或stdout的字符串行。记录了程序运行过程中发生的事件。 metrics，应用程序运行指标，用于测量程序的运行情况。 tracing，在微服务架构中应用程序/组件之间的调用链。  以error为例：\n logging 可以告诉你error合适发生，以及细节信息 metrics 可以告诉你error发生了多少次 tracing 可以告诉你这个error的影响面有多大  三者提供的数据不同：\n logging可以 1）提供事件细节；2）部分日志可以被聚合 metrics可以 1）提供数字，可被聚合；2）告诉数据趋势 tracing可以 1）提供调用span；2）提供部分事件的部分细节  三者存储的也不同：\n logging，时间戳 + 格式良好的非结构化文本/结构化日志（json） metrics，时间戳 + 数字 tracing，时间戳 + span  三者都是对事件的不同角度的描述，三者互补形成完整的监控系统。\n","date":"2019-02-21","img":"","permalink":"/post/article-review/observability-3-ways/","series":null,"tags":["日志","监控","调用链追踪"],"title":"Logging, Metrics \u0026 Tracing"},{"categories":null,"content":"本文介绍的方法是通过环境变量把容器自己的名字传递进去，仅支持以下两种部署方式：\n docker service create docker stack deploy  docker service create docker service create -e MY_NAME=\u0026quot;{{.Task.Name}}\u0026quot; -d --name abc tomcat:8.5-alpine\n这样容器里的MY_NAME环境变量就是容器自己的名字，比如：abc.1.rik8xgc0b9i2r7odnm6vnhnqg\ndocker stack deploy docker-compose file:\n1version:\u0026#39;3.7\u0026#39;2services:3webapp:4image:tomcat:8.5-alpine5environment:6MY_NAME:\u0026#34;{{.Task.Name}}\u0026#34;同样地将容器名传到环境变量MY_NAME里。\n参考资料  Docker logging best practice ，在这个文章里提到了可以用{{.Task.Name}}做template expansion来设置变量。 上述两种方式都用到了go template，Format command and log output 列举了几种template expansion的使用方式。 Inject chosen container name in container ，这个issue提出要能够在容器内获得自己的名字，但是此issue没有被解决，依然在讨论中。 ","date":"2019-02-20","img":"","permalink":"/post/get-name-from-within-container/","series":null,"tags":["docker"],"title":"Docker容器如何获得自己的名字"},{"categories":null,"content":"环境：Rancher管控的K8S集群。\n现象：某个Node频繁出现“PLEG is not healthy: pleg was last seen active 3m46.752815514s ago; threshold is 3m0s”错误，频率在5-10分钟就会出现一次。\n排查：\n kubectl get pods --all-namespaces 发现有一个istio-ingressgateway-6bbdd58f8c-nlgnd一直处于Terminating状态，也就是说杀不死。 到Node上docker logs --tail 100 kubelet也看到这个Pod的状态异常：  1I0218 01:21:17.383650 10311 kubelet.go:1775] skipping pod synchronization - [PLEG is not healthy: pleg was last seen active 3m46.752815514s ago; threshold is 3m0s] 2... 3E0218 01:21:30.654433 10311 generic.go:271] PLEG: pod istio-ingressgateway-6bbdd58f8c-nlgnd/istio-system failed reinspection: rpc error: code = DeadlineExceeded desc = context deadline exceeded  用kubelet delete pod尝试删除，命令挂住。 用kubectl delete pod --force --grace-period=0，强制删除Pod。 再到Node上检查这个容器是否真的被停止，docker ps -a| grep ingressgateway-6bbdd58f8c-nlgnd，看到容器处于Exited状态。 观察Node状态，问题依旧。 把Pod关联的Deployment删除，把一只处于Terminating的Pod用kubectl delete pod --force --grace-period=0的方式删除。 重新部署Deployment。 问题解决。  相关issue ","date":"2019-02-18","img":"","permalink":"/post/k8s/kublet-pleg-not-healthy/","series":null,"tags":["k8s","troubleshooting"],"title":"Kublet PLEG不健康问题排障"},{"categories":null,"content":"概览 详细 PC寄存器（PC Register） 所属：线程\n创建：创建线程时创建\n作用：记录线程执行到哪个JVM指令了\n存储：含有当前线程所正在执行JVM指令的地址。如果正在执行的是本地方法，则行为是未定义的\nJava虚拟机栈（Java Virtual Machine Stack） 所属：线程\n创建：创建线程时创建\n作用：Java虚拟机栈和C语言的栈类似，存储了本地变量（local variables）、部分结果（partial results）、在方法的调用和返回中起作用\n存储：存储栈帧（Frame）\n尺寸：固定尺寸或动态扩展缩减\n空间：不要求空间连续\n本地方法栈（Native Method Stack） 所属：线程\n创建：创建线程时创建\n作用：如果JVM实现支持native方法，则需要本地方法栈；本地方法栈就是传统栈（就是C栈）\n尺寸：固定尺寸或动态扩展缩减\n空间：不要求空间连续\n堆（Heap） 所属：JVM\n创建：JVM启动时创建\n作用：被JVM所有线程所共享；所有类的实例和数组都是在这里分配的\n存储：类的实例\n尺寸：固定尺寸或动态扩展缩减；对象回收工作由GC负责，JVM Spec不规定如何实现GC\n空间：不要求空间连续\n方法区（Method Area） 所属：\n 堆，虽然在堆中，但有个别名Non-heap 有些JVM实现选择不GC也不压缩方法区 该区域比较难以回收，因此有些时候被称为PermGen  创建：JVM启动时创建\n作用：方法区被JVM所有线程所共享\n存储：\n 类信息、常量、静态变量、JIT编译结果等 每个类的结构，如运行时常量池（run-time constant pool）、字段和方法数据 方法和构造函数的代码，包括类初始化代码块（静态代码块\u0026lt;clinit\u0026gt;）和类实例初始化代码块（\u0026lt;init\u0026gt;）和接口初始化代码这些特殊方法  尺寸：固定尺寸或动态扩展缩减\n空间：不要求空间连续\n运行时常量池（Run-time constant pool） 所属：方法区\n创建：类加载的【创建与加载】阶段\n作用：类似于传统语言的符号表（symbol table），但是存储的数据范围比传统符号表要广\n存储：\n 各种常量，范围从编译时所知的数字字面值（numeric literals）到运行时所必须解析（resolve）的方法与字段的引用 类的版本、字段、方法、接口  栈帧（Frame） 所属：Java虚拟机栈\n创建/销毁：\n 调用方法时创建 方法调用结束时销毁，正常结束/异常技术都会销毁  作用：\n 存储数据和部分结果 执行动态链接（dynamic linking） 为方法返回值（return values for methods） 派发异常（dispatch exceptions） 给定线程，有且仅有一个活动栈帧，这个栈帧代表了正在运行的方法  存储：每个帧有用自己的本地变量数组（local variable array）、操作数栈（operand stack）、一个指向当前运行方法所在类的运行时常量池的引用\n尺寸：\n 每个方法的本地变量数组长度和操作数栈的大小在编译时就已经确定下来了 因此它的尺寸仅依赖于JVM的实现以及这两个数据结构所需要的内存  直接内存 所属：\n 不属于JVM，JVM也不管 操作系统，所以被称为Direct Memory，或者堆外内存  作用：直接操作系统分配，减少Java堆和Native堆的数据Copy，提升效率\n创建：使用Native函数直接分配\n脑图 参考资料  Java Virtual Machine Specification | 2.5. Run-Time Data Areas  Java Virtual Machine Specification | 5.3. Creation and Loading  极客时间 | 深入拆解 Java 虚拟机 | 01 | Java代码是怎么运行的？  ","date":"2019-02-17","img":"","permalink":"/post/jvm/run-time-data-areas/","series":null,"tags":["JVM"],"title":"JVM - 运行时数据区域"},{"categories":null,"content":"记一次容器打印到控制台阻塞，且容器停止响应的问题。\n今日生产环境发现有些容器停止响应了，但是容器没有死，docker exec -it \u0026lt;container-name\u0026gt; /bin/bash也能正常使用。\n在容器内部使用jstack \u0026lt;pid\u0026gt;发现log4j2的Console Appender一直处于运行状态：\n1\u0026#34;AsyncAppender-asyncConsole\u0026#34; #21 daemon prio=5 os_prio=0 tid=0x00007fd968d07000 nid=0x1f runnable [0x00007fd91bffd000] 2 java.lang.Thread.State: RUNNABLE 3\tat java.io.FileOutputStream.writeBytes(Native Method) 4\tat java.io.FileOutputStream.write(FileOutputStream.java:326) 5\tat java.io.BufferedOutputStream.write(BufferedOutputStream.java:122) 6\t- locked \u0026lt;0x00000000f002b408\u0026gt; (a java.io.BufferedOutputStream) 7\tat java.io.PrintStream.write(PrintStream.java:480) 8\t- locked \u0026lt;0x00000000f002b3e8\u0026gt; (a java.io.PrintStream) 9\tat org.apache.logging.log4j.core.util.CloseShieldOutputStream.write(CloseShieldOutputStream.java:53) 10\tat org.apache.logging.log4j.core.appender.OutputStreamManager.writeToDestination(OutputStreamManager.java:262) 11\t- locked \u0026lt;0x00000000f021d848\u0026gt; (a org.apache.logging.log4j.core.appender.OutputStreamManager) 12\tat org.apache.logging.log4j.core.appender.OutputStreamManager.flushBuffer(OutputStreamManager.java:294) 13\t- locked \u0026lt;0x00000000f021d848\u0026gt; (a org.apache.logging.log4j.core.appender.OutputStreamManager) 14\tat org.apache.logging.log4j.core.appender.OutputStreamManager.drain(OutputStreamManager.java:351) 15\tat org.apache.logging.log4j.core.layout.TextEncoderHelper.drainIfByteBufferFull(TextEncoderHelper.java:260) 16\t- locked \u0026lt;0x00000000f021d848\u0026gt; (a org.apache.logging.log4j.core.appender.OutputStreamManager) 17\tat org.apache.logging.log4j.core.layout.TextEncoderHelper.writeAndEncodeAsMuchAsPossible(TextEncoderHelper.java:199) 18\tat org.apache.logging.log4j.core.layout.TextEncoderHelper.encodeChunkedText(TextEncoderHelper.java:159) 19\t- locked \u0026lt;0x00000000f021d848\u0026gt; (a org.apache.logging.log4j.core.appender.OutputStreamManager) 20\tat org.apache.logging.log4j.core.layout.TextEncoderHelper.encodeText(TextEncoderHelper.java:58) 21\tat org.apache.logging.log4j.core.layout.StringBuilderEncoder.encode(StringBuilderEncoder.java:68) 22\tat org.apache.logging.log4j.core.layout.StringBuilderEncoder.encode(StringBuilderEncoder.java:32) 23\tat org.apache.logging.log4j.core.layout.PatternLayout.encode(PatternLayout.java:220) 24\tat org.apache.logging.log4j.core.layout.PatternLayout.encode(PatternLayout.java:58) 25\tat org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender.directEncodeEvent(AbstractOutputStreamAppender.java:177) 26\tat org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender.tryAppend(AbstractOutputStreamAppender.java:170) 27\tat org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender.append(AbstractOutputStreamAppender.java:161) 28\tat org.apache.logging.log4j.core.config.AppenderControl.tryCallAppender(AppenderControl.java:156) 29\tat org.apache.logging.log4j.core.config.AppenderControl.callAppender0(AppenderControl.java:129) 30\tat org.apache.logging.log4j.core.config.AppenderControl.callAppenderPreventRecursion(AppenderControl.java:120) 31\tat org.apache.logging.log4j.core.config.AppenderControl.callAppender(AppenderControl.java:84) 32\tat org.apache.logging.log4j.core.appender.AsyncAppender$AsyncThread.callAppenders(AsyncAppender.java:459) 33\tat org.apache.logging.log4j.core.appender.AsyncAppender$AsyncThread.run(AsyncAppender.java:412) 但用docker logs -f \u0026lt;container-name\u0026gt;没有发现有新的日志输出，且访问该应用肯定会输出日志的接口也是没有任何日志输出，因此怀疑log4j2阻塞住了。\nGoogle到有人在log4j提出了类似了问题LOG4J2-2239 ，官方给出的解释是问题出在log4j2之外。\n于是查一下logback是否也有类似问题，找到LOGBACK-1422 ，同样给出的解释是问题出在logback之外。\n两个问题的共通点都是用docker运行，于是把应用直接进程方式运行，没有出现问题。\n于是Google搜索docker logging to stdout hangs，找到SO的这个回答 ，以及这个issue ，解决方案将Docker升级到18.06。\n查看生产环境的docker版本是18.03，升级到18.09后问题解决。\n","date":"2019-02-17","img":"","permalink":"/post/docker-console-logging-hangs/","series":null,"tags":["docker","troubleshooting"],"title":"容器打印日志到控制台阻塞的排障"},{"categories":null,"content":" 极客时间 - 数据结构与算法之美 - 12 | 排序（下）   算法描述：\n a为待排序数组，n为数组长度   在a中取一个数作为pivot，将a分为两个区，pivot左边的都 \u0026lt; pivot，pivot右边的都 \u0026gt;= pivot。 对 pivot 左边的元素 重复分区动作 对 pivot 右边的元素 重复分区动作  伪代码：\n1quickSort(a) { 2 pivot_i = partition(a); // 获得pivot的下标 3 quickSort(pivot_i\u0026#39;s left part); 4 quickSort(pivot_i\u0026#39;s right part); 5} 其中分区算法：\n 定义 i 作为下标，它具有以下特性：a[\u0026lt; i] \u0026lt; pivot ; a[\u0026gt;= i] \u0026gt;= pivot 定义 pivot = a[n-1]，即取 a 的最后一个元素作为pivot   初始 i = 0，意思是其左边还没有比 pivot 小的元素 遍历 a[0 \u0026hellip; n-1-1]，从头到倒数第二个元素，遍历用下标为 j 如果 a[j] \u0026lt; pivot，那么 swap(a[i], a[j])，i++ 当遍历结束时，a[i] = pivot 返回 i   在整个过程满足：a[0 \u0026hellip; i-1] \u0026lt; pivot，a[i \u0026hellip; j-1] \u0026gt;= pivot 因此如果 a[j] \u0026lt; pivot，把 a[i], a[j]互换位置，然后 i++，这个关系依旧保持不变，并且还使得a[j] \u0026gt;= pivot。  和归并排序 的区别：\n 归并排序将a等分成两半，快速排序则不一定 归并排序在将两边合并的时候不能简单串接，而需要依次对比两边元素，从而保证合并结果有序。快速排序则通过一个pivot巧妙的避开了这一点。pivot左边的都比pivot小，pivot右边的都比pivot大，而且左右两边都是有序的，那么直接合并就行了。  算法复杂度分析：\n如果每次分区都分为大小相等的两个区，那么复杂度和归并排序 一样，O(nlogn)。\n如果每次分区都只分得一个区，每次选择的pivot是最大/最小元素，那么复杂度为O(n^2)，以1 2 3 4 5 6 7 8这个有序数组来解释：\n 第1次分区，pivot=8，得到 1 2 3 4 5 6 7，比较次数 7 第1次分区，pivot=7，得到 1 2 3 4 5 6，比较次数 6 第1次分区，pivot=6，得到 1 2 3 4 5，比较次数 5 \u0026hellip; 第k次分区，pivot=2，得到 1，比较次数 1  总比较次数累加，就是等差数列累加，为\n 7 * (7 + 1) / 2 = (8 - 1) * (8 - 1 + 1) / 2 = 28  换成公式就是 n * (n - 1) / 2 = O(n^2)\n1public void sort(int[] a) { 2 quickSort(a, 0, a.length - 1); 3} 4 5private void quickSort(int[] a, int start, int end) { 6 7 if (start \u0026gt;= end) { 8 return; 9 } 10 int pivot_i = partition(a, start, end); 11 12 // 对 pivot_i 左边的元素进行排序 13 quickSort(a, start, pivot_i - 1); 14 // 对 pivot_i 右边的元素进行排序 15 quickSort(a, pivot_i + 1, end); 16} 17 18/** 19* 分区 20* 21* @param a 22* @param start 23* @param end 24* @return 返回分区点 25*/ 26private int partition(int[] a, int start, int end) { 27 // 取数组最后一个元素作为pivot 28 int pivot = a[end]; 29 // 要计算的pivot的下标 30 // pivot_i 左边的都是 \u0026lt; pivot的元素 31 // pivot_i 右边的(含)都是 \u0026gt;= pivot的元素 32 int pivot_i = start; 33 34 for (int j = start; j \u0026lt;= end - 1; j++) { 35 if (a[j] \u0026lt; pivot) { 36 if (pivot_i != j) { 37 // 因为 pivot_i 右边(含) 都是 \u0026gt;= pivot 的元素 38 // 一个元素 \u0026lt; pivot，则将其和 pivot_i 的位置互换 39 // pivot_i++ 40 int tmp = a[pivot_i]; 41 a[pivot_i] = a[j]; 42 a[j] = tmp; 43 } 44 pivot_i++; 45 } 46 } 47 // 把 pivot 和 pivot_i 元素位置互换 48 a[end] = a[pivot_i]; 49 a[pivot_i] = pivot; 50 return pivot_i; 51} ","date":"2019-02-14","img":"","permalink":"/post/algo/12-quick-sort/","series":null,"tags":["ARTS-A"],"title":"算法 - 快速排序（Quick Sort）"},{"categories":null,"content":" 极客时间 - 数据结构与算法之美 - 12 | 排序（下）   算法描述：\n a为待排序数组，n为数组长度 把 a 一分为二 对 a 左半部分排序 对 a 右半部分排序 把两部分合并，合并结果得是有序的 其中对 a 左、右部分排序也是使用相同的算法  伪代码：\n1mergeSort(a) { 2 mergeSort(a_left_part) 3 mergeSort(a_right_part) 4 merge(a_left_part, a_right_part) 5} 算法复杂度分析：\n1T(1) = C 因为无法再分左右两半了，所以n=1时只需要常数时间 2T(n) = 2 * T(n/2) + n 代表左右两半到时间 + 合并结果需要的时间 3 = 2 * (2 * T(n/4) + n/2) + n = 4 * T(n/4) + 2 * n 4 = 4 * (2 * T(n/8) + n/4) + 2 * n = 8 * T(n/8) + 3 * n 5 = 8 * (2 * T(n/16) + n/8) + 3 * n = 16 * T(n/16) + 4 * n 6 = ... 7 = 2 ^ k * T(n/2^k) + k * n 当T(n/2^k)=T(1)时，k为log2n，公式变成\n 2log2n * C + n * log2n =\u0026gt; n * C + n * log2n =\u0026gt; O(nlogn)  上面提到的k = log2n = 递归深度\n1// a为待排序数组，start为排序区间开始，end为排序区间结束 2public void merge_sort(int[] a, int start, int end) { 3 if (start \u0026gt;= end) { 4 return; 5 } 6 int mid = (start + end) / 2; 7 merge_sort(a, start, mid); 8 merge_sort(a, mid + 1, end); 9 merge(a, start, mid, end); 10} 11 12public void merge(int[] a, int start, int mid, int end) { 13 // 合并两个有序数组 14 int i = start; 15 int j = mid + 1; 16 int k = 0; 17 int[] tmp = new int[end - start + 1]; 18 while (i \u0026lt;= mid \u0026amp;\u0026amp; j \u0026lt;= end) { 19 if (a[i] \u0026lt;= a[j]) { 20 tmp[k] = a[i]; 21 i++; 22 } else { 23 tmp[k] = a[j]; 24 j++; 25 } 26 k++; 27 } 28 while (i \u0026lt;= mid) { 29 tmp[k] = a[i]; 30 i++; 31 k++; 32 } 33 while (j \u0026lt;= end) { 34 tmp[k] = a[j]; 35 j++; 36 k++; 37 } 38 for (int x = 0; x \u0026lt; k; x++) { 39 a[start + x] = tmp[x]; 40 } 41} ","date":"2019-02-14","img":"","permalink":"/post/algo/11-merge-sort/","series":null,"tags":["ARTS-A"],"title":"算法 - 归并排序（Merge Sort）"},{"categories":null,"content":" 极客时间 - 数据结构与算法之美 - 11 | 排序（上）   算法描述：\n a为待排序数组，n为数组长度 i为元素下标，a[ \u0026lt; i]的元素都是已排序好的，a[ \u0026gt;= i]的元素都是还未排序的。即把a分为两个区间：已排序区间和未排序区间。 循环 n - 1 次，初始i = 0：  在a[i .. n - 1]的范围里找到最小的元素，记为a[min] 将a[min]与a[i]交换，i++    速记法：想象成一个手扑克牌，从第一张～最后一张里找最小的牌，和第一张交换；从第二张～最后一张找最小的牌，和第二张交换，……\n算法本质：不停从未排序区间中找到最小的元素，将其放到已排序区间的末尾。第一次找最小的，第二次找第二小的，第三次找第三小的。\n1public void selectionSort(int[] a, int n) { 2 if (n \u0026lt;= 1) return; 3 4 for (int i = 0; i \u0026lt; n; i++) { 5 int min_i = i; 6 // 找到最小值的下标 7 for (int j = i + 1; j \u0026lt; n; j++) { 8 if (a[j] \u0026lt; a[min_i]) { 9 // 更新最小值的下标 10 min_i = j; 11 } 12 } 13 if (min_i == i) { 14 continue; 15 } 16 // 交换数据 17 int tmp = a[i]; 18 a[i] = a[min_i]; 19 a[min_i] = tmp; 20 } 21} ","date":"2019-02-13","img":"","permalink":"/post/algo/10-selection-sort/","series":null,"tags":["ARTS-A"],"title":"算法 - 选择排序（Selection Sort）"},{"categories":null,"content":" 极客时间 - 数据结构与算法之美 - 11 | 排序（上）   算法描述：\n a为待排序数组，n为数组长度 i为元素下标，a[ \u0026lt; i]的元素都是已排序好的，a[ \u0026gt;= i]的元素都是还未排序的。即把a分为两个区间：已排序区间和未排序区间。 循环 n - 1 次，初始i = 1：  取v = a[i]，与a[i - 1 \u0026hellip; 0]的元素比较（注意是从后往前的顺序），记这个元素为a[j] 若v \u0026lt; a[j]，则将a[j]往后移动 若v \u0026gt;= a[j]，则将v插入到a[j+1]的位置，i++ 直到 i = n 为止    速记法：把这个想象成整理手中的扑克牌，取第二张牌往前插，第三张牌往前插，第四张牌往前插，……\n算法本质：已排序区间初始为数组的第一个元素，然后不停将未排序区间的元素插入到已排序区间的合适的位置。\n1// 插入排序，a 表示数组，n 表示数组大小 2public void insertionSort(int[] a, int n) { 3 if (n \u0026lt;= 1) return; 4 5 for (int i = 1; i \u0026lt; n; ++i) { 6 int value = a[i]; 7 int j = i - 1; 8 // 查找插入的位置 9 for (; j \u0026gt;= 0; --j) { 10 if (a[j] \u0026gt; value) { 11 a[j+1] = a[j]; // 数据移动 12 } else { 13 break; 14 } 15 } 16 a[j+1] = value; // 插入数据 17 } 18} ","date":"2019-02-13","img":"","permalink":"/post/algo/9-insertion-sort/","series":null,"tags":["ARTS-A"],"title":"算法 - 插入排序（Insertion Sort）"},{"categories":null,"content":" 极客时间 - 数据结构与算法之美 - 11 | 排序（上）   算法描述：\n a为待排序数组 j = 0，比较 a[j] 和 a[j+1]：   如果 a[j] \u0026gt; a[j+1]，交换两个元素位置 否则啥都不用做 j++  循环n - 1次   第一次循环，把最大的元素移动到了 最后 第二次循环，把第2大元素移动到了 倒数第2位 第三次循环，把第3大元素移动到了 倒数第3位 \u0026hellip; 直到循环结束，元素都排序好了  算法本质：把大的元素像泡泡一样冒到最后。\n1// 冒泡排序，a 表示数组 2public void sort(int[] a) { 3 int n = a.length; 4 if (n \u0026lt;= 1) { 5 return; 6 } 7 for (int i = 0; i \u0026lt; n; i++) { 8 boolean flag = false; 9 for (int j = 0; j \u0026lt; n - i - 1; j++) { 10 // 每次交换把一个较大的元素移动到数组尾部 11 if (a[j] \u0026gt; a[j + 1]) { 12 int tmp = a[j]; 13 a[j] = a[j + 1]; 14 a[j + 1] = tmp; 15 flag = true; 16 } 17 } 18 if (!flag) { 19 // 如果没有数据交换，则说明数组已经有序 20 break; 21 } 22 } 23} ","date":"2019-02-13","img":"","permalink":"/post/algo/8-bubble-sort/","series":null,"tags":["ARTS-A"],"title":"算法 - 冒泡排序（Bubble Sort）"},{"categories":null,"content":" 极客时间 - 数据结构与算法之美 - 11 | 排序（上）   执行效率  最好、最坏、平均时间复杂度 时间复杂度的系数、常数、低阶 比较次数、交换（或移动）次数  空间复杂度\n 原地排序（Sorted in place）。原地排序算法，就是特指空间复杂度是 O(1) 的排序算法。  稳定性：如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变。\n有序度分析 有序度：有序元素对：a[i] \u0026lt;= a[j]，如果 i \u0026lt; j 的数量\n满序度：\n 完全有序的数组的有序度 对于长度为n的数组，满序度 = n * (n - 1) / 2 举例：长度6的数组，满序度 = 6 * (6 - 1) / 2 = 15  逆序度：逆序度 = 满序度 - 有序度\n","date":"2019-02-13","img":"","permalink":"/post/algo/7-analyze-sort/","series":null,"tags":["ARTS-A"],"title":"算法 - 如何分析排序算法"},{"categories":null,"content":" 极客时间 - 数据结构与算法之美 - 10 | 递归   递归 递归需要满足的三个条件\n 一个问题的解可以分解为几个子问题的解 这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样 存在递归终止条件  警惕  递归代码要警惕堆栈溢出 递归代码要警惕重复计算，看下面代码  1public int f(int n) { 2 if (n == 1) return 1; 3 if (n == 2) return 2; 4 5 // hasSolvedList 可以理解成一个 Map，key 是 n，value 是 f(n) 6 if (hasSolvedList.containsKey(n)) { 7 return hasSovledList.get(n); 8 } 9 10 int ret = f(n-1) + f(n-2); 11 hasSovledList.put(n, ret); 12 return ret; 13} 将递归代码改写为非递归代码 f(x)=f(x-1)+1改写：\n1int f(int n) { 2 int ret = 1; 3 for (int i = 2; i \u0026lt;= n; ++i) { 4 ret = ret + 1; 5 } 6 return ret; 7} f(n)=f(n-2)+f(n-1)改写：\n1int f(int n) { 2 if (n == 1) return 1; 3 if (n == 2) return 2; 4 5 int ret = 0; 6 int pre = 2; 7 int prepre = 1; 8 for (int i = 3; i \u0026lt;= n; ++i) { 9 ret = pre + prepre; 10 prepre = pre; 11 pre = ret; 12 } 13 return ret; 14} ","date":"2019-02-13","img":"","permalink":"/post/algo/6-recursion/","series":null,"tags":["ARTS-A"],"title":"算法 - 递归"},{"categories":null,"content":" 极客时间 - 数据结构与算法之美 - 09 | 队列   队列  先进者先出 顺序队列，由数组实现，有边界 循环队列，由数组实现，进一步优化顺序队列的操作时间复杂度 链式队列，由链表实现，无边界 操作：入队、出队。  顺序队列\n 缺点：数据搬移 优化1：tail到底时再搬，均摊复杂度  循环队列，由数组实现，进一步优化顺序队列的操作时间复杂度\n head指向头，tail指向尾，tail不存数据 队满条件，(tail+1) % n = head 队空条件，tail = head  1public class CircularQueue { 2 // 数组：items，数组大小：n 3 private String[] items; 4 private int n = 0; 5 // head 表示队头下标，tail 表示队尾下标 6 private int head = 0; 7 private int tail = 0; 8 9 // 申请一个大小为 capacity 的数组 10 public CircularQueue(int capacity) { 11 items = new String[capacity + 1]; 12 n = capacity; 13 } 14 15 // 入队 16 public boolean enqueue(String item) { 17 // 队列满了 18 if ((tail + 1) % n == head) return false; 19 items[tail] = item; 20 tail = (tail + 1) % n; 21 return true; 22 } 23 24 // 出队 25 public String dequeue() { 26 // 如果 head == tail 表示队列为空 27 if (head == tail) return null; 28 String ret = items[head]; 29 head = (head + 1) % n; 30 return ret; 31 } 32} ","date":"2019-02-13","img":"","permalink":"/post/algo/5-queue/","series":null,"tags":["ARTS-A"],"title":"算法 - 队列"},{"categories":null,"content":" 极客时间 - 数据结构与算法之美 - 08 | 栈   栈  当某个数据集合只涉及在一端插入和删除数据，并且满足后进先出、先进后出的特性 顺序栈，由数组实现，有边界，也可做动态扩容 链式栈，由链表实现，无边界 操作：入栈，出栈。  四则运算表达式求值：\n 两个栈：操作数栈，运算符栈 我们从左向右遍历表达式，当遇到数字，我们就直接压入操作数栈； 当遇到运算符，就与运算符栈的栈顶元素进行比较。  如果比运算符栈顶元素的优先级高，就将当前运算符压入栈； 如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。    四则运算表达式求值（带括号）：\n 两个栈：操作数栈，运算符栈 我们从左向右遍历表达式，当遇到数字，我们就直接压入操作数栈； 当遇到运算符，就与运算符栈的栈顶元素进行比较。  如果比运算符栈顶元素的优先级高，就将当前运算符压入栈； 如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。   当遇到(，直接压入运算符栈； 当遇到)，看运算符栈顶元素是否为(  如果是(，则运算符栈顶弹出 如果不是(，从运算符栈中取栈顶运算符，则从操作数栈的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续判断。   ","date":"2019-02-13","img":"","permalink":"/post/algo/4-stack/","series":null,"tags":["ARTS-A"],"title":"算法 - 栈"},{"categories":null,"content":" 极客时间 - 数据结构与算法之美 - 05 | 数组  极客时间 - 数据结构与算法之美 - 06 | 链表（上）  极客时间 - 数据结构与算法之美 - 07 | 链表（下）   数组  数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。 随机访问高效，O(1)，见下面一维数组内存寻址公式。 插入和删除低效，O(n)，需要移动后面的元素。  删除优化策略，标记删除，直到无空间可用时再做删除。    一维数组内存寻址公式：\n1对于二维数组 a[n] 2a[i]_addr = base_addr + i * type_size 二维数组内存寻址公式：\n1对于二维数组 a[m][n] 2a[i][j]_addr = base_addr + (i * n + j) * type_size 三维数组内存寻址公式：\n1对于三维数组 a[m][n][p] 2a[i][j][k]_addr = base_addr + (i * n * p + j * p + k) * type_size 关于多维数组在内存中的布局参考这篇文章：Memory Layout of Multi-Dimensional Arrays 链表  通过“指针”将一组零散的内存块串联起来使用 随机访问低效，需要遍历，O(n) 插入和删除高效，O(1)  类型：\n 单链表，每个节点有一个后继指针。 循环链表，tail-\u0026gt;next指向head的单链表。约瑟夫问题可由这个数据结构解决。 双向链表，每个节点除了有一个后继指针，还有一个前驱指针。 双向循环链表，略。  用单链表实现LRU 维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。\n 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。 如果此数据没有在缓存链表中，又可以分为两种情况：   如果此时缓存未满，则将此结点直接插入到链表的头部； 如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的的头部；  写好链表代码  技巧一：理解指针或引用的含义 技巧二：警惕指针丢失和内存泄漏 技巧三：利用哨兵简化实现难度。针对链表的插入、删除操作，需要对插入第一个结点和删除最后一个结点的情况进行特殊处理。哨兵结点不存储数据的，作为head存在，简化代码复杂度。 技巧四：重点留意边界条件处理  如果链表为空时，代码是否能正常工作？ 如果链表只包含一个结点时，代码是否能正常工作？ 如果链表只包含两个结点时，代码是否能正常工作？ 代码逻辑在处理头结点和尾结点的时候，是否能正常工作？   技巧五：举例画图，辅助思考 技巧六：多写多练，没有捷径  单链表反转 链表中环的检测 两个有序的链表合并 删除链表倒数第 n 个结点 求链表的中间结点   ","date":"2019-02-13","img":"","permalink":"/post/algo/3-array-linkedlist/","series":null,"tags":["ARTS-A"],"title":"算法 - 数组和链表"},{"categories":null,"content":"极客时间 - 数据结构与算法之美 - 04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度 最好、最坏时间复杂度 略，比较容易分析。\n平均时间复杂度 需考虑概率来计算。\n概率论中的加权平均值，也叫作期望值，所以平均时间复杂度的全称应该叫加权平均时间复杂度或者期望时间复杂度。\n均摊时间复杂度 均摊时间复杂度及对应的摊还分析法。\n对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。而且，在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。\n1// 全局变量，大小为 10 的数组 array，长度 len，下标 i。 2int array[] = new int[10]; 3int len = 10; 4int i = 0; 5 6// 往数组中添加一个元素 7void add(int element) { 8 if (i \u0026gt;= len) { // 数组空间不够了 9 // 重新申请一个 2 倍大小的数组空间 10 int new_array[] = new int[len*2]; 11 // 把原来 array 数组中的数据依次 copy 到 new_array 12 for (int j = 0; j \u0026lt; len; ++j) { 13 new_array[j] = array[j]; 14 } 15 // new_array 复制给 array，array 现在大小就是 2 倍 len 了 16 array = new_array; 17 len = 2 * len; 18 } 19 // 将 element 放到下标为 i 的位置，下标 i 加一 20 array[i] = element; 21 ++i; 22} ","date":"2019-02-13","img":"","permalink":"/post/algo/2-best-worst-avg-complexity/","series":null,"tags":["ARTS-A"],"title":"算法 - 最好、最坏、平均复杂度"},{"categories":null,"content":"极客时间 - 数据结构与算法之美 - 03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？ unit_time 读、运算、写均算作一个unit_time\n计算技巧  只关注循环执行次数最多的一段代码。 加法法则：总复杂度等于量级最大的那段代码的复杂度。 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积。  复杂度量级  常数阶 O(1) 线性阶 O(n) 对数阶 O(logn) 线性对数阶 O(nLogn) 平方阶 O(n^2)、立方阶 O(n^3)、k次方阶 O(n^k) 指数阶 O(2^n) 阶乘阶 O(n!)  举例：\nO(1)\n1int i = 8; 2int j = 6; 3int sum = i + j; O(n)\n1i=1; 2while (i \u0026lt;= n) { 3 i = i * 2; 4} O(m + n)\n1int cal(int m, int n) { 2 int sum_1 = 0; 3 int i = 1; 4 for (; i \u0026lt; m; ++i) { 5 sum_1 = sum_1 + i; 6 } 7 8 int sum_2 = 0; 9 int j = 1; 10 for (; j \u0026lt; n; ++j) { 11 sum_2 = sum_2 + j; 12 } 13 14 return sum_1 + sum_2; 15} ","date":"2019-02-13","img":"","permalink":"/post/algo/1-complexity/","series":null,"tags":["ARTS-A"],"title":"算法 - 时间复杂度"},{"categories":null,"content":"原文地址 | Presentation | Slides 关键词：微服务、event-first DDD、Reactive\n大纲  避免构建mini-moniliths，即microliths。 构建resilient和elastic的系统。 最小化系统内部的耦合度，最小化系统内部的通信。 使用reactive programming，reactive system design，eventual consistency。 把无状态行为从有状态实体分离出来，更容易扩展性。 实践event-first DDD。   Each microservice needs to be designed as a distributed system: a microsystem. We need to move from microliths to microsystems.\n microliths既非resilient也不elastic。根据The Reactive Manifesto ，要达成resilient和elastic需要：\n Decentralised architecture Bulkheading Replication Failure detection Supervision Gossip protocols Self-organisation Location transparency  一切信息都有延迟，我们总是通过分布式系统通信来窥视过去发生的事情。开发者应尽量减少耦合与通信，并拥抱最终一致性。\n作者推荐了两个设计微服务系统的工具：\n工具一：Reactive desgin\n Reactive programming，比如RxJava，可以帮助让单个服务实例高性能以及高效。 基于异步消息的Reactive系统可以帮助构建elastic and resilient的分布式系统。 实现异步和非阻塞微服务可以更有效的利用资源，降低共享资源的争用。 总是使用back-pressure ，一个快速系统不应该是慢速系统过载。  工具二：Event-first DDD \n 每一个微服务应该被设计成为一个微系统，无状态行为要从有状态实体中剥离出来，使得独立服务能够具有扩展性。 实体可以称为确定性和一致性的安全岛，但是扩展无状态行为易，扩展有状态实体难。 开发者应该实践event-first DDD，从一致性边界的角度思考data on the inside 代表现在，data from the outside代表过去，而command则代表未来的动作。   Don\u0026rsquo;t focus on the things - the nouns. Focus on what happens - the events! Let the events define the bounded context.\n 一个微服务应该包含一切可变状态并发布事实，所谓事实就是event。event log应该是一个“代表过去的数据库”，single immutable source of truth 。event logging可以避免臭名昭著的object-relational impedance mismatch ，读写问题可以通过CQRS 与Event sourcing 解开。开发者不应该基于assuming distributed transactions 来构建大型可扩展应用，而应该使用“guess, apoligize, compensate”（和TCC、Saga类似）协议。\n延伸阅读  Youtube - From Microliths to Microsystems  The Reactive Manifesto  Data on the Outside versus Data on the Inside  Immutability Changes Everything  Life Beyond Distributed Transactions  CQRS  Event sourcing  ","date":"2019-02-10","img":"","permalink":"/post/article-review/from-microliths-to-microsystems/","series":null,"tags":["微服务"],"title":"From Microliths to Microsystems"},{"categories":null,"content":"回顾Java语言中的重载与重写，并且看看JVM是怎么处理它们的。\n重载Overload 定义：\n 在同一个类中有多个方法，它们的名字相同，但是参数类型不同。 或者，父子类中，子类有一个方法与父类非私有方法名字相同，但是参数类型不同。那么子类的这个方法对父类方法构成重载。  JVM是怎么处理重载的？其实是编译阶段编译器就已经决定好调用哪一个重载方法。看下面代码：\n1class Overload { 2 void invoke(Object obj, Object... args) { } 3 void invoke(String s, Object obj, Object... args) { } 4 5 void test1() { 6 // 调用第二个 invoke 方法 7 invoke(null, 1); 8 } 9 void test2() { 10 // 调用第二个 invoke 方法 11 invoke(null, 1, 2); 12 } 13 void test3() { 14 // 只有手动绕开可变长参数的语法糖，才能调用第一个invoke方法 15 invoke(null, new Object[]{1}); 16 } 17} 上面的注释告诉了我们结果，那么怎么才能证明上面的注释呢？我们利用javap观察字节码可以知道。\n1$ javac Overload.java 2$ javap -c Overload.java 3 4Compiled from \u0026#34;Overload.java\u0026#34; 5class Overload { 6 ... 7 void invoke(java.lang.Object, java.lang.Object...); 8 Code: 9 0: return 10 void invoke(java.lang.String, java.lang.Object, java.lang.Object...); 11 Code: 12 0: return 13 void test1(); 14 Code: 15 ... 16 10: invokevirtual #4 // Method invoke:(Ljava/lang/String;Ljava/lang/Object;[Ljava/lang/Object;)V 17 13: return 18 void test2(); 19 Code: 20 ... 21 17: invokevirtual #4 // Method invoke:(Ljava/lang/String;Ljava/lang/Object;[Ljava/lang/Object;)V 22 20: return 23 void test3(); 24 Code: 25 ... 26 13: invokevirtual #5 // Method invoke:(Ljava/lang/Object;[Ljava/lang/Object;)V 27 16: return 28} 这里面有很多JVM指令，你暂且不用关心，我们看test1、test2、test3方法调用的是哪个方法：\n1 void test1(); 2 Code: 3 ... 4 10: invokevirtual #4 // Method invoke:(Ljava/lang/String;Ljava/lang/Object;[Ljava/lang/Object;)V 5 13: return invoke是方法名，(Ljava/lang/String;Ljava/lang/Object;[Ljava/lang/Object;)V则是方法描述符。这里翻译过来就是void invoke(String, Object, Object[])，Java的可变长参数实际上就是数组，所以等同于void invoke(String, Object, Object...)。同理，test2调用的是void invoke(String, Object, Object...)，test3调用的是void invoke(Object, Object...)。关于方法描述符的详参JVM Spec - 4.3.2. Field Descriptors 和JVM Spec - 4.3.3. Method Descriptors 。\n所以重载方法的选择是在编译过程中就已经决定的，下面是编译器的匹配步骤：\n 不允许自动拆装箱，不允许可变长参数，尝试匹配 如果没有匹配到，则允许自动拆装箱，不允许可变长参数，尝试匹配 如果没有匹配到，则允许自动拆装箱，允许可变长参数，尝试匹配  注意：编译器是根据实参类型来匹配，实参类型和实际类型不是一个概念\n如果在一个步骤里匹配到了多个方法，则根据形参类型来找最贴切的。在上面的例子中第一个invoke的参数是Object, Object...，第二个invoke的参数是String, Object, Object...，两个方法的第一个参数String是Object的子类，因此更为贴切，所以invoke(null, 1, 2)会匹配到第二个invoke方法上。\n重写Override Java语言中的定义：\n 子类方法有一个方法与父类方法的名字相同且参数类型相同。 父类方法的返回值可以替换掉子类方法的返回值。也就是说父类方法的返回值类型：  要么和子类方法返回值类型一样。 要么是子类方法返回值类型的父类。   两者都是非私有、非静态方法。  （更多详细信息可参考Java Language Spec - 8.4.8. Inheritance, Overriding, and Hiding ，这里除了有更精确详细的重写的定义，同时包含了范型方法的重写定义。）\n但是JVM中对于重写的定义则有点不同：\n 子类方法的名字与方法描述符与父类方法相同。 两者都是非私有、非静态方法。  （更多详细信息可参考JVM Spec - 5.4.5. Overriding ）\n注意上面提到的方法描述符，前面讲过方法描述符包含了参数类型及返回值，JVM要求这两个必须完全相同才可以，但是Java语言说的是参数类型相同但是返回值类型可以不同。Java编译器通过创建Bridge Method来解决这个问题，看下面代码：\n1class A { 2 Object f() { 3 return null; 4 } 5} 6class C extends A { 7 Integer f() { 8 return null; 9 } 10} 然后用javap查看编译结果：\n1$ javac Override.java 2$ javap -v C.class 3class C extends A 4... 5{ 6 java.lang.Integer f(); 7 descriptor: ()Ljava/lang/Integer; 8 flags: 9 Code: 10 stack=1, locals=1, args_size=1 11 0: aconst_null 12 1: areturn 13 ... 14 java.lang.Object f(); 15 descriptor: ()Ljava/lang/Object; 16 flags: ACC_BRIDGE, ACC_SYNTHETIC 17 Code: 18 stack=1, locals=1, args_size=1 19 0: aload_0 20 1: invokevirtual #2 // Method f:()Ljava/lang/Integer; 21 4: areturn 22 LineNumberTable: 23 line 7: 0 24} 可以看到编译器替我们创建了一个Object f()的Bridge Method，它调用的是Integer f()，这样就构成了JVM所定义的重写。\n思维导图 参考文档  极客时间 - 深入拆解 Java 虚拟机 - 04 | JVM是如何执行方法调用的？（上）  JVM Spec - 4.3.2. Field Descriptors  JVM Spec - 4.3.3. Method Descriptors  Java Language Spec - 8.4.8. Inheritance, Overriding, and Hiding  Java Language Spec - 8.4.9. Overloading  JVM Spec - 5.4.5. Overriding  Effects of Type Erasure and Bridge Methods  ","date":"2019-02-08","img":"","permalink":"/post/jvm/method-call/1-overload-override/","series":null,"tags":["JVM"],"title":"JVM执行方法调用（一）- 重载与重写"},{"categories":null,"content":"大纲 本文只是一种实际部署方案的例子，涉及到的技术有（除Docker/Docker Swarm外）：\n Docker overlay network  Fluentd  Prometheus stack vegasbrianc的Prometheus监控方案   步骤大纲：\n 部署Docker machine  基本配置 配置网络 启动Fluentd日志服务   部署Docker swarm集群  配置网络 添加Node   部署Prometheus stack  给Node打Label 创建监控网络 启动service   部署应用  识别stateless与stateful 创建应用网络 给Node打Label 启动service    1 部署Docker machine 1.1 基本配置 准备若干Linux服务器（本例使用Ubuntu 16.04），参照Docker CE 镜像源站 提到的步骤安装Docker CE。\n参照Docker Daemon生产环境配置 。\n1.2 配置bridge网络 参照Docker Daemon生产环境配置 中的mtu和子网章节。\n1.3 启动Fluentd日志服务 参考使用Fluentd收集Docker容器日志 。\n2 部署Docker swarm集群 到一台机器上执行docker swarm init，这个机器将作为manager node。\n执行docker node ls会看到类似下面的结果：\n1$ docker node ls 2 3ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS 4dxn1zf6l61qsb1josjja83ngz * manager1 Ready Active Leader 如果你计划不会把工作负载跑在manager node上，那么使用docker drain：\n1docker node update --availability drain \u0026lt;node-id\u0026gt; 可参考Docker Swarm基本命令清单 。\n2.1 配置网络MTU和子网 参考Docker Overlay网络的MTU 。\n特别注意\n观察docker_gwbridge和ingress的子网是否与已有网络冲突：\n1$ docker network inspect -f \u0026#39;{{json .IPAM}}\u0026#39; docker_gwbridge 2{\u0026#34;Driver\u0026#34;:\u0026#34;default\u0026#34;,\u0026#34;Options\u0026#34;:null,\u0026#34;Config\u0026#34;:[{\u0026#34;Subnet\u0026#34;:\u0026#34;172.18.0.0/16\u0026#34;,\u0026#34;Gateway\u0026#34;:\u0026#34;172.18.0.1\u0026#34;}]} 3 4$ docker network inspect -f \u0026#39;{{json .IPAM}}\u0026#39; ingress 5{\u0026#34;Driver\u0026#34;:\u0026#34;default\u0026#34;,\u0026#34;Options\u0026#34;:null,\u0026#34;Config\u0026#34;:[{\u0026#34;Subnet\u0026#34;:\u0026#34;10.255.0.0/16\u0026#34;,\u0026#34;Gateway\u0026#34;:\u0026#34;10.255.0.1\u0026#34;}]} 如果有冲突则参考Docker Overlay网络的MTU 中的方法修改子网。\n2.2 添加Node 参考Docker Swarm基本命令清单 。\n3 部署Prometheus stack 使用的是vegasbrianc的Prometheus监控方案 。\n整个监控方案包含一下几个组件：\n Prometheus Node-exporter，运行在每个node上 Alertmanager cAdvisor，运行在每个node上 Grafana  3.1 给Node打Label 挑选一台Node作为运行监控服务的机器。给这个node打上label：\n1$ docker node update --label-add for-monitor-stack=1 \u0026lt;node-id\u0026gt; 3.2 创建监控网络 1$ docker network create -d overlay --attachable monitor-net 参考参考Docker Overlay网络的MTU 检查子网与MTU是否配置正确。\n3.3 启动service clone vegasbrianc的Prometheus监控方案 项目代码。\n使用我修改过的docker-stack.yml 启动service：\n1$ docker stack deploy \\ 2 --with-registry-auth \\ 3 --prune \\ 4 -c docker-stack.yml \\ 5 p8s-monitor-stack 访问地址：\n Prometheus：http://\u0026lt;任意swarm node ip\u0026gt;:9000 Node-exporter：http://\u0026lt;任意swarm node ip\u0026gt;:9010 Alertmanager：http://\u0026lt;任意swarm node ip\u0026gt;:9020 cAdvisor：http://\u0026lt;任意swarm node ip\u0026gt;:9030 Grafana：http://\u0026lt;任意swarm node ip\u0026gt;:9040，用户名admin，密码foobar  4 部署应用 4.1 识别stateless与stateful 如果你的应用由多个组件（service）组成，那么在部署它们之前你得识别出哪些是stateless service哪些是stateful service。\n针对每个service你自问以下三个问题：\n 这个service崩溃之后，是不是只需要重启它就可以了，而不需要关心数据恢复？ 这个service是否可以在node之间任意迁移，且不需要分布式存储？ 这个service是否无需固定IP？  如果上述回答都是Yes，那么这个service就是stateless的，只要有一个是No，则这个service是stateful的。\n对于stateless service，你可以：\n 用docker stack deploy部署 用docker service create部署  对于stateful service，你可以：\n 用docker run部署 用docker-compose up部署 如果没有固定IP的要求，那么你也可以用docker stack deploy/docker service create部署，前提是你得保证这个service只会固定在一台机器上运行。  有时候你的应用既有stateless service又有stateful service，这时需要把他们挂载到同一个overlay网络里，这样它们之间就能够互相通信了。\n4.2 创建应用网络 创建app-net（你也可以改成自己的名字）\n1$ docker network create -d overlay --attachable app-net 参考Docker Overlay网络的MTU 检查子网与MTU是否配置正确。\n4.3 给Node打Label 如果你对于Service部署在哪个Node上有要求，那么你得给Node打上Label：\n1$ docker node update --label-add \u0026lt;your-label\u0026gt;=1 \u0026lt;node-id\u0026gt; 然后在docker-compose.yaml里添加约束条件：\n1version:\u0026#34;3.7\u0026#34;2services:3busybox:4image:busybox5deploy:6placement:7constraints:8- node.labels.\u0026lt;your-label\u0026gt; == 14.4 启动service 对于stateless service，编写docker-compose.yaml，里面写了同时挂载app-net和monitor-net，比如：\n1version:\u0026#34;3.7\u0026#34;2services:3busybox:4image:busybox5networks:6app-net:7monitor-net:8aliases:9- busybox10...11networks:12app-net:13external:true14monitor-net:15external:true注意上面设置了busybox service在monitor-net中的别名，这是因为如果你用docker stack deploy部署，那么busybox的名字默认是\u0026lt;stack-name\u0026gt;_busybox，这样对于prometheus而言此名字不稳定，不便于配置详见Prometehus监控Docker Swarm Overlay网络中的容器 。\n然后用docker stack deploy部署：\n1$ docker stack deploy \\ 2 --with-registry-auth \\ 3 --prune \\ 4 -c docker-compose.yaml 5 \u0026lt;stack-name\u0026gt; 如果用docker service create则：\n1$ docker service create \\ 2 --network app-net \\ 3 --network monitor-net \\ 4 --name \u0026lt;name\u0026gt; \\ 5 ... 其他参数 6 \u0026lt;image\u0026gt; 下面举例docker run启动stateful service的方法：\n1$ docker run -d \\ 2 --name \u0026lt;name\u0026gt; \\ 3 --network app-net \\ 4 ... 其他参数 \\ 5 \u0026lt;image\u0026gt; 6 7# 然后再挂载到monitor-net上 8$ docker network connect monitor-net \u0026lt;name\u0026gt; ","date":"2019-02-01","img":"","permalink":"/post/deploy-app-on-docker-swarm-steps/","series":null,"tags":["docker","运维"],"title":"Docker Swarm部署应用的总结"},{"categories":null,"content":"原文地址 关键词：微服务、Cloud-native stateful service、Akka\n大纲 Stateful service不可避免：\n stateless service在k8s上部署已经被证明是成功的。 将state从stateful service中剥离出来，使其成为stateless service是一种成功的做法。 但是这些stateless service依然大多依赖于，老的架构、设计、习惯、模式、实践和工具，而这些东西都是为运行“全能”的RDBMS之上的单体单节点系统所发展出来的。 当前的service越来越data-centric和data-driven，将service和data紧密贴合显得更为重要，因为这样做能够高效率、高性能，可靠的管理、处理、转换、丰富data。 service无法承受在data访问时与数据库 or 存储的round-trip，并需要持续处理接近实时的data，从永无止境的数据流中挖掘知识。而这份data在被存储之前，也时常需要被分布式地处理——以实现可扩展性、低延迟、高吞吐。  实施stateful service的难点：\n stateful 实例不是能够简单替换的，因为它有自己的状态，在替换的时候要考虑进去。 部署stateful 副本必须要求副本之间协作，比如启动依赖顺序、版本升级、schema变动等。 replication需要时间，一个正在处理replication的机器会获得比平时更高的负载。如果开启一个新副本，有可能会down掉整个数据库or服务。  k8s对于stateful service的方案：\n k8s对于不是cloud-native stateful service的方案是StatefulSet 每个pod有一个稳定的标识符（namespace + name）以及一个专用的即使Pod重启也不会丢失的磁盘，甚至Pod重新调度到另一台机器上也不会丢失。 开发人员需要新一代的能够构建cloud-native的stateful service工具，而这些service只需要k8s为stateless service提供的基础设施。  设计cloud-native stateful service的难点：\n 难点不在于设计和实现这些service，而是管理它们之间的空间。难点有：数据一致性保证、可靠通信、数据复制与故障转移、组件失败侦测、恢复、分片、路由、共识算法等等。 对于不同的service来说End-to-end的正确性、一致性、安全性是不同的，是完全依赖于用例的，是不能外包给基础设施的。我们需要一种编程模型，配合一个把重活都包了的运行时，让我们专注于实现业务价值，而不是陷入错综复杂的网络编程与failure mode里。Akka与K8S就是上述问题的解决方案  Akka 简介：\n 基于Reactive Manifesto 构建，是面向today和tomorrow的架构。 Akka的unit of work和state被称为actor，是stateful、fault-tolerant、isolated、autonomous的component or entity。 actor/entity是非常轻量级的，在一台机器上可以轻易运行百万个，并且它们之间使用异步通信。它们内置自动自我恢复机制，同时distributable and location transparent by default。也就意味着它们可以根据需要在集群里扩展、复制、移动，而这对于actor/entity的用户来说是透明的。 Akka和K8S的配合方式：K8S负责容器，粗粒度，负责资源。Akka负责应用层，细粒度，负责如何在给定资源下分发工作。  Akka的“let it crash”哲学：\n 传统基于线程的编程模型只给了你对于单个线程的控制，如果线程异常崩溃你就麻烦了，所以你需要显式地在这个线程内部做异常处理。异常不会在线程间传播，不会跨网络，没有办法在外部知道这个线程已经失败了。但是丢失这个线程又是代价极高的，最坏情况下，如果用了同步协议，会将这个错误波及到整个应用。 Akk把你的应用设计为“supervisor hierarchies”，actor们彼此注意健康、彼此管理失败。如果一个actor失败了，它的错误会被隔离并被包起来，以异步消息的方式发送到它的supervising actor（可能通过网络）。supervising actor能够在安全健康的上下文中处理异常，并且根据声明式定义规则自动重启失败的actor。 和K8S有点像，不过是在application stack层面。  延伸阅读  microliths  Designing Events-First Microservices  ","date":"2019-01-30","img":"","permalink":"/post/article-review/stateful-service-design-consideration-for-the-k8s-stack/","series":null,"tags":["Akka","微服务","k8s"],"title":"Stateful Service Design Consideration for the Kubernetes Stack"},{"categories":null,"content":"思维导图 参考资料  极客时间 - 深入拆解Java虚拟机 - 03 - Java虚拟机是如何加载Java类的?  Java Language Specification - Chapter 12. Execution  Java Virtual Machine Specification - Chapter 4. The class File Format  Java Virtual Machine Specification - Chapter 5. Loading, Linking, and Initializing  ","date":"2019-01-26","img":"","permalink":"/post/jvm/classloader/references/","series":null,"tags":["JVM","ClassLoader"],"title":"ClassLoader - 总结及参考"},{"categories":null,"content":"本文源代码在Github 。\n在前一篇文章初步了解ClassLoader 里提到了委托模型（又称双亲委派模型），解释了ClassLoader hierarchy（层级）处理类加载的过程。那么class文件是如何变成Class对象的呢？\nClass的加载过程 Class加载分为这几步：\n 创建和加载（Creation and Loading） 链接（Linking） 验证（Verification） 准备（Preparation） 解析（Resolution），此步骤可选 初始化（Initialization）  注: 前面说了数组类是虚拟机直接创建的，以上过程不适用于数组类。\n创建和加载（Creation and Loading） 何时会触发一个类的加载？\nJava Language Specification - 12.1.1. Load the Class Test ：\n The initial attempt to execute the method main of class Test discovers that the class Test is not loaded - that is, that the Java Virtual Machine does not currently contain a binary representation for this class. The Java Virtual Machine then uses a class loader to attempt to find such a binary representation.\n 也就是说，当要用到一个类，JVM发现还没有包含这个类的二进制形式（字节）时，就会使用ClassLoader尝试查找这个类的二进制形式。\n我们知道ClassLoader委托模型，也就是说实际触发加载的ClassLoader和真正加载的ClassLoader可能不是同一个，JVM将它们称之为initiating loader和defining loader（Java Virtual Machine Specification - 5.3. Creation and Loading ）：\n A class loader L may create C by defining it directly or by delegating to another class loader. If L creates C directly, we say that L defines C or, equivalently, that L is the defining loader of C.\n  When one class loader delegates to another class loader, the loader that initiates the loading is not necessarily the same loader that completes the loading and defines the class. If L creates C, either by defining it directly or by delegation, we say that L initiates loading of C or, equivalently, that L is an initiating loader of C.\n 那么当A类使用B类的时候，B类使用的是哪个ClassLoader呢？\nJava Virtual Machine Specification - 5.3. Creation and Loading ：\n The Java Virtual Machine uses one of three procedures to create class or interface C denoted by N:\n   If N denotes a nonarray class or an interface, one of the two following methods is used to load and thereby create C:  If D was defined by the bootstrap class loader, then the bootstrap class loader initiates loading of C (§5.3.1). If D was defined by a user-defined class loader, then that same user-defined class loader initiates loading of C (§5.3.2).   Otherwise N denotes an array class. An array class is created directly by the Java Virtual Machine (§5.3.3), not by a class loader. However, the defining class loader of D is used in the process of creating array class C.    注：上文的C和D都是类，N则是C的名字。\n 也就说如果D用到C，且C还没有被加载，且C不是数组，那么：\n 如果D的defining loader是bootstrap class loader，那么C的initiating loader就是bootstrap class loader。 如果D的defining loader是自定义的class loader X，那么C的initiating loader就是X。  再总结一下就是：如果D用到C，且C还没有被加载，且C不是数组，那么C的initiating loader就是D的defining loader。\n用下面的代码观察一下：\n1// 把这个项目打包然后放到/tmp目录下 2public class CreationAndLoading { 3 public static void main(String[] args) throws Exception { 4 // ucl1的parent是bootstrap class loader 5 URLClassLoader ucl1 = new NamedURLClassLoader(\u0026#34;user-defined 1\u0026#34;, new URL[] { new URL(\u0026#34;file:///tmp/classloader.jar\u0026#34;) }, null); 6 // ucl1是ucl2的parent 7 URLClassLoader ucl2 = new NamedURLClassLoader(\u0026#34;user-defined 2\u0026#34;, new URL[0], ucl1); 8 Class\u0026lt;?\u0026gt; fooClass2 = ucl2.loadClass(\u0026#34;me.chanjar.javarelearn.classloader.Foo\u0026#34;); 9 fooClass2.newInstance(); 10 } 11} 12 13public class Foo { 14 public Foo() { 15 System.out.println(\u0026#34;Foo\u0026#39;s classLoader: \u0026#34; + Foo.class.getClassLoader()); 16 System.out.println(\u0026#34;Bar\u0026#39;s classLoader: \u0026#34; + Bar.class.getClassLoader()); 17 } 18} 19 20public class NamedURLClassLoader extends URLClassLoader { 21 private String name; 22 public NamedURLClassLoader(String name, URL[] urls, ClassLoader parent) { 23 super(urls, parent); 24 this.name = name; 25 } 26 @Override 27 protected Class\u0026lt;?\u0026gt; findClass(String name) throws ClassNotFoundException { 28 System.out.println(\u0026#34;ClassLoader: \u0026#34; + this.name + \u0026#34; findClass(\u0026#34; + name + \u0026#34;)\u0026#34;); 29 return super.findClass(name); 30 } 31 @Override 32 public Class\u0026lt;?\u0026gt; loadClass(String name) throws ClassNotFoundException { 33 System.out.println(\u0026#34;ClassLoader: \u0026#34; + this.name + \u0026#34; loadClass(\u0026#34; + name + \u0026#34;)\u0026#34;); 34 return super.loadClass(name); 35 } 36 @Override 37 public String toString() { 38 return name; 39 } 40} 运行结果是：\n1ClassLoader: user-defined 2 loadClass(me.chanjar.javarelearn.classloader.Foo) 2ClassLoader: user-defined 1 findClass(me.chanjar.javarelearn.classloader.Foo) 3ClassLoader: user-defined 1 loadClass(java.lang.Object) 4ClassLoader: user-defined 1 loadClass(java.lang.System) 5ClassLoader: user-defined 1 loadClass(java.lang.StringBuilder) 6ClassLoader: user-defined 1 loadClass(java.lang.Class) 7ClassLoader: user-defined 1 loadClass(java.io.PrintStream) 8Foo\u0026#39;s classLoader: user-defined 1 9ClassLoader: user-defined 1 loadClass(me.chanjar.javarelearn.classloader.Bar) 10ClassLoader: user-defined 1 findClass(me.chanjar.javarelearn.classloader.Bar) 11Bar\u0026#39;s classLoader: user-defined 1 可以注意到Foo的initiating loader是user-defined 2，但是defining loader是user-defined 1。而Bar的initiating loader与defining loader则直接是user-defined 1，绕过了user-defined 2。观察结果符合预期。\n链接 验证（Verification） 验证类的二进制形式在结构上是否正确。\n准备（Preparation） 为类创建静态字段，并且为这些静态字段初始化默认值。\n解析（Resolution） JVM在运行时会为每个类维护一个run-time constant pool，run-time constant pool构建自类的二进制形式里的constant_pool表。run-time constant pool里的所有引用一开始都是符号引用（symbolic reference）（见Java Virutal Machine Specification - 5.1. The Run-Time Constant Pool ）。符号引用就是并非真正引用（即引用内存地址），只是指向了一个名字而已（就是字符串）。解析阶段做的事情就是将符号引用转变成实际引用）。\nJava Virutal Machine Specification - 5.4. Linking ：\n This specification allows an implementation flexibility as to when linking activities (and, because of recursion, loading) take place, provided that all of the following properties are maintained:\n   A class or interface is completely loaded before it is linked.     A class or interface is completely verified and prepared before it is initialized.   也就是说仅要求：\n 一个类在被链接之前得是完全加载的。 一个类在被初始化之前得是被完全验证和准备的。  所以对于解析的时机JVM Spec没有作出太多规定，只说了以下JVM指令在执行之前需要解析符号引用：anewarray, checkcast, getfield, getstatic, instanceof, invokedynamic, invokeinterface, invokespecial, invokestatic, invokevirtual, ldc, ldc_w, multianewarray, new, putfield 和 putstatic 。\n看不懂没关系，大致意思就是，用到字段、用到方法、用到静态方法、new类等时候需要解析符号引用。\n初始化 如果直接赋值的静态字段被 final 所修饰，并且它的类型是基本类型或字符串时，那么该字段便会被 Java 编译器标记成常量值（ConstantValue），其初始化直接由 Java 虚拟机完成。除此之外的直接赋值操作，以及所有静态代码块中的代码，则会被 Java 编译器置于同一方法中，并把它命为 \u0026lt;clinit\u0026gt;（class init）。\nJVM 规范枚举了下述类的初始化时机是：\n 当虚拟机启动时，初始化用户指定的主类； new 某个类的时候 调用某类的静态方法时 访问某类的静态字段时 子类初始化会触发父类初始化 用反射API对某个类进行调用时 一个接口定义了default方法（原文是non-abstract、non-static方法），某个实现了这个接口的类被初始化，那么这个接口也会被初始化 初次调用 MethodHandle 实例时  注意：这里没有提到new 数组的情况，所以new 数组的时候不会初始化类。\n同时类的初始化过程是线程安全的，下面是一个利用上述时机4和线程安全特性做的延迟加载的Singleton的例子：\n1public class Singleton { 2 private Singleton() {} 3 private static class LazyHolder { 4 static final Singleton INSTANCE = new Singleton(); 5 } 6 public static Singleton getInstance() { 7 return LazyHolder.INSTANCE; 8 } 9} 这种做法被称为Initialization-on-demand holder idiom 。\n类加载常见异常 ClassNotFoundException Java Virutal Machine Specification - 5.3.1. Loading Using the Bootstrap Class Loader ：\n If no purported representation of C is found, loading throws an instance of ClassNotFoundException.\n Java Virutal Machine Specification - 5.3.2. Loading Using a User-defined Class Loader ：\n When the loadClass method of the class loader L is invoked with the name N of a class or interface C to be loaded, L must perform one of the following two operations in order to load C:\n   The class loader L can create an array of bytes representing C as the bytes of a ClassFile structure (§4.1); it then must invoke the method defineClass of class ClassLoader. Invoking defineClass causes the Java Virtual Machine to derive a class or interface denoted by N using L from the array of bytes using the algorithm found in §5.3.5.     The class loader L can delegate the loading of C to some other class loader L'. This is accomplished by passing the argument N directly or indirectly to an invocation of a method on L' (typically the loadClass method). The result of the invocation is C.    In either (1) or (2), if the class loader L is unable to load a class or interface denoted by N for any reason, it must throw an instance of ClassNotFoundException.\n 所以，ClassNotFoundException发生在【加载阶段】：\n 如果用的是bootstrap class loader，则当找不到其该类的二进制形式时抛出ClassNotFoundException 如果用的是用户自定义class loader，不管是自己创建二进制（这里包括从文件读取或者内存中创建），还是代理给其他class loader，只要出现无法加载的情况，都要抛出ClassNotFoundException  NoClassDefFoundError Java Virtual Machine Specification - 5.3. Creation and Loading  If the Java Virtual Machine ever attempts to load a class C during verification (§5.4.1) or resolution (§5.4.3) (but not initialization (§5.5)), and the class loader that is used to initiate loading of C throws an instance of ClassNotFoundException, then the Java Virtual Machine must throw an instance of NoClassDefFoundError whose cause is the instance of ClassNotFoundException.\n  (A subtlety here is that recursive class loading to load superclasses is performed as part of resolution (§5.3.5, step 3). Therefore, a ClassNotFoundException that results from a class loader failing to load a superclass must be wrapped in a NoClassDefFoundError.)\n Java Virtual Machine Specification - 5.3.5. Deriving a Class from a class File Representation  Otherwise, if the purported representation does not actually represent a class named N, loading throws an instance of NoClassDefFoundError or an instance of one of its subclasses.\n Java Virtual Machine Specification - 5.5. Initialization  If the Class object for C is in an erroneous state, then initialization is not possible. Release LC and throw a NoClassDefFoundError.\n 所以，NoClassDefFoundError发生在：\n 【加载阶段】，因其他类的【验证】or【解析】触发对C类的【加载】，此时发生了ClassNotFoundException，那么就要抛出NoClassDefFoundError，cause 是ClassNotFoundException。 【加载阶段】，在【解析】superclass的过程中发生的ClassNotFoundException也必须包在NoClassDefFoundError里。 【加载阶段】，发现找到的二进制里的类名和要找的类名不一致时，抛出NoClassDefFoundError 【初始化阶段】，如果C类的Class对象处于错误状态，那么抛出NoClassDefFoundError  追踪类的加载 可以在JVM启动时添加-verbose:class来打印类加载过程。\n参考资料  Java Language Specification - Chapter 12. Execution  Java Virtual Machine Specification - Chapter 5. Loading, Linking, and Initializing  极客时间 - 深入拆解Java虚拟机 - 03 Java虚拟机是如何加载Java类的? （专栏文章，需付费购买） CS-Note 类加载机制  深入理解JVM(八)——类加载的时机  深入理解JVM(九)——类加载的过程  ","date":"2019-01-25","img":"","permalink":"/post/jvm/classloader/2-steps/","series":null,"tags":["ClassLoader","JVM"],"title":"ClassLoader（二）- 加载过程"},{"categories":null,"content":"本文源代码在Github 。\n什么是ClassLoader javadoc ClassLoader ：\n A class loader is an object that is responsible for loading classes. \u0026hellip; Given the binary name of a class, a class loader should attempt to locate or generate data that constitutes a definition for the class. A typical strategy is to transform the name into a file name and then read a \u0026ldquo;class file\u0026rdquo; of that name from a file system.\n 简单来说：\n ClassLoader是一个负责加载Class的对象。 给ClassLoader一个类名（需符合Java语言规范），那么它就应该尝试定位，或者生成包含该类定义的数据。 一个典型的定位策略是把类名转换成class文件名，然后从文件系统里读取这个class文件。  三种ClassLoader实现 讲到bootstrap class loader就不得不说三种常见的ClassLoader实现。\n执行下面代码会看到三种类型的ClassLoader实现：\n1import com.sun.javafx.util.Logging; 2import java.util.ArrayList; 3public class PrintClassLoader { 4 public static void main(String[] args) { 5 System.out.println(\u0026#34;Classloader for ArrayList: \u0026#34; + ArrayList.class.getClassLoader()); 6 System.out.println(\u0026#34;Classloader for Logging: \u0026#34; + Logging.class.getClassLoader()); 7 System.out.println(\u0026#34;Classloader for this class: \u0026#34; + PrintClassLoader.class.getClassLoader()); 8 } 9} 结果如下：\n1Classloader for ArrayList: null 2Classloader for Logging: sun.misc.Launcher$ExtClassLoader@5e2de80c 3Classloader for this class: sun.misc.Launcher$AppClassLoader@18b4aac2  Bootstrap class loader。bootstrap class loader是native code写的。它是所有ClassLoader的祖先，它是顶级ClassLoader。它负责加载JDK的内部类型，一般来说就是位于$JAVA_HOME/jre/lib下的核心库和rt.jar。 Extension class loader。即Extension class loader，负责加载Java核心类的扩展，加载$JAVA_HOME/lib/ext目录和System Property java.ext.dirs所指定目录下的类（见Java Extension Mechanism Architecture ）。 System class loader，又称Application class loader。它的parent class loader是extension class loader（可以从sun.misc.Launcher的构造函数里看到），负责加载CLASSPATH环境变量、-classpath/-cp启动参数指定路径下的类。  类的ClassLoader 每个Class对象引用了当初加载自己的ClassLoader（javadoc ClassLoader ）：\n Every Class object contains a reference to the ClassLoader that defined it.\n 其实Class对象的getClassLoader()方法就能够得到这个ClassLoader，并且说了如果该方法返回空，则说明此Class对象是被bootstrap class loader加载的，见getClassLoader() javadoc ：\n Returns the class loader for the class. Some implementations may use null to represent the bootstrap class loader. This method will return null in such implementations if this class was loaded by the bootstrap class loader.\n 数组类的ClassLoader  Class objects for array classes are not created by class loaders, but are created automatically as required by the Java runtime. The class loader for an array class, as returned by Class.getClassLoader() is the same as the class loader for its element type; if the element type is a primitive type, then the array class has no class loader.\n 简单来说说了三点：\n 数组也是类，但是它的Class对象不是由ClassLoader创建的，而是由Java runtime根据需要自动创建的。 数组的getClassLoader()的结果同其元素类型的ClassLoader 如果元素是基础类型，则数组类没有ClassLoader  下面是一段实验代码：\n1import com.sun.javafx.util.Logging; 2public class PrintArrayClassLoader { 3 public static void main(String[] args) { 4 System.out.println(\u0026#34;ClassLoader for int[]: \u0026#34; + new int[0].getClass().getClassLoader()); 5 System.out.println(\u0026#34;ClassLoader for string[]: \u0026#34; + new String[0].getClass().getClassLoader()); 6 System.out.println(\u0026#34;ClassLoader for Logging[]: \u0026#34; + new Logging[0].getClass().getClassLoader()); 7 System.out.println(\u0026#34;ClassLoader for this class[]: \u0026#34; + new PrintArrayClassLoader[0].getClass().getClassLoader()); 8 } 9} 得到的结果如下，符合上面的说法：\n1ClassLoader for int[]: null 2ClassLoader for string[]: null 3ClassLoader for Logging[]: sun.misc.Launcher$ExtClassLoader@5e2de80c 4ClassLoader for this class[]: sun.misc.Launcher$AppClassLoader@18b4aac2 那如果是二维数组会怎样呢？下面是实验代码：\n1import com.sun.javafx.util.Logging; 2public class PrintArrayArrayClassLoader { 3 public static void main(String[] args) { 4 System.out.println(\u0026#34;ClassLoader for int[][]: \u0026#34; + new int[0][].getClass().getClassLoader()); 5 System.out.println(\u0026#34;ClassLoader for string[][]: \u0026#34; + new String[0][].getClass().getClassLoader()); 6 System.out.println(\u0026#34;ClassLoader for Logging[][]: \u0026#34; + new Logging[0][].getClass().getClassLoader()); 7 System.out.println(\u0026#34;ClassLoader for this class[][]: \u0026#34; + new PrintArrayClassLoader[0][].getClass().getClassLoader()); 8 System.out.println(\u0026#34;ClassLoader for this Object[][] of this class[]: \u0026#34; + new Object[][]{new PrintArrayArrayClassLoader[0]}.getClass().getClassLoader()); 9 } 10} 结果是：\n1ClassLoader for int[][]: null 2ClassLoader for string[][]: null 3ClassLoader for Logging[][]: sun.misc.Launcher$ExtClassLoader@5e2de80c 4ClassLoader for this class[][]: sun.misc.Launcher$AppClassLoader@18b4aac2 5ClassLoader for this Object[][] of this class[]: null 注意第四行的结果，我们构建了一个Object[][]，里面放的是PrintArrayArrayClassLoader[]，但结果依然是null。所以：\n 二维数组的ClassLoader和其定义的类型（元素类型）的ClassLoader相同。 与其实际内部存放的类型无关。  ClassLoader类的ClassLoader ClassLoader本身也是类，那么是谁加载它们的呢？实际上ClassLoader类的ClassLoader就是bootstrap class loader。下面是实验代码：\n1import com.sun.javafx.util.Logging; 2public class PrintClassLoaderClassLoader { 3 public static void main(String[] args) { 4 // Launcher$ExtClassLoader 5 System.out.println(\u0026#34;ClassLoader for Logging\u0026#39;s ClassLoader: \u0026#34; + Logging.class.getClassLoader().getClass().getClassLoader()); 6 // Launcher$AppClassLoader 7 System.out.println(\u0026#34;ClassLoader for this class\u0026#39;s ClassLoader: \u0026#34; + PrintClassLoaderClassLoader.class.getClassLoader().getClass().getClassLoader()); 8 // 自定义ClassLoader 9 System.out.println(\u0026#34;ClassLoader for custom ClassLoader: \u0026#34; + DummyClassLoader.class.getClassLoader().getClass().getClassLoader()); 10 } 11 public static class DummyClassLoader extends ClassLoader { 12 } 13} 结果是：\n1ClassLoader for Logging\u0026#39;s ClassLoader: null 2ClassLoader for this class\u0026#39;s ClassLoader: null 3ClassLoader for custom ClassLoader: null ClassLoader解决了什么问题 简单来说ClassLoader就是解决类加载问题的，当然这是一句废话。JDK里的ClassLoader是一个抽象类，这样做的目的是能够让应用开发者定制自己的ClassLoader实现（比如添加解密/加密）、动态插入字节码等，我认为这才是ClassLoader存在的最大意义。\nClassLoader的工作原理 还是看javadoc的说法 ：\n The ClassLoader class uses a delegation model to search for classes and resources. Each instance of ClassLoader has an associated parent class loader. When requested to find a class or resource, a ClassLoader instance will delegate the search for the class or resource to its parent class loader before attempting to find the class or resource itself. The virtual machine\u0026rsquo;s built-in class loader, called the \u0026ldquo;bootstrap class loader\u0026rdquo;, does not itself have a parent but may serve as the parent of a ClassLoader instance.\n 简单来说：\n ClassLoader使用委托模型（国内普遍称之为双亲委派模型）查找Class或Resource。 每个 ClassLoader 实例都有一个parent ClassLoader。 当要查找Class或者Resource的时候，递归委托给parent，如果parent找不到，才会自己找。举例说明：如果ClassLoader层级关系是这样A-\u0026gt;B-\u0026gt;C，如果被查找Class只能被A找到，那么过程是A-delegate-\u0026gt;B-delegate-\u0026gt;C(not found)-\u0026gt;B(not found)-\u0026gt;A(found)。 JVM有一个内置的顶级ClassLoader，叫做bootstrap class loader，它没有parent，它是老祖宗。  ContextClassLoader ClassLoader的委托模型存在这么一个问题：子ClassLoader能够看见父ClassLoader所加载的类，而父ClassLoader看不到子ClassLoader所加载的类。\n这个问题出现在Java提供的SPI上，简单举例说明：\n Java核心库提供了SPI A 尝试提供了自己的实现 B SPI A尝试查找实现B，结果找不到  这是因为B一般都是在Classpath中的，它是被System class loader加载的，而SPI A是在核心库里的，它是被bootstrap class loader加载的，而bootstrap class loader是顶级ClassLoader，它不能向下委托给System class loader，所以SPI A是找不到实现B的。\n这个时候可以通过java.lang.Thread#getContextClassLoader()和java.lang.Thread#setContextClassLoader来让SPI A加载到B。\n为何SPI A不直接使用System class loader来加载呢？我想这是因为如果写死了System class loader那就缺少灵活性的关系吧。\nClass的唯一性 如果一个类被一个ClassLoader加载两次，那么两次的结果应该是一致的，并且这个加载过程是线程安全的，见ClassLoader.java源码：\n1protected Class\u0026lt;?\u0026gt; loadClass(String name, boolean resolve) 2 throws ClassNotFoundException 3{ 4 synchronized (getClassLoadingLock(name)) { 5 // First, check if the class has already been loaded 6 Class\u0026lt;?\u0026gt; c = findLoadedClass(name); 7 if (c == null) { 8 // ... 9 try { 10 if (parent != null) { 11 c = parent.loadClass(name, false); 12 } else { 13 c = findBootstrapClassOrNull(name); 14 } 15 } catch (ClassNotFoundException e) { 16 // ClassNotFoundException thrown if class not found 17 // from the non-null parent class loader 18 } 19 20 if (c == null) { 21 // If still not found, then invoke findClass in order 22 // to find the class. 23 // ... 24 c = findClass(name); 25 26 // ... 27 } 28 } 29 // ... 30 return c; 31 } 32} 如果一个类被两个不同的ClassLoader加载会怎样呢？看下面代码：\n1// 把这个项目打包然后放到/tmp目录下 2public class ClassUniqueness { 3 4 public static void main(String[] args) throws Exception { 5 Class\u0026lt;?\u0026gt; fooClass1 = Class.forName(\u0026#34;me.chanjar.javarelearn.classloader.ClassUniqueness\u0026#34;); 6 System.out.println(\u0026#34;1st ClassUniqueness\u0026#39;s ClassLoader: \u0026#34; + fooClass1.getClassLoader()); 7 8 // 故意将parent class loader设置为null，否则就是SystemClassLoader（即ApplicationClassLoader） 9 URLClassLoader ucl = new URLClassLoader(new URL[] { new URL(\u0026#34;file:///tmp/classloader.jar\u0026#34;) }, null); 10 Class\u0026lt;?\u0026gt; fooClass2 = ucl.loadClass(\u0026#34;me.chanjar.javarelearn.classloader.ClassUniqueness\u0026#34;); 11 System.out.println(\u0026#34;2nd ClassUniqueness\u0026#39;s ClassLoader: \u0026#34; + fooClass2.getClassLoader()); 12 13 System.out.println(\u0026#34;Two ClassUniqueness class equals? \u0026#34; + fooClass1.equals(fooClass2)); 14 } 15 16} 运行结果是：\n11st ClassUniqueness\u0026#39;s ClassLoader: sun.misc.Launcher$AppClassLoader@18b4aac2 22nd ClassUniqueness\u0026#39;s ClassLoader: java.net.URLClassLoader@66d3c617 3Two ClassUniqueness class equals? false``` 观察到两点：\n 虽然是同一个类，但是加载它们的ClassLoader不同。 虽然是同一个类，但是它们并不相等。  由此可以得出结论：一个Class的唯一性不仅仅是其全限定名（Fully-qualified-name），而是由【加载其的ClassLoader + 其全限定名】联合保证唯一。\n这种机制对于解决诸如类冲突问题非常有用，类冲突问题就是在运行时存在同一个类的两个不同版本，同时代码里又都需要使用这两个不同版本的类。解决这个问题的思路就是使用不同的ClassLoader加载这两个版本的类。事实上OSGi或者Web容器就是这样做的（它们不是严格遵照委托模型，而是先自己找，找不到了再委托给parent ClassLoader）。\n参考文档  JDK Javadoc - ClassLoader  JDK Javadoc - Class  Java虚拟机是如何加载Java类的? （极客时间专栏，需付费购买） Class Loaders in Java  深入探讨Java类加载器  Java Language Specification - Chapter 12. Execution  Java Virtual Machine Specification - Chapter 5. Loading, Linking, and Initializing  ","date":"2019-01-24","img":"","permalink":"/post/jvm/classloader/1-intro/","series":null,"tags":["ClassLoader","JVM"],"title":"ClassLoader（一）- 介绍"},{"categories":null,"content":" 小马哥技术博客 。Java、Spring Cloud Alibaba、Apache Dubbo。  操作系统/内核方面：\n Brendan D. Gregg ，许多内核检测工具的创建者，可以详细地看到如何使用perf、eBPF、FlameGraph分析各种性能问题。强烈推荐。 Code Capsule ，另一个对操作系统/内核具有深刻理解的工程师。 1024cores ， 作者Dmitry Vyukov，Golang scheduler的核心成员。lockfree, waitfree, obstructionfree synchronization algorithms and data structures, scalability-oriented architecture, multicore/multiprocessor design patterns, high-performance computing, threading technologies and libraries (OpenMP, TBB, PPL), message-passing systems and related topics.  其他：\n 用BFG瘦身Git仓库 ，如果你的历史里有视频文件。。。 ","date":"2019-01-24","img":"","permalink":"/post/bookmarks/bookmarks-blog/","series":null,"tags":["收藏夹"],"title":"收藏夹 - 博客"},{"categories":null,"content":"本文介绍使用Fluentd收集standalone容器日志的方法。\nDocker提供了很多logging driver ，默认情况下使用的json-file ，它会把容器打到stdout/stderr的日志收集起来存到json文件中，docker logs所看到的日志就是来自于这些json文件。\n当有多个docker host的时候你会希望能够把日志汇集起来，集中存放到一处，本文讲的是如何通过fluentd logging driver 配合fluentd 来达成这一目标。\n目标：\n 将standalone容器打到stdout/stderror的日志收集起来 收集的日志根据容器名分开存储 日志文件根据每天滚动  第一步：配置Fluentd实例 首先是配置文件fluent.conf：\n1\u0026lt;source\u0026gt; 2 @type forward 3\u0026lt;/source\u0026gt; 4 5# 处理docker service容器的日志 6# input 7# tag: busybox.2.sphii6yg9rw045kqi4kh6owxv 8# output 9# file: busybox/inst-2.yyyy-MM-dd.log 10\u0026lt;match *.*.*\u0026gt; 11 @type file 12 path /fluentd/log/${tag[0]}/inst-${tag[1]} 13 append true 14 \u0026lt;format\u0026gt; 15 @type single_value 16 message_key log 17 \u0026lt;/format\u0026gt; 18 \u0026lt;buffer tag,time\u0026gt; 19 @type file 20 timekey 1d 21 timekey_wait 10m 22 flush_mode interval 23 flush_interval 30s 24 \u0026lt;/buffer\u0026gt; 25\u0026lt;/match\u0026gt; 26 27# 处理standalone容器的日志 28# input 29# tag: busybox 30# output 31# file: busybox/busybox.yyyy-MM-dd.log 32\u0026lt;match *\u0026gt; 33 @type file 34 path /fluentd/log/${tag}/${tag} 35 append true 36 \u0026lt;format\u0026gt; 37 @type single_value 38 message_key log 39 \u0026lt;/format\u0026gt; 40 \u0026lt;buffer tag,time\u0026gt; 41 @type file 42 timekey 1d 43 timekey_wait 10m 44 flush_mode interval 45 flush_interval 30s 46 \u0026lt;/buffer\u0026gt; 47\u0026lt;/match\u0026gt; 新建一个目录比如/home/ubuntu/container-logs，并赋予权限chmod 777 /home/ubuntu/container-logs。\n然后启动Fluentd实例，这里使用的Docker方式：\n1docker run -it \\ 2 -d \\ 3 -p 24224:24224 \\ 4 -v /path/to/conf/fluent.conf:/fluentd/etc/fluent.conf \\ 5 -v /home/ubuntu/container-logs:/fluentd/log 6 fluent/fluentd:v1.3 第二步：指定容器的logging driver 在启动容器的时候执行使用fluentd作为logging driver，下面以standalone容器举例：\n1docker run -d \\ 2 ... 3 --log-driver=fluentd \\ 4 --log-opt fluentd-address=\u0026lt;fluentdhost\u0026gt;:24224 \\ 5 --log-opt mode=non-blocking \\ 6 --log-opt tag={{.Name}} \\ 7 \u0026lt;image\u0026gt; 注意上面的--log-opt tag={{.Name}}参数。\n如果是docker compose / docker stack deploy部署，则在docker-compose.yaml中这样做 ：\n1version:\u0026#34;3.7\u0026#34;2x-logging:3\u0026amp;default-logging4driver:fluentd5options:6fluentd-address:\u0026lt;fluentdhost\u0026gt;:242247fluentd-async-connect:\u0026#39;true\u0026#39;8mode:non-blocking9max-buffer-size:4m10tag:\u0026#34;{{.Name}}\u0026#34;11services:12busybox:13image:busybox14logging:*default-logging第三步：观察日志 到/home/ubuntu/container-logs目录下能够看到类似这样的目录结构：\n1. 2└── \u0026lt;container-name\u0026gt; 3 └── \u0026lt;container-name\u0026gt;.20190123.log 参考文档  Configure logging drivers  Customize log driver output  Use Fluentd logging driver  Docker CLI - run  Fluentd  Fluentd - out_file  Fluentd - formatter_single_value  Fluentd - buf_file  Fluentd - buffer    ","date":"2019-01-24","img":"","permalink":"/post/collect-docker-log-by-fluentd/","series":null,"tags":["docker","运维","fluentd","日志"],"title":"使用Fluentd收集Docker容器日志"},{"categories":null,"content":"Docker Daemon生产环境配置 提到了MTU设置，但是这只是针对于名为bridge的docker bridge network，对于overlay network是无效的。\n判断是否需要本文 如果存在以下任意一种情况，则需要阅读本文：\n Docker machine的MTU不是1500 Docker swarm创建ingress和docker_gwbridge网络的子网和现有网络冲突  观察MTU的方法：\n1$ docker network inspect -f \u0026#39;{{json .Options}}\u0026#39; \u0026lt;network-name\u0026gt; 2 3{\u0026#34;com.docker.network.driver.mtu\u0026#34;:\u0026#34;1450\u0026#34;,\u0026#34;com.docker.network.driver.overlay.vxlanid_list\u0026#34;:\u0026#34;4099\u0026#34;} 如果没有com.docker.network.driver.mtu，那么就是默认的1500。\n观察子网的方法：\n1$ docker network inspect -f \u0026#39;{{json .IPAM}}\u0026#39; \u0026lt;network-name\u0026gt; 2 3{\u0026#34;Driver\u0026#34;:\u0026#34;default\u0026#34;,\u0026#34;Options\u0026#34;:null,\u0026#34;Config\u0026#34;:[{\u0026#34;Subnet\u0026#34;:\u0026#34;10.0.0.0/24\u0026#34;,\u0026#34;Gateway\u0026#34;:\u0026#34;10.0.0.1\u0026#34;}]} 修改ingress和docker_gwbridge网络 以下步骤得在swarm init或join之前做\n假设你有三个机器，manager、worker-1、worker-2，准备搞一个Docker swarm集群\n  [manager] docker swarm init\n  [manager] 获得docker_gwbridge的参数，注意Subnet\n  1$ docker network inspect -f \u0026#39;{{json .IPAM}}\u0026#39; docker_gwbridge 2{\u0026#34;Driver\u0026#34;:\u0026#34;default\u0026#34;,\u0026#34;Options\u0026#34;:null,\u0026#34;Config\u0026#34;:[{\u0026#34;Subnet\u0026#34;:\u0026#34;172.18.0.0/16\u0026#34;,\u0026#34;Gateway\u0026#34;:\u0026#34;172.18.0.1\u0026#34;}]}  [manager] docker swarm leave --force\n  [manager] 停掉docker sudo systemctl stop docker.service\n  [manager] 删掉虚拟网卡docker_gwbridge\n  1$ sudo ip link set docker_gwbridge down 2$ sudo ip link del dev docker_gwbridge  [manager] 启动docker sudo systemctl start docker.service\n  [manager] 重建docker_gwbridge，\n  记得设置之前得到的Subnet参数和正确的MTU值，如果子网和现有网络冲突，则要修改subnet参数：\n1$ docker network rm docker_gwbridge 2$ docker network create \\ 3 --subnet 172.18.0.0/16 \\ 4 --opt com.docker.network.bridge.name=docker_gwbridge \\ 5 --opt com.docker.network.bridge.enable_icc=false \\ 6 --opt com.docker.network.bridge.enable_ip_masquerade=true \\ 7 --opt com.docker.network.driver.mtu=1450 \\ 8 docker_gwbridge 再到worker-1和worker-2上执行相同的命令。\n [manager] docker swarm init\n  [manager] 先观察ingress network的参数，注意Subnet和Gateway：\n  1$ docker network inspect -f \u0026#39;{{json .IPAM}}\u0026#39; ingress 2{\u0026#34;Driver\u0026#34;:\u0026#34;default\u0026#34;,\u0026#34;Options\u0026#34;:null,\u0026#34;Config\u0026#34;:[{\u0026#34;Subnet\u0026#34;:\u0026#34;10.255.0.0/16\u0026#34;,\u0026#34;Gateway\u0026#34;:\u0026#34;10.255.0.1\u0026#34;}]}  [manager] 删除ingress network，docker network rm ingress。\n  [manager] 重新创建ingress network，记得填写之前得到的Subnet和Gateway，以及正确的MTU值，如果子网和现有网络冲突，则要修改subnet参数：：\n  1$ docker network create \\ 2 --driver overlay \\ 3 --ingress \\ 4 --subnet=10.255.0.0/16 \\ 5 --gateway=10.255.0.1 \\ 6 --opt com.docker.network.driver.mtu=1450 \\ 7 ingress [worker-1] [worker-2] join docker swarm join ...  注意：新机器在join到swarm之前，得先执行第7步\n验证：\n  启动一个swarm service，docker service create -td --name busybox busybox\n  观察虚拟网卡\n  发现MTU都是1450：\n1$ ip link 21: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1 3 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 42: ens3: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1450 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000 5 link/ether fa:16:3e:71:09:f5 brd ff:ff:ff:ff:ff:ff 63: docker0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default 7 link/ether 02:42:6b🇩🇪95:71 brd ff:ff:ff:ff:ff:ff 8298: docker_gwbridge: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default 9 link/ether 02:42:ae:7b:cd:b4 brd ff:ff:ff:ff:ff:ff 10309: veth7e0f9e5@if308: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1450 qdisc noqueue master docker_gwbridge state UP mode DEFAULT group default 11 link/ether 16:ca:8f:c7:d3:7f brd ff:ff:ff:ff:ff:ff link-netnsid 1 12311: vethcb94fec@if310: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1450 qdisc noqueue master docker0 state UP mode DEFAULT group default 13 link/ether 9a:aa:de:7b:4f:d4 brd ff:ff:ff:ff:ff:ff link-netnsid 2 观察容器内网卡  网卡MTU也是1450：\n1$ docker exec b.1.pdsdgghzyy5rhqkk5et59qa3o ip link 21: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue qlen 1 3 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 4310: eth0@if311: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN\u0026gt; mtu 1450 qdisc noqueue 5 link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff 自建overlay network的MTU和子网 方法一：在docker compose file设置 1...23networks:4my-overlay:5driver:overlay6ipam:7driver:default8config:9- subnet:\u0026lt;subnet\u0026gt; 10driver_opts:11com.docker.network.driver.mtu:1450不过这样不好，因为这样就把docker compose file的内容和生产环境绑定了，换了个环境这个MTU值未必合适。\n方法二：外部创建时设置 1docker network create \\ 2 -d overlay \\ 3 --subnet \u0026lt;subnet-net\u0026gt; \\ 4 --opt com.docker.network.driver.mtu=1450 \\ 5 --attachable \\ 6 my-overlay 用法：\n 在docker compose file里这样用： 1...23app-net:4external:true5name:my-overlay docker run --network my-overlay ... docker service create --network my-overlay ...  参考资料  Use overlay networks  Docker MTU issues and solutions  docker network create  ","date":"2019-01-11","img":"","permalink":"/post/docker-overlay-network-mtu-subnet/","series":null,"tags":["docker"],"title":"Docker Overlay网络的MTU和子网"},{"categories":null,"content":"一些docker daemon生产环境中要注意的参数配置。\n本文介绍一些生产环境中dockerd要特别注意的参数，这些参数可以通过在dockerd命令行参数形式给，也可以通过在/etc/docker/daemon.json里配置。本文介绍的就是daemon.json配置方式。\n在开始之前，请先查看/etc/docker/daemon.json是否存在，如果不存在则新建一个，内容是{}。然后你要懂JSON文件格式。\n如何应用配置 下面所讲的配置最好在Docker安装完之后马上做，如果已经有容器运行了，那么先stop掉所有容器，然后再做。\n修改完之后重启Docker daemon，比如在Ubuntu 16.04下：sudo systemctl restart docker.service。\n然后执行docker info来验证配置是否生效。\n1. 当前用户添加到docker用户组 执行sudo usermod -aG docker $USER将当前用户添加到docker用户组。\n执行完成后重新登录服务器，你所登录的用户就能够执行docker命令了。\n2. registry-mirrors 1{ 2 \u0026#34;registry-mirrors\u0026#34;: [] 3} 此参数配置的是Docker registry的镜像网站，国内访问docker hub有时候会抽风，所以配置一个国内的镜像网站能够加速Docker image的下载。\n可以使用Daocloud加速器 （需注册，使用免费）或者其他云厂商提供的免费的加速服务。它们的原理就是修改registry-mirrors参数。\n3. dns 1{ 2 \u0026#34;dns\u0026#34;: [] 3} Docker内置了一个DNS Server，它用来做两件事情：\n 解析docker network里的容器或Service的IP地址 把解析不了的交给外部DNS Server解析（dns参数设定的地址）  默认情况下，dns参数值为Google DNS nameserver：8.8.8.8和8.8.4.4。我们得改成国内的DNS地址，比如：\n 1.2.4.8 阿里DNS：223.5.5.5和223.6.6.6 114DNS：114.114.114.114和114.114.115.115  比如：\n1{ 2 \u0026#34;dns\u0026#34;: [\u0026#34;223.5.5.5\u0026#34;, \u0026#34;223.6.6.6\u0026#34;] 3} 4. log-driver Log driver 是Docker用来接收来自容器内部stdout/stderr的日志的模块，Docker默认的log driver是JSON File logging driver 。这里只讲json-file的配置，其他的请查阅相关文档。\njson-file会将容器日志存储在docker host machine的/var/lib/docker/containers/\u0026lt;container id\u0026gt;/\u0026lt;container id\u0026gt;-json.log（需要root权限才能够读），既然日志是存在磁盘上的，那么就要磁盘消耗的问题。下面介绍两个关键参数：\n max-size，单个日志文件最大尺寸，当日志文件超过此尺寸时会滚动，即不再往这个文件里写，而是写到一个新的文件里。默认值是-1，代表无限。 max-files，最多保留多少个日志文件。默认值是1。  根据服务器的硬盘尺寸设定合理大小，比如：\n1{ 2 \u0026#34;log-driver\u0026#34;: \u0026#34;json-file\u0026#34;, 3 \u0026#34;log-opts\u0026#34;: { 4 \u0026#34;max-size\u0026#34;: \u0026#34;100m\u0026#34;, 5 \u0026#34;max-files\u0026#34;:\u0026#34;5\u0026#34; 6 } 7} 5. storage-driver Docker推荐使用overlay2 作为Storage driver。你可以通过docker info | grep Storage来确认一下当前使用的是什么：\n1$ docker info | grep \u0026#39;Storage\u0026#39; 2Storage Driver: overlay2 如果结果不是overlay2，那你就需要配置一下了：\n1{ 2 \u0026#34;storage-driver\u0026#34;: \u0026#34;overlay2\u0026#34; 3} 6. bridge网络的mtu 如果docker host machine的网卡MTU为1500，则不需要此步骤\nMTU是一个很容易被忽略的参数，Docker默认的MTU是1500，这也是大多数网卡的MTU值。但是！在虚拟化环境下，docker host machine网卡的MTU可能不是1500，比如在openstack创建的虚拟的网卡的MTU是1450：\n1$ ip link 21: ens3: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1450 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000 3 link/ether fa:16:3e:71:09:f5 brd ff:ff:ff:ff:ff:ff 也可以通过下列命令观察bridge网络的MTU：\n1$ docker network inspect -f \u0026#39;{{json .Options}}\u0026#39; bridge 2 3{\u0026#34;com.docker.network.bridge.default_bridge\u0026#34;:\u0026#34;true\u0026#34;,\u0026#34;com.docker.network.bridge.enable_icc\u0026#34;:\u0026#34;true\u0026#34;,\u0026#34;com.docker.network.bridge.enable_ip_masquerade\u0026#34;:\u0026#34;true\u0026#34;,\u0026#34;com.docker.network.bridge.host_binding_ipv4\u0026#34;:\u0026#34;0.0.0.0\u0026#34;,\u0026#34;com.docker.network.bridge.name\u0026#34;:\u0026#34;docker0\u0026#34;,\u0026#34;com.docker.network.driver.mtu\u0026#34;:\u0026#34;1500\u0026#34;} 当Docker网络的MTU比docker host machine网卡MTU大的时候可能会发生：\n 容器外出通信失败 影响网络性能  所以将Docker网络MTU设置成和host machine网卡保持一致就行了，比如：\n1{ 2 \u0026#34;mtu\u0026#34;: 1450 3} 验证：\n1$ ip link 23: docker0: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc noqueue state DOWN mode DEFAULT group default 3 link/ether 02:42:6b🇩🇪95:71 brd ff:ff:ff:ff:ff:ff 注意到docker0的MTU还是1500，不用惊慌，创建一个容器再观察就变成1450了（下面的veth是容器的虚拟网卡设备）：\n1$ docker run -itd --name busybox --rm busybox 2$ ip link 33: docker0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default 4 link/ether 02:42:6b🇩🇪95:71 brd ff:ff:ff:ff:ff:ff 5268: vethdf32b1b@if267: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1450 qdisc noqueue master docker0 state UP mode DEFAULT group default 6 link/ether 1a:d3:8a:3e:d3:dd brd ff:ff:ff:ff:ff:ff link-netnsid 2 在到容器里看看它的网卡，MTU也是1450：\n1$ docker exec busybox ip link 2267: eth0@if268: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN\u0026gt; mtu 1450 qdisc noqueue 3 link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff 7. bridge网络的子网 观察默认bridge的子网是否与已有网络冲突：\n1$ docker network inspect -f \u0026#39;{{json .IPAM}}\u0026#39; bridge 2 3{\u0026#34;Driver\u0026#34;:\u0026#34;default\u0026#34;,\u0026#34;Options\u0026#34;:null,\u0026#34;Config\u0026#34;:[{\u0026#34;Subnet\u0026#34;:\u0026#34;172.17.0.0/16\u0026#34;,\u0026#34;Gateway\u0026#34;:\u0026#34;172.17.0.1\u0026#34;}]} 如果有则参考Configure the default bridge network （可忽略IPv6部分的配置）。\n8. live restore 开启live restore特性能够在Docker daemon停止的时候依旧让容器保持运行。\n1{ 2 \u0026#34;live-restore\u0026#34;: true 3} 注意：在Daemon停机期间，容器的日志被暂存在一个缓冲区中，如果缓冲区满了（默认大小64K），则容器就会被阻塞住。\n本特性不支持，对Docker daemon做major或minor升级所引起的daemon停机。\n参考资料  Daemon CLI  Configure logging drivers  JSON File logging driver  Use the OverlayFS storage driver  Post-installation steps for Linux  Configure the default bridge network  Keep containers alive during daemon downtime  ","date":"2019-01-11","img":"","permalink":"/post/docker-daemon-prod/","series":null,"tags":["docker"],"title":"Docker Daemon生产环境配置"},{"categories":null,"content":"介绍如何使用Prometheus的dns service discovery机制，自动发现并抓取Docker swarm overlay网络中的容器所提供的指标。\n使用docker service create/docker stack deploy能够很方便管理多个docker host，并且对应用做扩缩容。那么我们如何抓取这些动态创建的容器应用所提供的指标呢？\n在《使用Prometheus+Grafana监控JVM》 一文里我们使用了static_config静态配置指标抓取目标，这显然在docker swarm环境里是不合适的。我们需要一种动态发现容器的方法。\n解决思路如下：\n 使用《一种生产环境Docker Overlay Network的配置方案》 提到的方法配置overlay网络，并且把docker service、stack、standalone container都挂到这个overlay网络里。 把Prometheus也挂到这个overlay网络里。 使用Prometheus的DNS service discovery机制，半自动的发现容器。  本文所提到的脚本可以在这里 下载\n下面构建一个实验环境以说明方法。\n第一步：构建overlay network 根据《一种生产环境Docker Overlay Network的配置方案》 里提到的方法，创建Docker swarm，和一个overlay网络，名字叫做test-overlay：\n1docker network create -d overlay --attachable test-overlay 第二步：启动容器 为了方便起见，使用prometheus-mock-data 来模拟一个提供指标的应用，这样就能够避免繁琐的jmx-exporter。\n  新建一个目录，名字叫做docker-swarm-demo\n  新建一个文件scrape-data.txt，这个文件就是我们要提供的假指标，内容如下：\n  1# HELP x mock metric 2# TYPE x gauge 3x 1 4--- 5# HELP x mock metric 6# TYPE x gauge 7x 2 8--- 9# HELP x mock metric 10# TYPE x gauge 11x 3 12--- 13# HELP x mock metric 14# TYPE x gauge 15x 4  为了演示docker service和standalone container都能被采集到，会启动这两种形式的容器：\n  使用docker service create启动一个service，replicas=3（注意--name参数）：\n  1docker service create \\ 2 --name mock \\ 3 --replicas 3 \\ 4 --network test-overlay \\ 5 --limit-memory 96M \\ 6 --mount type=bind,src=$(pwd)/scrape-data.txt,dst=/home/java-app/etc/scrape-data.txt \\ 7 chanjarster/prometheus-mock-data:latest 使用docker run启动一个standalone container（注意--name参数）：  1docker run -d \\ 2 -v $(pwd)/scrape-data.txt:/home/java-app/etc/scrape-data.txt \\ 3 --network test-overlay \\ 4 --name standalone-mock \\ 5 chanjarster/prometheus-mock-data:latest 第三步：启动Prometheus  在之前新建目录docker-swarm-demo里创建文件prom-config.yml，内容如下：  1scrape_configs:2- job_name:\u0026#39;swarm-service\u0026#39;3scrape_interval:30s4dns_sd_configs:5- names:6- tasks.mock7- standalone-mock8type:A9port:808010relabel_configs:11- source_labels:[\u0026#39;__meta_dns_name\u0026#39;]12target_label:\u0026#39;service\u0026#39;注意到上面的两个关键配置：\n 设定了两个DNS A记录，tasks.mock和standalone-mock。 tasks.mock是Docker自动为docker service mock创建的，而standalone-mock就是容器名。文章最开始说到的半自动就是这个意思，我们得事先知道DNS A记录有哪些，然后让Prometheus去发现这些DNS A记录背后对应的容器有哪些。 把__meta_dns_name的值设置到指标的service 这个label里。  启动Prometheus：  1docker run -d \\ 2 --name=prometheus \\ 3 --network test-overlay \\ 4 -p 9090:9090 \\ 5 -v $(pwd):/prometheus-config \\ 6 -v $(pwd)/prom-data:/prometheus \\ 7 prom/prometheus --config.file=/prometheus-config/prom-config.yml 访问 http://localhost:9090 看看Prometheus是否启动成功，在输入框里输入x然后执行，应该可以看到如下图的结果：  其中3个instance是属于tasks.mock的，还有一个则是standalone container（如果没有看到4个instance，那么等一会儿再试）。\n","date":"2019-01-09","img":"","permalink":"/post/p8s-scrape-container-in-docker-swarm-overlay-network/","series":null,"tags":["docker","prometheus"],"title":"Prometehus监控Docker Swarm Overlay网络中的容器"},{"categories":null,"content":"介绍一种生产环境Docker overlay network的配置方案。\n概要 先讲一下生产环境中的问题：\n 有多个Docker host，希望能够通过Docker swarm连接起来。 Docker swarm只适合于无状态应用，不适合有状态应用。 因此生产环境中会同时存在  无状态应用：利用docker service create/docker stack deploy创建的。 有状态应用：利用docker run/docker compose up创建的。   希望两种应用能够连接到同一个overlay网络，在网络内部能够通过  tasks.\u0026lt;service-name\u0026gt; DNS name 连接到无状态应用（见Container discovery ） \u0026lt;container-name\u0026gt; DNS name 连接到有状态应用    解决办法：\n 创建attachable的overlay network 有状态应用挂到这个overlay network上 无状态应用也挂到这个overlay network上  步骤 到manager节点上创建attachable的overlay network，名字叫做prod-overlay：\n1docker network create -d overlay --attachable prod-overlay 在manager节点上查看这个网络是否创建成功：\n1$ docker network ls 2 3NETWORK ID NAME DRIVER SCOPE 4fbfde97ed12a bridge bridge local 573ab6bbac970 docker_gwbridge bridge local 6a2adb3de5f7a host host local 7nm7pgzuh6ww4 ingress overlay swarm 8638e550dab67 none null local 9qqf78g8iio10 prod-overlay overlay swarm 在worker节点上查看这个网络，这时你看不到这个网络，不过不要担心，当后面在worker节点上创建工作负载后就能看到了：\n1$ docker network ls 2 3NETWORK ID NAME DRIVER SCOPE 4fbfde97ed12a bridge bridge local 573ab6bbac970 docker_gwbridge bridge local 6a2adb3de5f7a host host local 7nm7pgzuh6ww4 ingress overlay swarm 8638e550dab67 none null local 在manager上创建容器c1，挂到prod-overlay network上：\n1docker run --name c1 --network prod-overlay -itd busybox 在worker上创建容器c2，挂到prod-overlay network上：\n1docker run --name c2 --network prod-overlay -itd busybox 在manager上创建service c，挂到prod-overlay network上：\n1docker service create -td --name c --replicas 2 --network prod-overlay busybox 验证 查看worker节点的network 之前在worker节点上没有看到prod-overlay network，现在你应该可以看见了：\n1$ docker network ls 2NETWORK ID NAME DRIVER SCOPE 301180b9d4833 bridge bridge local 4cd94df435afc docker_gwbridge bridge local 574721e7670eb host host local 6nm7pgzuh6ww4 ingress overlay swarm 732e6853ea78d none null local 8dw8kd2nb2yl3 prod-overlay overlay swarm 确认容器可以互ping 到manager节点上，让c1 ping c2\n1$ docker exec c1 ping -c 2 c2 2PING c2 (10.0.2.2): 56 data bytes 364 bytes from 10.0.2.2: seq=0 ttl=64 time=0.682 ms 464 bytes from 10.0.2.2: seq=1 ttl=64 time=0.652 ms 到manager节点上，让c1 ping tasks.c，tasks.c是之前创建的service c的DNS name：\n1$ docker exec c1 ping -c 2 tasks.c 2PING tasks.c (10.0.2.8): 56 data bytes 364 bytes from 10.0.2.8: seq=0 ttl=64 time=2.772 ms 464 bytes from 10.0.2.8: seq=1 ttl=64 time=0.694 ms 到manager节点上，让c1 查询 tasks.c的DNS name，可以看到tasks.c有两条记录：\n1$ docker exec c1 nslookup -type=a tasks.c 2Server:\t127.0.0.11 3Address:\t127.0.0.11:53 4 5Non-authoritative answer: 6Name:\ttasks.c 7Address: 10.0.2.7 8Name:\ttasks.c 9Address: 10.0.2.8 到manager节点上，查看service c的task，看到有c.1、c.2两个task，分别部署在两个节点上：\n1$ docker service ps c 2ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS 3p5n70vhtnz2f c.1 busybox:latest docker-learn-1 Running Running 17 minutes ago 4byuoox1t7cve c.2 busybox:latest docker-learn-2 Running Running 17 minutes ago 到c.1 task所在的节点上，查看task c.1的容器名：\n1$ docker ps -f name=c.1 2CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3795a3bd3c20a busybox:latest \u0026#34;sh\u0026#34; 21 minutes ago Up 21 minutes c.1.p5n70vhtnz2f5q8p2pcvbyfmw 然后在c1里ping task c.1的容器名：\n1$ docker exec c1 ping -c 2 c.1.p5n70vhtnz2f5q8p2pcvbyfmw 2PING c.1.p5n70vhtnz2f5q8p2pcvbyfmw (10.0.2.7): 56 data bytes 364 bytes from 10.0.2.7: seq=0 ttl=64 time=0.198 ms 464 bytes from 10.0.2.7: seq=1 ttl=64 time=0.128 ms 你同样可以：\n 在c2里：  ping c1 ping tasks.c ping task c.1、c.2的容器   在task c.1、c.2的容器里：  ping c1、c2； ping tasks.c ping task c.1、c.2的容器    注意 通过docker run / docker compose up创建的容器的名字，要保证在整个集群里是唯一的。docker 不会帮你检查名称冲突的情况，如果名称冲突了那么会得到错误的DNS结果。\n参考资料  Use overlay networks  Use an overlay network for standalone containers  Docker Reference Architecture: Designing Scalable, Portable Docker Container Networks  ","date":"2019-01-09","img":"","permalink":"/post/docker-overlay-network/","series":null,"tags":["docker"],"title":"一种生产环境Docker Overlay Network的配置方案"},{"categories":null,"content":"Docker swarm基本命令，更复杂的生产环境请仔细参阅文档。\n创建Swarm 准备两台服务器A、B\n给服务器安装docker\n确保所有服务器的防火墙开启了以下端口\n TCP/2377 TCP/7946 UDP/7946 UDP/4789  ssh到A上，执行docker swarm init，A将作为manager，会输出类似下列的内容：\n1Swarm initialized: current node (dxn1zf6l61qsb1josjja83ngz) is now a manager. 2 3To add a worker to this swarm, run the following command: 4 5 docker swarm join \\ 6 --token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \\ 7 \u0026lt;ip\u0026gt;:2377 8 9To add a manager to this swarm, run \u0026#39;docker swarm join-token manager\u0026#39; and follow the instructions. ssh到B上，执行上面提到的docker swarm join ...指令，B将作为worker\n执行docker node ls，查看Swarm集群node\n1ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSION 2yd05eu5uvcqm0pbi8g6r25b2c * docker-learn-1 Ready Active Leader 18.09.0 3jkycxb3c7swrn5t37fp1d1xwb docker-learn-2 Ready Active 18.09.0 node管理 添加manager 生产环境中应该有多个manager来保证高可用，manager的数量应该是单数，比如1、3、5。\n到manager机器上，执行docker swarm join-token manager，得到以下输出：\n1To add a manager to this swarm, run the following command: 2 3 docker swarm join --token SWMTKN-1-0tfd7v1bu05od7fdsedqdu6tuny6ozjmfrq3hiwmc1xb5yaxix-e7kpq257cyblpdna9j89cjgyw \u0026lt;ip\u0026gt;:2377 到新机器上执行上述指令，添加manager\n添加worker 到manager node上执行docker swarm join-token worker，得到以下输出：\n1To add a worker to this swarm, run the following command: 2 3 docker swarm join --token SWMTKN-1-0tfd7v1bu05od7fdsedqdu6tuny6ozjmfrq3hiwmc1xb5yaxix-1fc3updzbx9tssop55yznh79w \u0026lt;ip\u0026gt;:2377 到新机器上执行上述指令，添加worker\n更新节点AVAILABILITY 节点AVAILABILITY有三种状态：\n ACTIVE：可以安排新的工作负载到这个节点 PAUSE：不会安排新的工作负载到这个节点，但是已经存在的负载继续运行 DRAIN：不会安排新的工作负载到这个节点，已经存在的负载会被驱逐到其他node上  注意，上面提到的禁止安排、驱逐工作负载仅针对于docker service create ...、docker stack deploy ...创建的工作负载。对于docker run ...、docker compose up ...的工作负载不起作用。\n运行以下命令更新节点的AVAILIBALITY：\n1docker node update --availability \u0026lt;active|pause|drain\u0026gt; \u0026lt;NODE-ID\u0026gt; 比如：\n1docker node update --availability drain \u0026lt;NODE-ID\u0026gt; 禁止manager承担工作负载 默认情况下manager也承担工作负载，在生产环境中这样不太好，因为manager可能会因为工作负载过多而变得卡顿，导致无法工作。\n解决办法很简单，将manager的AVAILIBALITY变成DRAIN就行了\n删除节点 到服务器上执行 docker swarm leave\n如果是manager，则可能会报warning，你只需要这样docker swarm leave --force\n清理swarm 删除所有manager和worker节点，swarm就被清理掉了。\n参考文档  Getting started with swarm mode  Create a swarm  Add nodes to the swarm  Manage nodes in a swarm  Administer and maintain a swarm of Docker Engines  ","date":"2019-01-09","img":"","permalink":"/post/docker/swarm-command-list/","series":null,"tags":["docker"],"title":"Docker Swarm基本命令清单"},{"categories":null,"content":"学习Prometheus各种函数的时候最好能够造一些我们想要的数据来测试，但是Prometheus没有提供直接操作其数据库的功能，所以在这里安利一个工具。\n下面讲一下步骤：\n提供假指标数据 我做了一个提供假指标的工具prometheus-mock-data 。利用这个工具我们可以提供给Prometheus我们想提供给它的指标，这样便于后面的测试。\n新建一个文件scrape-data.txt，内容见gist ，这个文件里定义了每次Prometheus抓指标的时候所能抓到的值，这个工具会依次提供这些指标（当然你也可以写自己的假数据）。\n运行：\n1docker run -d --rm \\ 2 --name=mock-metrics \\ 3 -v $(pwd)/scrape-data.txt:/home/java-app/etc/scrape-data.txt \\ 4 -p 8080:8080 \\ 5 chanjarster/prometheus-mock-data:latest 用浏览器访问：http://localhost:8080/metrics，刷新几次，能够看到指标数据在循环显示。\n启动Prometheus 新建配置文件：\n1scrape_configs:2- job_name:\u0026#39;mock\u0026#39;3scrape_interval:15s4static_configs:5- targets:6- \u0026#39;\u0026lt;docker-host-machine-ip\u0026gt;:8080\u0026#39;注意：Data point的间隔通过scrape_interval参数控制。\n启动：\n1docker run -d \\ 2 --name=prometheus \\ 3 -p 9090:9090 \\ 4 -v $(pwd)/prom-config.yml:/prometheus-config/prom-config.yml \\ 5 prom/prometheus --config.file=/prometheus-config/prom-config.yml 打开http://localhost:9090看看是不是抓到指标了。\n启动Grafana 1docker run -d \\ 2 --name=grafana \\ 3 -p 3000:3000 \\ 4 grafana/grafana 在Grafana里配置Prometheus数据源，然后作图。\n","date":"2018-12-28","img":"","permalink":"/post/p8s-mock-data/","series":null,"tags":["prometheus"],"title":"安利一个造Prometheus假数据的工具"},{"categories":null,"content":"详细解释Prometheus range query中的step参数的作用。\nPrometheus有两种query：instant query 、range query 。本文要讲的就是range query中的step参数。\nrange query是非常常见的一种query，看看它有哪些参数：\n query=\u0026lt;string\u0026gt;: PromQL表达式。 start=\u0026lt;rfc3339 | unix_timestamp\u0026gt;: 时间范围的开始。 end=\u0026lt;rfc3339 | unix_timestamp\u0026gt;: 时间范围的结束。 step=\u0026lt;duration | float\u0026gt;: 查询解析度（query resolution）。 timeout=\u0026lt;duration\u0026gt;: 执行超时。这个参数是可选的。  在Prometheus expression browser里看到的是这样的：\n注意到上图中的Res框里没有给值，没有给的话Prometheus会自动给一个值，这个值在图示右上角可以看到。\nstep对于查询结果的影响 Prometheues在对PromQL表达式求值的逻辑是这样的（详见这个issue 里的回答）：\n 对于[start, end]时间区间，从start开始，以step为长度，把时间区间分成若干段 对每个段进行求值  举例：start=10,end=20,step=2，那么就会有ts=10,ts=12,ts=14,ts=16,ts=18,ts=206段，然后为这6个段进行求值。求值方式视乎表达式中Time series selector的类型而定。\nPromQL有两种Time series selector：instant vector selector 和range vector selector 。下面将分别讲解：\nInstant vector selector 形如下面的就是Instant vector selector，x是metric的名字。\n1x Prometheus在对每段Instant vector selector求值的逻辑是这样的：\n 从该段的timestamp（含）往前找，取第一个找到的data point的值。如果有一个data point的timestamp==该段的timestamp，则直接使用该data point。 如果该段timestamp往前的5分钟范围内没有找到任何data point，则该段无值。  下面这张图解释了上面逻辑：\n图中的绿点是Prometheus实际存储的数据，按照时间轴从左到右排列。蓝点是根据step参数的求值结果。\n当data point间隔比step更大的时候会发生下图这种情况：\n可以看到有两个段的求值结果来自于同一个data point。\nRange vector selector 形如下面的就是Range vector selector，x是metric的名字，方括号里的是range duration。\n1x[5m] range vector select返回的是当前timestamp之前的range duration内的所有data point。range vector是不能直接用做绘图的，你得用某些function把range vector转换成instant vector才行，比如rate() 。\n下图解释了是如何对Range vector selector进行分段求值的：\nstep和rate duration step和range duration是独立的两个参数，在某些情况下两者的值存在某种限制条件，这里例举rate() 来说明。rate()的作用是获得一个range-vector的每秒平均增长率。\n如果step=10m而range duration=5m，那么rate在计算的时候会丢失一半的数据，两个分段之间的data point有一半没有被纳入计算。前面那张图就存在数据丢失的情况，有一个data point被漏掉了。\n因此在使用rate()时，range duration得大于等于step。\n而如果是irate() ，这个限制则是range duration不得大于step（详见Brian Brazil的Presentation ）。\nGrafana中的step参数 在Grafana中并没有直接提供step参数，而是这两个参数：min step和resolution（文档在这里 )。min step故名思义设定的是step的最小值，那么resolution是什么呢？\n大家都知道Grafana都是用来画图的，比如下面这张图Y轴是值，X轴则是时间线，因此在X轴方向的每个像素都代表了一个timestamp。\nresolution就是用来根据像素来计算step的一个参数。下面用6个像素以及它们的timestamp来说明：\n1x=1,ts=0; x=2,ts=5; x=3,ts=10; x=4,ts=15; x=5,ts=20; x=6,ts=25  resolution=1/1时，那么step就是相邻像素所代表的timestamp的差，即5； resolution=1/2时，那么step就是相隔1个像素的两个像素的timestamp的差，即10； resolution=1/3时，那么step就是相隔2个像素的两个像素的timestamp的差，即15； 以此类推  而每个像素所代表的timestamp受两个因素影响：\n 查询所定义的时间范围 Graph的宽度（单位：像素）  所以在Grafana发起的查询中step参数是动态的。其实这也是很合理的，因为只有这样才能够在Graph宽度小的时候绘图更粗糙（即step更大），Graph宽度大的时候绘图更精细（即step更小，但是不能小于min step）。实际发起的请求的step参数你可以在Graph的Query Inspector里看到：\n但是我们之前不说过了rate()的range duration不能小于step吗？那么把range duration给固定值的化就不太好了，怎么办呢？你可以使用Grafana提供的内置变量$__interval，它代表的Grafana就是计算出来的step的值。比如这样就能够将range duration和step保持一致了（更多内置变量可以见这里 ）：\n1rate(x[$__interval]) 所以，你想自己实验一把 如果你想自己动手实验，但是又苦于无法制造干净的假数据，那么可以参考这篇文章推荐的方法 。\n","date":"2018-12-28","img":"","permalink":"/post/p8s-step-param/","series":null,"tags":["prometheus"],"title":"Prometheus Range Query中的step参数"},{"categories":null,"content":"Monitoring  Metrics, tracing, and logging ，Metrics、tracing、logging三个监控系统的区别和联系 Observability 3 ways: logging metrics and tracing ，上篇文章的Slides。  Performance benchmark  \u0026ldquo;How NOT to Measure Latency\u0026rdquo; by Gil Tene ，如何正确解读监控/压力测试结果  Metrics Prometheus 基本概念：\n How does a Prometheus Counter work? ，对于理解rate()函数至关重要 Counting with Prometheus [I] ，上篇博客的关联Presentation rate()/increase() extrapolation considered harmful 关于rate()函数extrapolation（外推）算法的讨论 How does a Prometheus Gauge work? ，gauge类型的分析 irate graphs are better graphs ，irate提供了更即时的结果 Avoid irate() in alerts  Rate then sum, never sum then rate ，rate在前sum在后 Why are Prometheus histograms cumulative? ，histogram类型的分析  几个使用技巧：\n Existential issues with metrics ，使用metrics-based monitoring system的的注意事项 Common query patterns in PromQL ，几个常见的PromQL语句 Composing range vector functions in PromQL ，如何实现诸如这样的查询：最近1小时内，rate(x[5m])的最高值  运维技巧：\n Scaling and Federating Prometheus  Dropping metrics at scrape time with Prometheus   Machine metrics  Understanding Machine CPU usage ，虽然是P8S的一篇博客，但是对于理解常见的几个CPU指标还是有用的  Tracing TODO\nLogging TODO\n","date":"2018-12-03","img":"","permalink":"/post/bookmarks/bookmarks-monitoring/","series":null,"tags":["收藏夹"],"title":"收藏夹 - 监控（持续更新）"},{"categories":null,"content":"Coding集成Jenkins流水账。\n本文有以下假设和要求：\n 你的项目源代码的根目录已经存在Jenkinsfile 你的项目是一个Maven项目 你的Jenkins能够从公网访问  本文参考自官方文档使用Jenkins构建Coding项目 【Jenkins】新建文件夹 【Jenkins】配置SSH key pair 运行下列命令生成SSH key pair，生成两个文件deploykey和deploykey.pub：\n1ssh-keygen -f deploykey 进入刚刚创建的文件夹，按下图添加SSH Username with private key凭据：\n把deploykey的内容贴到下面这个页面里：\n把deploykey.pub的内容贴到Coding项目的部署公钥里：\n【Jenkins】配置Maven settings.xml 根据创建Jenkins Pipeline流水账 - 配置Maven settings.xml 操作\n【Coding】创建个人访问令牌 把令牌复制下来，注意这个页面是你能够复制令牌的唯一一次机会，如果把这个页面关了，那只能重新创建令牌了：\n【Jenkins】新建流水线 到刚才创建的文件夹里创建流水线：\n做这么几件事情：\n 把Webhook地址复制下来 设置Webhook令牌，这个相当于密码，你自己随便输。 把之前创建的个人访问令牌贴到【访问令牌】输入框。 然后按照下图方式配置。  点击下图所示问号能看到以下帮助文档，注意我们是私有项目看红框内容：\n在Pipeline部分配置仓库：\n Credential使用之前创建的SSH key Name和Refspec是根据前面帮助文档里要求的填写的  在Branches to build里添加两项：\n refs/remotes/origin/* refs/remotes/origin/merge/*  其实这两个值是帮助文档里提到的而来，注意两个refspec里冒号后面的部分：\n 如果是私有项目, 设置 refspec 为 +refs/heads/*:refs/remotes/origin/* +refs/merge/*/MERGE:refs/remotes/origin/merge/*\n 添加两个Additional Behaviours：\n去掉Lightweight checkout的勾：\n在Pipeline Maven Configuration部分选择刚才创建的Maven settings.xml：\n【Coding】配置Webhook 到项目的 设置 -\u0026gt; WebHook 页面，添加Webhook：\n按下图配置：\n效果 至此大功告成。\n你可以通过提交commit的方式触发Jenkins构建，然后可以在项目的这个页面看到构建结果：\n你也可以创建合并请求，Coding会触发Jenkins构建并且把构建结果添加到合并请求里：\n","date":"2018-11-29","img":"","permalink":"/post/jenkins-coding-integration/","series":null,"tags":["CI_CD","Jenkins"],"title":"Coding集成Jenkins流水账"},{"categories":null,"content":"创建Jenkins pipeline流水账。\n注：本文的例子基于搭建Jenkins集群流水账 搭建的集群所写。\n注：本文是一个Maven项目流水线的例子。\n创建流水线 利用Blueocean创建流水线。\n填写GIT仓库信息。\n将Blueocean生成的SSH key添加到GIT server里。\n点击创建流水线后Jenkins会拉取GIT仓库，并且尝试寻找存在Jenkinsfile的分支，然后构建。不过不管构建是否成功，都不要管它，我们回到经典页面做进一步配置。\n配置Maven settings.xml 我们先配置一下私有Maven仓库的用户名密码。\n按照下图的顺序进入凭据管理页面\n添加凭据\n输入用户名密码\n有了用户名密码还不够，还得提供Maven的settings.xml。\n进入Config Files管理页面\n添加新的Config\n选择Global Maven settings.xml\n在Server Credentials新增，ServerId填写的是pom.xml里的 project \u0026gt; distributionManagement \u0026gt; repository \u0026gt; id 的值。Credential选择之前创建的凭据。\n如果你有多个repository那么就添加多个Server Credential。\n配置流水线 最后还要配置一下流水线，因为默认配置还有点问题。\n点击Configure进入配置页面。\n点击分支源Tab，点击Add property，添加“不通过SCM自动化触发”，它的意思是Branch indexing（扫描多分支流水线）不会触发构建。\n点击“扫描多分支流水线Triggers“Tab，启用Periodically if not otherwise run，Interval选择15分钟，这是为了让该流水线能够感知到分支的删除/新建。\n点击“Pipeline Maven Configuration“，配置Global Settings file，选择我们刚刚新建的Config file。\n点击“JIRA”，勾选“Enable project-based security“，如下图所示配置。\n保存。\n创建Jenkinsfile 在你的源代码的根目录里创建Jenkinsfile，参考Pipeline文档 。然后提交到GIT仓库。\n然后点击“扫描多分支流水线Now”。\n查看结果 点击打开Blue Ocean\n然后就能看到每个分支的构建情况了\n","date":"2018-11-28","img":"","permalink":"/post/jenkins-pipeline/","series":null,"tags":["CI_CD","Jenkins"],"title":"创建Jenkins Pipeline流水账"},{"categories":null,"content":"搭建Jenkins集群的流水账。\n硬件要求 不论是master还是slave，都要安装：\n 操作系统：Ubuntu 16.04 Server LTS Docker-CE  Docker安装方法：\n 根据文档：https://yq.aliyun.com/articles/110806 安装docker-ce curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun sudo usermod -aG docker $USER  我在安装的时候碰到Jenkins无法从Update center下载metadata的问题，经发现是docker的mtu比服务器网卡mtu大的问题，解决办法如下：\n 新建或者修改文件：/etc/docker/daemon.json，添加mtu的设置比如：  1{ 2 \u0026#34;mtu\u0026#34;: \u0026lt;服务器网卡的mtu\u0026gt;, 3 ... 4}  你可以配置docker registry mirror，同样修改/etc/docker/daemon.json：  1{ 2 \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;...\u0026#34;], 3 ... 4} 然后重启docker：sudo systemctl restart docker\n部署master 创建目录：mkdir $HOME/jenkins-home\n启动Jenkins：\n1sudo docker run \\ 2 -u root \\ 3 -d \\ 4 -p 8080:8080 \\ 5 -p 50000:50000 \\ 6 -v $HOME/jenkins-home:/var/jenkins_home \\ 7 -v /var/run/docker.sock:/var/run/docker.sock \\ 8 --name jenkins \\ 9 jenkinsci/blueocean 创建ssh密钥对：ssh-keygen\n初始配置Jenkins  浏览器访问Jenkins：http://\u0026lt;jenkins-master-ip\u0026gt;:8080/ 选择安装社区推荐插件 设置管理员用户  安全配置 配置LDAP 如果要配置LDAP，那么一定要记住，配置完之后不要注销。\n系统管理 -\u0026gt; 全局安全设置，访问控制，选择LDAP，然后根据情况配置即可。\n注意配置完之后一定要Test。\n配置授权策略 系统管理 -\u0026gt; 全局安全设置，授权策略，项目矩阵授权策略。\n打开浏览器隐私窗口，用一个账号登录，这个账号将替代当前使用的管理员账号。\n下面为了方便理解，下面吧当前浏览器称为A窗口，隐私窗口浏览器称为B窗口。\n回到A窗口，添加刚才登录的用户，如果正常添加，用户名上不会有删除线。然后在全部这一栏勾选Administer，点击应用。\n此时A窗口的管理员账号应该就不能做任何操作了，而且再也不能登录了。\n到B窗口，刷新一下，继续后面的管理员动作。\n下图是推荐的配置方法：\n添加Slave节点 前期准备\n 准备Slave的机器 安装Docker-CE 安装openjdk：sudo apt install -y openjdk-8-jdk 新建工作目录：mkdir $HOME/jenkins-workdir 把master的pub key添加到slave上：把master的$HOME/.ssh/id_rsa.pub内容添加到slave的$HOME/.ssh/authorized_keys里。  到 系统管理 \u0026gt; 节点管理，新建节点\n 名字：slave-1 并发构建数：2（cpu核数） 远程工作目录：\u0026lt;jenkins-workdir的绝对路径\u0026gt; 用法：尽可能的使用这个节点 启动方式：Launch agent agents via SSH Host：\u0026lt;slave的ip\u0026gt; Credentials：这个时候要创建一个平局，方法如下：  Domain，全局凭据 类型：SSH username with private key username: \u0026lt;slave的操作系统用户名\u0026gt; private key: 把master $HOME/.ssh/id_rsa 的内容贴上去 Passphrase: \u0026lt;blank\u0026gt; ID: \u0026lt;blank\u0026gt; 描述：For slave connection   Host Key Verification Strategy：Non verifying Verification Strategy 保存 修改master节点，执行者数量设置为0，这样就能避免Job分配到master上。  安装其他插件 系统管理 -\u0026gt; 插件管理，安装下列插件：\n Config File Provider Pipeline Maven Coding Plugin Rancher Plugin TestNG Results SonarQube Scanner  配置工具 系统管理 -\u0026gt; 全局工具配置，都选择自动安装，下面列出的是工具的名字\n JDK：JDK6、JDK7、JDK8，要输入oracle网站账号密码 Maven：Maven3 Docker：Docker  配置时区 用Docker启动Jenkins时区是GMT+0\n见wiki：https://wiki.jenkins.io/display/JENKINS/Change+time+zone\n系统管理 -\u0026gt; 脚本命令行\n1System.setProperty(\u0026#39;org.apache.commons.jelly.tags.fmt.timeZone\u0026#39;, \u0026#39;Asia/Shanghai\u0026#39;) 清理重装方法 如果你配置错误搞砸了，想从头开始，那么这么做，只需要这么几步：\n ssh到master上： sudo docker stop jenkins sudo rm -rf $HOME/jenkins-home/* ","date":"2018-11-23","img":"","permalink":"/post/jenkins-cluster/","series":null,"tags":["CI_CD","Jenkins"],"title":"搭建Jenkins集群流水账"},{"categories":null,"content":"设计  一些设计原则 SOLID   Event  Events As First-Class Citizens  Event Sourcing - Martin Fowler   GC  Visualizing Garbage Collection Algorithms ，现代垃圾收集算法，不局限于特定语言。阅读笔记在此 。  Concurrency  Java Memory Model FAQ 。比较浅显的介绍了什么是reording、synchroniztion、volatile、DCL以及它们的影响、作用以及要注意的地方。  缓存  Design Of A Modern Cache ，Caffeine 作者总结的现代进程内缓存的设计 Design Of A Modern Cache—Part Deux ，上篇文章的续篇 Apache Kafka, Purgatory, and Hierarchical Timing Wheels ，Kafka使用层级时间轮子来处理大量定时任务 Hierarchical Timing Wheels论文   AuthN  The New RBAC: Resource-Based Access Control 基于资源的访问控制系统设计思路。  CPU、内存级性能优化  False sharing - Wikipedia, the free encyclopedia  Psychosomatic, Lobotomy, Saw: Know Thy Java Object Memory Layout  Mechanical Sympathy: False Sharing \u0026amp;\u0026amp; Java 7  Mechanical Sympathy: False Sharing  Mechanical Sympathy: Smart Batching   算法  Cracking the coding interview\u0026ndash;问题与解答  Apache Kafka, Purgatory, and Hierarchical Timing Wheels ，Kafka使用层级时间轮子来处理大量定时任务 Hierarchical Timing Wheels论文  ","date":"2018-11-15","img":"","permalink":"/post/bookmarks/bookmarks-code-arch/","series":null,"tags":["收藏夹"],"title":"收藏夹 - 代码架构（持续更新）"},{"categories":null,"content":"在前一篇文章 中提到了如何使用Prometheus+Grafana来监控JVM。本文介绍如何使用Prometheus+Alertmanager来对JVM的某些情况作出告警。\n本文所提到的脚本可以在这里 下载。\n摘要 用到的工具：\n Docker，本文大量使用了Docker来启动各个应用。 Prometheus ，负责抓取/存储指标信息，并提供查询功能，本文重点使用它的告警功能。 Grafana ，负责数据可视化（本文重点不在于此，只是为了让读者能够直观地看到异常指标）。 Alertmanager ，负责将告警通知给相关人员。 JMX exporter ，提供JMX中和JVM相关的metrics。 Tomcat，用来模拟一个Java应用。  先讲一下大致步骤：\n 利用JMX exporter ，在Java进程内启动一个小型的Http server 配置Prometheus 抓取那个Http server提供的metrics。 配置Prometheus 的告警触发规则  heap使用超过最大上限的50%、80%、90% instance down机时间超过30秒、1分钟、5分钟 old gc时间在最近5分钟里超过50%、80%   配置Grafana 连接Prometheus ，配置Dashboard。 配置Alertmanager 的告警通知规则  告警的大致过程如下：\n Prometheus 根据告警触发规则查看是否触发告警，如果是，就将告警信息发送给Alertmanager 。 Alertmanager 收到告警信息后，决定是否发送通知，如果是，则决定发送给谁。  第一步：启动几个Java应用   新建一个目录，名字叫做prom-jvm-demo。\n  下载JMX exporter 到这个目录。\n  新建一个文件simple-config.yml内容如下：\n  1---2lowercaseOutputLabelNames:true3lowercaseOutputName:true4whitelistObjectNames:[\u0026#34;java.lang:type=OperatingSystem\u0026#34;]5rules:6- pattern:\u0026#39;java.lang\u0026lt;type=OperatingSystem\u0026gt;\u0026lt;\u0026gt;((?!process_cpu_time)\\w+):\u0026#39;7name:os_$18type:GAUGE9attrNameSnakeCase:true运行以下命令启动3个Tomcat，记得把\u0026lt;path-to-prom-jvm-demo\u0026gt;替换成正确的路径（这里故意把-Xmx和-Xms设置的很小，以触发告警条件）：  1docker run -d \\ 2 --name tomcat-1 \\ 3 -v \u0026lt;path-to-prom-jvm-demo\u0026gt;:/jmx-exporter \\ 4 -e CATALINA_OPTS=\u0026#34;-Xms32m -Xmx32m -javaagent:/jmx-exporter/jmx_prometheus_javaagent-0.3.1.jar=6060:/jmx-exporter/simple-config.yml\u0026#34; \\ 5 -p 6060:6060 \\ 6 -p 8080:8080 \\ 7 tomcat:8.5-alpine 8 9docker run -d \\ 10 --name tomcat-2 \\ 11 -v \u0026lt;path-to-prom-jvm-demo\u0026gt;:/jmx-exporter \\ 12 -e CATALINA_OPTS=\u0026#34;-Xms32m -Xmx32m -javaagent:/jmx-exporter/jmx_prometheus_javaagent-0.3.1.jar=6060:/jmx-exporter/simple-config.yml\u0026#34; \\ 13 -p 6061:6060 \\ 14 -p 8081:8080 \\ 15 tomcat:8.5-alpine 16 17docker run -d \\ 18 --name tomcat-3 \\ 19 -v \u0026lt;path-to-prom-jvm-demo\u0026gt;:/jmx-exporter \\ 20 -e CATALINA_OPTS=\u0026#34;-Xms32m -Xmx32m -javaagent:/jmx-exporter/jmx_prometheus_javaagent-0.3.1.jar=6060:/jmx-exporter/simple-config.yml\u0026#34; \\ 21 -p 6062:6060 \\ 22 -p 8082:8080 \\ 23 tomcat:8.5-alpine  访问http://localhost:8080|8081|8082看看Tomcat是否启动成功。\n  访问对应的http://localhost:6060|6061|6062看看JMX exporter提供的metrics。\n  备注：这里提供的simple-config.yml仅仅提供了JVM的信息，更复杂的配置请参考JMX exporter文档 。\n第二步：启动Prometheus  在之前新建目录prom-jvm-demo，新建一个文件prom-jmx.yml，内容如下：  1scrape_configs:2- job_name:\u0026#39;java\u0026#39;3scrape_interval:30s4static_configs:5- targets:6- \u0026#39;\u0026lt;host-ip\u0026gt;:6060\u0026#39;7- \u0026#39;\u0026lt;host-ip\u0026gt;:6061\u0026#39;8- \u0026#39;\u0026lt;host-ip\u0026gt;:6062\u0026#39;910# alertmanager的地址11alerting:12alertmanagers:13- static_configs:14- targets:15- \u0026#39;\u0026lt;host-ip\u0026gt;:9093\u0026#39;1617# 读取告警触发条件规则18rule_files:19- \u0026#39;/prometheus-config/prom-alert-rules.yml\u0026#39;新建文件prom-alert-rules.yml，该文件是告警触发规则：  1# severity按严重程度由高到低：red、orange、yello、blue2groups:3- name:jvm-alerting4rules:56# down了超过30秒7- alert:instance-down8expr:up == 09for:30s10labels:11severity:yellow12annotations:13summary:\u0026#34;Instance {{ $labels.instance }} down\u0026#34;14description:\u0026#34;{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 30 seconds.\u0026#34;1516# down了超过1分钟17- alert:instance-down18expr:up == 019for:1m20labels:21severity:orange22annotations:23summary:\u0026#34;Instance {{ $labels.instance }} down\u0026#34;24description:\u0026#34;{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 1 minutes.\u0026#34;2526# down了超过5分钟27- alert:instance-down28expr:up == 029for:5m30labels:31severity:red32annotations:33summary:\u0026#34;Instance {{ $labels.instance }} down\u0026#34;34description:\u0026#34;{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.\u0026#34;3536# 堆空间使用超过50%37- alert:heap-usage-too-much38expr:jvm_memory_bytes_used{job=\u0026#34;java\u0026#34;, area=\u0026#34;heap\u0026#34;} / jvm_memory_bytes_max * 100 \u0026gt; 5039for:1m40labels:41severity:yellow42annotations:43summary:\u0026#34;JVM Instance {{ $labels.instance }} memory usage \u0026gt; 50%\u0026#34;44description:\u0026#34;{{ $labels.instance }} of job {{ $labels.job }} has been in status [heap usage \u0026gt; 50%] for more than 1 minutes. current usage ({{ $value }}%)\u0026#34;4546# 堆空间使用超过80%47- alert:heap-usage-too-much48expr:jvm_memory_bytes_used{job=\u0026#34;java\u0026#34;, area=\u0026#34;heap\u0026#34;} / jvm_memory_bytes_max * 100 \u0026gt; 8049for:1m50labels:51severity:orange52annotations:53summary:\u0026#34;JVM Instance {{ $labels.instance }} memory usage \u0026gt; 80%\u0026#34;54description:\u0026#34;{{ $labels.instance }} of job {{ $labels.job }} has been in status [heap usage \u0026gt; 80%] for more than 1 minutes. current usage ({{ $value }}%)\u0026#34;5556# 堆空间使用超过90%57- alert:heap-usage-too-much58expr:jvm_memory_bytes_used{job=\u0026#34;java\u0026#34;, area=\u0026#34;heap\u0026#34;} / jvm_memory_bytes_max * 100 \u0026gt; 9059for:1m60labels:61severity:red62annotations:63summary:\u0026#34;JVM Instance {{ $labels.instance }} memory usage \u0026gt; 90%\u0026#34;64description:\u0026#34;{{ $labels.instance }} of job {{ $labels.job }} has been in status [heap usage \u0026gt; 90%] for more than 1 minutes. current usage ({{ $value }}%)\u0026#34;6566# 在5分钟里，Old GC花费时间超过30%67- alert:old-gc-time-too-much68expr:increase(jvm_gc_collection_seconds_sum{gc=\u0026#34;PS MarkSweep\u0026#34;}[5m]) \u0026gt; 5 * 60 * 0.369for:5m70labels:71severity:yellow72annotations:73summary:\u0026#34;JVM Instance {{ $labels.instance }} Old GC time \u0026gt; 30% running time\u0026#34;74description:\u0026#34;{{ $labels.instance }} of job {{ $labels.job }} has been in status [Old GC time \u0026gt; 30% running time] for more than 5 minutes. current seconds ({{ $value }}%)\u0026#34;7576# 在5分钟里，Old GC花费时间超过50% 77- alert:old-gc-time-too-much78expr:increase(jvm_gc_collection_seconds_sum{gc=\u0026#34;PS MarkSweep\u0026#34;}[5m]) \u0026gt; 5 * 60 * 0.579for:5m80labels:81severity:orange82annotations:83summary:\u0026#34;JVM Instance {{ $labels.instance }} Old GC time \u0026gt; 50% running time\u0026#34;84description:\u0026#34;{{ $labels.instance }} of job {{ $labels.job }} has been in status [Old GC time \u0026gt; 50% running time] for more than 5 minutes. current seconds ({{ $value }}%)\u0026#34;8586# 在5分钟里，Old GC花费时间超过80%87- alert:old-gc-time-too-much88expr:increase(jvm_gc_collection_seconds_sum{gc=\u0026#34;PS MarkSweep\u0026#34;}[5m]) \u0026gt; 5 * 60 * 0.889for:5m90labels:91severity:red92annotations:93summary:\u0026#34;JVM Instance {{ $labels.instance }} Old GC time \u0026gt; 80% running time\u0026#34;94description:\u0026#34;{{ $labels.instance }} of job {{ $labels.job }} has been in status [Old GC time \u0026gt; 80% running time] for more than 5 minutes. current seconds ({{ $value }}%)\u0026#34;启动Prometheus：  1docker run -d \\ 2 --name=prometheus \\ 3 -p 9090:9090 \\ 4 -v \u0026lt;path-to-prom-jvm-demo\u0026gt;:/prometheus-config \\ 5 prom/prometheus --config.file=/prometheus-config/prom-jmx.yml 访问http://localhost:9090/alerts 应该能看到之前配置的告警规则：  如果没有看到三个instance，那么等一会儿再试。\n第三步：配置Grafana 参考使用Prometheus+Grafana监控JVM 第四步：启动Alertmanager  新建一个文件alertmanager-config.yml：  1global:2smtp_smarthost:\u0026#39;\u0026lt;smtp.host:ip\u0026gt;\u0026#39;3smtp_from:\u0026#39;\u0026lt;from\u0026gt;\u0026#39;4smtp_auth_username:\u0026#39;\u0026lt;username\u0026gt;\u0026#39;5smtp_auth_password:\u0026#39;\u0026lt;password\u0026gt;\u0026#39;67# The directory from which notification templates are read.8templates:9- \u0026#39;/alertmanager-config/*.tmpl\u0026#39;1011# The root route on which each incoming alert enters.12route:13# The labels by which incoming alerts are grouped together. For example,14# multiple alerts coming in for cluster=A and alertname=LatencyHigh would15# be batched into a single group.16group_by:[\u0026#39;alertname\u0026#39;,\u0026#39;instance\u0026#39;]1718# When a new group of alerts is created by an incoming alert, wait at19# least \u0026#39;group_wait\u0026#39; to send the initial notification.20# This way ensures that you get multiple alerts for the same group that start21# firing shortly after another are batched together on the first 22# notification.23group_wait:30s2425# When the first notification was sent, wait \u0026#39;group_interval\u0026#39; to send a batch26# of new alerts that started firing for that group.27group_interval:5m2829# If an alert has successfully been sent, wait \u0026#39;repeat_interval\u0026#39; to30# resend them.31repeat_interval:3h 3233# A default receiver34receiver:\u0026#34;user-a\u0026#34;3536# Inhibition rules allow to mute a set of alerts given that another alert is37# firing.38# We use this to mute any warning-level notifications if the same alert is 39# already critical.40inhibit_rules:41- source_match:42severity:\u0026#39;red\u0026#39;43target_match_re:44severity:^(blue|yellow|orange)$45# Apply inhibition if the alertname and instance is the same.46equal:[\u0026#39;alertname\u0026#39;,\u0026#39;instance\u0026#39;]47- source_match:48severity:\u0026#39;orange\u0026#39;49target_match_re:50severity:^(blue|yellow)$51# Apply inhibition if the alertname and instance is the same.52equal:[\u0026#39;alertname\u0026#39;,\u0026#39;instance\u0026#39;]53- source_match:54severity:\u0026#39;yellow\u0026#39;55target_match_re:56severity:^(blue)$57# Apply inhibition if the alertname and instance is the same.58equal:[\u0026#39;alertname\u0026#39;,\u0026#39;instance\u0026#39;]5960receivers:61- name:\u0026#39;user-a\u0026#39;62email_configs:63- to:\u0026#39;\u0026lt;user-a@domain.com\u0026gt;\u0026#39;修改里面关于smtp_*的部分和最下面user-a的邮箱地址。\n备注：因为国内邮箱几乎都不支持TLS，而Alertmanager目前又不支持SSL，因此请使用Gmail或其他支持TLS的邮箱来发送告警邮件，见这个issue ，这个问题已经修复，下面是阿里云企业邮箱的配置例子：\n1smtp_smarthost:\u0026#39;smtp.qiye.aliyun.com:465\u0026#39;2smtp_hello:\u0026#39;company.com\u0026#39;3smtp_from:\u0026#39;username@company.com\u0026#39;4smtp_auth_username:\u0026#39;username@company.com\u0026#39;5smtp_auth_password:password6smtp_require_tls:false新建文件alert-template.tmpl，这个是邮件内容模板：  1{{ define \u0026#34;email.default.html\u0026#34; }} 2\u0026lt;h2\u0026gt;Summary\u0026lt;/h2\u0026gt; 3 4\u0026lt;p\u0026gt;{{ .CommonAnnotations.summary }}\u0026lt;/p\u0026gt; 5 6\u0026lt;h2\u0026gt;Description\u0026lt;/h2\u0026gt; 7 8\u0026lt;p\u0026gt;{{ .CommonAnnotations.description }}\u0026lt;/p\u0026gt; 9{{ end}} 3） 运行下列命令启动：\n1docker run -d \\ 2 --name=alertmanager \\ 3 -v \u0026lt;path-to-prom-jvm-demo\u0026gt;:/alertmanager-config \\ 4 -p 9093:9093 \\ 5 prom/alertmanager:master --config.file=/alertmanager-config/alertmanager-config.yml 访问http://localhost:9093 ，看看有没有收到Prometheus发送过来的告警(如果没有看到稍等一下)：  第五步：等待邮件 等待一会儿（最多5分钟）看看是否收到邮件。如果没有收到，检查配置是否正确，或者docker logs alertmanager看看alertmanager的日志，一般来说都是邮箱配置错误导致。\n","date":"2018-10-26","img":"","permalink":"/post/prom-alert-jvm/","series":null,"tags":["java","jmx","prometheus","alertmanager","运维"],"title":"使用Prometheus+Alertmanager告警JVM异常情况"},{"categories":null,"content":"本文介绍如何使用Prometheus+Grafana监控JVM的方法。\n本文所提到的脚本可以在这里 下载。\n摘要 用到的工具：\n Docker，本文大量使用了Docker来启动各个应用。 Prometheus ，负责抓取/存储指标信息，并提供查询功能。 Grafana ，负责数据可视化。 JMX exporter ，提供JMX中和JVM相关的metrics。 Tomcat，用来模拟一个Java应用。  先讲一下大致步骤：\n 利用JMX exporter ，在Java进程内启动一个小型的Http server 配置Prometheus 抓取那个Http server提供的metrics。 配置Grafana 连接Prometheus ，配置Dashboard。  第一步：启动几个Java应用   新建一个目录，名字叫做prom-jvm-demo。\n  下载JMX exporter 到这个目录。\n  新建一个文件simple-config.yml内容如下：\n  1---2lowercaseOutputLabelNames:true3lowercaseOutputName:true4whitelistObjectNames:[\u0026#34;java.lang:type=OperatingSystem\u0026#34;]5rules:6- pattern:\u0026#39;java.lang\u0026lt;type=OperatingSystem\u0026gt;\u0026lt;\u0026gt;((?!process_cpu_time)\\w+):\u0026#39;7name:os_$18type:GAUGE9attrNameSnakeCase:true运行以下命令启动3个Tomcat，记得把\u0026lt;path-to-prom-jvm-demo\u0026gt;替换成正确的路径：  1docker run -d \\ 2 --name tomcat-1 \\ 3 -v \u0026lt;path-to-prom-jvm-demo\u0026gt;:/jmx-exporter \\ 4 -e CATALINA_OPTS=\u0026#34;-Xms64m -Xmx128m -javaagent:/jmx-exporter/jmx_prometheus_javaagent-0.3.1.jar=6060:/jmx-exporter/simple-config.yml\u0026#34; \\ 5 -p 6060:6060 \\ 6 -p 8080:8080 \\ 7 tomcat:8.5-alpine 8 9docker run -d \\ 10 --name tomcat-2 \\ 11 -v \u0026lt;path-to-prom-jvm-demo\u0026gt;:/jmx-exporter \\ 12 -e CATALINA_OPTS=\u0026#34;-Xms64m -Xmx128m -javaagent:/jmx-exporter/jmx_prometheus_javaagent-0.3.1.jar=6060:/jmx-exporter/simple-config.yml\u0026#34; \\ 13 -p 6061:6060 \\ 14 -p 8081:8080 \\ 15 tomcat:8.5-alpine 16 17docker run -d \\ 18 --name tomcat-3 \\ 19 -v \u0026lt;path-to-prom-jvm-demo\u0026gt;:/jmx-exporter \\ 20 -e CATALINA_OPTS=\u0026#34;-Xms64m -Xmx128m -javaagent:/jmx-exporter/jmx_prometheus_javaagent-0.3.1.jar=6060:/jmx-exporter/simple-config.yml\u0026#34; \\ 21 -p 6062:6060 \\ 22 -p 8082:8080 \\ 23 tomcat:8.5-alpine  访问http://localhost:8080|8081|8082看看Tomcat是否启动成功。\n  访问对应的http://localhost:6060|6061|6062看看JMX exporter提供的metrics。\n  备注：这里提供的simple-config.yml仅仅提供了JVM的信息，更复杂的配置请参考JMX exporter文档 。\n第二步：启动Prometheus  在之前新建目录prom-jvm-demo，新建一个文件prom-jmx.yml，内容如下：  1scrape_configs:2- job_name:\u0026#39;java\u0026#39;3scrape_interval:30s4static_configs:5- targets:6- \u0026#39;\u0026lt;host-ip\u0026gt;:6060\u0026#39;7- \u0026#39;\u0026lt;host-ip\u0026gt;:6061\u0026#39;8- \u0026#39;\u0026lt;host-ip\u0026gt;:6062\u0026#39;启动Prometheus：  1docker run -d \\ 2 --name=prometheus \\ 3 -p 9090:9090 \\ 4 -v \u0026lt;path-to-prom-jvm-demo\u0026gt;:/prometheus-config \\ 5 prom/prometheus --config.file=/prometheus-config/prom-jmx.yml 访问http://localhost:9090 看看Prometheus是否启动成功，在输入框里输入jvm_info然后执行，应该可以看到如下图的结果：  如果没有看到三个instance，那么等一会儿再试。\n第三步：配置Grafana  启动Grafana：  1docker run -d --name=grafana -p 3000:3000 grafana/grafana  访问http://localhost:3000 ，使用admin/admin登录。\n  添加Prometheus数据源，如下图所示到添加数据源页面：\n  配置数据源信息：   Name：随便取 Type：Prometheus URL：http://\u0026lt;host-ip\u0026gt;:9090 其余不要设置，点击Save \u0026amp; Test，应该会返回成功结果  导入Dashboard。我们不需要重头自己做Dashboard，用现成的就行，按下图所示进入导入页面  使用我制作的JVM Dashboard ，页面右侧出现的ID号是8563，记住这个号，填在如下图所示的位置：  然后鼠标点击别处稍等一下，出现下图，选择一下数据源就可以了  最后打开刚刚导入的Dashboard，如下图：  ","date":"2018-10-24","img":"","permalink":"/post/prom-grafana-jvm/","series":null,"tags":["java","jmx","prometheus","grafana","运维"],"title":"使用Prometheus+Grafana监控JVM"},{"categories":null,"content":"本文介绍几种在K8S中限制资源使用的几种方法。\n资源类型 在K8S中可以对两类资源进行限制：cpu和内存。\nCPU的单位有：\n 正实数，代表分配几颗CPU，可以是小数点，比如0.5代表0.5颗CPU，意思是一颗CPU的一半时间。2代表两颗CPU。 正整数m，也代表1000m=1，所以500m等价于0.5。  内存的单位：\n 正整数，直接的数字代表Byte k、K、Ki，Kilobyte m、M、Mi，Megabyte g、G、Gi，Gigabyte t、T、Ti，Terabyte p、P、Pi，Petabyte  方法一：在Pod Container Spec中设定资源限制 在K8S中，对于资源的设定是落在Pod里的Container上的，主要有两类，limits控制上限，requests控制下限。其位置在：\n spec.containers[].resources.limits.cpu spec.containers[].resources.limits.memory spec.containers[].resources.requests.cpu spec.containers[].resources.requests.memory  举例：\n1apiVersion:v12kind:Pod3metadata:4name:frontend5spec:6containers:7- name:...8image:...9resources:10requests:11memory:\u0026#34;64Mi\u0026#34;12cpu:\u0026#34;250m\u0026#34;13limits:14memory:\u0026#34;128Mi\u0026#34;15cpu:\u0026#34;500m\u0026#34;方法二：在Namespace中限定 方法一虽然很好，但是其不是强制性的，因此很容易出现因忘记设定limits/request，导致Host资源使用过度的情形，因此我们需要一种全局性的资源限制设定，以防止这种情况发生。K8S通过在Namespace设定LimitRange来达成这一目的。\n配置默认request/limit： 如果配置里默认的request/limit，那么当Pod Spec没有设定request/limit的时候，会使用这个配置，有效避免无限使用资源的情况。\n配置位置在：\n spec.limits[].default.cpu，default limit spec.limits[].default.memory，同上 spec.limits[].defaultRequest.cpu，default request spec.limits[].defaultRequest.memory，同上  例子：\n1apiVersion:v12kind:LimitRange3metadata:4name:\u0026lt;name\u0026gt;5spec:6limits:7- default:8memory:512Mi9cpu:110defaultRequest:11memory:256Mi12cpu:0.513type:Container配置request/limit的约束 我们还可以在K8S里对request/limit进行以下限定：\n 某资源的request必须\u0026gt;=某值 某资源的limit必须\u0026lt;=某值  这样的话就能有效避免Pod Spec中乱设limit导致资源耗尽的情况，或者乱设request导致Pod无法得到足够资源的情况。\n配置位置在：\n spec.limits[].max.cpu，limit必须\u0026lt;=某值 spec.limits[].max.memory，同上 spec.limits[].min.cpu，request必须\u0026gt;=某值 spec.limits[].min.memory，同上  例子：\n1apiVersion:v12kind:LimitRange3metadata:4name:\u0026lt;name\u0026gt;5spec:6limits:7- max:8memory:1Gi9cpu:800m10min:11memory:500Mi12cpu:200m13type:Container参考资料  Managing Compute Resources for Containers  Configure Default Memory Requests and Limits for a Namespace  Configure Default CPU Requests and Limits for a Namespace  Configure Minimum and Maximum Memory Constraints for a Namespace  Configure Minimum and Maximum CPU Constraints for a Namespace  ","date":"2018-10-22","img":"","permalink":"/post/k8s/k8s-how-to-limit-resource/","series":null,"tags":["k8s"],"title":"K8S如何限制资源使用"},{"categories":null,"content":"本文介绍如何安全地关闭Node。\n虽然我们可以直接将Node关机，让K8S自己将这个Node上的Pod在别的Node上重新创建，但是这样可能会对K8S集群造成冲击。\n我们设想中的顺序应该是这样的：\n 禁止有新的Pod安排到Node上 把Node上的Pod迁移到别处 把Node关掉  我们可以利用kubectl drain 来做到前面的两点，大致方式如下：\n kubectl get nodes找到Node kubectl drain \u0026lt;node-name\u0026gt; 然后关机就行了  当这个Node后来又启动了，那么只需要kubectl uncordon \u0026lt;node name\u0026gt;。\n","date":"2018-10-22","img":"","permalink":"/post/k8s/k8s-how-to-shutdown-node-safely/","series":null,"tags":["k8s"],"title":"K8s如何安全地关闭Node"},{"categories":null,"content":"本文介绍重启K8S Deployment的小技巧\n有时候我们会需要重启Deployment，原因可能是：\n docker image使用的是latest tag，这个latest在docker image registry已经更新了，我们需要重启deployment来使用新的latest Pod运行缓慢但是还活着，我们就是想重启一下 ConfigMap/Secret变更了，想重启一下应用新配置  上面两种情况的共同之处在于，Deployment spec没有发生任何变化，因此即使你kubectl appply -f deployment-spec.yaml也是没用的，因为K8S会认为你这个没有变化就什么都不做了。\n但是我们又不想使用手工删除Pod-让K8S新建Pod的方式来重启Deployment，最好的办法应该是像Updating a deployment 一样，让K8S自己滚动的删除-新建Pod。\n有人对此给了一个workaround ：\n1kubectl patch deployment \u0026lt;deployment-name\u0026gt; \\ 2 -p \u0026#39;{\u0026#34;spec\u0026#34;:{\u0026#34;template\u0026#34;:{\u0026#34;spec\u0026#34;:{\u0026#34;containers\u0026#34;:[{\u0026#34;name\u0026#34;:\u0026#34;\u0026lt;container-name\u0026gt;\u0026#34;,\u0026#34;env\u0026#34;:[{\u0026#34;name\u0026#34;:\u0026#34;RESTART_\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;\u0026#39;$(date +%s)\u0026#39;\u0026#34;}]}]}}}}\u0026#39; 基本思路就是给Container添加一个无关紧要的环境变量，这个环境变量的值就是时间戳，而这个时间戳则是每次执行上述命令的系统当前时间。这样一来对于K8S来讲这个Deployment spec就变化了，就可以像Updating a deployment 一样，重启Pod了。\n","date":"2018-10-22","img":"","permalink":"/post/k8s/k8s-restart-deployment/","series":null,"tags":["k8s"],"title":"K8S重启Deployment的小技巧"},{"categories":null,"content":"使用diskbenchmark 测试硬盘性能。\n本文使用的是Ubuntu服务器\n无法在虚拟机上运行此工具\n第1步：下载项目\n1git clone https://github.com/ongardie/diskbenchmark.git 第2步：安装必要的软件包\n1sudo apt install -y gcc r-base-core r-cran-ggplot2 r-cran-plyr r-cran-scales 第3步：编译项目\n1make bench 第4步：benchmark配置文件\n在machines目录下新建配置文件，比如machine-a：\n1disks=\u0026#34;\u0026lt;硬盘名称\u0026gt;:\u0026lt;硬盘在/dev下的名称\u0026gt;:\u0026lt;测试文件写的目录\u0026gt;\u0026#34; 2rootcmd () { 3 sudo $* 4} 5cmd () { 6 $* 7} 8sendfile () { 9 cp $1 ~/ 10} 比如下面这样：\n1disks=\u0026#34;mydisk:sda2:/tmp\u0026#34; 2rootcmd () { 3 sudo $* 4} 5cmd () { 6 $* 7} 8sendfile () { 9 cp $1 ~/ 10} \u0026lt;硬盘在/dev下的名称\u0026gt;可以通过sudo fdisk -l得到。\n第5步：执行\n1./runner.sh 第6步：制作图表\n压测需要很长时间，我所测试的硬盘配置如下的情况下，跑了大约2小时：\n 6 * 1.2TB 10K RPM SAS 12Gbps 512n 2.5英寸热插拔硬盘 PERC H730P+ RAID 控制器, 2Gb NV 缓存 RAID 5 开启回写，预读  完成后会得到results.csv文件。\n使用如下命令制作图表，获得results.svg文件：\n1R -e \u0026#34;source(\u0026#39;post.R\u0026#39;); ggsave(\u0026#39;results.svg\u0026#39;, g, width=10, height=7)\u0026#34; 用浏览器打开：\n","date":"2018-10-19","img":"","permalink":"/post/intro-diskbenchmark/","series":null,"tags":["运维"],"title":"使用Diskbenchmark测试硬盘性能"},{"categories":null,"content":"在利用VisualVm和JMX远程监控Java进程 和VisualVm利用SSL连接JMX的方法 里介绍了如何使用VisualVm+JMX监控远程Java进程的方法。那么如何监控一个运行在K8S集群中的Java进程呢？其实大致方法也是类似的。\n非SSL JMX连接 如果采用非SSL JMX连接，那么你只需要这么几步就可以让你本地的VisualVm连接到K8S集群里的Java进程了。\nStep1 修改Deployment.yaml，添加以下System Properties\n1-Dcom.sun.management.jmxremote 2-Dcom.sun.management.jmxremote.authenticate=false 3-Dcom.sun.management.jmxremote.ssl=false 4-Dcom.sun.management.jmxremote.port=1100 5-Dcom.sun.management.jmxremote.rmi.port=1100 6-Djava.rmi.server.hostname=localhost 注意，-Djava.rmi.server.hostname一定要设置成localhost\nStep2 修改Deployment.yaml，添加Container Port\n1containers:2- name:...3image:...4ports:5- containerPort:11006name:tcp-jmxStep3 部署Deployment\nStep4 利用kubectl转发端口\n1kubectl -n \u0026lt;namespace\u0026gt; port-forward \u0026lt;pod-name\u0026gt; 1100 Step5 启动VisualVm，创建JMX连接localhost:1100\nSSL JMX连接 启用SSL JMX连接，那么需要增加三个步骤，步骤就稍微复杂一些，假设你已经根据VisualVm利用SSL连接JMX的方法 创建好了java-app和visualvm的keystore和truststore。\nStep1 创建一个Secret包含java-app.keystore和java-app.truststore\n1kubectl -n \u0026lt;namespace\u0026gt; create secret generic jmx-ssl \\ 2 --from-file=java-app.keystore \\ 3 --from-file=java-app.truststore Step2 修改Deployment.yaml，把Secret挂载到容器内的/jmx-ssl目录下\n12containers:3- name:...4image:...5volumeMounts:6- name:jmx-ssl-vol7mountPath:/jmx-ssl8volumes:9- name:jmx-ssl-vol10secret:11secretName:jmx-sslStep3 修改Deployment.yaml，添加以下System Properties\n1-Dcom.sun.management.jmxremote 2-Dcom.sun.management.jmxremote.port=1100 3-Dcom.sun.management.jmxremote.rmi.port=1100 4-Dcom.sun.management.jmxremote.authenticate=false 5-Dcom.sun.management.jmxremote.ssl=true 6-Dcom.sun.management.jmxremote.registry.ssl=true 7-Dcom.sun.management.jmxremote.ssl.need.client.auth=true 8-Djavax.net.ssl.keyStore=/jmx-ssl/java-app.keystore 9-Djavax.net.ssl.keyStorePassword=\u0026lt;keystore password\u0026gt; 10-Djavax.net.ssl.trustStore=/jmx-ssl/java-app.truststore 11-Djavax.net.ssl.trustStorePassword=\u0026lt;truststore password\u0026gt; 12-Djava.rmi.server.hostname=localhost 注意，-Djava.rmi.server.hostname一定要设置成localhost\nStep4 修改Deployment.yaml，添加Container Port\n1containers:2- name:...3image:...4ports:5- containerPort:11006name:tcp-jmx7...Step5 部署Deployment\nStep6 利用kubectl转发端口\n1kubectl -n \u0026lt;namespace\u0026gt; port-forward \u0026lt;pod-name\u0026gt; 1100 Step7 启动VisualVm，创建JMX连接localhost:1100\n1jvisualvm -J-Djavax.net.ssl.keyStore=\u0026lt;path to visualvm.keystore\u0026gt; \\ 2 -J-Djavax.net.ssl.keyStorePassword=\u0026lt;visualvm.keystore的密码\u0026gt; \\ 3 -J-Djavax.net.ssl.trustStore=\u0026lt;path to visualvm.truststore\u0026gt; \\ 4 -J-Djavax.net.ssl.trustStorePassword=\u0026lt;visualvm.truststore的密码\u0026gt; K8S样例配置文件 相关K8S样例配置文件在这里 （用tomcat做的例子）。\n参考文档  Why Java opens 3 ports when JMX is configured?  How can I connect to JMX through Kubernetes managed Docker containers?  ","date":"2018-10-15","img":"","permalink":"/post/visualvm-remote-monitoring-jmx-k8s/","series":null,"tags":["java","visualvm","jmx","k8s"],"title":"利用VisualVm和JMX远程监控K8S里的Java进程"},{"categories":null,"content":"在前一篇文章 里提到在生产环境下应该使用SSL来创建JMX连接，本文就来讲一下具体怎么做。\n前导知识 先了解一下Java客户端程序在创建SSL连接的一些相关的事情：\n Java client程序在做SSL连接的时候，会拉取server的证书，利用truststore去验证这个证书，如果不存在 or 证书过期 or 不是由可信CA签发，就意味着服务端不被信任，就不能连接。 如果在程序启动时没有特别指定使用哪个truststore（通过System Property javax.net.ssl.trustStore 指定），那么就会使用$JAVA_HOME/jre/lib/security/cacerts。如果指定了，就会使用指定的truststore + cacerts来验证。 cacerts存放了JDK信任的CA证书（含有public key），它里面预先已经存放了已知的权威CA证书。你可以通过keytool -list -keystore $JAVA_HOME/jre/lib/security/cacerts看到（让你输密码的时候直接回车就行了）  以上过程被称为server authentication，也就是说client验证server是否可信，server authentication是最常见的，https就是这种模式。\n不过在用SSL连接JMX的时候，还要做client authentication，即server验证client是否可信。原理和上面提到的一样，只不过变成server用自己的truststore里验证client的证书是否可信。\n第一步：制作keystore和truststore 上面提到的证书主要保存了一个public key，SSL是一个非对称加密协议，因此还有一个对应的private key，在java里private key和private key存放在keystore里。\n下面我们来制作visualvm（client）和java app（server）的keystore和truststore。\n先讲大致流程，然后再给出命令：\n 生成visualvm的keystore，导出cert，把cert导入到java-app的truststore里 生成java-app的keystore，导出cert，把cert导入到visualvm的truststore里  具体命令：\n  生成visualvm的keystore\n1 keytool -genkeypair \\ 2 -alias visualvm \\ 3 -keyalg RSA \\ 4 -validity 365 \\ 5 -storetype pkcs12 \\ 6 -keystore visualvm.keystore \\ 7 -storepass \u0026lt;visualvm keystore的密码\u0026gt; \\ 8 -keypass \u0026lt;同visualvm keystore的密码\u0026gt; \\ 9 -dname \u0026#34;CN=\u0026lt;姓名\u0026gt;, OU=\u0026lt;组织下属单位\u0026gt;, O=\u0026lt;组织名称\u0026gt;, L=\u0026lt;城市\u0026gt;, S=\u0026lt;省份\u0026gt;, C=\u0026lt;国家2字母\u0026gt;\u0026#34;   导出visualvm的cert\n1keytool -exportcert \\ 2 -alias visualvm \\ 3 -storetype pkcs12 \\ 4 -keystore visualvm.keystore \\ 5 -file visualvm.cer \\ 6 -storepass \u0026lt;visualvm keystore的密码\u0026gt;   把visualvm的cert导入到java-app的truststore里，实际上就是生成了一个truststore\n1keytool -importcert \\ 2 -alias visualvm \\ 3 -file visualvm.cer \\ 4 -keystore java-app.truststore \\ 5 -storepass \u0026lt;java-app truststore的密码\u0026gt; \\ 6 -noprompt   生成java-app的keystore\n1 keytool -genkeypair \\ 2 -alias java-app \\ 3 -keyalg RSA \\ 4 -validity 365 \\ 5 -storetype pkcs12 \\ 6 -keystore java-app.keystore \\ 7 -storepass \u0026lt;java-app keystore的密码\u0026gt; \\ 8 -keypass \u0026lt;同java-app keystore的密码\u0026gt; \\ 9 -dname \u0026#34;CN=\u0026lt;姓名\u0026gt;, OU=\u0026lt;组织下属单位\u0026gt;, O=\u0026lt;组织名称\u0026gt;, L=\u0026lt;城市\u0026gt;, S=\u0026lt;省份\u0026gt;, C=\u0026lt;国家2字母\u0026gt;\u0026#34;   导出java-app的cert\n1keytool -exportcert \\ 2 -alias java-app \\ 3 -storetype pkcs12 \\ 4 -keystore java-app.keystore \\ 5 -file java-app.cer \\ 6 -storepass \u0026lt;java-app keystore的密码\u0026gt;   把java-app的cert导入到visualvm的truststore里\n1keytool -importcert 2 -alias java-app \\ 3 -file java-app.cer \\ 4 -keystore visualvm.truststore \\ 5 -storepass \u0026lt;visualvm truststore的密码\u0026gt; \\ 6 -noprompt   所以最终得到的文件是这么几个：\n visualvm.keystore，包含visualvm的public key和private key visualvm.truststore，包含java-app cert java-app.keystore，包含java-app的public key和private key java-app.truststore，包含visualvm cert  第二步：启动Tomcat 我们还是用Tomcat做实验，给CATALINA_OPTS添加几个参数像下面这样，因为参数比较多，所以我们在$TOMCAT/bin下添加一个setenv.sh的文件（记得加上可执行权限）：\n1CATALINA_OPTS=\u0026#34;-Dcom.sun.management.jmxremote\u0026#34; 2CATALINA_OPTS=\u0026#34;$CATALINA_OPTS-Dcom.sun.management.jmxremote.port=1100\u0026#34; 3CATALINA_OPTS=\u0026#34;$CATALINA_OPTS-Dcom.sun.management.jmxremote.rmi.port=1100\u0026#34; 4CATALINA_OPTS=\u0026#34;$CATALINA_OPTS-Djava.rmi.server.hostname=\u0026lt;host or ip\u0026gt;\u0026#34; 5CATALINA_OPTS=\u0026#34;$CATALINA_OPTS-Dcom.sun.management.jmxremote.authenticate=false\u0026#34; 6# 以下和启用SSL有关 7CATALINA_OPTS=\u0026#34;$CATALINA_OPTS-Dcom.sun.management.jmxremote.ssl=true\u0026#34; 8CATALINA_OPTS=\u0026#34;$CATALINA_OPTS-Dcom.sun.management.jmxremote.registry.ssl=true\u0026#34; 9CATALINA_OPTS=\u0026#34;$CATALINA_OPTS-Dcom.sun.management.jmxremote.ssl.need.client.auth=true\u0026#34; 10CATALINA_OPTS=\u0026#34;$CATALINA_OPTS-Djavax.net.ssl.keyStore=\u0026lt;path to java-app.keystore\u0026gt;\u0026#34; 11CATALINA_OPTS=\u0026#34;$CATALINA_OPTS-Djavax.net.ssl.keyStorePassword=\u0026lt;java-app.keystore的密码\u0026gt;\u0026#34; 12CATALINA_OPTS=\u0026#34;$CATALINA_OPTS-Djavax.net.ssl.trustStore=\u0026lt;path to java-app.truststore\u0026gt;\u0026#34; 13CATALINA_OPTS=\u0026#34;$CATALINA_OPTS-Djavax.net.ssl.trustStorePassword=\u0026lt;java-app.truststore的密码\u0026gt;\u0026#34; 然后$TOMCAT/bin/startup.sh\n第三步：启动visualvm 1jvisualvm -J-Djavax.net.ssl.keyStore=\u0026lt;path to visualvm.keystore\u0026gt; \\ 2 -J-Djavax.net.ssl.keyStorePassword=\u0026lt;visualvm.keystore的密码\u0026gt; \\ 3 -J-Djavax.net.ssl.trustStore=\u0026lt;path to visualvm.truststore\u0026gt; \\ 4 -J-Djavax.net.ssl.trustStorePassword=\u0026lt;visualvm.truststore的密码\u0026gt; 你可以不加参数启动jvisualvm，看看下一步创建JMX连接是否成功，如果配置正确应该是不会成功的。\n第四步：创建JMX连接 加了上述参数启动jvisualvm后，和利用VisualVm和JMX远程监控Java进程 里提到的步骤一样创建JMX连接，只不过在创建JMX连接的时候不要勾选【不要求SSL连接】（不过经实测，勾不勾选都能连接成功的）。\n参考资料  Monitoring and Management Using JMX Technology - Using SSL  Customizing the Default Keystores and Truststores, Store Types, and Store Passwords  Customizing JSSE ，这个表格列出了一些SSL相关的System Properties Creating a Keystore to Use with JSSE  keytool  Monitor Java with JMX  Java Secure Socket Extension (JSSE) Reference Guide ，这是Java对于SSL支持的最全的参考文档 ","date":"2018-10-10","img":"","permalink":"/post/visualvm-remote-monitoring-jmx-ssl/","series":null,"tags":["java","visualvm","jmx","ssl"],"title":"VisualVm利用SSL连接JMX的方法"},{"categories":null,"content":"在前一篇文章 里我们发现通过jstatd + VisualVm的方式，不能获得Java进程的CPU、线程、MBean信息，这时JMX就要登场了。\n自Java 6开始，Java程序启动时都会在JVM内部启动一个JMX agent，JMX agent会启动一个MBean server组件，把MBeans（Java平台标准的MBean + 你自己创建的MBean）注册到它里面，然后暴露给JMX client管理。简单来说就是每个Java程序都可以通过JMX来被JMX client管理，而且这一切都是自动发生的。而VisualVm就是一个JMX Client。\nVisualVm能够自动发现本机的Java进程，如果要监控远程主机上的Java进程则需要显式地配置JMX连接，下面讲配置方法：\n第一步：与启动相关的System Properties 要给远程主机上的监控的Java进程在启动时必须带上几个JMX相关的System Properties（常用的几个）：\n com.sun.management.jmxremote.port, 指定暴露的JMX端口。 com.sun.management.jmxremote.rmi.port, 指定RMI connector端口，可以和com.sun.management.jmxremote.port保持一致。 com.sun.management.jmxremote.ssl, 指定是否使用SSL，在开发环境下可以是false，但是在生产环境下强烈建议为true。 com.sun.management.jmxremote.authenticate, 指定是否需要密码才能够创建JMX连接。  为了演示目的，我们用Tomcat来测试，不开启ssl和authenticate，把JMX端口设置为1100，执行下列命令启动Tomcat：\n1CATALINA_OPTS=\u0026#39;-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=1100 -Dcom.sun.management.jmxremote.rmi.port=1100 -Djava.rmi.server.hostname=k8s-oracle\u0026#39; bin/startup.sh 注意上面有一个-Djava.rmi.server.hostname=k8s-oracle参数，JMX agent本质上也是一个RMI server，因此需要指定这个参数，否则就会像利用VisualVm远程监控Java进程 里提到的一样，VisualVm无法连接到该Java进程。\nPS. 使用SSL方式保护JMX连接的方法会另写文章说明。\n第二步：创建JMX连接 在远程主机上右键，选择添加JMX连接（在下图里出现了之前启动的Tomcat进程）：\n根据Java进程启动时设置的JMX System Properties配置JMX连接：\n成功后你会发现多了一个进程，小图标上有JMX字样：\n双击这个进程，你就能看到CPU、线程、还有MBeans了。\n但是Visual GC没有内容 使用上面的步骤建立完JMX连接之后，你会发现Visual GC没有内容：\n解决办法要启动jstatd。\n按照利用VisualVm远程监控Java进程 的方法先建立远程主机。\n给这个远程主机添加JMX连接：\n然后你会发现多了一个JMX图标的Java进程：\n在这个进程里就能看到Visual GC了。\n参考资料  VisualVm - Connecting to JMX Agents Explicitly  Why Java opens 3 ports when JMX is configured?  JMX - Remote Monitoring and Management  Using JMX Agents  MBeans Tab  ","date":"2018-10-10","img":"","permalink":"/post/visualvm-remote-monitoring-jmx/","series":null,"tags":["java","visualvm","jmx"],"title":"利用VisualVm和JMX远程监控Java进程"},{"categories":null,"content":"本文介绍利用VisualVm 和jstatd 来远程监控Java进程的方法。\n要实现远程监控Java进程，必须在远程主机（运行Java程序的主机）上跑一个jstatd 进程，这个进程相当于一个agent，用来收集远程主机上的JVM运行情况，然后用VisualVm 连接到这个jstatd ，从而实现远程监控的目的。\n第一步：在远程主机上启动jstatd 要注意的是，jstatd 是一个RMI server application，因此在启动时支持java.rmi properties 。\n根据jstatd 文档，我们需要在启动jstatd 时提供一个security policy文件：\n1grant codebase \u0026#34;file:${java.home}/../lib/tools.jar\u0026#34; { 2 permission java.security.AllPermission; 3}; 然后运行下面命令启动：\n1jstatd -J-Djava.security.policy=jstatd.all.policy 不过这里有一个陷阱，见SO上的这个提问：VisualVm connect to remote jstatd not showing applications 。在启动时还得指定rmi server hostname，否则VisualVm无法看到远程主机上的Java进程。所以正确的命令应该是这样：\n1jstatd -J-Djava.security.policy=jstatd.all.policy -J-Djava.rmi.server.hostname=\u0026lt;host or ip\u0026gt; 远程主机的hostname可以随便填，只要VisualVm能够ping通这个hostname就行了。所以说下面这几种情况都是可行的：\n 远程主机没有DNS name，但VisualVm所在主机的/etc/hosts里配置了some-name \u0026lt;ip-to-remote-host\u0026gt;。jstatd启动时指定-J-Djava.rmi.server.hostname=some-name，VisualVm连接some-name。 远程主机经过层层NAT，它的内部ip比如是192.168.xxx.xxx，它的对外的NAT地址是172.100.xxx.xxx。jstatd启动时指定-J-Djava.rmi.server.hostname=172.100.xxx.xxx，VisualVm连接172.100.xxx.xxx。 上面两种方式混合，即在VisualVm所在主机的/etc/hosts里配置some-name \u0026lt;ip-to-remote-host-nat-address\u0026gt;。jstatd启动时指定-J-Djava.rmi.server.hostname=some-name，VisualVm连接some-name。  还有要注意一点，运行jstatd的用户必须和运行Java程序的用户相同，或者是root，否则会监控不到远程主机上的Java进程。\n第二步：启动VisualVm 在你的机器上运行jvisualvm启动VisualVm。按照下面步骤添加远程主机：\n第一步\n第二步\n第三步\n你就能看到远程主机上的Java进程了。\n需要注意的是如果你点开一个远程进程，那么你会发现有些信息是没有的，比如：CPU、线程、和MBeans。这是正常的，如果需要这些信息（就像监控本地Java进程一样），那么就需要用JMX，相关内容会在另一篇文章中讲解。\n参考资料  VisualVm - Working with Remote Applications  jstatd  java.rmi Properties  VisualVm connect to remote jstatd not showing applications  ","date":"2018-10-10","img":"","permalink":"/post/visualvm-remote-monitoring/","series":null,"tags":["java","visualvm"],"title":"利用VisualVm远程监控Java进程"},{"categories":null,"content":"本文介绍了远程Debug Java进程的方法。\n远程debug的意思是启动一个Java进程，启动一个debugger进程，将两者连接起来，利用debugger来debug Java进程。\n事实上目前所有的IDE的debug功能都是通过远程debug方式来实现的，它们都利用了一个叫做JDPA（Java Platform Debugger Architecture）的技术。\n利用JDPA我们除了能够在IDE开发的时候debug，也能够将IDE attach到一个生产环境上正在运行的Java进程做debug（事实上这两个场景在本质上是一样的）。\n下面会用两个例子来说明如何使用Intellij IDEA来debug一个Java进程。\ndebug一个简单的Java应用 我们做了一个很简单的Java应用，它启动后会每隔2秒打印出一个不断增长的数字。\n源代码在Github debug-simple-app ：\n 执行mvn clean package打包 执行java -jar target/debug-simple-app.jar运行  现在我们要用IDEA远程Debug它。我们先ctrl+c把进程停止掉。\n1）把项目导入到IDEA里，因为如果没有源码的话我们没有办法打断点\n2）按照下面步骤新建一个Remote Run/Debug Configuration:\n    选择Remote   除了改个名字，设定Use module classpath，其余的选项不需要修改，直接用默认的就行 这里解释一下各种参数：\nDebugger mode：debugger的模式，有两种：attach和listen。\n attach的意思是debugger连接到被debug的Java进程，是主动式的。 listen的意思是debugger监听由Java进程发送过来的通信，是被动式的。  Host和Port的设定了被debug的Java进程的Host和Port，实际上这也告诉我们，远程Debug是通过网络进行的。\nJDK选项可根据你的不同JDK版本来构造不同的Command line arguments for remote JVM。\nCommand line arguments for remote JVM这个文本框你是不能修改的，它告诉了你如果要这个Java进程能够被远程Debug，那么必须添加这些参数才可以。 所以你要把这里的参数复制出来，后面会用得着。\nUse module classpath，该选项设定使用那个module的源代码来debug。\n  3）把刚才的Command line arguments for remote JVM添加到刚才的运行命令。\n像这样：java -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005 -jar target/debug-simple-app.jar\n4）点击下图里的Debug按钮开始debug\n你会发现Console里出现这么一句话Connected to the target VM, address: 'localhost:5005', transport: 'socket'， 这说明debugger已经attach成功了。\n5）在debug-simple-app里的代码打个断点看看效果。\ndebug一个tomcat应用 实际上debug一个tomcat应用和前面的例子没有什么大的区别。\n我们写了一个很简单的Servlet，它会返回Hello World以及被访问的次数。\n源代码在Github debug-tomcat-app ：\n 执行mvn clean package打包 把target/debug-tomcat-app.war丢到tomcat 然后访问http://localhost:8080/debug-tomcat-app/hello 查看结果  现在我们要用IDEA来debug，那么先把tomcat停掉。\n1）同样需要把项目导入到IDEA里\n2）执行tomcat的bin/catalina.sh jpda start，让tomcat可以被debug\n3）执行jps -v | grep Bootstrap找到Tomcat进程：\n176905 Bootstrap -Djava.util.logging.config.file=... 2-Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager 3-Djdk.tls.ephemeralDHKeySize=2048 4-Djava.protocol.handler.pkgs=org.apache.catalina.webresources 5-agentlib:jdwp=transport=dt_socket,address=localhost:8000,server=y,suspend=n 6-Dcatalina.base=... 7-Dcatalina.home=... 8-Djava.io.tmpdir=... 注意上面的-agentlib...address=localhost:8000参数，记住这个端口\n4）和前面的例子一样，新建一个Remote Run/Debug Configuration，把端口设定为8000，然后启动\n5）然后打个断点试试\n如果你想改变Tomcat的端口怎么做？看看bin/catalina.sh你会发现这么一段注释\n1JPDA_TRANSPORT (Optional) JPDA transport used when the \u0026#34;jpda start\u0026#34; 2 command is executed. The default is \u0026#34;dt_socket\u0026#34;. 3 4JPDA_ADDRESS (Optional) Java runtime options used when the \u0026#34;jpda start\u0026#34; 5 command is executed. The default is localhost:8000. 6 7JPDA_SUSPEND (Optional) Java runtime options used when the \u0026#34;jpda start\u0026#34; 8 command is executed. Specifies whether JVM should suspend 9 execution immediately after startup. Default is \u0026#34;n\u0026#34;. 10 11JPDA_OPTS (Optional) Java runtime options used when the \u0026#34;jpda start\u0026#34; 12 command is executed. If used, JPDA_TRANSPORT, JPDA_ADDRESS, 13 and JPDA_SUSPEND are ignored. Thus, all required jpda 14 options MUST be specified. The default is: 15 16 -agentlib:jdwp=transport=$JPDA_TRANSPORT, 17 address=$JPDA_ADDRESS,server=y,suspend=$JPDA_SUSPEND 所以你只需要提供JPDA_ADDRESS环境变量参数就行了。比如这样：JPDA_ADDRESS=5005 bin/catalina.sh jpda start\n参考文档  Debug your Java code with ease using JPDA  JPDA Connection and Invocation  Oracle VM Invocation Options  ","date":"2018-10-09","img":"","permalink":"/post/java-remote-debug/","series":null,"tags":["java","debug","jdpa"],"title":"远程Debug Java进程的方法"},{"categories":null,"content":"本文推荐了一种Java程序制作Docker Image的方案。\n本文源代码是一个spring-boot应用（在 https://github.com/chanjarster/dockerfile-examples ），不过本例子适用于所有Java应用。\n要求 这里先给出一些Docker Image制作的要求，之后我们再看怎么做。\n 制作过程要融合在项目构建过程中 使用官方Image作为基础Image 设定正确的时区 Container内的程序以非root用户启动 指定Web程序的端口 能够传递JVM参数、Java System Properties、程序自定义的参数  下面具体讲一下具体怎么做到以上几点：\n制作过程要融合在项目构建过程中 这里推荐使用Spotify的dockerfile-maven-plugin ，理由是这个plugin用起来最简单且容易掌握。\n该plugin的本质上是你写一个Dockerfile（关于Dockerfile的具体写法请参照官方文档 ），这个plugin把一些参数传递进去来帮助你构建Docker Image。\n因此只要你会写Dockerfile，就会使用这个plugin，它没有加入任何额外的概念。\n使用官方Image作为基础Image Java的基础镜像应该在openjdk repository 里寻找，而不是在已经过时的java repository 里找。\nopenjdk repository提供了各种各样的image tags看起来眼花缭乱，但是本质上来说就这么几个：\n openjdk:\u0026lt;version\u0026gt; openjdk:\u0026lt;version\u0026gt;-slim openjdk:\u0026lt;version\u0026gt;-alpine  关于\u0026lt;version\u0026gt;一般来说指定大版本号就行了，比如你可以在Dockerfile这样写：\n1FROM openjdk:8-alpine 从尺寸上来讲，alpine最小、slim稍大、默认的最大。所以应该尽可能的使用alpine版本的，如果发现程序的运行环境缺少某些东西，那么尝试用slim版本或者默认版本。就目前的经验来讲：\n 如果需要操作系统字体库，那么就得使用slim版本或者默认版本。需要操作系统字体库的程序例如：图片验证码、PDF导出。 如果需要某些Linux标准的动态/静态连接库，那么在alpine版本不行的情况下，尝试slim版本或默认版本。因为alpine版本是一个及其精简的Linux，它删除了很多东西。  设定正确的时区 几乎所有的Docker Image的时区都是UTC，我们需要给我们自己制作的Docker Image设定时区：\n1ENV TZ=Asia/Shanghai 2RUN set -eux; \\ 3 ln -snf /usr/share/zoneinfo/$TZ /etc/localtime; \\ 4 echo $TZ \u0026gt; /etc/timezone 如果是alpine系列的则要安装tzdata：\n1ENV TZ=Asia/Shanghai 2RUN set -eux; \\ 3 apk add --no-cache --update tzdata; \\ 4 ln -snf /usr/share/zoneinfo/$TZ /etc/localtime; \\ 5 echo $TZ \u0026gt; /etc/timezone 关于数据库时区的相关内容可以见：\n 数据库时区那些事儿 - MySQL的时区处理  数据库时区那些事儿 - Oracle的时区处理   Container内的程序以非root用户启动 在Docker Image内部，我们应该使用非root用户启动程序，这需要新建用户。\n如果你用的是openjdk:\u0026lt;version\u0026gt;-alpine新建用户命令是这样的：\n1RUN set -eux; \\ 2 addgroup --gid 1000 java-app; \\ 3 adduser -S -u 1000 -g java-app -h /home/java-app/ -s /bin/sh -D java-app; 如果你用的是openjdk:\u0026lt;version\u0026gt;-slim或者openjdk:\u0026lt;version\u0026gt;新建用户命令是这样的：\n1RUN set -eux; \\ 2 addgroup --gid 1000 java-app; \\ 3 adduser --system --uid 1000 --gid 1000 --home=/home/java-app/ --shell=/bin/sh --disabled-password java-app; 然后使用Dockerfile USER指令 1USER java-app 2 3# 后面的指令就都是以java-app用户身份执行了 指定Web程序的接口 对于联网应用而言，必须在Dockerfile中指定暴露的端口，否则该端口无法映射。\n1EXPOSE 8080 能够传递JVM参数、Java System Properties、程序自定义的参数 我们需要能够在启动Docker Image的时候将一些参数传递进去：\n JVM参数 Java System Properties 程序启动参数  这里就需要参考Dockerfile best practice 和Docker ENTRYPOINT 了。\n样例项目拆解 目录结构 所有与程序相关的东西都存放在/home/java-app/下：\n1/home/java-app 2 ├── docker-entrypoint.sh 3 ├── lib 4 │ └── java-app.jar 5 ├── etc 6 ├── logs 7 └── tmp  docker-entrypoint.sh，启动脚本 lib，存放JAR包 lib/java-app.jar，程序JAR包 etc，存放配置文件 logs，存放日志文件 tmp，存放临时文件  构建Image的方法 1mvn clean package dockerfile:build 运行 普通启动，然后访问http://localhost:8080：\n1docker run -p 8080:8080 chanjarster/dockerfile-java-examples-1:1.0-SNAPSHOT 设定JVM参数/System Properties，使用JAVA_OPTS环境变量：\n1docker run -p 8080:8080 -e JAVA_OPTS=\u0026#39;-Xmx128M -Xms128M -Dabc=xyz -Ddef=uvw\u0026#39; chanjarster/dockerfile-java-examples-1:1.0-SNAPSHOT 提供程序运行参数，在后面直接添加即可：\n1docker run -p 8080:8080 chanjarster/dockerfile-java-examples-1:1.0-SNAPSHOT --debug 2018-12-27更新 在docker-entrypoint.sh里启动Java进程时，使用exec /usr/bin/java ...这种形式，保证进程PID=1，这样在进程能够在docker stop时收到SIGTERM。 详见：docker stop 参考文档  Dockerfile best practice  Docker ENTRYPOINT  Postgres Dockerfile \u0026amp; script  MySQL Dockerfile \u0026amp; script  Bash set命令教程  ","date":"2018-09-20","img":"","permalink":"/post/java-dockerfile-best-practice/","series":null,"tags":["docker","java"],"title":"Java程序制作Docker Image推荐方案"},{"categories":null,"content":"当JVM时区和数据库时区不一致的时候，会发生什么？这个问题也许你从来没有注意过，但是当把Java程序容器化的时候，问题就浮现出来了，因为目前几乎所有的Docker Image的时区都是UTC。本文探究了Oracle及其JDBC驱动对于时区的处理方式，并尝试给出最佳实践。\n先给总结  DATE和TIMESTAMP类型不支持时区转换。 如果应用和Oracle的时区不一致，那么应该使用TIMESTAMP WITH LOCAL TIME ZONE。  对于JDBC程序来说，JVM时区和用户时区保持一致就行了。   如果应用和Oracle的时区不一致，而且需要保存时区信息，那么应该使用TIMESTAMP WITH TIME ZONE。 格式化日期时间字符串函数TO_CHAR：  对于TIMESTAMP WITH TIME ZONE来说，使用TO_CHAR时要注意让它输出时区信息（TZH:TZM TZR TZD），否则结果会是截断的。 对于TIMESTAMP WITH LOCAL TIME ZONE来说，使用TO_CHAR返回的结果会转换时区。   当前日期时间的函数：  除非必要，不要使用SYSDATE和SYSTIMESTAMP，这个返回的是数据库所在操作系统的时间。 尽量使用CURRENT_TIMESTAMP，它返回的是TIMESTAMP WITH TIME ZONE，能够用来安全的比较时间。    日期时间类型的时区 Oracle Datetime Datatypes 有这么几种：\n DATE ，保存YYYY-MM-DD HH24:MI:SS。 TIMESTAMP ，比DATE多存了fractional seconds（FF）。 TIMESTAMP WITH TIME ZONE ，比TIMESTAMP多了时区偏移量（比如+08:00，TZH:TZM）or 时区区域名称（比如Asia/Shanghai，TZR）和夏令时标记（TZD）。 TIMESTAMP WITH LOCAL TIME ZONE 。和TIMESTAMP类似，不过存储的数据会标准化为数据库的时区，用户获取它的时候会转换成用户时区（对于JDBC来说，就是JVM时区）。  1docker run --name oracle-xe-timezone-test \\ 2 -e ORACLE_ALLOW_REMOTE=true \\ 3 -p 1521:1521 \\ 4 -d wnameless/oracle-xe-11g:16.04 然后用system/oracle用户登录到oracle，执行下列sql建表：\n1createtabletest(2date_fielddate,3ts_fieldtimestamp,4ts_tz_fieldtimestampwithtimezone,5ts_ltz_fieldtimestampwithlocaltimezone6);为了验证这个结论，我写了一段程序来实验，这个程序做了三件事情：\n 使用Asia/Shanghai时区构造一个日期java.util.Date：2018-09-14 10:00:00，然后插入到数据库里。 使用Asia/Shanghai时区把这个值再查出来，看看结果。 使用Asia/Shanghai时区，获得这个字段的格式化字符串（使用DATE_FORMAT()函数）。 使用Europe/Paris时区重复第2-3步的动作。  运行程序获得以下结果：\n1JVM Time Zone : 中国标准时间 2Retrieve java.util.Date from DATE column : 2018-09-14 10:00:00.0 3Retrieve java.util.Date from TIMESTAMP column : 2018-09-14 10:00:00.0 4Retrieve java.util.Date from TIMESTAMP WITH TIME ZONE column : 2018-09-14 10:00:00.0 5Retrieve java.util.Date from TIMESTAMP WITH LOCAL TIME ZONE column : 2018-09-14 10:00:00.0 6Retrieve formatted string from DATE column : 2018-09-14 10:00:00 7Retrieve formatted string from TIMESTAMP column : 2018-09-14 10:00:00 8Retrieve formatted string from TIMESTAMP WITH TIME ZONE column : 2018-09-14 10:00:00 +08:00 ASIA/SHANGHAI CST 9Retrieve formatted string from TIMESTAMP WITH LOCAL TIME ZONE column : 2018-09-14 10:00:00 10-------------------- 11JVM Time Zone : 中欧时间 12Retrieve java.util.Date from DATE column : 2018-09-14 10:00:00.0 13Retrieve java.util.Date from TIMESTAMP column : 2018-09-14 10:00:00.0 14Retrieve java.util.Date from TIMESTAMP WITH TIME ZONE column : 2018-09-14 04:00:00.0 15Retrieve java.util.Date from TIMESTAMP WITH LOCAL TIME ZONE column : 2018-09-14 04:00:00.0 16Retrieve formatted string from DATE column : 2018-09-14 10:00:00 17Retrieve formatted string from TIMESTAMP column : 2018-09-14 10:00:00 18Retrieve formatted string from TIMESTAMP WITH TIME ZONE column : 2018-09-14 10:00:00 +08:00 ASIA/SHANGHAI CST 19Retrieve formatted string from TIMESTAMP WITH LOCAL TIME ZONE column : 2018-09-14 04:00:00 可以看到，DATE和TIMESTAMP是不支持时区转换的，实际上DATE和TIMESTAMP会丢弃掉时区信息。\n对于TIMESTAMP WITH TIME ZONE来说，使用TO_CHAR时要注意让它输出时区信息（TZH:TZM TZR TZD），否则结果会是截断的。\n对于TIMESTAMP WITH LOCAL TIME ZONE来说，使用TO_CHAR返回的结果会转换时区。\n当前日期时间相关函数 Oracle和当前时间有关的函数 有这么几个：\n CURRENT_DATE，返回的是DATE类型 CURRENT_TIMESTAMP，返回的是TIMESTAMP WITH TIME ZONE类型 LOCALTIMESTAMP，返回的是TIMESTAMP类型 SYSDATE，返回的是DATE类型 SYSTIMESTAMP，返回的是TIMESTAMP类型  写了一段程序，输出结果是这样的：\n1=========TEST CURRENT DATE/TIME FUNCTIONS=========== 2JVM Time Zone : 中国标准时间 3Test CURRENT_DATE : 2018-09-18 10:27:23.0 4Test CURRENT_TIMESTAMP : 2018-09-18 10:27:23.880378 Asia/Shanghai 5Test LOCALTIMESTAMP : 2018-09-18 10:27:23.926375 6Test SYSDATE : 2018-09-18 02:27:23.0 7Test SYSTIMESTAMP : 2018-09-18 02:27:23.929605 +0:00 8-------------------- 9JVM Time Zone : 中欧时间 10Test CURRENT_DATE : 2018-09-18 04:27:45.0 11Test CURRENT_TIMESTAMP : 2018-09-18 04:27:45.429024 Europe/Paris 12Test LOCALTIMESTAMP : 2018-09-18 04:27:45.482485 13Test SYSDATE : 2018-09-18 02:27:45.0 14Test SYSTIMESTAMP : 2018-09-18 02:27:45.48582 +0:00 可以发现，CURRENT_DATE、CURRENT_TIMESTAMP、LOCALTIMESTAMP的结果都根据客户端时区做了转换。而SYSDATE和SYSTIMESTAMP返回的则是数据库所在操作系统所在时区的时间。\n在Oracle客户端操作时区 1-- 查询系统时区和session时区 2SELECTDBTIMEZONE,SESSIONTIMEZONEFROMDUAL;34-- 设置session时区 5ALTERSESSIONSETTIME_ZONE=\u0026#39;Asia/Shanghai\u0026#39;;参见Setting the Database Time Zone 和 Setting the Session Time Zone 参考资料  Oracle Datetime Datatypes  Oracle和当前时间有关的函数  Oracle Datetime Comparisons  Setting the Database Time Zone  Setting the Session Time Zone  Oracle JDBC Connection Constant Field Values  W3C- Working with timezone   相关代码 https://github.com/chanjarster/jdbc-timezone ","date":"2018-09-18","img":"","permalink":"/post/oracle-timezone/","series":null,"tags":["JDBC","Oracle","数据库时区那些事儿"],"title":"数据库时区那些事儿 - Oracle的时区处理"},{"categories":null,"content":"当JVM时区和数据库时区不一致的时候，会发生什么？这个问题也许你从来没有注意过，但是当把Java程序容器化的时候，问题就浮现出来了，因为目前几乎所有的Docker Image的时区都是UTC。本文探究了MySQL及其JDBC驱动对于时区的处理方式，并尝试给出最佳实践。\n先给总结  DATE和TIME类型不支持时区转换。 对于TIMESTAMP类型，MySQL会正确的根据connection时区（对于JDBC来说就是JVM时区）/服务端时区做转换。  JDBC程序不需要特别注意什么事情。只要保证JVM时区和用户所在时区保持一致即可。   不要在服务器端做日期时间的字符串格式化（DATE_FORMAT()），因为返回的结果是服务端的时区，而不是connection的时区（对于JDBC来说就是JVM时区）。 CURRENT_TIMESTAMP(), CURRENT_TIME(), CURRENT_DATE()可以安全的使用，返回的结果会转换成connection时区（对于JDBC来说就是JVM时区）。 CURRENT_TIME()有一个不知道是不是BUG的Bug #92453 。  日期时间类型的时区 MySQL - The DATE, DATETIME, and TIMESTAMP Types ：\n MySQL converts TIMESTAMP values from the current time zone to UTC for storage, and back from UTC to the current time zone for retrieval. (This does not occur for other types such as DATETIME.) By default, the current time zone for each connection is the server\u0026rsquo;s time. The time zone can be set on a per-connection basis. As long as the time zone setting remains constant, you get back the same value you store. If you store a TIMESTAMP value, and then change the time zone and retrieve the value, the retrieved value is different from the value you stored. This occurs because the same time zone was not used for conversion in both directions.\n 简而言之就是两句话：\n 查询TIMESTAMP类型所返回的值，会根据connection的时区（对于JDBC来说就是JVM时区）做转换 在MySQL中只有TIMESTAMP类型会做时区转换  为了验证这个结论，我写了一段程序来实验，这个程序做了三件事情：\n 使用Asia/Shanghai时区构造一个日期java.util.Date：2018-09-14 10:00:00，然后插入到数据库里（表：test，列：timestamp类型） 使用Asia/Shanghai时区把这个值再查出来，看看结果。 使用Asia/Shanghai时区，获得这个字段的格式化字符串（使用DATE_FORMAT()函数）。 使用Europe/Paris时区重复第2-3步的动作  在运行程序之前，我们先用Docker启动一个MySQL，它所在的MySQL的时区是UTC（除非特别设定，所有Docker Image时区都默认为UTC）：\n1docker run --name mysql-timezone-test \\ 2 -e MYSQL_RANDOM_ROOT_PASSWORD=yes \\ 3 -e MYSQL_DATABASE=testdb \\ 4 -e MYSQL_USER=tz \\ 5 -e MYSQL_PASSWORD=tz \\ 6 -p 3306:3306 \\ 7 -d mysql:8 下面是结果：\n1Insert data, Time Zone : 中国标准时间 2java.util.Date : 2018-09-14 10:00:00 3Insert into timestamp column : 2018-09-14 10:00:00 4-------------------- 5Retrieve data, Time Zone : 中国标准时间 6Retrieve java.util.Date : 2018-09-14 10:00:00 7Retrieve formatted string : 2018-09-14 02:00:00 8-------------------- 9Retrieve data, Time Zone : 中欧时间 10Retrieve java.util.Date : 2018-09-14 04:00:00 11Retrieve formatted string : 2018-09-14 02:00:00 可以看到Retrieve java.util.Date返回的结果根据JVM时区做了转换的。而Retrieve formatted string返回的结果则是UTC时间。\n当前日期时间相关函数 MySQL与\u0026quot;当前日期时间\u0026quot;相关的函数有这么些，MySQL - Date and Time Functions ：\n The CURRENT_TIMESTAMP(), CURRENT_TIME(), CURRENT_DATE(), and FROM_UNIXTIME() functions return values in the connection\u0026rsquo;s current time zone, which is available as the value of the time_zone system variable.\n 而且根据文档所讲，它们返回的结果匹配当前连接所设定的时区。\n为了验证这个结论，同样写了一段程序，分别使用Asia/Shanghai和Europe/Paris来调用CURRENT_TIMESTAMP()、CURRENT_TIME()、CURRENT_DATE()。\n下面是运行结果：\n1JVM Time Zone : 中国标准时间 2Test CURRENT_DATE() : 2018-09-18 3Test CURRENT_TIME() : 10:55:41 4Test CURRENT_TIMESTAMP() : 2018-09-18 10:55:41.0 5-------------------- 6JVM Time Zone : 中欧时间 7Test CURRENT_DATE() : 2018-09-18 8Test CURRENT_TIME() : 03:56:02 9Test CURRENT_TIMESTAMP() : 2018-09-18 04:56:02.0 可以看到结果是基本符合文档里的说明的，但是要注意，在Europe/Paris时区，CURRENT_TIME()和CURRENT_TIMESTAMP()的时间部分相差一小时。 看上去CURRENT_TIMESTAMP()返回的是UTC DST offset结果，而CURRENT_TIME()返回的是UTC offset结果，关于这个我登记了Bug #92453 。 关于Europe/Paris的DST信息可以在这里找到Wiki - List of tz database time zones 。\n在MySQL客户端操作时区 1-- 查询系统时区和session时区 2SELECT@@global.time_zone,@@session.time_zone;34-- 设置session时区 5SETtime_zone=\u0026#39;Asia/Shanghai\u0026#39;;详见：MySQL Server Time Zone Support Docker启动时设定时区 你可以在docker启动的时候设定MySQL容器的时区，比如这样-e TZ=Asia/Shanghai。\n这个方法有问题，会出现时间错乱，workaround是root用户连接到MySQL，然后执行SET GLOBAL time_zone = 'Asia/Shanghai';。\n这样客户端（非JDBC）连接MySQL时，查询的时间的时区都是Asia/Shanghai了。\n参考资料  MySQL - The DATE, DATETIME, and TIMESTAMP Types  MySQL - Date and Time Functions  MySQL Server Time Zone Support  Wiki - List of tz database time zones  W3C- Working with timezone   相关代码 https://github.com/chanjarster/jdbc-timezone ","date":"2018-09-17","img":"","permalink":"/post/mysql-timezone/","series":null,"tags":["JDBC","MySQL","数据库时区那些事儿"],"title":"数据库时区那些事儿 - MySQL的时区处理"},{"categories":null,"content":"大多数Spring Cloud项目都会使用Spring Cloud Config来管理应用启动时的配置文件，同时开发人员面临着多样化的程序启动方式：操作系统进程启动、docker启动、k8s启动。那么如何规划这些配置文件以适应多种启动方式呢？本文尝试给出一些建议\n先讲几个规则  程序打包时，要将bootstrap.properties和application.properties（或者它们的yaml变种）打到包里。 bootstrap.properties里，要针对可变配置项做环境变量化。 application.properties里，要针对可变配置项做环境变量化。 Spring Cloud应用关于Config Server的配置要放在bootstrap.properties里，并且要做环境变量化。 Config Server所提供的application-*.properties里不得有环境变量。因为既然直接提供配置了，那么就不应该再使用环境变量。  要针对可变配置项做环境变量化 这句话对应The 12-factor App的Config章节 。具体做法是在配置文件里使用placeholder 。下面是两种方式：\n1app.name=${APP_NAME} 2app.description=${APP_DESC:Default description} 第一种方式Spring Boot/Cloud应用在启动时，会根据这个顺序 找APP_NAME的值，如果找不到程序启动会报错。\n第二种方式和第一种方式的不同在于如果找不到，则使用application.properties里定义的默认值。\n而程序在启动时应该通过环境变量的方式将这些值传递进去。\n在真实应用中应该尽量多的使用第二种方式，只有少数的配置才是程序启动时必须提供的，一般来说都是一些数据库连接字符串、用户名密码等信息。\nSpring Cloud应用关于Config Server的配置要放在bootstrap.properties里，并且要做环境变量化 比如这样：\n1spring.cloud.config.enabled=${CONFIG_ENABLED:true} 2spring.cloud.config.profile=${CONFIG_PROFILE:production} 3spring.cloud.config.label=${CONFIG_LABEL:master} 4spring.cloud.config.uri=${CONFIG_SERVER_URL:http://config-server:8080/} 上面这个配置可以控制是否连接config server，因为在开发环境下我们可能并不需要config server。也提供了可以config server启动程序的可能。 同时也控制了如果连接config server，应该使用哪个application.properties。\n需要注意的是，如果我们选择程序启动的时候连接config server，那么在程序启动时提供的环境变量就只能是和config server相关的环境变量（在这个例子里就是上面的CONFIG_*），这些配置用来控制如何获得application.properties。\n因为此时程序所使用的配置都来自于config server，如果config server提供一些，环境变量又提供一些则会造成运维上的混乱。\n各种启动方式 下面讲讲各种启动方式如何传递环境变量。\n以操作系统进程启动 直接以操作系统进程启动的方法是类似于这样的：\n1APP_NAME=my-app APP_DESC=\u0026#34;My App Desc\u0026#34; java -jar spring-cloud-app.jar 用Docker启动 用docker启动则是这样的，参见Docker ENV (environment variables) ：\n1docker run --name my-app -e APP_NAME=my-app -e APP_DESC=\u0026#34;My App Desc\u0026#34; spring-cloud-app:latest 在K8S里启动 定义ConfigMap或Secret（用在密码类配置上），然后在Deployment spec里使用configMapRef或者secretRef或者configMapKeyRef 或者secretKeyRef，比如下面的例子：\n1apiVersion:apps/v12kind:Deployment3metadata:4name:my-app5namespace:\u0026lt;namespace\u0026gt;6spec:7...8template:9...10spec:11containers:12- name:my-app13image:\u0026lt;image repository\u0026gt;14...15envFrom:16- configMapRef:17name:my-app-config18- secretRef:19name:my-app-secret20env:21- name:APP_NAME22valueFrom:23configMapKeyRef:24name:my-app-config25key:APP_NAME26- name:APP_DESC27valueFrom:28secretKeyRef:29name:my-app-secret30key:APP_DESC详见Configure a Pod to Use a ConfigMap 、Secrets 和Load env variables from ConfigMaps and Secrets upon Pod boot 。\n","date":"2018-09-10","img":"","permalink":"/post/spring-cloud-config-best-practice/","series":null,"tags":["微服务","Spring Cloud","k8s"],"title":"Spring Cloud Config配置文件最佳实践"},{"categories":null,"content":"本文探讨了如何创建并落地一个公共服务的方法。\n在单体到微服务架构的迁移过程中，我们经常会问一个问题：在什么情况下我需要从单体中剥离一部分出来将其作为一个微服务？答案有很多，其中有一个答案就是：我发现好多单体都有相似的功能，我觉得可以把它抽出来做一个公共服务。\n那么何为公共服务？公共服务就是那些专门为其他服务提供服务的服务，它的业务具有高度普适性和可复用性。比如用户服务、订单服务就是这样一类服务。\n那我们怎样才能达成这一目标呢？下面举个例子说明：\n我们发现单体A、B、C中的具有高度相似的功能F，经过初步研究发现可以抽取出一个公共服务P，于是马上安排人员开发，然后上线、迁移。 一切似乎会很顺利，但是等等，这里有太多风险和未经验证的东西。那我们应该怎么做？\n第一步：识别不兼容\n我们需要深入到单体A、B、C的功能F的细节中去考察，虽然功能F在各个单体中的看起来差不多，但是细节是魔鬼。 毕竟这三个单体是独立演进的，如果深入细节，就会发现AF、BF、CF总有一些不兼容的地方，具体表现形式可以是数据schema不一致、接口不一致，还有更糟糕的——部分业务逻辑不一致。\n这些不兼容如果一开始不识别出来，那最有可能的结果是开发人员从单体A中抽取功能F开发公共服务P，结果公共服务P只能给单体A使用，单体B、C完全无法使用。\n第二步：设计并导入概念\n识别出了不兼容，那么我们就需要作出一套兼容单体A、B、C的功能F的设计，在设计过程中我们需要和单体A、B、C的产品经理、需求设计人员、开发人员做详尽的沟通。 做这些沟通最主要的目的就是将新的功能F的设计导入到相关人员的脑中，即所谓的概念导入。\n概念导入是非常重要的一步，道理很简单，如果大家对同一件事情的认知是一样的，那么这件事情就好办了，否则在推行过程中很可能出现不可预料的阻力。\n第三步：开发类库\n好了，咱们设计也做了，思想也统一了，为什么不直接开始开发服务P呢？这是因为虽然我们在第二步已经统一了思想，但是在真正落地的时候很可能还会存在意想不到的困难。 因此我们要把这些困难在早期趟平，用的办法就是提供功能F的公共类库，将其替换掉原来单体A、B、C中的代码。\n这一工作完成后我能能够得到的成果有：\n 设计、概念层面形成了统一 表、实体结构形成了统一 接口形成了统一 代码层面的复用  也就是说，我们做到了表里一致，有了这个基础，开发公共服务P才有了真正坚实的基础。\n第四步：微服务架构设计\n公共类库的思路毕竟还是单体应用的思路，只是做到了代码层面的复用。当你要做公共服务P的时候就需要额外考虑一些额外的设计，比如：\n Client的认证模式。不认证、OAuth 2.0，如果用OAuth 2.0那么用哪种Grant type？ 通信协议。http、https、gRPC。 接口协议。RESTful、SOAP。 接口定义。Swagger、OpenAPI。 加密方式。TLS、对称加密。 是否涉及多租户，如果涉及，那么还需要设计多租户的业务、功能、数据schema。 考虑服务注册、服务发现等等。 弹性设计、容错设计、分布式事务等等。 运维相关的日志采集、监控指标等等。  当然以上这些并不是说要一次性全部做到，可以一开始只实现一部分，之后通过迭代不断地完善。\n第五步：迁移\n好了，我们的公共服务P已经上线了，那么如何从公共类库迁移到公共服务P呢？\n其实到这一步就很简单了，在制作公共类库的时候我们应该定义了良好的接口，并且提供了一套基于单体架构的实现。 现在我们只需提供一套基于公共服务的实现然后替换上去就可以了。举个例子，公共类库有一个接口叫做UserRepository，它有一个实现是查询本地数据库的，我们只需提供另一个实现是查询RESTful接口的就可以了。\n当然，这个查询RESTful接口的实现最好也由公共服务P的开发团队提供，这样可以避免单体A、B、C开发团队的重复劳动。\n第六步：没有第六步\n到此为止大功告成。\n","date":"2018-08-23","img":"","permalink":"/post/extract-public-service/","series":null,"tags":["微服务","分布式架构"],"title":"如何抽取公共服务并成功迁移"},{"categories":null,"content":"本文比较了OAuth2.0的几种模式以及基于Session和JWT的认证模式。\n本文主要列举在如今前后端分离、手机App大行其道的现状下，用户认证、授权的几种做法及对比。\nPS. 本文假设你已经理解了各种认证模式的具体细节。\nOAuth2.0的几种模式 OAuth2.0是一个被广泛采用的事实标准，它同时包含认证和授权两种模式，我们来看一下它有几种模式：\n   Grant type Client owner User context? Client type App type     Authorization Code Third-party Y confidential Web app   Authorization Code, without client secret Third-party Y public User-agent app   Authorization Code, without client secret, with PKCE Third-party Y public Native app   OAuth2 Implicit(deprecated) Third-party Y public User-agent app, Native app   Password First-party Y both Web app, User-agent app, Native app   Client Credentials Third-party N confidential Web app    名词定义：\n User: 自然人。 Client: 索要Authorization Code和Access Token的程序。  Client owner:\n First-party: 第一方client，即client开发者/厂商和Resource Server是同一个人/厂商。 Third-party: 第三方client，即client开发者/厂商和Resource Server不是同一个人/厂商。OAuth 2.0主要解决的是第三方client的授权问题。  User context:\n Y: 代表被授权的资源是和当前User相关的。 N: 代表被授权的资源是和Client相关的。  Client type:\n Confidential: 这类Client和Authorization Server/Resource Server的通信是秘密进行的。 Public: 这类Client和Authorization Server/Resource Server的通信是公开进行的。  App type:\n web app: 这类App的代码在服务器上执行，用户通过User-Agent（浏览器）下载App渲染的HTML页面，并与之交互。比如，传统的MVC应用。 user-agent app: 这类App的代码是直接下载到User-Agent（浏览器）里执行的。比如，前后端分离App、SPA。 native app: 这类App安装在用户的设备上，可以认为这类App内部存储的credential信息是有可能被提取的。比如，手机App、桌面App。  仅做认证的模式    Mode Client belong User Context App type     Session First-party Y Web app   SSO First-party Y Web app   JWT First-party Y Web app, User-agent app, Native app    详细说明以上三种模式：\nSession模式: 就是我们传统的Web app所使用的技术，用户输入账号和密码登录系统，服务端返回一个名字叫做SESSIONID的Cookie，之后User-agent和服务端每次交互都会携带这个Cookie，通过这种方式来做到用户登录状态的保持。\nSSO模式: 其实是Session模式的变种，只不过把认证从Session模式的本地认证变成了利用SSO服务器做认证。已知SSO类型有：CAS、SAML。\nJWT模式: 它和Session模式的区别在于:\n 用户会话信息不通过Cookie携带，而是放在Header里，这个信息我们叫做Token。 Token里包含了加密的、不可篡改的当前登录用户的信息，SESSIONID只是一个代号，是没有这个信息的。 服务端可以做到无状态，因为用户信息在Token里已经存在，再也不需要维护Session了。  JWT模式可以使用SSO吗？答案是可以的，但是有条件，在SSO认证流程的最后一步——获取用户信息——的通信必须是confidential的。\n对于Web app来说只要它接入了SSO，获取用户信息的通信本来就是confidential的，它获得用户信息之后构造JWT并返回就可以了。\n对于User-agent app和Native app来说，需要为它做一个中介Web app，这个Web app和SSO通信，然后构造JWT返回给User-agent app。\n参考资料  OAuth 2.0 official site  OAuth 2.0 - Written by Aaron Parecki  JWT official site  SSO的一种 - CAS Protocol  ","date":"2018-08-22","img":"","permalink":"/post/compare-authc-authz-models/","series":null,"tags":["oauth","jwt"],"title":"多种认证、授权模型的比较"},{"categories":null,"content":"github 1987年普林斯顿大学的Hector Garcia-Molina和Kenneth Salem发表了一篇Paper Sagas ，讲述的是如何处理long lived transaction（长活事务）。听起来是不是觉得和分布式事务很像？没错，下面来看看这个来自1987年的解决方案是如何启发当今的分布式事务问题的。\n协议介绍 Saga的组成：\n 每个Saga由一系列sub-transaction Ti 组成 每个Ti 都有对应的补偿动作Ci，补偿动作用于撤销Ti造成的结果  可以看到，和TCC 相比，Saga没有“预留”动作，它的Ti就是直接提交到库。\nSaga的执行顺序有两种：\n T1, T2, T3, \u0026hellip;, Tn T1, T2, \u0026hellip;, Tj, Cj,\u0026hellip;, C2, C1，其中0 \u0026lt; j \u0026lt; n  Saga定义了两种恢复策略：\n backward recovery，向后恢复，即上面提到的第二种执行顺序，其中j是发生错误的sub-transaction，这种做法的效果是撤销掉之前所有成功的sub-transation，使得整个Saga的执行结果撤销。 forward recovery，向前恢复，适用于必须要成功的场景，执行顺序是类似于这样的：T1, T2, \u0026hellip;, Tj(失败), Tj(重试),\u0026hellip;, Tn，其中j是发生错误的sub-transaction。该情况下不需要Ci。  对于ACID的保证 Saga对于ACID的保证和TCC一样：\n A，正常情况下保证。 C，在某个时间点，会出现A库和B库的数据违反一致性要求的情况，但是最终是一致的。 I，在某个时间点，A事务能够读到B事务部分提交的结果。 D，和本地事务一样，只要commit则数据被持久。  和TCC对比 Saga相比TCC的缺点是缺少预留动作，导致补偿动作的实现比较麻烦：Ti就是commit，比如一个业务是发送邮件，在TCC模式下，先保存草稿（Try）再发送（Confirm），撤销的话直接删除草稿（Cancel）就行了。而Saga则就直接发送邮件了（Ti），如果要撤销则得再发送一份邮件说明撤销（Ci），实现起来有一些麻烦。\n如果把上面的发邮件的例子换成：A服务在完成Ti后立即发送Event到ESB（企业服务总线，可以认为是一个消息中间件），下游服务监听到这个Event做自己的一些工作然后再发送Event到ESB，如果A服务执行补偿动作Ci，那么整个补偿动作的层级就很深。\n不过没有预留动作也可以认为是优点：\n 有些业务很简单，套用TCC需要修改原来的业务逻辑，而Saga只需要添加一个补偿动作就行了。 TCC最少通信次数为2n，而Saga为n（n=sub-transaction的数量）。 有些第三方服务没有Try接口，TCC模式实现起来就比较tricky了，而Saga则很简单。 没有预留动作就意味着不必担心资源释放的问题，异常处理起来也更简单（请对比Saga的恢复策略和TCC的异常处理）。  实现Saga的注意事项 对于服务来说，实现Saga有以下这些要求：\n Ti和Ci是幂等的。 Ci必须是能够成功的，如果无法成功则需要人工介入。 Ti - Ci和Ci - Ti的执行结果必须是一样的：sub-transaction被撤销了。  第一点要求Ti和Ci是幂等的，举个例子，假设在执行Ti的时候超时了，此时我们是不知道执行结果的，如果采用forward recovery策略就会再次发送Ti，那么就有可能出现Ti被执行了两次，所以要求Ti幂等。如果采用backward recovery策略就会发送Ci，而如果Ci也超时了，就会尝试再次发送Ci，那么就有可能出现Ci被执行两次，所以要求Ci幂等。\n第二点要求Ci必须能够成功，这个很好理解，因为，如果Ci不能执行成功就意味着整个Saga无法完全撤销，这个是不允许的。但总会出现一些特殊情况比如Ci的代码有bug、服务长时间崩溃等，这个时候就需要人工介入了。\n第三点乍看起来比较奇怪，举例说明，还是考虑Ti执行超时的场景，我们采用了backward recovery，发送一个Ci，那么就会有三种情况：\n Ti的请求丢失了，服务之前没有、之后也不会执行Ti Ti在Ci之前执行 Ci在Ti之前执行  对于第1种情况，容易处理。对于第2、3种情况，则要求Ti和Ci是可交换的（commutative)，并且其最终结果都是sub-transaction被撤销。\n参考资料  Paper - Sagas  Eventual Data Consistency Solution in ServiceComb - part 1  Eventual Data Consistency Solution in ServiceComb - part 2  Eventual Data Consistency Solution in ServiceComb - part 3  Distributed Sagas: A Protocol for Coordinating Microservices  ","date":"2018-03-21","img":"","permalink":"/post/d-transactions/saga/","series":null,"tags":["分布式事务"],"title":"事务 - Saga"},{"categories":null,"content":"github 在前一篇文章中讲到了BASE模式 ，这种模式可以应用在单库or跨库事务的场景下。事实上BASE模式不仅仅局限于数据库层面，还可以应用于分布式系统，这类分布式系统最典型的例子就是电商平台，它们有以下几个特征：\n SOA化/微服务化：单体应用拆分成多个服务。 数据库的各种拆分技术的运用：分表、分库、分区。 大量NoSQL数据库的兴起。 应用之间的通信手段并非直接读数据库：RESTful、RPC、消息中间件等。 大量跨应用事务的出现。  在这种场景下，2PC （及XA）已经无法满足需求，因为它：\n 性能低下，2PC协议是阻塞式的。当协调的数据库越来越多时，性能无法接受。 无法水平扩展以提升性能，只能靠垂直扩展（提升硬件）——更快的CPU、更快更大的硬盘、更大更快的内存——但是这样很贵，并且很容易遇到极限。 染指其他数据库。 依赖于数据库是否支持2PC（XA）。  而BASE只解决最后提交的问题，不能解决诸如在上一篇文章 中最后提到的如何保证刷卡消费不透支的问题.于是就有人提出了TCC模式 （Try、Confirm、Cancel），这一模式在国内因阿里巴巴的推广而广为人知。\n协议介绍 在TCC协议里，参与的主体分为两种：\n 发起方：发起事务的应用。 参与方：执行事务请求，手上握有资源的服务。  并且有三种动作：Try、Confirm、Cancel。\nTCC是Try、Confirm、Cancel的简称，它们分别的职责是：\n Try：负责预留资源（比如新建一条状态=PENDING的订单），同时也做业务检查（比如看看余额是否足够），简单来说就是不能预留已经被占用的资源。 Confirm：负责落地所预留的资源（比如扣费、把订单状态变成COMPLETED） Cancel：负责撤销所预留的资源（比如把订单状态变成CANCELED）  关于预留资源要多说两句，资源都是有限的，因此预留资源都是有时效的，如果当预留资源迟迟得不到Confirm——我们将这种情况称为timeout——参与方会自行将其Cancel（这里有坑，下面会讲）。也就是说参与方对于资源具有自我管理能力，这样可以避免因发起方的问题导致资源被长期占用。\nTCC于BASE相比，增加了业务检查和撤销事务的功能。\n同时，TCC将2PC数据库层面的动作提升到了服务层面，不同的是TCC的所有动作都是一个本地事务，每个本地事务都在动作完成后commit到数据库：\n Try相当于2PC的Commit request phase，外加了业务检查逻辑 Confirm相当于2PC的Commit phase的commit动作 Cancel相当于2PC的Commit phase的rollback动作  流程 以下是TCC的状态图：\n下面是流程步骤（你会发现和2PC很像）：\n 【发起方】发送Try到所有参与方 每个【参与方】执行Try，预留资源 【发起方】收到所有【参与方】的Try结果 【发起方】发送Confirm/Cancel到所有参与房 每个【参与方】执行Confirm/Cancel 【发起方】收到所有【参与方】的Confirm/Cancel结果  异常处理 从【发起方】的角度来看出现异常要怎么处理：\n step 1发生异常，【发起方】可以什么都不做等待【参与方】自行Cancel，也可以直接发起Cancel请求 step 2、3发生异常，意味着【发起方】没有收到【参与方】的响应，这个时候因认定为失败，执行Cancel step 4发生异常，【发起方】重试Confirm/Cancel step 5、6发生异常，意味着【发起方】没有收到【参与方】的响应，这个时候因认定为失败，重试Confirm/Cancel  从【参与方】角度来看看看出现异常怎么处理：\n step 1，意味着【参与方】没有收到请求，什么都不需要做 step 2，意味着【参与方】没有执行成功，什么都不需要做 step 3，意味着【发起方】没有收到结果，什么都不需要做，等待【发起方】重试即可。【参与方】要保证prepare是幂等的。 step 4，等待【发起方】重试，或者等待timeout后自行Cancel。 step 5，等待【发起方】重试即可 step 6，意味着【发起方】没有收到结果，什么都不需要做，等待【发起方】重试即可，【参与方】要保证Confirm/Cancel是幂等的。  观察一下你就会发现TCC和2PC存在一样的问题：\n 若【发起方】/【参与方】因崩溃遗失了信息，则会造成有的【参与方】已Confirm，有的【参与方】则被Cancel了，甚至于依然保持在预留状态。 若【发起方】在step 4发送Confirm，而【参与方】在Cancel（因timeout导致）。  不过TCC在处理这种情况相比2PC具有一些优势，因为TCC是在服务层面的，当出现这种问题的时候可以很容易通过日志、业务数据排查出来，然后人工介入，而2PC完全是数据库底层的。\n对于ACID的保证 TCC对于ACID的保证：\n A，正常情况下保证 C，在某个时间点，会出现A库和B库的数据违反一致性要求的情况，但是最终是一致的 I，在某个时间点，A事务能够读到B事务部分提交的结果 D，和本地事务一样，只要commit则数据被持久  实现TCC时的注意事项 实现TCC需要关注以下几个方面：\n TCC模式在于服务层面而非数据库层面 TCC模式依赖于各服务正确实现Try、Confirm、Cancel和timeout处理机制 TCC模式最少通信次数为2n（n=服务数量） 不是所有业务模型都适合使用TCC，比如发邮件业务根本就不需要预留资源 需要良好地设计服务的日志、人工处理流程/机制，便于异常情况的处理  参考资料  Paper - Rest TCC  Presentation - Transactions for the REST of Us  Article - Transactions for the REST of Us  Article - Atomic Distributed Transactions: a RESTful Design  大规模SOA系统中的分布事务处事_程立  深入解读微服务架构下分布式事务解决方案  分布式事务之说说TCC事务  程立谈大规模SOA系统  ","date":"2018-03-20","img":"","permalink":"/post/d-transactions/tcc/","series":null,"tags":["分布式事务"],"title":"事务 - TCC"},{"categories":null,"content":"github ACID的局限 在本地事务 这篇文章里我们讲到了数据库事务必须保证ACID，在2PC 这篇文章里，我们探讨了跨数据库事务是如何保证ACID的。\n当数据量越来越大的时候，我们会对将大数据库拆分成若干小库，随着数据库数量越来越多，2PC（及XA）就显得有些捉襟见肘了：\n 性能低下，2PC协议是阻塞式的。当协调的数据库越来越多时，性能无法接受。 无法水平扩展以提升性能，只能靠垂直扩展（提升硬件）——更快的CPU、更快更大的硬盘、更大更快的内存——但是这样很贵，并且很容易遇到极限。  CAP理论 CAP理论 是Eric Brewer教授针对分布式数据库所提出的一套理论，他认为在实现分布式数据库，需要考虑3个需求：\n Consistency：当写发生时，每个节点的数据必须都被更新到。当查询发生时，如果还未全部更新到则返回error或timeout；如果全部更新到了，则直接返回结果。 Availability：当查询发生时，不用考虑上一次写是否更新到了每个节点，直接提供当下的数据作为结果。 Partition-tolerance：除非所有节点都挂，它都应该能继续提供服务。  CAP理论指出，当每个节点都工作正常的时候，C、A、P是可以都满足的，当出现节点故障时，我们只能3选2。\n如果我们不想因为数据库的某个节点出现故障就让数据库停止服务，那么我们必定选择P，那么我们就只能在C和A之间做选择。如果选择C：后续的读都将失败。如果选择A：会读到不一致的结果。\nBASE模式 Basically Available, Soft state, Eventually consistent，简称BASE。\nBASE和ACID相反，ACID是悲观的，它要求所有操作都必须保证一致性，而BASE是乐观的，它接受数据库的一致性在不断变化当中。同时，BASE对于CAP中的C做出了一定的妥协——接受临时的不一致，采用最终一致性。最终一致性，听上去怪怪的，一些开发人员觉得这是个坏东西。不过我们真的要时时刻刻保证一致性吗？BASE认为我们可以做一些妥协，因此如果我们按照BASE设计系统的话就能够保证：\n ACID - A，不保证，一旦开始“写”则不可能回滚。 ACID - C，保证最终一致性。 ACID - I，不保证，是因为一个大事务是由多个小事务组成，每个小事务都会独立提交。 ACID - D，保证，因为数据库保证D。 CAP - C，保证最终一致性。 CAP - A，保证基本可用。 CAP - P，保证。  举个例子，现在我们有3条insert要执行（至于是否是3个不同的表、数据库不重要），那么只要保证下面几点就能够满足BASE：\n 最终都能够执行成功 任何一条语句执行失败都会重试 任意一条语句重复执行结果都一样——幂等  正确地使用BASE模式也不是那么容易，比如消费业务，我们要保证“检查余额”和“扣款、记录消费日志”这两组动作不会产生交叉，否则就会因为高并发场景而发生透支，在这个例子里我们可以对“扣款、记录消费日志”做最终一致性，但是如何保证下达“扣款、记录消费日志”这两个指令肯定不会产生透支的情况则不是BASE解决的问题了。\n所以总结一下BASE的特点就是：\n 解决的是提交的问题 2PC将提交动作放在数据库，而BASE将提交动作放在应用程序  关于BASE可以详见这篇文章BASE: An Acid Alternative 。\n参考资料  Wiki - CAP Theorem  Wiki - Eventual Consistency  Article - BASE: An Acid Alternative  Article - Better Explaining CAP Theorem  ","date":"2018-03-19","img":"","permalink":"/post/d-transactions/base/","series":null,"tags":["分布式事务"],"title":"事务 - BASE"},{"categories":null,"content":"github 什么是本地事务（Local Transaction）？本地事务也称为数据库事务或传统事务（相对于分布式事务而言）。它的执行模式就是常见的：\n transaction begin insert/delete/update insert/delete/update \u0026hellip; transaction commit/rollback  本地事务有这么几个特征:\n 一次事务只连接一个支持事务的数据库（一般来说都是关系型数据库） 事务的执行结果保证ACID  会用到数据库锁  ACID 在讨论事务时，我们绕不过一组概念：ACID，我们来看看Wiki是怎么解释ACID的：\nAtomicity 原子性  Atomicity requires that each transaction be \u0026ldquo;all or nothing\u0026rdquo;: if one part of the transaction fails, then the entire transaction fails, and the database state is left unchanged. An atomic system must guarantee atomicity in each and every situation, including power failures, errors and crashes. To the outside world, a committed transaction appears (by its effects on the database) to be indivisible (\u0026ldquo;atomic\u0026rdquo;), and an aborted transaction does not happen.\n 关键词在于：\n all or nothing，它的意思是数据库要么被修改了，要么保持原来的状态。所谓保持原来的状态不是我先insert再delete，而是压根就没有发生过任何操作。因为insert然后再delete实际上还是修改了数据库状态的，至少在数据库日志层面是这样。 indivisible，不可分割，一个事务就是一个最小的无法分割的独立单元，不允许部分成功部分失败。  Consistency 一致性  The consistency property ensures that any transaction will bring the database from one valid state to another. Any data written to the database must be valid according to all defined rules, including constraints, cascades, triggers, and any combination thereof. This does not guarantee correctness of the transaction in all ways the application programmer might have wanted (that is the responsibility of application-level code), but merely that any programming errors cannot result in the violation of any defined rules.\n 一致性要求任何写到数据库的数据都必须满足于预先定义的规则（比如余额不能小于0、外键约束等），简单来说就是在任何时间点都不能出现违反一致性要求的状态。\nIsolation 隔离性  The isolation property ensures that the concurrent execution of transactions results in a system state that would be obtained if transactions were executed sequentially, i.e., one after the other. Providing isolation is the main goal of concurrency control. Depending on the concurrency control method (i.e., if it uses strict - as opposed to relaxed - serializability), the effects of an incomplete transaction might not even be visible to another transaction.\n 隔离性要求如果两个事务修改同一个数据，则必须按顺序执行，并且前一个事务如果未完成，那么未完成的中间状态对另一个事务不可见。\nDurability 持久性  The durability property ensures that once a transaction has been committed, it will remain so, even in the event of power loss, crashes, or errors. In a relational database, for instance, once a group of SQL statements execute, the results need to be stored permanently (even if the database crashes immediately thereafter). To defend against power loss, transactions (or their effects) must be recorded in a non-volatile memory.\n 持久性的关键在于一旦“完成提交”（committed），那么数据就不会丢失。\n数据库锁 在提到隔离性的时候我们提到，在修改同一份数据的情况下，两个事务必须挨个执行以免出现冲突情况。而数据库有四种隔离级别（注意：不是所有数据库支持所有隔离级别）\n   Isolation Level Dirty Reads Non-Repeatable Reads Phantom Reads     Read uncommitted 允许 允许 允许   Read committed 不允许 允许 允许   Repeatable reads 不允许 不允许 允许   Serializable 不允许 不允许 不允许    PS. 大多数数据库的默认隔离级别是Read committed。\n来复习一下Dirty reads、Non-repeatable reads、Phantom reads的概念：\n Dirty reads：A事务可以读到B事务还未提交的数据 Non-repeatable read：A事务读取一行数据，B事务后续修改了这行数据，A事务再次读取这行数据，结果得到的数据不同。 Phantom reads：A事务通过SELECT ... WHERE得到一些行，B事务插入新行或者更新已有的行使得这些行满足A事务的WHERE条件，A事务再次SELECT ... WHERE结果比上一次少了一些或者多了一些行。  大多数数据库在实现以上事务隔离级别（Read uncommitted除外）时采用的机制是锁。这也就是为什么经常说当应用程序里大量使用事务或者高并发情况下会出现性能低下、死锁的问题。\n参考资料  wiki - ACID  wiki - Database Transaction  wiki - Isolation (database systems)  JDK中对于事务的介绍  ","date":"2018-03-16","img":"","permalink":"/post/d-transactions/local-transaction/","series":null,"tags":["分布式事务"],"title":"事务 - 本地事务"}]